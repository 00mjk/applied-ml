{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "tagifai",
      "language": "python",
      "name": "tagifai"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "optimize.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPZmAUydQIC9"
      },
      "source": [
        "<div align=\"center\">\n",
        "<h1><img width=\"30\" src=\"https://madewithml.com/static/images/rounded_logo.png\">&nbsp;<a href=\"https://madewithml.com/\">Made With ML</a></h1>\n",
        "Applied ML Â· MLOps Â· Production\n",
        "<br>\n",
        "Join 20K+ developers in learning how to responsibly <a href=\"https://madewithml.com/about/\">deliver value</a> with applied ML.\n",
        "</div>\n",
        "\n",
        "<br>\n",
        "\n",
        "<div align=\"center\">\n",
        "    <a target=\"_blank\" href=\"https://madewithml.com/subscribe/\"><img src=\"https://img.shields.io/badge/Subscribe-20K-brightgreen\"></a>&nbsp;\n",
        "    <a target=\"_blank\" href=\"https://github.com/GokuMohandas/madewithml\"><img src=\"https://img.shields.io/github/stars/GokuMohandas/madewithml.svg?style=social&label=Star\"></a>&nbsp;\n",
        "    <a target=\"_blank\" href=\"https://www.linkedin.com/in/goku\"><img src=\"https://img.shields.io/badge/style--5eba00.svg?label=LinkedIn&logo=linkedin&style=social\"></a>&nbsp;\n",
        "    <a target=\"_blank\" href=\"https://twitter.com/GokuMohandas\"><img src=\"https://img.shields.io/twitter/follow/GokuMohandas.svg?label=Follow&style=social\"></a>\n",
        "    <p>ðŸ”¥&nbsp; Among the <a href=\"https://github.com/topics/deep-learning\" target=\"_blank\">top ML</a> repositories on GitHub</p>\n",
        "</div>\n",
        "\n",
        "<br>\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7--e8qjzvte"
      },
      "source": [
        "# Optimize (GPU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRyA7luizvtf"
      },
      "source": [
        "Use this notebooks to run hyperparameter optimization on Google Colab and utilize it's free GPUs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HacuZe08zvtf"
      },
      "source": [
        "# In case you update the code after installing\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOAOZ5NJzvtl"
      },
      "source": [
        "## Clone repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dC_KGdE6zvtl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f57bc2e3-356a-409a-bb1f-8d3210e15fa5"
      },
      "source": [
        "# Load repository\n",
        "!git clone https://github.com/GokuMohandas/applied-ml.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'applied-ml'...\n",
            "remote: Enumerating objects: 67, done.\u001b[K\n",
            "remote: Counting objects: 100% (67/67), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 67 (delta 22), reused 57 (delta 16), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (67/67), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiKzsC9kzvtn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4df7835-3b39-4614-e3bf-93556e72b7c2"
      },
      "source": [
        "# Files\n",
        "% cd applied-ml\n",
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/applied-ml\n",
            "config\t  LICENSE   notebooks  requirements.txt  tagifai\n",
            "datasets  Makefile  README.md  setup.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnZVQRcZzvtp"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKp6B4M478m_"
      },
      "source": [
        "# Use latest pip\n",
        "!pip install --upgrade pip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wdx2DRGjzvtq"
      },
      "source": [
        "# Set up\n",
        "!make install-dev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzxXb5mjzvts"
      },
      "source": [
        "## Optimize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4oQwat9Syf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25016f4b-813a-4bb5-a196-fd29a71c5401"
      },
      "source": [
        "from tagifai import main"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PzQcqIuKLkU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d67aa40-f852-4c3f-95ac-019602b69097"
      },
      "source": [
        "# Download data\n",
        "main.download_data()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[01/25/21 18:38:15] INFO     âœ… Data downloaded!                      main.py:46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsPyGrZYIsmA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb4290d8-23ec-46e1-c798-3dcda8ad2d0b"
      },
      "source": [
        "# Check if data downloaded\n",
        "!ls assets/data"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "projects.json  tags.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNGWNx_uSvaU",
        "outputId": "b1d752e3-77b4-4efb-bc42-1c5612087941"
      },
      "source": [
        "# Optimize\n",
        "main.optimize(num_trials=100)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "                               \"hidden_dim\": 336,                               \n",
            "                               \"dropout_p\": 0.6133092831559217,                 \n",
            "                               \"lr\": 0.00017556694564589025,                    \n",
            "                               \"lr_factor\": 0.031775134557186994,               \n",
            "                               \"lr_patience\": 6,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 15,                                  \n",
            "                               \"threshold\": 0.26958951354026794                 \n",
            "                             }                                                  \n",
            "[01/25/21 20:38:34] INFO     Epoch: 1 | train_loss: 0.00552,        train.py:144\n",
            "                             val_loss: 0.00413, lr: 1.76E-04,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 20:38:36] INFO     Epoch: 2 | train_loss: 0.00457,        train.py:144\n",
            "                             val_loss: 0.00373, lr: 1.76E-04,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 20:38:37] INFO     Epoch: 3 | train_loss: 0.00385,        train.py:144\n",
            "                             val_loss: 0.00287, lr: 1.76E-04,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 20:38:39] INFO     Epoch: 4 | train_loss: 0.00325,        train.py:144\n",
            "                             val_loss: 0.00272, lr: 1.76E-04,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 20:38:41] INFO     Epoch: 5 | train_loss: 0.00303,        train.py:144\n",
            "                             val_loss: 0.00271, lr: 1.76E-04,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 20:38:42] INFO     Unpromising trial pruned!              train.py:128\n",
            "[01/25/21 20:38:43] INFO                                            train.py:441\n",
            "                             Trial 34:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 113,                               \n",
            "                               \"embedding_dim\": 226,                            \n",
            "                               \"num_filters\": 390,                              \n",
            "                               \"hidden_dim\": 368,                               \n",
            "                               \"dropout_p\": 0.6857505036812043,                 \n",
            "                               \"lr\": 0.00013499137794432769,                    \n",
            "                               \"lr_factor\": 0.03287283586493298,                \n",
            "                               \"lr_patience\": 5,                                \n",
            "                               \"patience\": 13                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 113,                               \n",
            "                               \"embedding_dim\": 226,                            \n",
            "                               \"num_filters\": 390,                              \n",
            "                               \"hidden_dim\": 368,                               \n",
            "                               \"dropout_p\": 0.6857505036812043,                 \n",
            "                               \"lr\": 0.00013499137794432769,                    \n",
            "                               \"lr_factor\": 0.03287283586493298,                \n",
            "                               \"lr_patience\": 5,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 13,                                  \n",
            "                               \"threshold\": 0.26958951354026794                 \n",
            "                             }                                                  \n",
            "[01/25/21 20:38:45] INFO     Epoch: 1 | train_loss: 0.00566,        train.py:144\n",
            "                             val_loss: 0.00400, lr: 1.35E-04,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 20:38:47] INFO     Epoch: 2 | train_loss: 0.00455,        train.py:144\n",
            "                             val_loss: 0.00368, lr: 1.35E-04,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 20:38:49] INFO     Epoch: 3 | train_loss: 0.00401,        train.py:144\n",
            "                             val_loss: 0.00284, lr: 1.35E-04,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 20:38:51] INFO     Epoch: 4 | train_loss: 0.00346,        train.py:144\n",
            "                             val_loss: 0.00272, lr: 1.35E-04,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 20:38:53] INFO     Epoch: 5 | train_loss: 0.00321,        train.py:144\n",
            "                             val_loss: 0.00269, lr: 1.35E-04,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 20:38:55] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 35:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 102,                               \n",
            "                               \"embedding_dim\": 241,                            \n",
            "                               \"num_filters\": 307,                              \n",
            "                               \"hidden_dim\": 501,                               \n",
            "                               \"dropout_p\": 0.5964538324945108,                 \n",
            "                               \"lr\": 7.283550177966968e-05,                     \n",
            "                               \"lr_factor\": 0.04529862051133046,                \n",
            "                               \"lr_patience\": 6,                                \n",
            "                               \"patience\": 12                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 102,                               \n",
            "                               \"embedding_dim\": 241,                            \n",
            "                               \"num_filters\": 307,                              \n",
            "                               \"hidden_dim\": 501,                               \n",
            "                               \"dropout_p\": 0.5964538324945108,                 \n",
            "                               \"lr\": 7.283550177966968e-05,                     \n",
            "                               \"lr_factor\": 0.04529862051133046,                \n",
            "                               \"lr_patience\": 6,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 12,                                  \n",
            "                               \"threshold\": 0.26958951354026794                 \n",
            "                             }                                                  \n",
            "[01/25/21 20:38:57] INFO     Epoch: 1 | train_loss: 0.00583,        train.py:144\n",
            "                             val_loss: 0.00371, lr: 7.28E-05,                   \n",
            "                             _patience: 12                                      \n",
            "[01/25/21 20:38:58] INFO     Epoch: 2 | train_loss: 0.00361,        train.py:144\n",
            "                             val_loss: 0.00428, lr: 7.28E-05,                   \n",
            "                             _patience: 11                                      \n",
            "[01/25/21 20:39:00] INFO     Epoch: 3 | train_loss: 0.00355,        train.py:144\n",
            "                             val_loss: 0.00373, lr: 7.28E-05,                   \n",
            "                             _patience: 10                                      \n",
            "[01/25/21 20:39:02] INFO     Epoch: 4 | train_loss: 0.00323,        train.py:144\n",
            "                             val_loss: 0.00331, lr: 7.28E-05,                   \n",
            "                             _patience: 12                                      \n",
            "[01/25/21 20:39:03] INFO     Epoch: 5 | train_loss: 0.00309,        train.py:144\n",
            "                             val_loss: 0.00322, lr: 7.28E-05,                   \n",
            "                             _patience: 12                                      \n",
            "[01/25/21 20:39:05] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 36:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 119,                               \n",
            "                               \"embedding_dim\": 235,                            \n",
            "                               \"num_filters\": 416,                              \n",
            "                               \"hidden_dim\": 431,                               \n",
            "                               \"dropout_p\": 0.5624825326508619,                 \n",
            "                               \"lr\": 0.0005806014471495106,                     \n",
            "                               \"lr_factor\": 0.03517986208981054,                \n",
            "                               \"lr_patience\": 6,                                \n",
            "                               \"patience\": 17                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 119,                               \n",
            "                               \"embedding_dim\": 235,                            \n",
            "                               \"num_filters\": 416,                              \n",
            "                               \"hidden_dim\": 431,                               \n",
            "                               \"dropout_p\": 0.5624825326508619,                 \n",
            "                               \"lr\": 0.0005806014471495106,                     \n",
            "                               \"lr_factor\": 0.03517986208981054,                \n",
            "                               \"lr_patience\": 6,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 17,                                  \n",
            "                               \"threshold\": 0.26958951354026794                 \n",
            "                             }                                                  \n",
            "[01/25/21 20:39:07] INFO     Epoch: 1 | train_loss: 0.00818,        train.py:144\n",
            "                             val_loss: 0.00565, lr: 5.81E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:39:09] INFO     Epoch: 2 | train_loss: 0.00521,        train.py:144\n",
            "                             val_loss: 0.00302, lr: 5.81E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:39:11] INFO     Epoch: 3 | train_loss: 0.00334,        train.py:144\n",
            "                             val_loss: 0.00283, lr: 5.81E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:39:13] INFO     Epoch: 4 | train_loss: 0.00299,        train.py:144\n",
            "                             val_loss: 0.00266, lr: 5.81E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:39:15] INFO     Epoch: 5 | train_loss: 0.00257,        train.py:144\n",
            "                             val_loss: 0.00245, lr: 5.81E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:39:17] INFO     Epoch: 6 | train_loss: 0.00222,        train.py:144\n",
            "                             val_loss: 0.00223, lr: 5.81E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:39:19] INFO     Epoch: 7 | train_loss: 0.00191,        train.py:144\n",
            "                             val_loss: 0.00207, lr: 5.81E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:39:21] INFO     Epoch: 8 | train_loss: 0.00170,        train.py:144\n",
            "                             val_loss: 0.00198, lr: 5.81E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:39:23] INFO     Epoch: 9 | train_loss: 0.00152,        train.py:144\n",
            "                             val_loss: 0.00191, lr: 5.81E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:39:25] INFO     Epoch: 10 | train_loss: 0.00133,       train.py:144\n",
            "                             val_loss: 0.00183, lr: 5.81E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:39:27] INFO     Epoch: 11 | train_loss: 0.00114,       train.py:144\n",
            "                             val_loss: 0.00182, lr: 5.81E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:39:28] INFO     Epoch: 12 | train_loss: 0.00102,       train.py:144\n",
            "                             val_loss: 0.00177, lr: 5.81E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:39:30] INFO     Epoch: 13 | train_loss: 0.00090,       train.py:144\n",
            "                             val_loss: 0.00174, lr: 5.81E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:39:32] INFO     Epoch: 14 | train_loss: 0.00079,       train.py:144\n",
            "                             val_loss: 0.00171, lr: 5.81E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:39:34] INFO     Epoch: 15 | train_loss: 0.00067,       train.py:144\n",
            "                             val_loss: 0.00167, lr: 5.81E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:39:36] INFO     Epoch: 16 | train_loss: 0.00060,       train.py:144\n",
            "                             val_loss: 0.00168, lr: 5.81E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:39:38] INFO     Epoch: 17 | train_loss: 0.00053,       train.py:144\n",
            "                             val_loss: 0.00175, lr: 5.81E-04,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 20:39:40] INFO     Epoch: 18 | train_loss: 0.00048,       train.py:144\n",
            "                             val_loss: 0.00186, lr: 5.81E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 20:39:42] INFO     Epoch: 19 | train_loss: 0.00044,       train.py:144\n",
            "                             val_loss: 0.00209, lr: 5.81E-04,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 20:39:44] INFO     Epoch: 20 | train_loss: 0.00039,       train.py:144\n",
            "                             val_loss: 0.00241, lr: 5.81E-04,                   \n",
            "                             _patience: 12                                      \n",
            "[01/25/21 20:39:46] INFO     Epoch: 21 | train_loss: 0.00041,       train.py:144\n",
            "                             val_loss: 0.00237, lr: 5.81E-04,                   \n",
            "                             _patience: 11                                      \n",
            "[01/25/21 20:39:48] INFO     Epoch: 22 | train_loss: 0.00038,       train.py:144\n",
            "                             val_loss: 0.00220, lr: 2.04E-05,                   \n",
            "                             _patience: 10                                      \n",
            "[01/25/21 20:39:50] INFO     Epoch: 23 | train_loss: 0.00035,       train.py:144\n",
            "                             val_loss: 0.00213, lr: 2.04E-05,                   \n",
            "                             _patience: 9                                       \n",
            "[01/25/21 20:39:52] INFO     Epoch: 24 | train_loss: 0.00031,       train.py:144\n",
            "                             val_loss: 0.00197, lr: 2.04E-05,                   \n",
            "                             _patience: 8                                       \n",
            "[01/25/21 20:39:54] INFO     Epoch: 25 | train_loss: 0.00027,       train.py:144\n",
            "                             val_loss: 0.00189, lr: 2.04E-05,                   \n",
            "                             _patience: 7                                       \n",
            "[01/25/21 20:39:56] INFO     Epoch: 26 | train_loss: 0.00027,       train.py:144\n",
            "                             val_loss: 0.00188, lr: 2.04E-05,                   \n",
            "                             _patience: 6                                       \n",
            "[01/25/21 20:39:58] INFO     Epoch: 27 | train_loss: 0.00025,       train.py:144\n",
            "                             val_loss: 0.00190, lr: 2.04E-05,                   \n",
            "                             _patience: 5                                       \n",
            "[01/25/21 20:40:00] INFO     Epoch: 28 | train_loss: 0.00025,       train.py:144\n",
            "                             val_loss: 0.00193, lr: 2.04E-05,                   \n",
            "                             _patience: 4                                       \n",
            "[01/25/21 20:40:02] INFO     Epoch: 29 | train_loss: 0.00025,       train.py:144\n",
            "                             val_loss: 0.00194, lr: 7.19E-07,                   \n",
            "                             _patience: 3                                       \n",
            "[01/25/21 20:40:04] INFO     Epoch: 30 | train_loss: 0.00024,       train.py:144\n",
            "                             val_loss: 0.00194, lr: 7.19E-07,                   \n",
            "                             _patience: 2                                       \n",
            "[01/25/21 20:40:06] INFO     Epoch: 31 | train_loss: 0.00025,       train.py:144\n",
            "                             val_loss: 0.00194, lr: 7.19E-07,                   \n",
            "                             _patience: 1                                       \n",
            "[01/25/21 20:40:08] INFO     Stopping early!                        train.py:139\n",
            "[01/25/21 20:40:15] INFO                                            train.py:441\n",
            "                             Trial 37:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 115,                               \n",
            "                               \"embedding_dim\": 219,                            \n",
            "                               \"num_filters\": 425,                              \n",
            "                               \"hidden_dim\": 378,                               \n",
            "                               \"dropout_p\": 0.7304726698191171,                 \n",
            "                               \"lr\": 9.313380544122724e-05,                     \n",
            "                               \"lr_factor\": 0.049900399486446485,               \n",
            "                               \"lr_patience\": 5,                                \n",
            "                               \"patience\": 16                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 115,                               \n",
            "                               \"embedding_dim\": 219,                            \n",
            "                               \"num_filters\": 425,                              \n",
            "                               \"hidden_dim\": 378,                               \n",
            "                               \"dropout_p\": 0.7304726698191171,                 \n",
            "                               \"lr\": 9.313380544122724e-05,                     \n",
            "                               \"lr_factor\": 0.049900399486446485,               \n",
            "                               \"lr_patience\": 5,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 16,                                  \n",
            "                               \"threshold\": 0.3250288665294647                  \n",
            "                             }                                                  \n",
            "[01/25/21 20:40:17] INFO     Epoch: 1 | train_loss: 0.00626,        train.py:144\n",
            "                             val_loss: 0.00339, lr: 9.31E-05,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:40:19] INFO     Epoch: 2 | train_loss: 0.00460,        train.py:144\n",
            "                             val_loss: 0.00370, lr: 9.31E-05,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 20:40:21] INFO     Epoch: 3 | train_loss: 0.00430,        train.py:144\n",
            "                             val_loss: 0.00311, lr: 9.31E-05,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:40:23] INFO     Epoch: 4 | train_loss: 0.00378,        train.py:144\n",
            "                             val_loss: 0.00278, lr: 9.31E-05,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:40:25] INFO     Epoch: 5 | train_loss: 0.00356,        train.py:144\n",
            "                             val_loss: 0.00273, lr: 9.31E-05,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:40:27] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 38:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 110,                               \n",
            "                               \"embedding_dim\": 231,                            \n",
            "                               \"num_filters\": 324,                              \n",
            "                               \"hidden_dim\": 348,                               \n",
            "                               \"dropout_p\": 0.5463256979989564,                 \n",
            "                               \"lr\": 0.0003663664468014829,                     \n",
            "                               \"lr_factor\": 0.014003644065507161,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"patience\": 20                                   \n",
            "                             }                                                  \n",
            "[01/25/21 20:40:28] INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 110,                               \n",
            "                               \"embedding_dim\": 231,                            \n",
            "                               \"num_filters\": 324,                              \n",
            "                               \"hidden_dim\": 348,                               \n",
            "                               \"dropout_p\": 0.5463256979989564,                 \n",
            "                               \"lr\": 0.0003663664468014829,                     \n",
            "                               \"lr_factor\": 0.014003644065507161,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 20,                                  \n",
            "                               \"threshold\": 0.3250288665294647                  \n",
            "                             }                                                  \n",
            "[01/25/21 20:40:29] INFO     Epoch: 1 | train_loss: 0.00574,        train.py:144\n",
            "                             val_loss: 0.00472, lr: 3.66E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:40:31] INFO     Epoch: 2 | train_loss: 0.00420,        train.py:144\n",
            "                             val_loss: 0.00283, lr: 3.66E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:40:33] INFO     Epoch: 3 | train_loss: 0.00328,        train.py:144\n",
            "                             val_loss: 0.00268, lr: 3.66E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:40:34] INFO     Epoch: 4 | train_loss: 0.00281,        train.py:144\n",
            "                             val_loss: 0.00258, lr: 3.66E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:40:36] INFO     Epoch: 5 | train_loss: 0.00250,        train.py:144\n",
            "                             val_loss: 0.00238, lr: 3.66E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:40:37] INFO     Epoch: 6 | train_loss: 0.00221,        train.py:144\n",
            "                             val_loss: 0.00223, lr: 3.66E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:40:39] INFO     Epoch: 7 | train_loss: 0.00201,        train.py:144\n",
            "                             val_loss: 0.00207, lr: 3.66E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:40:41] INFO     Epoch: 8 | train_loss: 0.00176,        train.py:144\n",
            "                             val_loss: 0.00199, lr: 3.66E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:40:42] INFO     Epoch: 9 | train_loss: 0.00156,        train.py:144\n",
            "                             val_loss: 0.00186, lr: 3.66E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:40:44] INFO     Epoch: 10 | train_loss: 0.00144,       train.py:144\n",
            "                             val_loss: 0.00180, lr: 3.66E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:40:45] INFO     Epoch: 11 | train_loss: 0.00132,       train.py:144\n",
            "                             val_loss: 0.00180, lr: 3.66E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:40:47] INFO     Epoch: 12 | train_loss: 0.00117,       train.py:144\n",
            "                             val_loss: 0.00173, lr: 3.66E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:40:49] INFO     Epoch: 13 | train_loss: 0.00106,       train.py:144\n",
            "                             val_loss: 0.00172, lr: 3.66E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:40:50] INFO     Epoch: 14 | train_loss: 0.00097,       train.py:144\n",
            "                             val_loss: 0.00170, lr: 3.66E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:40:52] INFO     Epoch: 15 | train_loss: 0.00087,       train.py:144\n",
            "                             val_loss: 0.00168, lr: 3.66E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:40:53] INFO     Epoch: 16 | train_loss: 0.00078,       train.py:144\n",
            "                             val_loss: 0.00165, lr: 3.66E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:40:55] INFO     Epoch: 17 | train_loss: 0.00071,       train.py:144\n",
            "                             val_loss: 0.00164, lr: 3.66E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:40:57] INFO     Epoch: 18 | train_loss: 0.00065,       train.py:144\n",
            "                             val_loss: 0.00166, lr: 3.66E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:40:58] INFO     Epoch: 19 | train_loss: 0.00058,       train.py:144\n",
            "                             val_loss: 0.00165, lr: 3.66E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:41:00] INFO     Epoch: 20 | train_loss: 0.00053,       train.py:144\n",
            "                             val_loss: 0.00167, lr: 3.66E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:41:01] INFO     Epoch: 21 | train_loss: 0.00049,       train.py:144\n",
            "                             val_loss: 0.00169, lr: 3.66E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:41:03] INFO     Epoch: 22 | train_loss: 0.00047,       train.py:144\n",
            "                             val_loss: 0.00170, lr: 3.66E-04,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 20:41:05] INFO     Epoch: 23 | train_loss: 0.00043,       train.py:144\n",
            "                             val_loss: 0.00167, lr: 3.66E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 20:41:06] INFO     Epoch: 24 | train_loss: 0.00040,       train.py:144\n",
            "                             val_loss: 0.00165, lr: 3.66E-04,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 20:41:08] INFO     Epoch: 25 | train_loss: 0.00037,       train.py:144\n",
            "                             val_loss: 0.00171, lr: 5.13E-06,                   \n",
            "                             _patience: 12                                      \n",
            "[01/25/21 20:41:09] INFO     Epoch: 26 | train_loss: 0.00037,       train.py:144\n",
            "                             val_loss: 0.00173, lr: 5.13E-06,                   \n",
            "                             _patience: 11                                      \n",
            "[01/25/21 20:41:11] INFO     Epoch: 27 | train_loss: 0.00034,       train.py:144\n",
            "                             val_loss: 0.00178, lr: 5.13E-06,                   \n",
            "                             _patience: 10                                      \n",
            "[01/25/21 20:41:13] INFO     Epoch: 28 | train_loss: 0.00030,       train.py:144\n",
            "                             val_loss: 0.00182, lr: 5.13E-06,                   \n",
            "                             _patience: 9                                       \n",
            "[01/25/21 20:41:14] INFO     Epoch: 29 | train_loss: 0.00029,       train.py:144\n",
            "                             val_loss: 0.00185, lr: 5.13E-06,                   \n",
            "                             _patience: 8                                       \n",
            "[01/25/21 20:41:16] INFO     Epoch: 30 | train_loss: 0.00031,       train.py:144\n",
            "                             val_loss: 0.00185, lr: 5.13E-06,                   \n",
            "                             _patience: 7                                       \n",
            "[01/25/21 20:41:17] INFO     Epoch: 31 | train_loss: 0.00030,       train.py:144\n",
            "                             val_loss: 0.00183, lr: 5.13E-06,                   \n",
            "                             _patience: 6                                       \n",
            "[01/25/21 20:41:19] INFO     Epoch: 32 | train_loss: 0.00029,       train.py:144\n",
            "                             val_loss: 0.00182, lr: 5.13E-06,                   \n",
            "                             _patience: 5                                       \n",
            "[01/25/21 20:41:21] INFO     Epoch: 33 | train_loss: 0.00029,       train.py:144\n",
            "                             val_loss: 0.00182, lr: 7.18E-08,                   \n",
            "                             _patience: 4                                       \n",
            "[01/25/21 20:41:22] INFO     Epoch: 34 | train_loss: 0.00029,       train.py:144\n",
            "                             val_loss: 0.00182, lr: 7.18E-08,                   \n",
            "                             _patience: 3                                       \n",
            "[01/25/21 20:41:24] INFO     Epoch: 35 | train_loss: 0.00030,       train.py:144\n",
            "                             val_loss: 0.00182, lr: 7.18E-08,                   \n",
            "                             _patience: 2                                       \n",
            "[01/25/21 20:41:25] INFO     Epoch: 36 | train_loss: 0.00029,       train.py:144\n",
            "                             val_loss: 0.00182, lr: 7.18E-08,                   \n",
            "                             _patience: 1                                       \n",
            "[01/25/21 20:41:27] INFO     Stopping early!                        train.py:139\n",
            "[01/25/21 20:41:32] INFO                                            train.py:441\n",
            "                             Trial 39:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 124,                               \n",
            "                               \"embedding_dim\": 204,                            \n",
            "                               \"num_filters\": 449,                              \n",
            "                               \"hidden_dim\": 325,                               \n",
            "                               \"dropout_p\": 0.6539484597231097,                 \n",
            "                               \"lr\": 0.0006003791276774,                        \n",
            "                               \"lr_factor\": 0.011146071624594175,               \n",
            "                               \"lr_patience\": 10,                               \n",
            "                               \"patience\": 18                                   \n",
            "                             }                                                  \n",
            "[01/25/21 20:41:33] INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 124,                               \n",
            "                               \"embedding_dim\": 204,                            \n",
            "                               \"num_filters\": 449,                              \n",
            "                               \"hidden_dim\": 325,                               \n",
            "                               \"dropout_p\": 0.6539484597231097,                 \n",
            "                               \"lr\": 0.0006003791276774,                        \n",
            "                               \"lr_factor\": 0.011146071624594175,               \n",
            "                               \"lr_patience\": 10,                               \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 18,                                  \n",
            "                               \"threshold\": 0.26229074597358704                 \n",
            "                             }                                                  \n",
            "[01/25/21 20:41:35] INFO     Epoch: 1 | train_loss: 0.00904,        train.py:144\n",
            "                             val_loss: 0.00713, lr: 6.00E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:41:37] INFO     Epoch: 2 | train_loss: 0.00592,        train.py:144\n",
            "                             val_loss: 0.00309, lr: 6.00E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:41:39] INFO     Epoch: 3 | train_loss: 0.00368,        train.py:144\n",
            "                             val_loss: 0.00288, lr: 6.00E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:41:41] INFO     Epoch: 4 | train_loss: 0.00309,        train.py:144\n",
            "                             val_loss: 0.00290, lr: 6.00E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:41:43] INFO     Epoch: 5 | train_loss: 0.00278,        train.py:144\n",
            "                             val_loss: 0.00261, lr: 6.00E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:41:45] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 40:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 107,                               \n",
            "                               \"embedding_dim\": 210,                            \n",
            "                               \"num_filters\": 367,                              \n",
            "                               \"hidden_dim\": 395,                               \n",
            "                               \"dropout_p\": 0.7799876195760792,                 \n",
            "                               \"lr\": 0.0001769815284260679,                     \n",
            "                               \"lr_factor\": 0.038838107103229665,               \n",
            "                               \"lr_patience\": 6,                                \n",
            "                               \"patience\": 14                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 107,                               \n",
            "                               \"embedding_dim\": 210,                            \n",
            "                               \"num_filters\": 367,                              \n",
            "                               \"hidden_dim\": 395,                               \n",
            "                               \"dropout_p\": 0.7799876195760792,                 \n",
            "                               \"lr\": 0.0001769815284260679,                     \n",
            "                               \"lr_factor\": 0.038838107103229665,               \n",
            "                               \"lr_patience\": 6,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 14,                                  \n",
            "                               \"threshold\": 0.26229074597358704                 \n",
            "                             }                                                  \n",
            "[01/25/21 20:41:47] INFO     Epoch: 1 | train_loss: 0.00635,        train.py:144\n",
            "                             val_loss: 0.00410, lr: 1.77E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 20:41:48] INFO     Epoch: 2 | train_loss: 0.00503,        train.py:144\n",
            "                             val_loss: 0.00329, lr: 1.77E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 20:41:50] INFO     Epoch: 3 | train_loss: 0.00409,        train.py:144\n",
            "                             val_loss: 0.00275, lr: 1.77E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 20:41:52] INFO     Epoch: 4 | train_loss: 0.00354,        train.py:144\n",
            "                             val_loss: 0.00271, lr: 1.77E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 20:41:54] INFO     Epoch: 5 | train_loss: 0.00335,        train.py:144\n",
            "                             val_loss: 0.00267, lr: 1.77E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 20:41:56] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 41:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 122,                               \n",
            "                               \"embedding_dim\": 292,                            \n",
            "                               \"num_filters\": 343,                              \n",
            "                               \"hidden_dim\": 314,                               \n",
            "                               \"dropout_p\": 0.6808167472380822,                 \n",
            "                               \"lr\": 0.00044896836356169524,                    \n",
            "                               \"lr_factor\": 0.012058133943765932,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"patience\": 19                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 122,                               \n",
            "                               \"embedding_dim\": 292,                            \n",
            "                               \"num_filters\": 343,                              \n",
            "                               \"hidden_dim\": 314,                               \n",
            "                               \"dropout_p\": 0.6808167472380822,                 \n",
            "                               \"lr\": 0.00044896836356169524,                    \n",
            "                               \"lr_factor\": 0.012058133943765932,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 19,                                  \n",
            "                               \"threshold\": 0.26229074597358704                 \n",
            "                             }                                                  \n",
            "[01/25/21 20:41:58] INFO     Epoch: 1 | train_loss: 0.00714,        train.py:144\n",
            "                             val_loss: 0.00557, lr: 4.49E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:42:00] INFO     Epoch: 2 | train_loss: 0.00506,        train.py:144\n",
            "                             val_loss: 0.00283, lr: 4.49E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:42:02] INFO     Epoch: 3 | train_loss: 0.00356,        train.py:144\n",
            "                             val_loss: 0.00273, lr: 4.49E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:42:04] INFO     Epoch: 4 | train_loss: 0.00315,        train.py:144\n",
            "                             val_loss: 0.00262, lr: 4.49E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:42:06] INFO     Epoch: 5 | train_loss: 0.00276,        train.py:144\n",
            "                             val_loss: 0.00244, lr: 4.49E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:42:08] INFO     Epoch: 6 | train_loss: 0.00246,        train.py:144\n",
            "                             val_loss: 0.00229, lr: 4.49E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:42:10] INFO     Epoch: 7 | train_loss: 0.00223,        train.py:144\n",
            "                             val_loss: 0.00215, lr: 4.49E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:42:12] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 42:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 128,                               \n",
            "                               \"embedding_dim\": 289,                            \n",
            "                               \"num_filters\": 351,                              \n",
            "                               \"hidden_dim\": 271,                               \n",
            "                               \"dropout_p\": 0.6942596944979362,                 \n",
            "                               \"lr\": 0.0005070897555671661,                     \n",
            "                               \"lr_factor\": 0.01080370900246109,                \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"patience\": 20                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 128,                               \n",
            "                               \"embedding_dim\": 289,                            \n",
            "                               \"num_filters\": 351,                              \n",
            "                               \"hidden_dim\": 271,                               \n",
            "                               \"dropout_p\": 0.6942596944979362,                 \n",
            "                               \"lr\": 0.0005070897555671661,                     \n",
            "                               \"lr_factor\": 0.01080370900246109,                \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 20,                                  \n",
            "                               \"threshold\": 0.26229074597358704                 \n",
            "                             }                                                  \n",
            "[01/25/21 20:42:14] INFO     Epoch: 1 | train_loss: 0.00799,        train.py:144\n",
            "                             val_loss: 0.00613, lr: 5.07E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:42:16] INFO     Epoch: 2 | train_loss: 0.00580,        train.py:144\n",
            "                             val_loss: 0.00306, lr: 5.07E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:42:18] INFO     Epoch: 3 | train_loss: 0.00374,        train.py:144\n",
            "                             val_loss: 0.00279, lr: 5.07E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:42:20] INFO     Epoch: 4 | train_loss: 0.00323,        train.py:144\n",
            "                             val_loss: 0.00274, lr: 5.07E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:42:22] INFO     Epoch: 5 | train_loss: 0.00291,        train.py:144\n",
            "                             val_loss: 0.00250, lr: 5.07E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:42:24] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 43:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 120,                               \n",
            "                               \"embedding_dim\": 284,                            \n",
            "                               \"num_filters\": 306,                              \n",
            "                               \"hidden_dim\": 288,                               \n",
            "                               \"dropout_p\": 0.6662476843009308,                 \n",
            "                               \"lr\": 0.0003308656279970437,                     \n",
            "                               \"lr_factor\": 0.013071685275127117,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"patience\": 19                                   \n",
            "                             }                                                  \n",
            "[01/25/21 20:42:25] INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 120,                               \n",
            "                               \"embedding_dim\": 284,                            \n",
            "                               \"num_filters\": 306,                              \n",
            "                               \"hidden_dim\": 288,                               \n",
            "                               \"dropout_p\": 0.6662476843009308,                 \n",
            "                               \"lr\": 0.0003308656279970437,                     \n",
            "                               \"lr_factor\": 0.013071685275127117,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 19,                                  \n",
            "                               \"threshold\": 0.26229074597358704                 \n",
            "                             }                                                  \n",
            "[01/25/21 20:42:26] INFO     Epoch: 1 | train_loss: 0.00637,        train.py:144\n",
            "                             val_loss: 0.00475, lr: 3.31E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:42:28] INFO     Epoch: 2 | train_loss: 0.00494,        train.py:144\n",
            "                             val_loss: 0.00310, lr: 3.31E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:42:30] INFO     Epoch: 3 | train_loss: 0.00361,        train.py:144\n",
            "                             val_loss: 0.00271, lr: 3.31E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:42:32] INFO     Epoch: 4 | train_loss: 0.00319,        train.py:144\n",
            "                             val_loss: 0.00264, lr: 3.31E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:42:33] INFO     Epoch: 5 | train_loss: 0.00292,        train.py:144\n",
            "                             val_loss: 0.00247, lr: 3.31E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:42:35] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 44:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 128,                               \n",
            "                               \"embedding_dim\": 274,                            \n",
            "                               \"num_filters\": 378,                              \n",
            "                               \"hidden_dim\": 310,                               \n",
            "                               \"dropout_p\": 0.7204155905650639,                 \n",
            "                               \"lr\": 0.00041574125137952116,                    \n",
            "                               \"lr_factor\": 0.014423583916922774,               \n",
            "                               \"lr_patience\": 6,                                \n",
            "                               \"patience\": 18                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 128,                               \n",
            "                               \"embedding_dim\": 274,                            \n",
            "                               \"num_filters\": 378,                              \n",
            "                               \"hidden_dim\": 310,                               \n",
            "                               \"dropout_p\": 0.7204155905650639,                 \n",
            "                               \"lr\": 0.00041574125137952116,                    \n",
            "                               \"lr_factor\": 0.014423583916922774,               \n",
            "                               \"lr_patience\": 6,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 18,                                  \n",
            "                               \"threshold\": 0.26229074597358704                 \n",
            "                             }                                                  \n",
            "[01/25/21 20:42:37] INFO     Epoch: 1 | train_loss: 0.00769,        train.py:144\n",
            "                             val_loss: 0.00604, lr: 4.16E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:42:39] INFO     Epoch: 2 | train_loss: 0.00584,        train.py:144\n",
            "                             val_loss: 0.00335, lr: 4.16E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:42:41] INFO     Epoch: 3 | train_loss: 0.00400,        train.py:144\n",
            "                             val_loss: 0.00277, lr: 4.16E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:42:43] INFO     Epoch: 4 | train_loss: 0.00334,        train.py:144\n",
            "                             val_loss: 0.00275, lr: 4.16E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:42:45] INFO     Epoch: 5 | train_loss: 0.00309,        train.py:144\n",
            "                             val_loss: 0.00253, lr: 4.16E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:42:47] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 45:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 115,                               \n",
            "                               \"embedding_dim\": 293,                            \n",
            "                               \"num_filters\": 342,                              \n",
            "                               \"hidden_dim\": 378,                               \n",
            "                               \"dropout_p\": 0.6392487185687962,                 \n",
            "                               \"lr\": 0.0002844192836323563,                     \n",
            "                               \"lr_factor\": 0.016911269638801844,               \n",
            "                               \"lr_patience\": 9,                                \n",
            "                               \"patience\": 17                                   \n",
            "                             }                                                  \n",
            "[01/25/21 20:42:48] INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 115,                               \n",
            "                               \"embedding_dim\": 293,                            \n",
            "                               \"num_filters\": 342,                              \n",
            "                               \"hidden_dim\": 378,                               \n",
            "                               \"dropout_p\": 0.6392487185687962,                 \n",
            "                               \"lr\": 0.0002844192836323563,                     \n",
            "                               \"lr_factor\": 0.016911269638801844,               \n",
            "                               \"lr_patience\": 9,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 17,                                  \n",
            "                               \"threshold\": 0.26229074597358704                 \n",
            "                             }                                                  \n",
            "[01/25/21 20:42:50] INFO     Epoch: 1 | train_loss: 0.00597,        train.py:144\n",
            "                             val_loss: 0.00502, lr: 2.84E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:42:52] INFO     Epoch: 2 | train_loss: 0.00478,        train.py:144\n",
            "                             val_loss: 0.00307, lr: 2.84E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:42:54] INFO     Epoch: 3 | train_loss: 0.00356,        train.py:144\n",
            "                             val_loss: 0.00267, lr: 2.84E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:42:56] INFO     Epoch: 4 | train_loss: 0.00312,        train.py:144\n",
            "                             val_loss: 0.00261, lr: 2.84E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:42:58] INFO     Epoch: 5 | train_loss: 0.00283,        train.py:144\n",
            "                             val_loss: 0.00243, lr: 2.84E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:43:00] INFO     Epoch: 6 | train_loss: 0.00251,        train.py:144\n",
            "                             val_loss: 0.00229, lr: 2.84E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:43:02] INFO     Epoch: 7 | train_loss: 0.00230,        train.py:144\n",
            "                             val_loss: 0.00215, lr: 2.84E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:43:04] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 46:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 124,                               \n",
            "                               \"embedding_dim\": 286,                            \n",
            "                               \"num_filters\": 331,                              \n",
            "                               \"hidden_dim\": 295,                               \n",
            "                               \"dropout_p\": 0.7626729255142497,                 \n",
            "                               \"lr\": 0.00023168338497344198,                    \n",
            "                               \"lr_factor\": 0.02672874186238045,                \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"patience\": 17                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 124,                               \n",
            "                               \"embedding_dim\": 286,                            \n",
            "                               \"num_filters\": 331,                              \n",
            "                               \"hidden_dim\": 295,                               \n",
            "                               \"dropout_p\": 0.7626729255142497,                 \n",
            "                               \"lr\": 0.00023168338497344198,                    \n",
            "                               \"lr_factor\": 0.02672874186238045,                \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 17,                                  \n",
            "                               \"threshold\": 0.26229074597358704                 \n",
            "                             }                                                  \n",
            "[01/25/21 20:43:06] INFO     Epoch: 1 | train_loss: 0.00643,        train.py:144\n",
            "                             val_loss: 0.00409, lr: 2.32E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:43:08] INFO     Epoch: 2 | train_loss: 0.00528,        train.py:144\n",
            "                             val_loss: 0.00332, lr: 2.32E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:43:10] INFO     Epoch: 3 | train_loss: 0.00413,        train.py:144\n",
            "                             val_loss: 0.00276, lr: 2.32E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:43:12] INFO     Epoch: 4 | train_loss: 0.00343,        train.py:144\n",
            "                             val_loss: 0.00271, lr: 2.32E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:43:14] INFO     Epoch: 5 | train_loss: 0.00321,        train.py:144\n",
            "                             val_loss: 0.00268, lr: 2.32E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:43:16] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 47:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 117,                               \n",
            "                               \"embedding_dim\": 258,                            \n",
            "                               \"num_filters\": 365,                              \n",
            "                               \"hidden_dim\": 350,                               \n",
            "                               \"dropout_p\": 0.7016620374976719,                 \n",
            "                               \"lr\": 0.0006293964485586094,                     \n",
            "                               \"lr_factor\": 0.011090183258192847,               \n",
            "                               \"lr_patience\": 6,                                \n",
            "                               \"patience\": 19                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 117,                               \n",
            "                               \"embedding_dim\": 258,                            \n",
            "                               \"num_filters\": 365,                              \n",
            "                               \"hidden_dim\": 350,                               \n",
            "                               \"dropout_p\": 0.7016620374976719,                 \n",
            "                               \"lr\": 0.0006293964485586094,                     \n",
            "                               \"lr_factor\": 0.011090183258192847,               \n",
            "                               \"lr_patience\": 6,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 19,                                  \n",
            "                               \"threshold\": 0.26229074597358704                 \n",
            "                             }                                                  \n",
            "[01/25/21 20:43:18] INFO     Epoch: 1 | train_loss: 0.00890,        train.py:144\n",
            "                             val_loss: 0.00610, lr: 6.29E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:43:20] INFO     Epoch: 2 | train_loss: 0.00522,        train.py:144\n",
            "                             val_loss: 0.00295, lr: 6.29E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:43:22] INFO     Epoch: 3 | train_loss: 0.00358,        train.py:144\n",
            "                             val_loss: 0.00297, lr: 6.29E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:43:24] INFO     Epoch: 4 | train_loss: 0.00316,        train.py:144\n",
            "                             val_loss: 0.00269, lr: 6.29E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:43:25] INFO     Epoch: 5 | train_loss: 0.00278,        train.py:144\n",
            "                             val_loss: 0.00254, lr: 6.29E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:43:27] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 48:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 104,                               \n",
            "                               \"embedding_dim\": 300,                            \n",
            "                               \"num_filters\": 393,                              \n",
            "                               \"hidden_dim\": 328,                               \n",
            "                               \"dropout_p\": 0.7967951874720522,                 \n",
            "                               \"lr\": 0.0003926758594362858,                     \n",
            "                               \"lr_factor\": 0.012767620072590519,               \n",
            "                               \"lr_patience\": 8,                                \n",
            "                               \"patience\": 15                                   \n",
            "                             }                                                  \n",
            "[01/25/21 20:43:28] INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 104,                               \n",
            "                               \"embedding_dim\": 300,                            \n",
            "                               \"num_filters\": 393,                              \n",
            "                               \"hidden_dim\": 328,                               \n",
            "                               \"dropout_p\": 0.7967951874720522,                 \n",
            "                               \"lr\": 0.0003926758594362858,                     \n",
            "                               \"lr_factor\": 0.012767620072590519,               \n",
            "                               \"lr_patience\": 8,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 15,                                  \n",
            "                               \"threshold\": 0.26229074597358704                 \n",
            "                             }                                                  \n",
            "[01/25/21 20:43:30] INFO     Epoch: 1 | train_loss: 0.00895,        train.py:144\n",
            "                             val_loss: 0.00803, lr: 3.93E-04,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 20:43:32] INFO     Epoch: 2 | train_loss: 0.00596,        train.py:144\n",
            "                             val_loss: 0.00403, lr: 3.93E-04,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 20:43:35] INFO     Epoch: 3 | train_loss: 0.00390,        train.py:144\n",
            "                             val_loss: 0.00359, lr: 3.93E-04,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 20:43:37] INFO     Epoch: 4 | train_loss: 0.00344,        train.py:144\n",
            "                             val_loss: 0.00357, lr: 3.93E-04,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 20:43:40] INFO     Epoch: 5 | train_loss: 0.00304,        train.py:144\n",
            "                             val_loss: 0.00332, lr: 3.93E-04,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 20:43:42] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 49:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 109,                               \n",
            "                               \"embedding_dim\": 216,                            \n",
            "                               \"num_filters\": 297,                              \n",
            "                               \"hidden_dim\": 256,                               \n",
            "                               \"dropout_p\": 0.6239762428560575,                 \n",
            "                               \"lr\": 0.000546400694753301,                      \n",
            "                               \"lr_factor\": 0.01535190915516923,                \n",
            "                               \"lr_patience\": 5,                                \n",
            "                               \"patience\": 20                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 109,                               \n",
            "                               \"embedding_dim\": 216,                            \n",
            "                               \"num_filters\": 297,                              \n",
            "                               \"hidden_dim\": 256,                               \n",
            "                               \"dropout_p\": 0.6239762428560575,                 \n",
            "                               \"lr\": 0.000546400694753301,                      \n",
            "                               \"lr_factor\": 0.01535190915516923,                \n",
            "                               \"lr_patience\": 5,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 20,                                  \n",
            "                               \"threshold\": 0.26229074597358704                 \n",
            "                             }                                                  \n",
            "[01/25/21 20:43:44] INFO     Epoch: 1 | train_loss: 0.00705,        train.py:144\n",
            "                             val_loss: 0.00500, lr: 5.46E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:43:45] INFO     Epoch: 2 | train_loss: 0.00451,        train.py:144\n",
            "                             val_loss: 0.00281, lr: 5.46E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:43:47] INFO     Epoch: 3 | train_loss: 0.00333,        train.py:144\n",
            "                             val_loss: 0.00276, lr: 5.46E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:43:48] INFO     Epoch: 4 | train_loss: 0.00300,        train.py:144\n",
            "                             val_loss: 0.00256, lr: 5.46E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:43:50] INFO     Epoch: 5 | train_loss: 0.00263,        train.py:144\n",
            "                             val_loss: 0.00241, lr: 5.46E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:43:51] INFO     Epoch: 6 | train_loss: 0.00231,        train.py:144\n",
            "                             val_loss: 0.00222, lr: 5.46E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:43:53] INFO     Epoch: 7 | train_loss: 0.00206,        train.py:144\n",
            "                             val_loss: 0.00207, lr: 5.46E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:43:54] INFO     Epoch: 8 | train_loss: 0.00187,        train.py:144\n",
            "                             val_loss: 0.00197, lr: 5.46E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:43:56] INFO     Epoch: 9 | train_loss: 0.00166,        train.py:144\n",
            "                             val_loss: 0.00191, lr: 5.46E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:43:57] INFO     Epoch: 10 | train_loss: 0.00151,       train.py:144\n",
            "                             val_loss: 0.00181, lr: 5.46E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:43:59] INFO     Epoch: 11 | train_loss: 0.00137,       train.py:144\n",
            "                             val_loss: 0.00182, lr: 5.46E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:44:00] INFO     Epoch: 12 | train_loss: 0.00126,       train.py:144\n",
            "                             val_loss: 0.00174, lr: 5.46E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:44:02] INFO     Epoch: 13 | train_loss: 0.00109,       train.py:144\n",
            "                             val_loss: 0.00177, lr: 5.46E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:44:03] INFO     Epoch: 14 | train_loss: 0.00099,       train.py:144\n",
            "                             val_loss: 0.00173, lr: 5.46E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:44:05] INFO     Epoch: 15 | train_loss: 0.00090,       train.py:144\n",
            "                             val_loss: 0.00168, lr: 5.46E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:44:06] INFO     Epoch: 16 | train_loss: 0.00082,       train.py:144\n",
            "                             val_loss: 0.00174, lr: 5.46E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:44:08] INFO     Epoch: 17 | train_loss: 0.00074,       train.py:144\n",
            "                             val_loss: 0.00175, lr: 5.46E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:44:09] INFO     Epoch: 18 | train_loss: 0.00065,       train.py:144\n",
            "                             val_loss: 0.00167, lr: 5.46E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:44:11] INFO     Epoch: 19 | train_loss: 0.00061,       train.py:144\n",
            "                             val_loss: 0.00175, lr: 5.46E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:44:12] INFO     Epoch: 20 | train_loss: 0.00056,       train.py:144\n",
            "                             val_loss: 0.00169, lr: 5.46E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:44:14] INFO     Epoch: 21 | train_loss: 0.00055,       train.py:144\n",
            "                             val_loss: 0.00179, lr: 5.46E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:44:15] INFO     Epoch: 22 | train_loss: 0.00049,       train.py:144\n",
            "                             val_loss: 0.00164, lr: 5.46E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:44:17] INFO     Epoch: 23 | train_loss: 0.00053,       train.py:144\n",
            "                             val_loss: 0.00166, lr: 5.46E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:44:18] INFO     Epoch: 24 | train_loss: 0.00050,       train.py:144\n",
            "                             val_loss: 0.00170, lr: 5.46E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:44:20] INFO     Epoch: 25 | train_loss: 0.00054,       train.py:144\n",
            "                             val_loss: 0.00207, lr: 5.46E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:44:21] INFO     Epoch: 26 | train_loss: 0.00067,       train.py:144\n",
            "                             val_loss: 0.00180, lr: 5.46E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:44:23] INFO     Epoch: 27 | train_loss: 0.00066,       train.py:144\n",
            "                             val_loss: 0.00180, lr: 5.46E-04,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 20:44:24] INFO     Epoch: 28 | train_loss: 0.00080,       train.py:144\n",
            "                             val_loss: 0.00245, lr: 8.39E-06,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 20:44:26] INFO     Epoch: 29 | train_loss: 0.00148,       train.py:144\n",
            "                             val_loss: 0.00201, lr: 8.39E-06,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 20:44:27] INFO     Epoch: 30 | train_loss: 0.00070,       train.py:144\n",
            "                             val_loss: 0.00196, lr: 8.39E-06,                   \n",
            "                             _patience: 12                                      \n",
            "[01/25/21 20:44:29] INFO     Epoch: 31 | train_loss: 0.00045,       train.py:144\n",
            "                             val_loss: 0.00207, lr: 8.39E-06,                   \n",
            "                             _patience: 11                                      \n",
            "[01/25/21 20:44:30] INFO     Epoch: 32 | train_loss: 0.00044,       train.py:144\n",
            "                             val_loss: 0.00212, lr: 8.39E-06,                   \n",
            "                             _patience: 10                                      \n",
            "[01/25/21 20:44:32] INFO     Epoch: 33 | train_loss: 0.00042,       train.py:144\n",
            "                             val_loss: 0.00213, lr: 8.39E-06,                   \n",
            "                             _patience: 9                                       \n",
            "[01/25/21 20:44:33] INFO     Epoch: 34 | train_loss: 0.00042,       train.py:144\n",
            "                             val_loss: 0.00210, lr: 1.29E-07,                   \n",
            "                             _patience: 8                                       \n",
            "[01/25/21 20:44:35] INFO     Epoch: 35 | train_loss: 0.00040,       train.py:144\n",
            "                             val_loss: 0.00209, lr: 1.29E-07,                   \n",
            "                             _patience: 7                                       \n",
            "[01/25/21 20:44:36] INFO     Epoch: 36 | train_loss: 0.00038,       train.py:144\n",
            "                             val_loss: 0.00209, lr: 1.29E-07,                   \n",
            "                             _patience: 6                                       \n",
            "[01/25/21 20:44:38] INFO     Epoch: 37 | train_loss: 0.00041,       train.py:144\n",
            "                             val_loss: 0.00209, lr: 1.29E-07,                   \n",
            "                             _patience: 5                                       \n",
            "[01/25/21 20:44:39] INFO     Epoch: 38 | train_loss: 0.00039,       train.py:144\n",
            "                             val_loss: 0.00209, lr: 1.29E-07,                   \n",
            "                             _patience: 4                                       \n",
            "[01/25/21 20:44:41] INFO     Epoch: 39 | train_loss: 0.00039,       train.py:144\n",
            "                             val_loss: 0.00209, lr: 1.29E-07,                   \n",
            "                             _patience: 3                                       \n",
            "[01/25/21 20:44:42] INFO     Epoch: 40 | train_loss: 0.00041,       train.py:144\n",
            "                             val_loss: 0.00209, lr: 1.98E-09,                   \n",
            "                             _patience: 2                                       \n",
            "[01/25/21 20:44:44] INFO     Epoch: 41 | train_loss: 0.00039,       train.py:144\n",
            "                             val_loss: 0.00209, lr: 1.98E-09,                   \n",
            "                             _patience: 1                                       \n",
            "[01/25/21 20:44:45] INFO     Stopping early!                        train.py:139\n",
            "[01/25/21 20:44:50] INFO                                            train.py:441\n",
            "                             Trial 50:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 113,                               \n",
            "                               \"embedding_dim\": 248,                            \n",
            "                               \"num_filters\": 318,                              \n",
            "                               \"hidden_dim\": 404,                               \n",
            "                               \"dropout_p\": 0.7314390671689366,                 \n",
            "                               \"lr\": 0.0002995000614108739,                     \n",
            "                               \"lr_factor\": 0.01724158151766302,                \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"patience\": 16                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 113,                               \n",
            "                               \"embedding_dim\": 248,                            \n",
            "                               \"num_filters\": 318,                              \n",
            "                               \"hidden_dim\": 404,                               \n",
            "                               \"dropout_p\": 0.7314390671689366,                 \n",
            "                               \"lr\": 0.0002995000614108739,                     \n",
            "                               \"lr_factor\": 0.01724158151766302,                \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 16,                                  \n",
            "                               \"threshold\": 0.23522233963012695                 \n",
            "                             }                                                  \n",
            "[01/25/21 20:44:52] INFO     Epoch: 1 | train_loss: 0.00617,        train.py:144\n",
            "                             val_loss: 0.00494, lr: 3.00E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:44:54] INFO     Epoch: 2 | train_loss: 0.00488,        train.py:144\n",
            "                             val_loss: 0.00318, lr: 3.00E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:44:55] INFO     Epoch: 3 | train_loss: 0.00380,        train.py:144\n",
            "                             val_loss: 0.00271, lr: 3.00E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:44:57] INFO     Epoch: 4 | train_loss: 0.00325,        train.py:144\n",
            "                             val_loss: 0.00269, lr: 3.00E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:44:58] INFO     Epoch: 5 | train_loss: 0.00300,        train.py:144\n",
            "                             val_loss: 0.00255, lr: 3.00E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:45:00] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 51:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 109,                               \n",
            "                               \"embedding_dim\": 233,                            \n",
            "                               \"num_filters\": 324,                              \n",
            "                               \"hidden_dim\": 342,                               \n",
            "                               \"dropout_p\": 0.4865448877935982,                 \n",
            "                               \"lr\": 0.0003344499591578773,                     \n",
            "                               \"lr_factor\": 0.014806429902605864,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"patience\": 20                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 109,                               \n",
            "                               \"embedding_dim\": 233,                            \n",
            "                               \"num_filters\": 324,                              \n",
            "                               \"hidden_dim\": 342,                               \n",
            "                               \"dropout_p\": 0.4865448877935982,                 \n",
            "                               \"lr\": 0.0003344499591578773,                     \n",
            "                               \"lr_factor\": 0.014806429902605864,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 20,                                  \n",
            "                               \"threshold\": 0.23522233963012695                 \n",
            "                             }                                                  \n",
            "[01/25/21 20:45:02] INFO     Epoch: 1 | train_loss: 0.00560,        train.py:144\n",
            "                             val_loss: 0.00463, lr: 3.34E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:45:03] INFO     Epoch: 2 | train_loss: 0.00412,        train.py:144\n",
            "                             val_loss: 0.00281, lr: 3.34E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:45:05] INFO     Epoch: 3 | train_loss: 0.00327,        train.py:144\n",
            "                             val_loss: 0.00265, lr: 3.34E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:45:07] INFO     Epoch: 4 | train_loss: 0.00278,        train.py:144\n",
            "                             val_loss: 0.00258, lr: 3.34E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:45:08] INFO     Epoch: 5 | train_loss: 0.00251,        train.py:144\n",
            "                             val_loss: 0.00237, lr: 3.34E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:45:10] INFO     Epoch: 6 | train_loss: 0.00220,        train.py:144\n",
            "                             val_loss: 0.00223, lr: 3.34E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:45:12] INFO     Epoch: 7 | train_loss: 0.00195,        train.py:144\n",
            "                             val_loss: 0.00208, lr: 3.34E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:45:13] INFO     Epoch: 8 | train_loss: 0.00176,        train.py:144\n",
            "                             val_loss: 0.00198, lr: 3.34E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:45:15] INFO     Epoch: 9 | train_loss: 0.00157,        train.py:144\n",
            "                             val_loss: 0.00188, lr: 3.34E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:45:16] INFO     Epoch: 10 | train_loss: 0.00142,       train.py:144\n",
            "                             val_loss: 0.00185, lr: 3.34E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:45:18] INFO     Epoch: 11 | train_loss: 0.00126,       train.py:144\n",
            "                             val_loss: 0.00179, lr: 3.34E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:45:20] INFO     Epoch: 12 | train_loss: 0.00115,       train.py:144\n",
            "                             val_loss: 0.00172, lr: 3.34E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:45:21] INFO     Epoch: 13 | train_loss: 0.00105,       train.py:144\n",
            "                             val_loss: 0.00174, lr: 3.34E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:45:23] INFO     Epoch: 14 | train_loss: 0.00095,       train.py:144\n",
            "                             val_loss: 0.00174, lr: 3.34E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:45:24] INFO     Epoch: 15 | train_loss: 0.00086,       train.py:144\n",
            "                             val_loss: 0.00169, lr: 3.34E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:45:26] INFO     Epoch: 16 | train_loss: 0.00078,       train.py:144\n",
            "                             val_loss: 0.00168, lr: 3.34E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:45:28] INFO     Epoch: 17 | train_loss: 0.00069,       train.py:144\n",
            "                             val_loss: 0.00167, lr: 3.34E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:45:29] INFO     Epoch: 18 | train_loss: 0.00064,       train.py:144\n",
            "                             val_loss: 0.00165, lr: 3.34E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:45:31] INFO     Epoch: 19 | train_loss: 0.00060,       train.py:144\n",
            "                             val_loss: 0.00170, lr: 3.34E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:45:33] INFO     Epoch: 20 | train_loss: 0.00054,       train.py:144\n",
            "                             val_loss: 0.00169, lr: 3.34E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:45:34] INFO     Epoch: 21 | train_loss: 0.00049,       train.py:144\n",
            "                             val_loss: 0.00166, lr: 3.34E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:45:36] INFO     Epoch: 22 | train_loss: 0.00045,       train.py:144\n",
            "                             val_loss: 0.00168, lr: 3.34E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:45:37] INFO     Epoch: 23 | train_loss: 0.00043,       train.py:144\n",
            "                             val_loss: 0.00173, lr: 3.34E-04,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 20:45:39] INFO     Epoch: 24 | train_loss: 0.00042,       train.py:144\n",
            "                             val_loss: 0.00181, lr: 3.34E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 20:45:41] INFO     Epoch: 25 | train_loss: 0.00037,       train.py:144\n",
            "                             val_loss: 0.00200, lr: 3.34E-04,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 20:45:42] INFO     Epoch: 26 | train_loss: 0.00036,       train.py:144\n",
            "                             val_loss: 0.00216, lr: 4.95E-06,                   \n",
            "                             _patience: 12                                      \n",
            "[01/25/21 20:45:44] INFO     Epoch: 27 | train_loss: 0.00039,       train.py:144\n",
            "                             val_loss: 0.00208, lr: 4.95E-06,                   \n",
            "                             _patience: 11                                      \n",
            "[01/25/21 20:45:45] INFO     Epoch: 28 | train_loss: 0.00034,       train.py:144\n",
            "                             val_loss: 0.00198, lr: 4.95E-06,                   \n",
            "                             _patience: 10                                      \n",
            "[01/25/21 20:45:47] INFO     Epoch: 29 | train_loss: 0.00032,       train.py:144\n",
            "                             val_loss: 0.00190, lr: 4.95E-06,                   \n",
            "                             _patience: 9                                       \n",
            "[01/25/21 20:45:49] INFO     Epoch: 30 | train_loss: 0.00030,       train.py:144\n",
            "                             val_loss: 0.00186, lr: 4.95E-06,                   \n",
            "                             _patience: 8                                       \n",
            "[01/25/21 20:45:50] INFO     Epoch: 31 | train_loss: 0.00028,       train.py:144\n",
            "                             val_loss: 0.00185, lr: 4.95E-06,                   \n",
            "                             _patience: 7                                       \n",
            "[01/25/21 20:45:52] INFO     Epoch: 32 | train_loss: 0.00028,       train.py:144\n",
            "                             val_loss: 0.00185, lr: 4.95E-06,                   \n",
            "                             _patience: 6                                       \n",
            "[01/25/21 20:45:54] INFO     Epoch: 33 | train_loss: 0.00029,       train.py:144\n",
            "                             val_loss: 0.00184, lr: 4.95E-06,                   \n",
            "                             _patience: 5                                       \n",
            "[01/25/21 20:45:55] INFO     Epoch: 34 | train_loss: 0.00027,       train.py:144\n",
            "                             val_loss: 0.00184, lr: 7.33E-08,                   \n",
            "                             _patience: 4                                       \n",
            "[01/25/21 20:45:57] INFO     Epoch: 35 | train_loss: 0.00028,       train.py:144\n",
            "                             val_loss: 0.00184, lr: 7.33E-08,                   \n",
            "                             _patience: 3                                       \n",
            "[01/25/21 20:45:58] INFO     Epoch: 36 | train_loss: 0.00027,       train.py:144\n",
            "                             val_loss: 0.00184, lr: 7.33E-08,                   \n",
            "                             _patience: 2                                       \n",
            "[01/25/21 20:46:00] INFO     Epoch: 37 | train_loss: 0.00028,       train.py:144\n",
            "                             val_loss: 0.00184, lr: 7.33E-08,                   \n",
            "                             _patience: 1                                       \n",
            "[01/25/21 20:46:02] INFO     Stopping early!                        train.py:139\n",
            "[01/25/21 20:46:07] INFO                                            train.py:441\n",
            "                             Trial 52:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 93,                                \n",
            "                               \"embedding_dim\": 226,                            \n",
            "                               \"num_filters\": 335,                              \n",
            "                               \"hidden_dim\": 303,                               \n",
            "                               \"dropout_p\": 0.5439476702476118,                 \n",
            "                               \"lr\": 0.0003799466966730442,                     \n",
            "                               \"lr_factor\": 0.013893434167757467,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"patience\": 20                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 93,                                \n",
            "                               \"embedding_dim\": 226,                            \n",
            "                               \"num_filters\": 335,                              \n",
            "                               \"hidden_dim\": 303,                               \n",
            "                               \"dropout_p\": 0.5439476702476118,                 \n",
            "                               \"lr\": 0.0003799466966730442,                     \n",
            "                               \"lr_factor\": 0.013893434167757467,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 20,                                  \n",
            "                               \"threshold\": 0.31572413444519043                 \n",
            "                             }                                                  \n",
            "[01/25/21 20:46:09] INFO     Epoch: 1 | train_loss: 0.00573,        train.py:144\n",
            "                             val_loss: 0.00451, lr: 3.80E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:46:11] INFO     Epoch: 2 | train_loss: 0.00414,        train.py:144\n",
            "                             val_loss: 0.00288, lr: 3.80E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:46:12] INFO     Epoch: 3 | train_loss: 0.00322,        train.py:144\n",
            "                             val_loss: 0.00276, lr: 3.80E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:46:14] INFO     Epoch: 4 | train_loss: 0.00274,        train.py:144\n",
            "                             val_loss: 0.00255, lr: 3.80E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:46:16] INFO     Epoch: 5 | train_loss: 0.00239,        train.py:144\n",
            "                             val_loss: 0.00236, lr: 3.80E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:46:17] INFO     Epoch: 6 | train_loss: 0.00208,        train.py:144\n",
            "                             val_loss: 0.00218, lr: 3.80E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:46:19] INFO     Epoch: 7 | train_loss: 0.00184,        train.py:144\n",
            "                             val_loss: 0.00207, lr: 3.80E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:46:20] INFO     Epoch: 8 | train_loss: 0.00169,        train.py:144\n",
            "                             val_loss: 0.00194, lr: 3.80E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:46:22] INFO     Epoch: 9 | train_loss: 0.00149,        train.py:144\n",
            "                             val_loss: 0.00188, lr: 3.80E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:46:24] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 53:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 99,                                \n",
            "                               \"embedding_dim\": 230,                            \n",
            "                               \"num_filters\": 359,                              \n",
            "                               \"hidden_dim\": 351,                               \n",
            "                               \"dropout_p\": 0.546514414519596,                  \n",
            "                               \"lr\": 0.0004541185172184553,                     \n",
            "                               \"lr_factor\": 0.01245454616304799,                \n",
            "                               \"lr_patience\": 10,                               \n",
            "                               \"patience\": 19                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 99,                                \n",
            "                               \"embedding_dim\": 230,                            \n",
            "                               \"num_filters\": 359,                              \n",
            "                               \"hidden_dim\": 351,                               \n",
            "                               \"dropout_p\": 0.546514414519596,                  \n",
            "                               \"lr\": 0.0004541185172184553,                     \n",
            "                               \"lr_factor\": 0.01245454616304799,                \n",
            "                               \"lr_patience\": 10,                               \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 19,                                  \n",
            "                               \"threshold\": 0.31572413444519043                 \n",
            "                             }                                                  \n",
            "[01/25/21 20:46:26] INFO     Epoch: 1 | train_loss: 0.00674,        train.py:144\n",
            "                             val_loss: 0.00569, lr: 4.54E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:46:27] INFO     Epoch: 2 | train_loss: 0.00431,        train.py:144\n",
            "                             val_loss: 0.00322, lr: 4.54E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:46:29] INFO     Epoch: 3 | train_loss: 0.00314,        train.py:144\n",
            "                             val_loss: 0.00303, lr: 4.54E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:46:31] INFO     Epoch: 4 | train_loss: 0.00270,        train.py:144\n",
            "                             val_loss: 0.00281, lr: 4.54E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:46:33] INFO     Epoch: 5 | train_loss: 0.00240,        train.py:144\n",
            "                             val_loss: 0.00259, lr: 4.54E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:46:34] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 54:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 125,                               \n",
            "                               \"embedding_dim\": 237,                            \n",
            "                               \"num_filters\": 507,                              \n",
            "                               \"hidden_dim\": 270,                               \n",
            "                               \"dropout_p\": 0.6090971233018097,                 \n",
            "                               \"lr\": 0.0003496402087336157,                     \n",
            "                               \"lr_factor\": 0.010579658604209886,               \n",
            "                               \"lr_patience\": 8,                                \n",
            "                               \"patience\": 18                                   \n",
            "                             }                                                  \n",
            "[01/25/21 20:46:35] INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 125,                               \n",
            "                               \"embedding_dim\": 237,                            \n",
            "                               \"num_filters\": 507,                              \n",
            "                               \"hidden_dim\": 270,                               \n",
            "                               \"dropout_p\": 0.6090971233018097,                 \n",
            "                               \"lr\": 0.0003496402087336157,                     \n",
            "                               \"lr_factor\": 0.010579658604209886,               \n",
            "                               \"lr_patience\": 8,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 18,                                  \n",
            "                               \"threshold\": 0.31572413444519043                 \n",
            "                             }                                                  \n",
            "[01/25/21 20:46:37] INFO     Epoch: 1 | train_loss: 0.00713,        train.py:144\n",
            "                             val_loss: 0.00601, lr: 3.50E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:46:39] INFO     Epoch: 2 | train_loss: 0.00553,        train.py:144\n",
            "                             val_loss: 0.00334, lr: 3.50E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:46:41] INFO     Epoch: 3 | train_loss: 0.00380,        train.py:144\n",
            "                             val_loss: 0.00276, lr: 3.50E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:46:44] INFO     Epoch: 4 | train_loss: 0.00315,        train.py:144\n",
            "                             val_loss: 0.00269, lr: 3.50E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:46:46] INFO     Epoch: 5 | train_loss: 0.00290,        train.py:144\n",
            "                             val_loss: 0.00253, lr: 3.50E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:46:48] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 55:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 113,                               \n",
            "                               \"embedding_dim\": 203,                            \n",
            "                               \"num_filters\": 348,                              \n",
            "                               \"hidden_dim\": 316,                               \n",
            "                               \"dropout_p\": 0.3990640160018668,                 \n",
            "                               \"lr\": 0.0004309569654376579,                     \n",
            "                               \"lr_factor\": 0.016748777521379047,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"patience\": 18                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 113,                               \n",
            "                               \"embedding_dim\": 203,                            \n",
            "                               \"num_filters\": 348,                              \n",
            "                               \"hidden_dim\": 316,                               \n",
            "                               \"dropout_p\": 0.3990640160018668,                 \n",
            "                               \"lr\": 0.0004309569654376579,                     \n",
            "                               \"lr_factor\": 0.016748777521379047,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 18,                                  \n",
            "                               \"threshold\": 0.31572413444519043                 \n",
            "                             }                                                  \n",
            "[01/25/21 20:46:50] INFO     Epoch: 1 | train_loss: 0.00602,        train.py:144\n",
            "                             val_loss: 0.00471, lr: 4.31E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:46:52] INFO     Epoch: 2 | train_loss: 0.00432,        train.py:144\n",
            "                             val_loss: 0.00287, lr: 4.31E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:46:53] INFO     Epoch: 3 | train_loss: 0.00327,        train.py:144\n",
            "                             val_loss: 0.00266, lr: 4.31E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:46:55] INFO     Epoch: 4 | train_loss: 0.00276,        train.py:144\n",
            "                             val_loss: 0.00256, lr: 4.31E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:46:57] INFO     Epoch: 5 | train_loss: 0.00247,        train.py:144\n",
            "                             val_loss: 0.00234, lr: 4.31E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:46:58] INFO     Epoch: 6 | train_loss: 0.00215,        train.py:144\n",
            "                             val_loss: 0.00216, lr: 4.31E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:47:00] INFO     Epoch: 7 | train_loss: 0.00188,        train.py:144\n",
            "                             val_loss: 0.00202, lr: 4.31E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:47:02] INFO     Epoch: 8 | train_loss: 0.00165,        train.py:144\n",
            "                             val_loss: 0.00194, lr: 4.31E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:47:03] INFO     Epoch: 9 | train_loss: 0.00147,        train.py:144\n",
            "                             val_loss: 0.00185, lr: 4.31E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:47:05] INFO     Epoch: 10 | train_loss: 0.00131,       train.py:144\n",
            "                             val_loss: 0.00179, lr: 4.31E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:47:07] INFO     Epoch: 11 | train_loss: 0.00117,       train.py:144\n",
            "                             val_loss: 0.00175, lr: 4.31E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:47:08] INFO     Epoch: 12 | train_loss: 0.00102,       train.py:144\n",
            "                             val_loss: 0.00172, lr: 4.31E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:47:10] INFO     Epoch: 13 | train_loss: 0.00087,       train.py:144\n",
            "                             val_loss: 0.00171, lr: 4.31E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:47:11] INFO     Epoch: 14 | train_loss: 0.00080,       train.py:144\n",
            "                             val_loss: 0.00170, lr: 4.31E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:47:13] INFO     Epoch: 15 | train_loss: 0.00071,       train.py:144\n",
            "                             val_loss: 0.00169, lr: 4.31E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:47:15] INFO     Epoch: 16 | train_loss: 0.00063,       train.py:144\n",
            "                             val_loss: 0.00170, lr: 4.31E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:47:16] INFO     Epoch: 17 | train_loss: 0.00058,       train.py:144\n",
            "                             val_loss: 0.00166, lr: 4.31E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:47:18] INFO     Epoch: 18 | train_loss: 0.00050,       train.py:144\n",
            "                             val_loss: 0.00168, lr: 4.31E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:47:20] INFO     Epoch: 19 | train_loss: 0.00045,       train.py:144\n",
            "                             val_loss: 0.00174, lr: 4.31E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:47:21] INFO     Epoch: 20 | train_loss: 0.00041,       train.py:144\n",
            "                             val_loss: 0.00177, lr: 4.31E-04,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 20:47:23] INFO     Epoch: 21 | train_loss: 0.00037,       train.py:144\n",
            "                             val_loss: 0.00191, lr: 4.31E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 20:47:25] INFO     Epoch: 22 | train_loss: 0.00036,       train.py:144\n",
            "                             val_loss: 0.00187, lr: 4.31E-04,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 20:47:26] INFO     Epoch: 23 | train_loss: 0.00031,       train.py:144\n",
            "                             val_loss: 0.00189, lr: 4.31E-04,                   \n",
            "                             _patience: 12                                      \n",
            "[01/25/21 20:47:28] INFO     Epoch: 24 | train_loss: 0.00029,       train.py:144\n",
            "                             val_loss: 0.00186, lr: 4.31E-04,                   \n",
            "                             _patience: 11                                      \n",
            "[01/25/21 20:47:30] INFO     Epoch: 25 | train_loss: 0.00025,       train.py:144\n",
            "                             val_loss: 0.00185, lr: 7.22E-06,                   \n",
            "                             _patience: 10                                      \n",
            "[01/25/21 20:47:31] INFO     Epoch: 26 | train_loss: 0.00023,       train.py:144\n",
            "                             val_loss: 0.00185, lr: 7.22E-06,                   \n",
            "                             _patience: 9                                       \n",
            "[01/25/21 20:47:33] INFO     Epoch: 27 | train_loss: 0.00022,       train.py:144\n",
            "                             val_loss: 0.00185, lr: 7.22E-06,                   \n",
            "                             _patience: 8                                       \n",
            "[01/25/21 20:47:34] INFO     Epoch: 28 | train_loss: 0.00022,       train.py:144\n",
            "                             val_loss: 0.00185, lr: 7.22E-06,                   \n",
            "                             _patience: 7                                       \n",
            "[01/25/21 20:47:36] INFO     Epoch: 29 | train_loss: 0.00021,       train.py:144\n",
            "                             val_loss: 0.00185, lr: 7.22E-06,                   \n",
            "                             _patience: 6                                       \n",
            "[01/25/21 20:47:38] INFO     Epoch: 30 | train_loss: 0.00021,       train.py:144\n",
            "                             val_loss: 0.00185, lr: 7.22E-06,                   \n",
            "                             _patience: 5                                       \n",
            "[01/25/21 20:47:39] INFO     Epoch: 31 | train_loss: 0.00021,       train.py:144\n",
            "                             val_loss: 0.00186, lr: 7.22E-06,                   \n",
            "                             _patience: 4                                       \n",
            "[01/25/21 20:47:41] INFO     Epoch: 32 | train_loss: 0.00022,       train.py:144\n",
            "                             val_loss: 0.00186, lr: 7.22E-06,                   \n",
            "                             _patience: 3                                       \n",
            "[01/25/21 20:47:43] INFO     Epoch: 33 | train_loss: 0.00021,       train.py:144\n",
            "                             val_loss: 0.00185, lr: 1.21E-07,                   \n",
            "                             _patience: 2                                       \n",
            "[01/25/21 20:47:44] INFO     Epoch: 34 | train_loss: 0.00021,       train.py:144\n",
            "                             val_loss: 0.00185, lr: 1.21E-07,                   \n",
            "                             _patience: 1                                       \n",
            "[01/25/21 20:47:46] INFO     Stopping early!                        train.py:139\n",
            "[01/25/21 20:47:51] INFO                                            train.py:441\n",
            "                             Trial 56:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 72,                                \n",
            "                               \"embedding_dim\": 222,                            \n",
            "                               \"num_filters\": 263,                              \n",
            "                               \"hidden_dim\": 355,                               \n",
            "                               \"dropout_p\": 0.5721610346859269,                 \n",
            "                               \"lr\": 0.0005346091878138493,                     \n",
            "                               \"lr_factor\": 0.011466689383540115,               \n",
            "                               \"lr_patience\": 6,                                \n",
            "                               \"patience\": 20                                   \n",
            "                             }                                                  \n",
            "[01/25/21 20:47:52] INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 72,                                \n",
            "                               \"embedding_dim\": 222,                            \n",
            "                               \"num_filters\": 263,                              \n",
            "                               \"hidden_dim\": 355,                               \n",
            "                               \"dropout_p\": 0.5721610346859269,                 \n",
            "                               \"lr\": 0.0005346091878138493,                     \n",
            "                               \"lr_factor\": 0.011466689383540115,               \n",
            "                               \"lr_patience\": 6,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 20,                                  \n",
            "                               \"threshold\": 0.2666660249233246                  \n",
            "                             }                                                  \n",
            "[01/25/21 20:47:53] INFO     Epoch: 1 | train_loss: 0.00595,        train.py:144\n",
            "                             val_loss: 0.00329, lr: 5.35E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:47:54] INFO     Epoch: 2 | train_loss: 0.00368,        train.py:144\n",
            "                             val_loss: 0.00274, lr: 5.35E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:47:56] INFO     Epoch: 3 | train_loss: 0.00290,        train.py:144\n",
            "                             val_loss: 0.00251, lr: 5.35E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:47:57] INFO     Epoch: 4 | train_loss: 0.00243,        train.py:144\n",
            "                             val_loss: 0.00225, lr: 5.35E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:47:59] INFO     Epoch: 5 | train_loss: 0.00206,        train.py:144\n",
            "                             val_loss: 0.00202, lr: 5.35E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:48:00] INFO     Epoch: 6 | train_loss: 0.00173,        train.py:144\n",
            "                             val_loss: 0.00189, lr: 5.35E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:48:01] INFO     Epoch: 7 | train_loss: 0.00149,        train.py:144\n",
            "                             val_loss: 0.00179, lr: 5.35E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:48:03] INFO     Epoch: 8 | train_loss: 0.00127,        train.py:144\n",
            "                             val_loss: 0.00178, lr: 5.35E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:48:04] INFO     Epoch: 9 | train_loss: 0.00111,        train.py:144\n",
            "                             val_loss: 0.00173, lr: 5.35E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:48:06] INFO     Epoch: 10 | train_loss: 0.00093,       train.py:144\n",
            "                             val_loss: 0.00175, lr: 5.35E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:48:07] INFO     Epoch: 11 | train_loss: 0.00081,       train.py:144\n",
            "                             val_loss: 0.00171, lr: 5.35E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:48:09] INFO     Epoch: 12 | train_loss: 0.00070,       train.py:144\n",
            "                             val_loss: 0.00181, lr: 5.35E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:48:10] INFO     Epoch: 13 | train_loss: 0.00062,       train.py:144\n",
            "                             val_loss: 0.00171, lr: 5.35E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:48:11] INFO     Epoch: 14 | train_loss: 0.00052,       train.py:144\n",
            "                             val_loss: 0.00176, lr: 5.35E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:48:13] INFO     Epoch: 15 | train_loss: 0.00048,       train.py:144\n",
            "                             val_loss: 0.00182, lr: 5.35E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:48:14] INFO     Epoch: 16 | train_loss: 0.00040,       train.py:144\n",
            "                             val_loss: 0.00185, lr: 5.35E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:48:16] INFO     Epoch: 17 | train_loss: 0.00039,       train.py:144\n",
            "                             val_loss: 0.00197, lr: 5.35E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:48:17] INFO     Epoch: 18 | train_loss: 0.00036,       train.py:144\n",
            "                             val_loss: 0.00204, lr: 5.35E-04,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 20:48:19] INFO     Epoch: 19 | train_loss: 0.00033,       train.py:144\n",
            "                             val_loss: 0.00187, lr: 5.35E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 20:48:20] INFO     Epoch: 20 | train_loss: 0.00029,       train.py:144\n",
            "                             val_loss: 0.00200, lr: 6.13E-06,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 20:48:21] INFO     Epoch: 21 | train_loss: 0.00032,       train.py:144\n",
            "                             val_loss: 0.00204, lr: 6.13E-06,                   \n",
            "                             _patience: 12                                      \n",
            "[01/25/21 20:48:23] INFO     Epoch: 22 | train_loss: 0.00028,       train.py:144\n",
            "                             val_loss: 0.00209, lr: 6.13E-06,                   \n",
            "                             _patience: 11                                      \n",
            "[01/25/21 20:48:24] INFO     Epoch: 23 | train_loss: 0.00024,       train.py:144\n",
            "                             val_loss: 0.00212, lr: 6.13E-06,                   \n",
            "                             _patience: 10                                      \n",
            "[01/25/21 20:48:26] INFO     Epoch: 24 | train_loss: 0.00023,       train.py:144\n",
            "                             val_loss: 0.00212, lr: 6.13E-06,                   \n",
            "                             _patience: 9                                       \n",
            "[01/25/21 20:48:27] INFO     Epoch: 25 | train_loss: 0.00023,       train.py:144\n",
            "                             val_loss: 0.00211, lr: 6.13E-06,                   \n",
            "                             _patience: 8                                       \n",
            "[01/25/21 20:48:28] INFO     Epoch: 26 | train_loss: 0.00022,       train.py:144\n",
            "                             val_loss: 0.00210, lr: 6.13E-06,                   \n",
            "                             _patience: 7                                       \n",
            "[01/25/21 20:48:30] INFO     Epoch: 27 | train_loss: 0.00022,       train.py:144\n",
            "                             val_loss: 0.00209, lr: 7.03E-08,                   \n",
            "                             _patience: 6                                       \n",
            "[01/25/21 20:48:31] INFO     Epoch: 28 | train_loss: 0.00022,       train.py:144\n",
            "                             val_loss: 0.00209, lr: 7.03E-08,                   \n",
            "                             _patience: 5                                       \n",
            "[01/25/21 20:48:33] INFO     Epoch: 29 | train_loss: 0.00022,       train.py:144\n",
            "                             val_loss: 0.00209, lr: 7.03E-08,                   \n",
            "                             _patience: 4                                       \n",
            "[01/25/21 20:48:34] INFO     Epoch: 30 | train_loss: 0.00022,       train.py:144\n",
            "                             val_loss: 0.00209, lr: 7.03E-08,                   \n",
            "                             _patience: 3                                       \n",
            "[01/25/21 20:48:36] INFO     Epoch: 31 | train_loss: 0.00022,       train.py:144\n",
            "                             val_loss: 0.00209, lr: 7.03E-08,                   \n",
            "                             _patience: 2                                       \n",
            "[01/25/21 20:48:37] INFO     Epoch: 32 | train_loss: 0.00022,       train.py:144\n",
            "                             val_loss: 0.00209, lr: 7.03E-08,                   \n",
            "                             _patience: 1                                       \n",
            "[01/25/21 20:48:38] INFO     Stopping early!                        train.py:139\n",
            "[01/25/21 20:48:43] INFO                                            train.py:441\n",
            "                             Trial 57:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 104,                               \n",
            "                               \"embedding_dim\": 216,                            \n",
            "                               \"num_filters\": 379,                              \n",
            "                               \"hidden_dim\": 343,                               \n",
            "                               \"dropout_p\": 0.6689922288408755,                 \n",
            "                               \"lr\": 0.00023624617157304634,                    \n",
            "                               \"lr_factor\": 0.013507373998098272,               \n",
            "                               \"lr_patience\": 8,                                \n",
            "                               \"patience\": 12                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 104,                               \n",
            "                               \"embedding_dim\": 216,                            \n",
            "                               \"num_filters\": 379,                              \n",
            "                               \"hidden_dim\": 343,                               \n",
            "                               \"dropout_p\": 0.6689922288408755,                 \n",
            "                               \"lr\": 0.00023624617157304634,                    \n",
            "                               \"lr_factor\": 0.013507373998098272,               \n",
            "                               \"lr_patience\": 8,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 12,                                  \n",
            "                               \"threshold\": 0.2861778140068054                  \n",
            "                             }                                                  \n",
            "[01/25/21 20:48:45] INFO     Epoch: 1 | train_loss: 0.00593,        train.py:144\n",
            "                             val_loss: 0.00689, lr: 2.36E-04,                   \n",
            "                             _patience: 12                                      \n",
            "[01/25/21 20:48:47] INFO     Epoch: 2 | train_loss: 0.00484,        train.py:144\n",
            "                             val_loss: 0.00428, lr: 2.36E-04,                   \n",
            "                             _patience: 12                                      \n",
            "[01/25/21 20:48:49] INFO     Epoch: 3 | train_loss: 0.00365,        train.py:144\n",
            "                             val_loss: 0.00351, lr: 2.36E-04,                   \n",
            "                             _patience: 12                                      \n",
            "[01/25/21 20:48:50] INFO     Epoch: 4 | train_loss: 0.00323,        train.py:144\n",
            "                             val_loss: 0.00358, lr: 2.36E-04,                   \n",
            "                             _patience: 11                                      \n",
            "[01/25/21 20:48:52] INFO     Epoch: 5 | train_loss: 0.00300,        train.py:144\n",
            "                             val_loss: 0.00338, lr: 2.36E-04,                   \n",
            "                             _patience: 12                                      \n",
            "[01/25/21 20:48:54] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 58:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 117,                               \n",
            "                               \"embedding_dim\": 229,                            \n",
            "                               \"num_filters\": 297,                              \n",
            "                               \"hidden_dim\": 332,                               \n",
            "                               \"dropout_p\": 0.5050699797089151,                 \n",
            "                               \"lr\": 0.00028751524042092895,                    \n",
            "                               \"lr_factor\": 0.018488012906315323,               \n",
            "                               \"lr_patience\": 6,                                \n",
            "                               \"patience\": 17                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 117,                               \n",
            "                               \"embedding_dim\": 229,                            \n",
            "                               \"num_filters\": 297,                              \n",
            "                               \"hidden_dim\": 332,                               \n",
            "                               \"dropout_p\": 0.5050699797089151,                 \n",
            "                               \"lr\": 0.00028751524042092895,                    \n",
            "                               \"lr_factor\": 0.018488012906315323,               \n",
            "                               \"lr_patience\": 6,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 17,                                  \n",
            "                               \"threshold\": 0.2861778140068054                  \n",
            "                             }                                                  \n",
            "[01/25/21 20:48:56] INFO     Epoch: 1 | train_loss: 0.00545,        train.py:144\n",
            "                             val_loss: 0.00462, lr: 2.88E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:48:57] INFO     Epoch: 2 | train_loss: 0.00412,        train.py:144\n",
            "                             val_loss: 0.00305, lr: 2.88E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:48:59] INFO     Epoch: 3 | train_loss: 0.00338,        train.py:144\n",
            "                             val_loss: 0.00269, lr: 2.88E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:49:00] INFO     Epoch: 4 | train_loss: 0.00298,        train.py:144\n",
            "                             val_loss: 0.00261, lr: 2.88E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:49:02] INFO     Epoch: 5 | train_loss: 0.00266,        train.py:144\n",
            "                             val_loss: 0.00249, lr: 2.88E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:49:03] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 59:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 109,                               \n",
            "                               \"embedding_dim\": 238,                            \n",
            "                               \"num_filters\": 324,                              \n",
            "                               \"hidden_dim\": 368,                               \n",
            "                               \"dropout_p\": 0.6298964577514421,                 \n",
            "                               \"lr\": 0.00032039626143849843,                    \n",
            "                               \"lr_factor\": 0.014326782809192109,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"patience\": 19                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 109,                               \n",
            "                               \"embedding_dim\": 238,                            \n",
            "                               \"num_filters\": 324,                              \n",
            "                               \"hidden_dim\": 368,                               \n",
            "                               \"dropout_p\": 0.6298964577514421,                 \n",
            "                               \"lr\": 0.00032039626143849843,                    \n",
            "                               \"lr_factor\": 0.014326782809192109,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 19,                                  \n",
            "                               \"threshold\": 0.2861778140068054                  \n",
            "                             }                                                  \n",
            "[01/25/21 20:49:05] INFO     Epoch: 1 | train_loss: 0.00612,        train.py:144\n",
            "                             val_loss: 0.00488, lr: 3.20E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:49:07] INFO     Epoch: 2 | train_loss: 0.00465,        train.py:144\n",
            "                             val_loss: 0.00302, lr: 3.20E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:49:08] INFO     Epoch: 3 | train_loss: 0.00345,        train.py:144\n",
            "                             val_loss: 0.00270, lr: 3.20E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:49:10] INFO     Epoch: 4 | train_loss: 0.00302,        train.py:144\n",
            "                             val_loss: 0.00264, lr: 3.20E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:49:11] INFO     Epoch: 5 | train_loss: 0.00273,        train.py:144\n",
            "                             val_loss: 0.00246, lr: 3.20E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:49:13] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 60:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 121,                               \n",
            "                               \"embedding_dim\": 295,                            \n",
            "                               \"num_filters\": 278,                              \n",
            "                               \"hidden_dim\": 276,                               \n",
            "                               \"dropout_p\": 0.5960869976475198,                 \n",
            "                               \"lr\": 0.0004824461447981298,                     \n",
            "                               \"lr_factor\": 0.010085715656305623,               \n",
            "                               \"lr_patience\": 9,                                \n",
            "                               \"patience\": 14                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 121,                               \n",
            "                               \"embedding_dim\": 295,                            \n",
            "                               \"num_filters\": 278,                              \n",
            "                               \"hidden_dim\": 276,                               \n",
            "                               \"dropout_p\": 0.5960869976475198,                 \n",
            "                               \"lr\": 0.0004824461447981298,                     \n",
            "                               \"lr_factor\": 0.010085715656305623,               \n",
            "                               \"lr_patience\": 9,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 14,                                  \n",
            "                               \"threshold\": 0.2861778140068054                  \n",
            "                             }                                                  \n",
            "[01/25/21 20:49:15] INFO     Epoch: 1 | train_loss: 0.00643,        train.py:144\n",
            "                             val_loss: 0.00498, lr: 4.82E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 20:49:17] INFO     Epoch: 2 | train_loss: 0.00450,        train.py:144\n",
            "                             val_loss: 0.00284, lr: 4.82E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 20:49:19] INFO     Epoch: 3 | train_loss: 0.00338,        train.py:144\n",
            "                             val_loss: 0.00273, lr: 4.82E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 20:49:20] INFO     Epoch: 4 | train_loss: 0.00295,        train.py:144\n",
            "                             val_loss: 0.00256, lr: 4.82E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 20:49:22] INFO     Epoch: 5 | train_loss: 0.00259,        train.py:144\n",
            "                             val_loss: 0.00237, lr: 4.82E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 20:49:24] INFO     Epoch: 6 | train_loss: 0.00228,        train.py:144\n",
            "                             val_loss: 0.00218, lr: 4.82E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 20:49:26] INFO     Epoch: 7 | train_loss: 0.00202,        train.py:144\n",
            "                             val_loss: 0.00204, lr: 4.82E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 20:49:27] INFO     Epoch: 8 | train_loss: 0.00173,        train.py:144\n",
            "                             val_loss: 0.00195, lr: 4.82E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 20:49:29] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 61:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 108,                               \n",
            "                               \"embedding_dim\": 215,                            \n",
            "                               \"num_filters\": 313,                              \n",
            "                               \"hidden_dim\": 263,                               \n",
            "                               \"dropout_p\": 0.7004285308418966,                 \n",
            "                               \"lr\": 0.00055845660014009,                       \n",
            "                               \"lr_factor\": 0.015702610209367873,               \n",
            "                               \"lr_patience\": 5,                                \n",
            "                               \"patience\": 20                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 108,                               \n",
            "                               \"embedding_dim\": 215,                            \n",
            "                               \"num_filters\": 313,                              \n",
            "                               \"hidden_dim\": 263,                               \n",
            "                               \"dropout_p\": 0.7004285308418966,                 \n",
            "                               \"lr\": 0.00055845660014009,                       \n",
            "                               \"lr_factor\": 0.015702610209367873,               \n",
            "                               \"lr_patience\": 5,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 20,                                  \n",
            "                               \"threshold\": 0.2861778140068054                  \n",
            "                             }                                                  \n",
            "[01/25/21 20:49:31] INFO     Epoch: 1 | train_loss: 0.00780,        train.py:144\n",
            "                             val_loss: 0.00511, lr: 5.58E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:49:32] INFO     Epoch: 2 | train_loss: 0.00489,        train.py:144\n",
            "                             val_loss: 0.00286, lr: 5.58E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:49:34] INFO     Epoch: 3 | train_loss: 0.00350,        train.py:144\n",
            "                             val_loss: 0.00278, lr: 5.58E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:49:36] INFO     Epoch: 4 | train_loss: 0.00308,        train.py:144\n",
            "                             val_loss: 0.00261, lr: 5.58E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:49:37] INFO     Epoch: 5 | train_loss: 0.00274,        train.py:144\n",
            "                             val_loss: 0.00246, lr: 5.58E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:49:39] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 62:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 111,                               \n",
            "                               \"embedding_dim\": 207,                            \n",
            "                               \"num_filters\": 298,                              \n",
            "                               \"hidden_dim\": 256,                               \n",
            "                               \"dropout_p\": 0.6333882039551306,                 \n",
            "                               \"lr\": 0.00035942033499878555,                    \n",
            "                               \"lr_factor\": 0.014929324044598869,               \n",
            "                               \"lr_patience\": 5,                                \n",
            "                               \"patience\": 20                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 111,                               \n",
            "                               \"embedding_dim\": 207,                            \n",
            "                               \"num_filters\": 298,                              \n",
            "                               \"hidden_dim\": 256,                               \n",
            "                               \"dropout_p\": 0.6333882039551306,                 \n",
            "                               \"lr\": 0.00035942033499878555,                    \n",
            "                               \"lr_factor\": 0.014929324044598869,               \n",
            "                               \"lr_patience\": 5,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 20,                                  \n",
            "                               \"threshold\": 0.2861778140068054                  \n",
            "                             }                                                  \n",
            "[01/25/21 20:49:40] INFO     Epoch: 1 | train_loss: 0.00584,        train.py:144\n",
            "                             val_loss: 0.00474, lr: 3.59E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:49:42] INFO     Epoch: 2 | train_loss: 0.00466,        train.py:144\n",
            "                             val_loss: 0.00297, lr: 3.59E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:49:43] INFO     Epoch: 3 | train_loss: 0.00356,        train.py:144\n",
            "                             val_loss: 0.00271, lr: 3.59E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:49:45] INFO     Epoch: 4 | train_loss: 0.00307,        train.py:144\n",
            "                             val_loss: 0.00267, lr: 3.59E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:49:46] INFO     Epoch: 5 | train_loss: 0.00284,        train.py:144\n",
            "                             val_loss: 0.00253, lr: 3.59E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:49:48] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 63:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 104,                               \n",
            "                               \"embedding_dim\": 213,                            \n",
            "                               \"num_filters\": 286,                              \n",
            "                               \"hidden_dim\": 291,                               \n",
            "                               \"dropout_p\": 0.656177809928817,                  \n",
            "                               \"lr\": 0.00039843985520738695,                    \n",
            "                               \"lr_factor\": 0.012168382614329688,               \n",
            "                               \"lr_patience\": 5,                                \n",
            "                               \"patience\": 19                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 104,                               \n",
            "                               \"embedding_dim\": 213,                            \n",
            "                               \"num_filters\": 286,                              \n",
            "                               \"hidden_dim\": 291,                               \n",
            "                               \"dropout_p\": 0.656177809928817,                  \n",
            "                               \"lr\": 0.00039843985520738695,                    \n",
            "                               \"lr_factor\": 0.012168382614329688,               \n",
            "                               \"lr_patience\": 5,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 19,                                  \n",
            "                               \"threshold\": 0.2861778140068054                  \n",
            "                             }                                                  \n",
            "[01/25/21 20:49:50] INFO     Epoch: 1 | train_loss: 0.00637,        train.py:144\n",
            "                             val_loss: 0.00689, lr: 3.98E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:49:51] INFO     Epoch: 2 | train_loss: 0.00487,        train.py:144\n",
            "                             val_loss: 0.00390, lr: 3.98E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:49:52] INFO     Epoch: 3 | train_loss: 0.00364,        train.py:144\n",
            "                             val_loss: 0.00353, lr: 3.98E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:49:54] INFO     Epoch: 4 | train_loss: 0.00310,        train.py:144\n",
            "                             val_loss: 0.00353, lr: 3.98E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:49:55] INFO     Epoch: 5 | train_loss: 0.00283,        train.py:144\n",
            "                             val_loss: 0.00327, lr: 3.98E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:49:57] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 64:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 113,                               \n",
            "                               \"embedding_dim\": 224,                            \n",
            "                               \"num_filters\": 337,                              \n",
            "                               \"hidden_dim\": 283,                               \n",
            "                               \"dropout_p\": 0.6796794805583606,                 \n",
            "                               \"lr\": 0.0005366718950823072,                     \n",
            "                               \"lr_factor\": 0.015783232995365,                  \n",
            "                               \"lr_patience\": 5,                                \n",
            "                               \"patience\": 18                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 113,                               \n",
            "                               \"embedding_dim\": 224,                            \n",
            "                               \"num_filters\": 337,                              \n",
            "                               \"hidden_dim\": 283,                               \n",
            "                               \"dropout_p\": 0.6796794805583606,                 \n",
            "                               \"lr\": 0.0005366718950823072,                     \n",
            "                               \"lr_factor\": 0.015783232995365,                  \n",
            "                               \"lr_patience\": 5,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 18,                                  \n",
            "                               \"threshold\": 0.2861778140068054                  \n",
            "                             }                                                  \n",
            "[01/25/21 20:49:59] INFO     Epoch: 1 | train_loss: 0.00777,        train.py:144\n",
            "                             val_loss: 0.00567, lr: 5.37E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:50:00] INFO     Epoch: 2 | train_loss: 0.00529,        train.py:144\n",
            "                             val_loss: 0.00290, lr: 5.37E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:50:02] INFO     Epoch: 3 | train_loss: 0.00369,        train.py:144\n",
            "                             val_loss: 0.00275, lr: 5.37E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:50:04] INFO     Epoch: 4 | train_loss: 0.00317,        train.py:144\n",
            "                             val_loss: 0.00268, lr: 5.37E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:50:05] INFO     Epoch: 5 | train_loss: 0.00284,        train.py:144\n",
            "                             val_loss: 0.00247, lr: 5.37E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:50:07] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 65:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 101,                               \n",
            "                               \"embedding_dim\": 220,                            \n",
            "                               \"num_filters\": 358,                              \n",
            "                               \"hidden_dim\": 301,                               \n",
            "                               \"dropout_p\": 0.5291859058870156,                 \n",
            "                               \"lr\": 0.0006486175789967085,                     \n",
            "                               \"lr_factor\": 0.01299389831480524,                \n",
            "                               \"lr_patience\": 6,                                \n",
            "                               \"patience\": 20                                   \n",
            "                             }                                                  \n",
            "[01/25/21 20:50:08] INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 101,                               \n",
            "                               \"embedding_dim\": 220,                            \n",
            "                               \"num_filters\": 358,                              \n",
            "                               \"hidden_dim\": 301,                               \n",
            "                               \"dropout_p\": 0.5291859058870156,                 \n",
            "                               \"lr\": 0.0006486175789967085,                     \n",
            "                               \"lr_factor\": 0.01299389831480524,                \n",
            "                               \"lr_patience\": 6,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 20,                                  \n",
            "                               \"threshold\": 0.2861778140068054                  \n",
            "                             }                                                  \n",
            "[01/25/21 20:50:09] INFO     Epoch: 1 | train_loss: 0.00814,        train.py:144\n",
            "                             val_loss: 0.00677, lr: 6.49E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:50:11] INFO     Epoch: 2 | train_loss: 0.00474,        train.py:144\n",
            "                             val_loss: 0.00344, lr: 6.49E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:50:13] INFO     Epoch: 3 | train_loss: 0.00340,        train.py:144\n",
            "                             val_loss: 0.00335, lr: 6.49E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:50:15] INFO     Epoch: 4 | train_loss: 0.00292,        train.py:144\n",
            "                             val_loss: 0.00310, lr: 6.49E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:50:16] INFO     Epoch: 5 | train_loss: 0.00255,        train.py:144\n",
            "                             val_loss: 0.00296, lr: 6.49E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:50:18] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 66:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 119,                               \n",
            "                               \"embedding_dim\": 219,                            \n",
            "                               \"num_filters\": 324,                              \n",
            "                               \"hidden_dim\": 259,                               \n",
            "                               \"dropout_p\": 0.6097126618817353,                 \n",
            "                               \"lr\": 0.00047106573362881243,                    \n",
            "                               \"lr_factor\": 0.018644595575114883,               \n",
            "                               \"lr_patience\": 5,                                \n",
            "                               \"patience\": 19                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 119,                               \n",
            "                               \"embedding_dim\": 219,                            \n",
            "                               \"num_filters\": 324,                              \n",
            "                               \"hidden_dim\": 259,                               \n",
            "                               \"dropout_p\": 0.6097126618817353,                 \n",
            "                               \"lr\": 0.00047106573362881243,                    \n",
            "                               \"lr_factor\": 0.018644595575114883,               \n",
            "                               \"lr_patience\": 5,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 19,                                  \n",
            "                               \"threshold\": 0.2861778140068054                  \n",
            "                             }                                                  \n",
            "[01/25/21 20:50:20] INFO     Epoch: 1 | train_loss: 0.00688,        train.py:144\n",
            "                             val_loss: 0.00531, lr: 4.71E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:50:22] INFO     Epoch: 2 | train_loss: 0.00490,        train.py:144\n",
            "                             val_loss: 0.00295, lr: 4.71E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:50:23] INFO     Epoch: 3 | train_loss: 0.00362,        train.py:144\n",
            "                             val_loss: 0.00270, lr: 4.71E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:50:25] INFO     Epoch: 4 | train_loss: 0.00305,        train.py:144\n",
            "                             val_loss: 0.00265, lr: 4.71E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:50:26] INFO     Epoch: 5 | train_loss: 0.00274,        train.py:144\n",
            "                             val_loss: 0.00241, lr: 4.71E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:50:28] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 67:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 126,                               \n",
            "                               \"embedding_dim\": 231,                            \n",
            "                               \"num_filters\": 308,                              \n",
            "                               \"hidden_dim\": 413,                               \n",
            "                               \"dropout_p\": 0.3122689283934166,                 \n",
            "                               \"lr\": 0.00037235593664360897,                    \n",
            "                               \"lr_factor\": 0.04577288215056255,                \n",
            "                               \"lr_patience\": 6,                                \n",
            "                               \"patience\": 13                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 126,                               \n",
            "                               \"embedding_dim\": 231,                            \n",
            "                               \"num_filters\": 308,                              \n",
            "                               \"hidden_dim\": 413,                               \n",
            "                               \"dropout_p\": 0.3122689283934166,                 \n",
            "                               \"lr\": 0.00037235593664360897,                    \n",
            "                               \"lr_factor\": 0.04577288215056255,                \n",
            "                               \"lr_patience\": 6,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 13,                                  \n",
            "                               \"threshold\": 0.2861778140068054                  \n",
            "                             }                                                  \n",
            "[01/25/21 20:50:30] INFO     Epoch: 1 | train_loss: 0.00577,        train.py:144\n",
            "                             val_loss: 0.00495, lr: 3.72E-04,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 20:50:31] INFO     Epoch: 2 | train_loss: 0.00402,        train.py:144\n",
            "                             val_loss: 0.00297, lr: 3.72E-04,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 20:50:33] INFO     Epoch: 3 | train_loss: 0.00315,        train.py:144\n",
            "                             val_loss: 0.00273, lr: 3.72E-04,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 20:50:34] INFO     Epoch: 4 | train_loss: 0.00273,        train.py:144\n",
            "                             val_loss: 0.00268, lr: 3.72E-04,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 20:50:36] INFO     Epoch: 5 | train_loss: 0.00245,        train.py:144\n",
            "                             val_loss: 0.00242, lr: 3.72E-04,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 20:50:37] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 68:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 95,                                \n",
            "                               \"embedding_dim\": 211,                            \n",
            "                               \"num_filters\": 328,                              \n",
            "                               \"hidden_dim\": 377,                               \n",
            "                               \"dropout_p\": 0.7197114539076421,                 \n",
            "                               \"lr\": 0.00042921922581971704,                    \n",
            "                               \"lr_factor\": 0.011636800253925633,               \n",
            "                               \"lr_patience\": 5,                                \n",
            "                               \"patience\": 19                                   \n",
            "                             }                                                  \n",
            "[01/25/21 20:50:38] INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 95,                                \n",
            "                               \"embedding_dim\": 211,                            \n",
            "                               \"num_filters\": 328,                              \n",
            "                               \"hidden_dim\": 377,                               \n",
            "                               \"dropout_p\": 0.7197114539076421,                 \n",
            "                               \"lr\": 0.00042921922581971704,                    \n",
            "                               \"lr_factor\": 0.011636800253925633,               \n",
            "                               \"lr_patience\": 5,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 19,                                  \n",
            "                               \"threshold\": 0.2861778140068054                  \n",
            "                             }                                                  \n",
            "[01/25/21 20:50:39] INFO     Epoch: 1 | train_loss: 0.00735,        train.py:144\n",
            "                             val_loss: 0.00584, lr: 4.29E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:50:41] INFO     Epoch: 2 | train_loss: 0.00499,        train.py:144\n",
            "                             val_loss: 0.00300, lr: 4.29E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:50:42] INFO     Epoch: 3 | train_loss: 0.00350,        train.py:144\n",
            "                             val_loss: 0.00291, lr: 4.29E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:50:44] INFO     Epoch: 4 | train_loss: 0.00311,        train.py:144\n",
            "                             val_loss: 0.00278, lr: 4.29E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:50:45] INFO     Epoch: 5 | train_loss: 0.00277,        train.py:144\n",
            "                             val_loss: 0.00260, lr: 4.29E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:50:47] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 69:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 106,                               \n",
            "                               \"embedding_dim\": 245,                            \n",
            "                               \"num_filters\": 299,                              \n",
            "                               \"hidden_dim\": 384,                               \n",
            "                               \"dropout_p\": 0.585924774841504,                  \n",
            "                               \"lr\": 0.00027167478536029737,                    \n",
            "                               \"lr_factor\": 0.021801712336118887,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"patience\": 14                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 106,                               \n",
            "                               \"embedding_dim\": 245,                            \n",
            "                               \"num_filters\": 299,                              \n",
            "                               \"hidden_dim\": 384,                               \n",
            "                               \"dropout_p\": 0.585924774841504,                  \n",
            "                               \"lr\": 0.00027167478536029737,                    \n",
            "                               \"lr_factor\": 0.021801712336118887,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 14,                                  \n",
            "                               \"threshold\": 0.2861778140068054                  \n",
            "                             }                                                  \n",
            "[01/25/21 20:50:48] INFO     Epoch: 1 | train_loss: 0.00544,        train.py:144\n",
            "                             val_loss: 0.00565, lr: 2.72E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 20:50:50] INFO     Epoch: 2 | train_loss: 0.00421,        train.py:144\n",
            "                             val_loss: 0.00348, lr: 2.72E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 20:50:52] INFO     Epoch: 3 | train_loss: 0.00340,        train.py:144\n",
            "                             val_loss: 0.00309, lr: 2.72E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 20:50:53] INFO     Epoch: 4 | train_loss: 0.00295,        train.py:144\n",
            "                             val_loss: 0.00307, lr: 2.72E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 20:50:55] INFO     Epoch: 5 | train_loss: 0.00271,        train.py:144\n",
            "                             val_loss: 0.00291, lr: 2.72E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 20:50:56] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 70:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 123,                               \n",
            "                               \"embedding_dim\": 270,                            \n",
            "                               \"num_filters\": 375,                              \n",
            "                               \"hidden_dim\": 359,                               \n",
            "                               \"dropout_p\": 0.7407084057664066,                 \n",
            "                               \"lr\": 8.215616367387529e-05,                     \n",
            "                               \"lr_factor\": 0.01324615253476134,                \n",
            "                               \"lr_patience\": 6,                                \n",
            "                               \"patience\": 15                                   \n",
            "                             }                                                  \n",
            "[01/25/21 20:50:57] INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 123,                               \n",
            "                               \"embedding_dim\": 270,                            \n",
            "                               \"num_filters\": 375,                              \n",
            "                               \"hidden_dim\": 359,                               \n",
            "                               \"dropout_p\": 0.7407084057664066,                 \n",
            "                               \"lr\": 8.215616367387529e-05,                     \n",
            "                               \"lr_factor\": 0.01324615253476134,                \n",
            "                               \"lr_patience\": 6,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 15,                                  \n",
            "                               \"threshold\": 0.2861778140068054                  \n",
            "                             }                                                  \n",
            "[01/25/21 20:50:59] INFO     Epoch: 1 | train_loss: 0.00625,        train.py:144\n",
            "                             val_loss: 0.00307, lr: 8.22E-05,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 20:51:01] INFO     Epoch: 2 | train_loss: 0.00441,        train.py:144\n",
            "                             val_loss: 0.00342, lr: 8.22E-05,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 20:51:03] INFO     Epoch: 3 | train_loss: 0.00425,        train.py:144\n",
            "                             val_loss: 0.00315, lr: 8.22E-05,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 20:51:05] INFO     Epoch: 4 | train_loss: 0.00381,        train.py:144\n",
            "                             val_loss: 0.00284, lr: 8.22E-05,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 20:51:07] INFO     Epoch: 5 | train_loss: 0.00357,        train.py:144\n",
            "                             val_loss: 0.00275, lr: 8.22E-05,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 20:51:09] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 71:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 83,                                \n",
            "                               \"embedding_dim\": 203,                            \n",
            "                               \"num_filters\": 478,                              \n",
            "                               \"hidden_dim\": 466,                               \n",
            "                               \"dropout_p\": 0.4679815245177566,                 \n",
            "                               \"lr\": 0.0001229920615353193,                     \n",
            "                               \"lr_factor\": 0.049963870427032674,               \n",
            "                               \"lr_patience\": 10,                               \n",
            "                               \"patience\": 16                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 83,                                \n",
            "                               \"embedding_dim\": 203,                            \n",
            "                               \"num_filters\": 478,                              \n",
            "                               \"hidden_dim\": 466,                               \n",
            "                               \"dropout_p\": 0.4679815245177566,                 \n",
            "                               \"lr\": 0.0001229920615353193,                     \n",
            "                               \"lr_factor\": 0.049963870427032674,               \n",
            "                               \"lr_patience\": 10,                               \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 16,                                  \n",
            "                               \"threshold\": 0.2861778140068054                  \n",
            "                             }                                                  \n",
            "[01/25/21 20:51:11] INFO     Epoch: 1 | train_loss: 0.00476,        train.py:144\n",
            "                             val_loss: 0.00446, lr: 1.23E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:51:13] INFO     Epoch: 2 | train_loss: 0.00367,        train.py:144\n",
            "                             val_loss: 0.00302, lr: 1.23E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:51:15] INFO     Epoch: 3 | train_loss: 0.00304,        train.py:144\n",
            "                             val_loss: 0.00278, lr: 1.23E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:51:17] INFO     Epoch: 4 | train_loss: 0.00273,        train.py:144\n",
            "                             val_loss: 0.00274, lr: 1.23E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:51:19] INFO     Epoch: 5 | train_loss: 0.00258,        train.py:144\n",
            "                             val_loss: 0.00261, lr: 1.23E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:51:22] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 72:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 72,                                \n",
            "                               \"embedding_dim\": 208,                            \n",
            "                               \"num_filters\": 433,                              \n",
            "                               \"hidden_dim\": 478,                               \n",
            "                               \"dropout_p\": 0.507921040621207,                  \n",
            "                               \"lr\": 0.0005105214869352019,                     \n",
            "                               \"lr_factor\": 0.02918382012739884,                \n",
            "                               \"lr_patience\": 9,                                \n",
            "                               \"patience\": 17                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 72,                                \n",
            "                               \"embedding_dim\": 208,                            \n",
            "                               \"num_filters\": 433,                              \n",
            "                               \"hidden_dim\": 478,                               \n",
            "                               \"dropout_p\": 0.507921040621207,                  \n",
            "                               \"lr\": 0.0005105214869352019,                     \n",
            "                               \"lr_factor\": 0.02918382012739884,                \n",
            "                               \"lr_patience\": 9,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 17,                                  \n",
            "                               \"threshold\": 0.2861778140068054                  \n",
            "                             }                                                  \n",
            "[01/25/21 20:51:24] INFO     Epoch: 1 | train_loss: 0.00752,        train.py:144\n",
            "                             val_loss: 0.00394, lr: 5.11E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:51:26] INFO     Epoch: 2 | train_loss: 0.00384,        train.py:144\n",
            "                             val_loss: 0.00280, lr: 5.11E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:51:28] INFO     Epoch: 3 | train_loss: 0.00291,        train.py:144\n",
            "                             val_loss: 0.00261, lr: 5.11E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:51:30] INFO     Epoch: 4 | train_loss: 0.00247,        train.py:144\n",
            "                             val_loss: 0.00237, lr: 5.11E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:51:31] INFO     Epoch: 5 | train_loss: 0.00203,        train.py:144\n",
            "                             val_loss: 0.00211, lr: 5.11E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:51:33] INFO     Epoch: 6 | train_loss: 0.00176,        train.py:144\n",
            "                             val_loss: 0.00197, lr: 5.11E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:51:35] INFO     Epoch: 7 | train_loss: 0.00152,        train.py:144\n",
            "                             val_loss: 0.00184, lr: 5.11E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:51:37] INFO     Epoch: 8 | train_loss: 0.00131,        train.py:144\n",
            "                             val_loss: 0.00177, lr: 5.11E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:51:39] INFO     Epoch: 9 | train_loss: 0.00107,        train.py:144\n",
            "                             val_loss: 0.00172, lr: 5.11E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:51:41] INFO     Epoch: 10 | train_loss: 0.00088,       train.py:144\n",
            "                             val_loss: 0.00169, lr: 5.11E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:51:43] INFO     Epoch: 11 | train_loss: 0.00075,       train.py:144\n",
            "                             val_loss: 0.00169, lr: 5.11E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:51:45] INFO     Epoch: 12 | train_loss: 0.00063,       train.py:144\n",
            "                             val_loss: 0.00170, lr: 5.11E-04,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 20:51:47] INFO     Epoch: 13 | train_loss: 0.00053,       train.py:144\n",
            "                             val_loss: 0.00169, lr: 5.11E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 20:51:49] INFO     Epoch: 14 | train_loss: 0.00044,       train.py:144\n",
            "                             val_loss: 0.00172, lr: 5.11E-04,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 20:51:51] INFO     Epoch: 15 | train_loss: 0.00038,       train.py:144\n",
            "                             val_loss: 0.00180, lr: 5.11E-04,                   \n",
            "                             _patience: 12                                      \n",
            "[01/25/21 20:51:53] INFO     Epoch: 16 | train_loss: 0.00034,       train.py:144\n",
            "                             val_loss: 0.00187, lr: 5.11E-04,                   \n",
            "                             _patience: 11                                      \n",
            "[01/25/21 20:51:55] INFO     Epoch: 17 | train_loss: 0.00031,       train.py:144\n",
            "                             val_loss: 0.00192, lr: 5.11E-04,                   \n",
            "                             _patience: 10                                      \n",
            "[01/25/21 20:51:57] INFO     Epoch: 18 | train_loss: 0.00027,       train.py:144\n",
            "                             val_loss: 0.00200, lr: 5.11E-04,                   \n",
            "                             _patience: 9                                       \n",
            "[01/25/21 20:51:59] INFO     Epoch: 19 | train_loss: 0.00025,       train.py:144\n",
            "                             val_loss: 0.00219, lr: 5.11E-04,                   \n",
            "                             _patience: 8                                       \n",
            "[01/25/21 20:52:00] INFO     Epoch: 20 | train_loss: 0.00024,       train.py:144\n",
            "                             val_loss: 0.00223, lr: 1.49E-05,                   \n",
            "                             _patience: 7                                       \n",
            "[01/25/21 20:52:02] INFO     Epoch: 21 | train_loss: 0.00021,       train.py:144\n",
            "                             val_loss: 0.00215, lr: 1.49E-05,                   \n",
            "                             _patience: 6                                       \n",
            "[01/25/21 20:52:04] INFO     Epoch: 22 | train_loss: 0.00019,       train.py:144\n",
            "                             val_loss: 0.00210, lr: 1.49E-05,                   \n",
            "                             _patience: 5                                       \n",
            "[01/25/21 20:52:06] INFO     Epoch: 23 | train_loss: 0.00017,       train.py:144\n",
            "                             val_loss: 0.00208, lr: 1.49E-05,                   \n",
            "                             _patience: 4                                       \n",
            "[01/25/21 20:52:08] INFO     Epoch: 24 | train_loss: 0.00016,       train.py:144\n",
            "                             val_loss: 0.00206, lr: 1.49E-05,                   \n",
            "                             _patience: 3                                       \n",
            "[01/25/21 20:52:10] INFO     Epoch: 25 | train_loss: 0.00015,       train.py:144\n",
            "                             val_loss: 0.00205, lr: 1.49E-05,                   \n",
            "                             _patience: 2                                       \n",
            "[01/25/21 20:52:12] INFO     Epoch: 26 | train_loss: 0.00016,       train.py:144\n",
            "                             val_loss: 0.00206, lr: 1.49E-05,                   \n",
            "                             _patience: 1                                       \n",
            "[01/25/21 20:52:14] INFO     Stopping early!                        train.py:139\n",
            "[01/25/21 20:52:20] INFO                                            train.py:441\n",
            "                             Trial 73:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 90,                                \n",
            "                               \"embedding_dim\": 216,                            \n",
            "                               \"num_filters\": 315,                              \n",
            "                               \"hidden_dim\": 439,                               \n",
            "                               \"dropout_p\": 0.6439659280601928,                 \n",
            "                               \"lr\": 0.00034132410258556943,                    \n",
            "                               \"lr_factor\": 0.0252523145428287,                 \n",
            "                               \"lr_patience\": 10,                               \n",
            "                               \"patience\": 18                                   \n",
            "                             }                                                  \n",
            "[01/25/21 20:52:21] INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 90,                                \n",
            "                               \"embedding_dim\": 216,                            \n",
            "                               \"num_filters\": 315,                              \n",
            "                               \"hidden_dim\": 439,                               \n",
            "                               \"dropout_p\": 0.6439659280601928,                 \n",
            "                               \"lr\": 0.00034132410258556943,                    \n",
            "                               \"lr_factor\": 0.0252523145428287,                 \n",
            "                               \"lr_patience\": 10,                               \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 18,                                  \n",
            "                               \"threshold\": 0.3101758360862732                  \n",
            "                             }                                                  \n",
            "[01/25/21 20:52:22] INFO     Epoch: 1 | train_loss: 0.00605,        train.py:144\n",
            "                             val_loss: 0.00447, lr: 3.41E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:52:24] INFO     Epoch: 2 | train_loss: 0.00420,        train.py:144\n",
            "                             val_loss: 0.00291, lr: 3.41E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:52:25] INFO     Epoch: 3 | train_loss: 0.00316,        train.py:144\n",
            "                             val_loss: 0.00279, lr: 3.41E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:52:26] INFO     Epoch: 4 | train_loss: 0.00282,        train.py:144\n",
            "                             val_loss: 0.00263, lr: 3.41E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:52:28] INFO     Epoch: 5 | train_loss: 0.00250,        train.py:144\n",
            "                             val_loss: 0.00248, lr: 3.41E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:52:29] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 74:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 78,                                \n",
            "                               \"embedding_dim\": 223,                            \n",
            "                               \"num_filters\": 350,                              \n",
            "                               \"hidden_dim\": 320,                               \n",
            "                               \"dropout_p\": 0.5572988060133971,                 \n",
            "                               \"lr\": 0.00039675502926783717,                    \n",
            "                               \"lr_factor\": 0.04005803160786183,                \n",
            "                               \"lr_patience\": 10,                               \n",
            "                               \"patience\": 16                                   \n",
            "                             }                                                  \n",
            "[01/25/21 20:52:30] INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 78,                                \n",
            "                               \"embedding_dim\": 223,                            \n",
            "                               \"num_filters\": 350,                              \n",
            "                               \"hidden_dim\": 320,                               \n",
            "                               \"dropout_p\": 0.5572988060133971,                 \n",
            "                               \"lr\": 0.00039675502926783717,                    \n",
            "                               \"lr_factor\": 0.04005803160786183,                \n",
            "                               \"lr_patience\": 10,                               \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 16,                                  \n",
            "                               \"threshold\": 0.3101758360862732                  \n",
            "                             }                                                  \n",
            "[01/25/21 20:52:31] INFO     Epoch: 1 | train_loss: 0.00603,        train.py:144\n",
            "                             val_loss: 0.00394, lr: 3.97E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:52:33] INFO     Epoch: 2 | train_loss: 0.00398,        train.py:144\n",
            "                             val_loss: 0.00276, lr: 3.97E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:52:34] INFO     Epoch: 3 | train_loss: 0.00304,        train.py:144\n",
            "                             val_loss: 0.00264, lr: 3.97E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:52:36] INFO     Epoch: 4 | train_loss: 0.00262,        train.py:144\n",
            "                             val_loss: 0.00235, lr: 3.97E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:52:38] INFO     Epoch: 5 | train_loss: 0.00222,        train.py:144\n",
            "                             val_loss: 0.00215, lr: 3.97E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:52:39] INFO     Epoch: 6 | train_loss: 0.00195,        train.py:144\n",
            "                             val_loss: 0.00202, lr: 3.97E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:52:41] INFO     Epoch: 7 | train_loss: 0.00169,        train.py:144\n",
            "                             val_loss: 0.00189, lr: 3.97E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:52:43] INFO     Epoch: 8 | train_loss: 0.00150,        train.py:144\n",
            "                             val_loss: 0.00179, lr: 3.97E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:52:44] INFO     Epoch: 9 | train_loss: 0.00133,        train.py:144\n",
            "                             val_loss: 0.00176, lr: 3.97E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:52:46] INFO     Epoch: 10 | train_loss: 0.00119,       train.py:144\n",
            "                             val_loss: 0.00170, lr: 3.97E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:52:47] INFO     Epoch: 11 | train_loss: 0.00102,       train.py:144\n",
            "                             val_loss: 0.00169, lr: 3.97E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:52:49] INFO     Epoch: 12 | train_loss: 0.00091,       train.py:144\n",
            "                             val_loss: 0.00167, lr: 3.97E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:52:51] INFO     Epoch: 13 | train_loss: 0.00079,       train.py:144\n",
            "                             val_loss: 0.00168, lr: 3.97E-04,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 20:52:52] INFO     Epoch: 14 | train_loss: 0.00068,       train.py:144\n",
            "                             val_loss: 0.00168, lr: 3.97E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 20:52:54] INFO     Epoch: 15 | train_loss: 0.00065,       train.py:144\n",
            "                             val_loss: 0.00166, lr: 3.97E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:52:56] INFO     Epoch: 16 | train_loss: 0.00056,       train.py:144\n",
            "                             val_loss: 0.00171, lr: 3.97E-04,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 20:52:57] INFO     Epoch: 17 | train_loss: 0.00050,       train.py:144\n",
            "                             val_loss: 0.00179, lr: 3.97E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 20:52:59] INFO     Epoch: 18 | train_loss: 0.00047,       train.py:144\n",
            "                             val_loss: 0.00173, lr: 3.97E-04,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 20:53:00] INFO     Epoch: 19 | train_loss: 0.00044,       train.py:144\n",
            "                             val_loss: 0.00172, lr: 3.97E-04,                   \n",
            "                             _patience: 12                                      \n",
            "[01/25/21 20:53:02] INFO     Epoch: 20 | train_loss: 0.00037,       train.py:144\n",
            "                             val_loss: 0.00175, lr: 3.97E-04,                   \n",
            "                             _patience: 11                                      \n",
            "[01/25/21 20:53:04] INFO     Epoch: 21 | train_loss: 0.00036,       train.py:144\n",
            "                             val_loss: 0.00175, lr: 3.97E-04,                   \n",
            "                             _patience: 10                                      \n",
            "[01/25/21 20:53:05] INFO     Epoch: 22 | train_loss: 0.00034,       train.py:144\n",
            "                             val_loss: 0.00188, lr: 3.97E-04,                   \n",
            "                             _patience: 9                                       \n",
            "[01/25/21 20:53:07] INFO     Epoch: 23 | train_loss: 0.00033,       train.py:144\n",
            "                             val_loss: 0.00182, lr: 3.97E-04,                   \n",
            "                             _patience: 8                                       \n",
            "[01/25/21 20:53:09] INFO     Epoch: 24 | train_loss: 0.00030,       train.py:144\n",
            "                             val_loss: 0.00179, lr: 3.97E-04,                   \n",
            "                             _patience: 7                                       \n",
            "[01/25/21 20:53:10] INFO     Epoch: 25 | train_loss: 0.00032,       train.py:144\n",
            "                             val_loss: 0.00175, lr: 3.97E-04,                   \n",
            "                             _patience: 6                                       \n",
            "[01/25/21 20:53:12] INFO     Epoch: 26 | train_loss: 0.00029,       train.py:144\n",
            "                             val_loss: 0.00189, lr: 1.59E-05,                   \n",
            "                             _patience: 5                                       \n",
            "[01/25/21 20:53:13] INFO     Epoch: 27 | train_loss: 0.00029,       train.py:144\n",
            "                             val_loss: 0.00196, lr: 1.59E-05,                   \n",
            "                             _patience: 4                                       \n",
            "[01/25/21 20:53:15] INFO     Epoch: 28 | train_loss: 0.00022,       train.py:144\n",
            "                             val_loss: 0.00212, lr: 1.59E-05,                   \n",
            "                             _patience: 3                                       \n",
            "[01/25/21 20:53:17] INFO     Epoch: 29 | train_loss: 0.00022,       train.py:144\n",
            "                             val_loss: 0.00213, lr: 1.59E-05,                   \n",
            "                             _patience: 2                                       \n",
            "[01/25/21 20:53:18] INFO     Epoch: 30 | train_loss: 0.00022,       train.py:144\n",
            "                             val_loss: 0.00207, lr: 1.59E-05,                   \n",
            "                             _patience: 1                                       \n",
            "[01/25/21 20:53:20] INFO     Stopping early!                        train.py:139\n",
            "[01/25/21 20:53:25] INFO                                            train.py:441\n",
            "                             Trial 75:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 110,                               \n",
            "                               \"embedding_dim\": 205,                            \n",
            "                               \"num_filters\": 399,                              \n",
            "                               \"hidden_dim\": 444,                               \n",
            "                               \"dropout_p\": 0.6891983428342147,                 \n",
            "                               \"lr\": 0.0003076401793725756,                     \n",
            "                               \"lr_factor\": 0.03496420360230065,                \n",
            "                               \"lr_patience\": 8,                                \n",
            "                               \"patience\": 18                                   \n",
            "                             }                                                  \n",
            "[01/25/21 20:53:26] INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 110,                               \n",
            "                               \"embedding_dim\": 205,                            \n",
            "                               \"num_filters\": 399,                              \n",
            "                               \"hidden_dim\": 444,                               \n",
            "                               \"dropout_p\": 0.6891983428342147,                 \n",
            "                               \"lr\": 0.0003076401793725756,                     \n",
            "                               \"lr_factor\": 0.03496420360230065,                \n",
            "                               \"lr_patience\": 8,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 18,                                  \n",
            "                               \"threshold\": 0.3386393189430237                  \n",
            "                             }                                                  \n",
            "[01/25/21 20:53:28] INFO     Epoch: 1 | train_loss: 0.00665,        train.py:144\n",
            "                             val_loss: 0.00553, lr: 3.08E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:53:30] INFO     Epoch: 2 | train_loss: 0.00505,        train.py:144\n",
            "                             val_loss: 0.00304, lr: 3.08E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:53:31] INFO     Epoch: 3 | train_loss: 0.00363,        train.py:144\n",
            "                             val_loss: 0.00272, lr: 3.08E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:53:33] INFO     Epoch: 4 | train_loss: 0.00312,        train.py:144\n",
            "                             val_loss: 0.00268, lr: 3.08E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:53:35] INFO     Epoch: 5 | train_loss: 0.00282,        train.py:144\n",
            "                             val_loss: 0.00251, lr: 3.08E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:53:37] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 76:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 66,                                \n",
            "                               \"embedding_dim\": 200,                            \n",
            "                               \"num_filters\": 363,                              \n",
            "                               \"hidden_dim\": 309,                               \n",
            "                               \"dropout_p\": 0.5246696852989366,                 \n",
            "                               \"lr\": 0.0004318493025464269,                     \n",
            "                               \"lr_factor\": 0.01532217163669073,                \n",
            "                               \"lr_patience\": 9,                                \n",
            "                               \"patience\": 17                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 66,                                \n",
            "                               \"embedding_dim\": 200,                            \n",
            "                               \"num_filters\": 363,                              \n",
            "                               \"hidden_dim\": 309,                               \n",
            "                               \"dropout_p\": 0.5246696852989366,                 \n",
            "                               \"lr\": 0.0004318493025464269,                     \n",
            "                               \"lr_factor\": 0.01532217163669073,                \n",
            "                               \"lr_patience\": 9,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 17,                                  \n",
            "                               \"threshold\": 0.3386393189430237                  \n",
            "                             }                                                  \n",
            "[01/25/21 20:53:39] INFO     Epoch: 1 | train_loss: 0.00605,        train.py:144\n",
            "                             val_loss: 0.00391, lr: 4.32E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:53:41] INFO     Epoch: 2 | train_loss: 0.00370,        train.py:144\n",
            "                             val_loss: 0.00296, lr: 4.32E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:53:42] INFO     Epoch: 3 | train_loss: 0.00290,        train.py:144\n",
            "                             val_loss: 0.00271, lr: 4.32E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:53:44] INFO     Epoch: 4 | train_loss: 0.00239,        train.py:144\n",
            "                             val_loss: 0.00242, lr: 4.32E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:53:45] INFO     Epoch: 5 | train_loss: 0.00203,        train.py:144\n",
            "                             val_loss: 0.00223, lr: 4.32E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:53:47] INFO     Epoch: 6 | train_loss: 0.00175,        train.py:144\n",
            "                             val_loss: 0.00211, lr: 4.32E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:53:49] INFO     Epoch: 7 | train_loss: 0.00150,        train.py:144\n",
            "                             val_loss: 0.00204, lr: 4.32E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:53:50] INFO     Epoch: 8 | train_loss: 0.00131,        train.py:144\n",
            "                             val_loss: 0.00195, lr: 4.32E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:53:52] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 77:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 99,                                \n",
            "                               \"embedding_dim\": 212,                            \n",
            "                               \"num_filters\": 383,                              \n",
            "                               \"hidden_dim\": 501,                               \n",
            "                               \"dropout_p\": 0.6644420020191818,                 \n",
            "                               \"lr\": 0.0003782907449006497,                     \n",
            "                               \"lr_factor\": 0.01399935020619207,                \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"patience\": 17                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 99,                                \n",
            "                               \"embedding_dim\": 212,                            \n",
            "                               \"num_filters\": 383,                              \n",
            "                               \"hidden_dim\": 501,                               \n",
            "                               \"dropout_p\": 0.6644420020191818,                 \n",
            "                               \"lr\": 0.0003782907449006497,                     \n",
            "                               \"lr_factor\": 0.01399935020619207,                \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 17,                                  \n",
            "                               \"threshold\": 0.3386393189430237                  \n",
            "                             }                                                  \n",
            "[01/25/21 20:53:54] INFO     Epoch: 1 | train_loss: 0.00683,        train.py:144\n",
            "                             val_loss: 0.00575, lr: 3.78E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:53:56] INFO     Epoch: 2 | train_loss: 0.00462,        train.py:144\n",
            "                             val_loss: 0.00327, lr: 3.78E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:53:58] INFO     Epoch: 3 | train_loss: 0.00335,        train.py:144\n",
            "                             val_loss: 0.00308, lr: 3.78E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:53:59] INFO     Epoch: 4 | train_loss: 0.00288,        train.py:144\n",
            "                             val_loss: 0.00297, lr: 3.78E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:54:01] INFO     Epoch: 5 | train_loss: 0.00260,        train.py:144\n",
            "                             val_loss: 0.00273, lr: 3.78E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:54:03] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 78:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 116,                               \n",
            "                               \"embedding_dim\": 218,                            \n",
            "                               \"num_filters\": 339,                              \n",
            "                               \"hidden_dim\": 452,                               \n",
            "                               \"dropout_p\": 0.6244515260076261,                 \n",
            "                               \"lr\": 0.0005913917032405606,                     \n",
            "                               \"lr_factor\": 0.04453683346768017,                \n",
            "                               \"lr_patience\": 5,                                \n",
            "                               \"patience\": 18                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 116,                               \n",
            "                               \"embedding_dim\": 218,                            \n",
            "                               \"num_filters\": 339,                              \n",
            "                               \"hidden_dim\": 452,                               \n",
            "                               \"dropout_p\": 0.6244515260076261,                 \n",
            "                               \"lr\": 0.0005913917032405606,                     \n",
            "                               \"lr_factor\": 0.04453683346768017,                \n",
            "                               \"lr_patience\": 5,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 18,                                  \n",
            "                               \"threshold\": 0.3386393189430237                  \n",
            "                             }                                                  \n",
            "[01/25/21 20:54:05] INFO     Epoch: 1 | train_loss: 0.00797,        train.py:144\n",
            "                             val_loss: 0.00555, lr: 5.91E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:54:07] INFO     Epoch: 2 | train_loss: 0.00501,        train.py:144\n",
            "                             val_loss: 0.00293, lr: 5.91E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:54:08] INFO     Epoch: 3 | train_loss: 0.00343,        train.py:144\n",
            "                             val_loss: 0.00283, lr: 5.91E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:54:10] INFO     Epoch: 4 | train_loss: 0.00299,        train.py:144\n",
            "                             val_loss: 0.00268, lr: 5.91E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:54:12] INFO     Epoch: 5 | train_loss: 0.00268,        train.py:144\n",
            "                             val_loss: 0.00250, lr: 5.91E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:54:13] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 79:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 114,                               \n",
            "                               \"embedding_dim\": 227,                            \n",
            "                               \"num_filters\": 453,                              \n",
            "                               \"hidden_dim\": 421,                               \n",
            "                               \"dropout_p\": 0.7075452119771314,                 \n",
            "                               \"lr\": 0.00010530986004413445,                    \n",
            "                               \"lr_factor\": 0.016566540593745578,               \n",
            "                               \"lr_patience\": 6,                                \n",
            "                               \"patience\": 16                                   \n",
            "                             }                                                  \n",
            "[01/25/21 20:54:14] INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 114,                               \n",
            "                               \"embedding_dim\": 227,                            \n",
            "                               \"num_filters\": 453,                              \n",
            "                               \"hidden_dim\": 421,                               \n",
            "                               \"dropout_p\": 0.7075452119771314,                 \n",
            "                               \"lr\": 0.00010530986004413445,                    \n",
            "                               \"lr_factor\": 0.016566540593745578,               \n",
            "                               \"lr_patience\": 6,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 16,                                  \n",
            "                               \"threshold\": 0.3386393189430237                  \n",
            "                             }                                                  \n",
            "[01/25/21 20:54:16] INFO     Epoch: 1 | train_loss: 0.00574,        train.py:144\n",
            "                             val_loss: 0.00382, lr: 1.05E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:54:18] INFO     Epoch: 2 | train_loss: 0.00459,        train.py:144\n",
            "                             val_loss: 0.00379, lr: 1.05E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:54:20] INFO     Epoch: 3 | train_loss: 0.00401,        train.py:144\n",
            "                             val_loss: 0.00292, lr: 1.05E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:54:23] INFO     Epoch: 4 | train_loss: 0.00357,        train.py:144\n",
            "                             val_loss: 0.00275, lr: 1.05E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:54:25] INFO     Epoch: 5 | train_loss: 0.00329,        train.py:144\n",
            "                             val_loss: 0.00271, lr: 1.05E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:54:27] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 80:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 120,                               \n",
            "                               \"embedding_dim\": 210,                            \n",
            "                               \"num_filters\": 292,                              \n",
            "                               \"hidden_dim\": 275,                               \n",
            "                               \"dropout_p\": 0.7672596732114833,                 \n",
            "                               \"lr\": 0.00024917310330638097,                    \n",
            "                               \"lr_factor\": 0.020494814988021404,               \n",
            "                               \"lr_patience\": 9,                                \n",
            "                               \"patience\": 19                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 120,                               \n",
            "                               \"embedding_dim\": 210,                            \n",
            "                               \"num_filters\": 292,                              \n",
            "                               \"hidden_dim\": 275,                               \n",
            "                               \"dropout_p\": 0.7672596732114833,                 \n",
            "                               \"lr\": 0.00024917310330638097,                    \n",
            "                               \"lr_factor\": 0.020494814988021404,               \n",
            "                               \"lr_patience\": 9,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 19,                                  \n",
            "                               \"threshold\": 0.3386393189430237                  \n",
            "                             }                                                  \n",
            "[01/25/21 20:54:29] INFO     Epoch: 1 | train_loss: 0.00674,        train.py:144\n",
            "                             val_loss: 0.00405, lr: 2.49E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:54:30] INFO     Epoch: 2 | train_loss: 0.00533,        train.py:144\n",
            "                             val_loss: 0.00333, lr: 2.49E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:54:32] INFO     Epoch: 3 | train_loss: 0.00422,        train.py:144\n",
            "                             val_loss: 0.00277, lr: 2.49E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:54:33] INFO     Epoch: 4 | train_loss: 0.00365,        train.py:144\n",
            "                             val_loss: 0.00274, lr: 2.49E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:54:35] INFO     Epoch: 5 | train_loss: 0.00338,        train.py:144\n",
            "                             val_loss: 0.00269, lr: 2.49E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:54:36] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 81:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 109,                               \n",
            "                               \"embedding_dim\": 232,                            \n",
            "                               \"num_filters\": 322,                              \n",
            "                               \"hidden_dim\": 346,                               \n",
            "                               \"dropout_p\": 0.44374558342109427,                \n",
            "                               \"lr\": 0.00033082665397015824,                    \n",
            "                               \"lr_factor\": 0.014933557930593139,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"patience\": 20                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 109,                               \n",
            "                               \"embedding_dim\": 232,                            \n",
            "                               \"num_filters\": 322,                              \n",
            "                               \"hidden_dim\": 346,                               \n",
            "                               \"dropout_p\": 0.44374558342109427,                \n",
            "                               \"lr\": 0.00033082665397015824,                    \n",
            "                               \"lr_factor\": 0.014933557930593139,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 20,                                  \n",
            "                               \"threshold\": 0.3386393189430237                  \n",
            "                             }                                                  \n",
            "[01/25/21 20:54:38] INFO     Epoch: 1 | train_loss: 0.00538,        train.py:144\n",
            "                             val_loss: 0.00440, lr: 3.31E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:54:39] INFO     Epoch: 2 | train_loss: 0.00392,        train.py:144\n",
            "                             val_loss: 0.00280, lr: 3.31E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:54:41] INFO     Epoch: 3 | train_loss: 0.00307,        train.py:144\n",
            "                             val_loss: 0.00262, lr: 3.31E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:54:43] INFO     Epoch: 4 | train_loss: 0.00267,        train.py:144\n",
            "                             val_loss: 0.00253, lr: 3.31E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:54:44] INFO     Epoch: 5 | train_loss: 0.00241,        train.py:144\n",
            "                             val_loss: 0.00232, lr: 3.31E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:54:46] INFO     Epoch: 6 | train_loss: 0.00213,        train.py:144\n",
            "                             val_loss: 0.00216, lr: 3.31E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:54:47] INFO     Epoch: 7 | train_loss: 0.00190,        train.py:144\n",
            "                             val_loss: 0.00206, lr: 3.31E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:54:49] INFO     Epoch: 8 | train_loss: 0.00169,        train.py:144\n",
            "                             val_loss: 0.00197, lr: 3.31E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:54:50] INFO     Epoch: 9 | train_loss: 0.00150,        train.py:144\n",
            "                             val_loss: 0.00186, lr: 3.31E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:54:52] INFO     Epoch: 10 | train_loss: 0.00134,       train.py:144\n",
            "                             val_loss: 0.00181, lr: 3.31E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:54:54] INFO     Epoch: 11 | train_loss: 0.00123,       train.py:144\n",
            "                             val_loss: 0.00175, lr: 3.31E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:54:55] INFO     Epoch: 12 | train_loss: 0.00111,       train.py:144\n",
            "                             val_loss: 0.00170, lr: 3.31E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:54:57] INFO     Epoch: 13 | train_loss: 0.00098,       train.py:144\n",
            "                             val_loss: 0.00168, lr: 3.31E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:54:58] INFO     Epoch: 14 | train_loss: 0.00088,       train.py:144\n",
            "                             val_loss: 0.00167, lr: 3.31E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:55:00] INFO     Epoch: 15 | train_loss: 0.00079,       train.py:144\n",
            "                             val_loss: 0.00166, lr: 3.31E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:55:02] INFO     Epoch: 16 | train_loss: 0.00073,       train.py:144\n",
            "                             val_loss: 0.00163, lr: 3.31E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:55:03] INFO     Epoch: 17 | train_loss: 0.00063,       train.py:144\n",
            "                             val_loss: 0.00162, lr: 3.31E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:55:05] INFO     Epoch: 18 | train_loss: 0.00059,       train.py:144\n",
            "                             val_loss: 0.00166, lr: 3.31E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:55:06] INFO     Epoch: 19 | train_loss: 0.00051,       train.py:144\n",
            "                             val_loss: 0.00164, lr: 3.31E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:55:08] INFO     Epoch: 20 | train_loss: 0.00044,       train.py:144\n",
            "                             val_loss: 0.00172, lr: 3.31E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:55:09] INFO     Epoch: 21 | train_loss: 0.00042,       train.py:144\n",
            "                             val_loss: 0.00173, lr: 3.31E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:55:11] INFO     Epoch: 22 | train_loss: 0.00039,       train.py:144\n",
            "                             val_loss: 0.00182, lr: 3.31E-04,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 20:55:13] INFO     Epoch: 23 | train_loss: 0.00036,       train.py:144\n",
            "                             val_loss: 0.00181, lr: 3.31E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 20:55:14] INFO     Epoch: 24 | train_loss: 0.00032,       train.py:144\n",
            "                             val_loss: 0.00182, lr: 3.31E-04,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 20:55:16] INFO     Epoch: 25 | train_loss: 0.00030,       train.py:144\n",
            "                             val_loss: 0.00194, lr: 4.94E-06,                   \n",
            "                             _patience: 12                                      \n",
            "[01/25/21 20:55:17] INFO     Epoch: 26 | train_loss: 0.00031,       train.py:144\n",
            "                             val_loss: 0.00190, lr: 4.94E-06,                   \n",
            "                             _patience: 11                                      \n",
            "[01/25/21 20:55:19] INFO     Epoch: 27 | train_loss: 0.00027,       train.py:144\n",
            "                             val_loss: 0.00186, lr: 4.94E-06,                   \n",
            "                             _patience: 10                                      \n",
            "[01/25/21 20:55:21] INFO     Epoch: 28 | train_loss: 0.00027,       train.py:144\n",
            "                             val_loss: 0.00182, lr: 4.94E-06,                   \n",
            "                             _patience: 9                                       \n",
            "[01/25/21 20:55:22] INFO     Epoch: 29 | train_loss: 0.00027,       train.py:144\n",
            "                             val_loss: 0.00179, lr: 4.94E-06,                   \n",
            "                             _patience: 8                                       \n",
            "[01/25/21 20:55:24] INFO     Epoch: 30 | train_loss: 0.00026,       train.py:144\n",
            "                             val_loss: 0.00177, lr: 4.94E-06,                   \n",
            "                             _patience: 7                                       \n",
            "[01/25/21 20:55:25] INFO     Epoch: 31 | train_loss: 0.00025,       train.py:144\n",
            "                             val_loss: 0.00177, lr: 4.94E-06,                   \n",
            "                             _patience: 6                                       \n",
            "[01/25/21 20:55:27] INFO     Epoch: 32 | train_loss: 0.00025,       train.py:144\n",
            "                             val_loss: 0.00177, lr: 4.94E-06,                   \n",
            "                             _patience: 5                                       \n",
            "[01/25/21 20:55:28] INFO     Epoch: 33 | train_loss: 0.00026,       train.py:144\n",
            "                             val_loss: 0.00177, lr: 7.38E-08,                   \n",
            "                             _patience: 4                                       \n",
            "[01/25/21 20:55:30] INFO     Epoch: 34 | train_loss: 0.00025,       train.py:144\n",
            "                             val_loss: 0.00177, lr: 7.38E-08,                   \n",
            "                             _patience: 3                                       \n",
            "[01/25/21 20:55:32] INFO     Epoch: 35 | train_loss: 0.00026,       train.py:144\n",
            "                             val_loss: 0.00177, lr: 7.38E-08,                   \n",
            "                             _patience: 2                                       \n",
            "[01/25/21 20:55:33] INFO     Epoch: 36 | train_loss: 0.00025,       train.py:144\n",
            "                             val_loss: 0.00177, lr: 7.38E-08,                   \n",
            "                             _patience: 1                                       \n",
            "[01/25/21 20:55:35] INFO     Stopping early!                        train.py:139\n",
            "[01/25/21 20:55:40] INFO                                            train.py:441\n",
            "                             Trial 82:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 105,                               \n",
            "                               \"embedding_dim\": 232,                            \n",
            "                               \"num_filters\": 311,                              \n",
            "                               \"hidden_dim\": 332,                               \n",
            "                               \"dropout_p\": 0.37991591123518176,                \n",
            "                               \"lr\": 0.0003198943106923731,                     \n",
            "                               \"lr_factor\": 0.012601998562096229,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"patience\": 20                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 105,                               \n",
            "                               \"embedding_dim\": 232,                            \n",
            "                               \"num_filters\": 311,                              \n",
            "                               \"hidden_dim\": 332,                               \n",
            "                               \"dropout_p\": 0.37991591123518176,                \n",
            "                               \"lr\": 0.0003198943106923731,                     \n",
            "                               \"lr_factor\": 0.012601998562096229,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 20,                                  \n",
            "                               \"threshold\": 0.29202279448509216                 \n",
            "                             }                                                  \n",
            "[01/25/21 20:55:42] INFO     Epoch: 1 | train_loss: 0.00538,        train.py:144\n",
            "                             val_loss: 0.00461, lr: 3.20E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:55:44] INFO     Epoch: 2 | train_loss: 0.00389,        train.py:144\n",
            "                             val_loss: 0.00314, lr: 3.20E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:55:45] INFO     Epoch: 3 | train_loss: 0.00308,        train.py:144\n",
            "                             val_loss: 0.00289, lr: 3.20E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:55:47] INFO     Epoch: 4 | train_loss: 0.00270,        train.py:144\n",
            "                             val_loss: 0.00282, lr: 3.20E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:55:48] INFO     Epoch: 5 | train_loss: 0.00241,        train.py:144\n",
            "                             val_loss: 0.00264, lr: 3.20E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:55:50] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 83:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 107,                               \n",
            "                               \"embedding_dim\": 240,                            \n",
            "                               \"num_filters\": 275,                              \n",
            "                               \"hidden_dim\": 342,                               \n",
            "                               \"dropout_p\": 0.4733483492320421,                 \n",
            "                               \"lr\": 0.00035674775204566693,                    \n",
            "                               \"lr_factor\": 0.014518378997237562,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"patience\": 20                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 107,                               \n",
            "                               \"embedding_dim\": 240,                            \n",
            "                               \"num_filters\": 275,                              \n",
            "                               \"hidden_dim\": 342,                               \n",
            "                               \"dropout_p\": 0.4733483492320421,                 \n",
            "                               \"lr\": 0.00035674775204566693,                    \n",
            "                               \"lr_factor\": 0.014518378997237562,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 20,                                  \n",
            "                               \"threshold\": 0.29202279448509216                 \n",
            "                             }                                                  \n",
            "[01/25/21 20:55:51] INFO     Epoch: 1 | train_loss: 0.00530,        train.py:144\n",
            "                             val_loss: 0.00425, lr: 3.57E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:55:53] INFO     Epoch: 2 | train_loss: 0.00400,        train.py:144\n",
            "                             val_loss: 0.00281, lr: 3.57E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:55:54] INFO     Epoch: 3 | train_loss: 0.00319,        train.py:144\n",
            "                             val_loss: 0.00261, lr: 3.57E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:55:56] INFO     Epoch: 4 | train_loss: 0.00273,        train.py:144\n",
            "                             val_loss: 0.00247, lr: 3.57E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:55:57] INFO     Epoch: 5 | train_loss: 0.00243,        train.py:144\n",
            "                             val_loss: 0.00227, lr: 3.57E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:55:59] INFO     Epoch: 6 | train_loss: 0.00212,        train.py:144\n",
            "                             val_loss: 0.00211, lr: 3.57E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:56:00] INFO     Epoch: 7 | train_loss: 0.00186,        train.py:144\n",
            "                             val_loss: 0.00196, lr: 3.57E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:56:02] INFO     Epoch: 8 | train_loss: 0.00165,        train.py:144\n",
            "                             val_loss: 0.00186, lr: 3.57E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:56:03] INFO     Epoch: 9 | train_loss: 0.00148,        train.py:144\n",
            "                             val_loss: 0.00178, lr: 3.57E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:56:05] INFO     Epoch: 10 | train_loss: 0.00133,       train.py:144\n",
            "                             val_loss: 0.00174, lr: 3.57E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:56:06] INFO     Epoch: 11 | train_loss: 0.00118,       train.py:144\n",
            "                             val_loss: 0.00171, lr: 3.57E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:56:07] INFO     Epoch: 12 | train_loss: 0.00109,       train.py:144\n",
            "                             val_loss: 0.00168, lr: 3.57E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:56:09] INFO     Epoch: 13 | train_loss: 0.00096,       train.py:144\n",
            "                             val_loss: 0.00164, lr: 3.57E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:56:10] INFO     Epoch: 14 | train_loss: 0.00085,       train.py:144\n",
            "                             val_loss: 0.00161, lr: 3.57E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:56:12] INFO     Epoch: 15 | train_loss: 0.00077,       train.py:144\n",
            "                             val_loss: 0.00160, lr: 3.57E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:56:13] INFO     Epoch: 16 | train_loss: 0.00070,       train.py:144\n",
            "                             val_loss: 0.00161, lr: 3.57E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:56:15] INFO     Epoch: 17 | train_loss: 0.00063,       train.py:144\n",
            "                             val_loss: 0.00162, lr: 3.57E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:56:16] INFO     Epoch: 18 | train_loss: 0.00056,       train.py:144\n",
            "                             val_loss: 0.00160, lr: 3.57E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:56:18] INFO     Epoch: 19 | train_loss: 0.00052,       train.py:144\n",
            "                             val_loss: 0.00161, lr: 3.57E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:56:19] INFO     Epoch: 20 | train_loss: 0.00046,       train.py:144\n",
            "                             val_loss: 0.00162, lr: 3.57E-04,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 20:56:21] INFO     Epoch: 21 | train_loss: 0.00042,       train.py:144\n",
            "                             val_loss: 0.00160, lr: 3.57E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 20:56:22] INFO     Epoch: 22 | train_loss: 0.00041,       train.py:144\n",
            "                             val_loss: 0.00162, lr: 3.57E-04,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 20:56:24] INFO     Epoch: 23 | train_loss: 0.00040,       train.py:144\n",
            "                             val_loss: 0.00164, lr: 5.18E-06,                   \n",
            "                             _patience: 12                                      \n",
            "[01/25/21 20:56:25] INFO     Epoch: 24 | train_loss: 0.00037,       train.py:144\n",
            "                             val_loss: 0.00165, lr: 5.18E-06,                   \n",
            "                             _patience: 11                                      \n",
            "[01/25/21 20:56:26] INFO     Epoch: 25 | train_loss: 0.00033,       train.py:144\n",
            "                             val_loss: 0.00169, lr: 5.18E-06,                   \n",
            "                             _patience: 10                                      \n",
            "[01/25/21 20:56:28] INFO     Epoch: 26 | train_loss: 0.00030,       train.py:144\n",
            "                             val_loss: 0.00173, lr: 5.18E-06,                   \n",
            "                             _patience: 9                                       \n",
            "[01/25/21 20:56:29] INFO     Epoch: 27 | train_loss: 0.00031,       train.py:144\n",
            "                             val_loss: 0.00176, lr: 5.18E-06,                   \n",
            "                             _patience: 8                                       \n",
            "[01/25/21 20:56:31] INFO     Epoch: 28 | train_loss: 0.00030,       train.py:144\n",
            "                             val_loss: 0.00176, lr: 5.18E-06,                   \n",
            "                             _patience: 7                                       \n",
            "[01/25/21 20:56:32] INFO     Epoch: 29 | train_loss: 0.00030,       train.py:144\n",
            "                             val_loss: 0.00176, lr: 5.18E-06,                   \n",
            "                             _patience: 6                                       \n",
            "[01/25/21 20:56:34] INFO     Epoch: 30 | train_loss: 0.00031,       train.py:144\n",
            "                             val_loss: 0.00175, lr: 5.18E-06,                   \n",
            "                             _patience: 5                                       \n",
            "[01/25/21 20:56:35] INFO     Epoch: 31 | train_loss: 0.00030,       train.py:144\n",
            "                             val_loss: 0.00175, lr: 7.52E-08,                   \n",
            "                             _patience: 4                                       \n",
            "[01/25/21 20:56:37] INFO     Epoch: 32 | train_loss: 0.00030,       train.py:144\n",
            "                             val_loss: 0.00175, lr: 7.52E-08,                   \n",
            "                             _patience: 3                                       \n",
            "[01/25/21 20:56:38] INFO     Epoch: 33 | train_loss: 0.00030,       train.py:144\n",
            "                             val_loss: 0.00175, lr: 7.52E-08,                   \n",
            "                             _patience: 2                                       \n",
            "[01/25/21 20:56:40] INFO     Epoch: 34 | train_loss: 0.00031,       train.py:144\n",
            "                             val_loss: 0.00175, lr: 7.52E-08,                   \n",
            "                             _patience: 1                                       \n",
            "[01/25/21 20:56:41] INFO     Stopping early!                        train.py:139\n",
            "[01/25/21 20:56:46] INFO                                            train.py:441\n",
            "                             Trial 84:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 108,                               \n",
            "                               \"embedding_dim\": 235,                            \n",
            "                               \"num_filters\": 260,                              \n",
            "                               \"hidden_dim\": 392,                               \n",
            "                               \"dropout_p\": 0.47285912102622557,                \n",
            "                               \"lr\": 0.00035241249053029165,                    \n",
            "                               \"lr_factor\": 0.014288995948134514,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"patience\": 20                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 108,                               \n",
            "                               \"embedding_dim\": 235,                            \n",
            "                               \"num_filters\": 260,                              \n",
            "                               \"hidden_dim\": 392,                               \n",
            "                               \"dropout_p\": 0.47285912102622557,                \n",
            "                               \"lr\": 0.00035241249053029165,                    \n",
            "                               \"lr_factor\": 0.014288995948134514,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 20,                                  \n",
            "                               \"threshold\": 0.279301255941391                   \n",
            "                             }                                                  \n",
            "[01/25/21 20:56:47] INFO     Epoch: 1 | train_loss: 0.00520,        train.py:144\n",
            "                             val_loss: 0.00415, lr: 3.52E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:56:49] INFO     Epoch: 2 | train_loss: 0.00374,        train.py:144\n",
            "                             val_loss: 0.00277, lr: 3.52E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:56:50] INFO     Epoch: 3 | train_loss: 0.00307,        train.py:144\n",
            "                             val_loss: 0.00263, lr: 3.52E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:56:52] INFO     Epoch: 4 | train_loss: 0.00266,        train.py:144\n",
            "                             val_loss: 0.00251, lr: 3.52E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:56:53] INFO     Epoch: 5 | train_loss: 0.00242,        train.py:144\n",
            "                             val_loss: 0.00231, lr: 3.52E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:56:54] INFO     Epoch: 6 | train_loss: 0.00211,        train.py:144\n",
            "                             val_loss: 0.00214, lr: 3.52E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:56:56] INFO     Epoch: 7 | train_loss: 0.00184,        train.py:144\n",
            "                             val_loss: 0.00200, lr: 3.52E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:56:57] INFO     Epoch: 8 | train_loss: 0.00164,        train.py:144\n",
            "                             val_loss: 0.00191, lr: 3.52E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:56:59] INFO     Epoch: 9 | train_loss: 0.00148,        train.py:144\n",
            "                             val_loss: 0.00183, lr: 3.52E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:57:00] INFO     Epoch: 10 | train_loss: 0.00129,       train.py:144\n",
            "                             val_loss: 0.00178, lr: 3.52E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:57:01] INFO     Epoch: 11 | train_loss: 0.00119,       train.py:144\n",
            "                             val_loss: 0.00176, lr: 3.52E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:57:03] INFO     Epoch: 12 | train_loss: 0.00108,       train.py:144\n",
            "                             val_loss: 0.00173, lr: 3.52E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:57:04] INFO     Epoch: 13 | train_loss: 0.00096,       train.py:144\n",
            "                             val_loss: 0.00170, lr: 3.52E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:57:05] INFO     Epoch: 14 | train_loss: 0.00085,       train.py:144\n",
            "                             val_loss: 0.00167, lr: 3.52E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:57:07] INFO     Epoch: 15 | train_loss: 0.00076,       train.py:144\n",
            "                             val_loss: 0.00168, lr: 3.52E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:57:08] INFO     Epoch: 16 | train_loss: 0.00070,       train.py:144\n",
            "                             val_loss: 0.00160, lr: 3.52E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:57:10] INFO     Epoch: 17 | train_loss: 0.00062,       train.py:144\n",
            "                             val_loss: 0.00160, lr: 3.52E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:57:11] INFO     Epoch: 18 | train_loss: 0.00055,       train.py:144\n",
            "                             val_loss: 0.00161, lr: 3.52E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:57:13] INFO     Epoch: 19 | train_loss: 0.00050,       train.py:144\n",
            "                             val_loss: 0.00169, lr: 3.52E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:57:14] INFO     Epoch: 20 | train_loss: 0.00046,       train.py:144\n",
            "                             val_loss: 0.00179, lr: 3.52E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:57:15] INFO     Epoch: 21 | train_loss: 0.00043,       train.py:144\n",
            "                             val_loss: 0.00183, lr: 3.52E-04,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 20:57:17] INFO     Epoch: 22 | train_loss: 0.00039,       train.py:144\n",
            "                             val_loss: 0.00202, lr: 3.52E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 20:57:18] INFO     Epoch: 23 | train_loss: 0.00038,       train.py:144\n",
            "                             val_loss: 0.00207, lr: 3.52E-04,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 20:57:20] INFO     Epoch: 24 | train_loss: 0.00035,       train.py:144\n",
            "                             val_loss: 0.00206, lr: 5.04E-06,                   \n",
            "                             _patience: 12                                      \n",
            "[01/25/21 20:57:21] INFO     Epoch: 25 | train_loss: 0.00032,       train.py:144\n",
            "                             val_loss: 0.00202, lr: 5.04E-06,                   \n",
            "                             _patience: 11                                      \n",
            "[01/25/21 20:57:22] INFO     Epoch: 26 | train_loss: 0.00031,       train.py:144\n",
            "                             val_loss: 0.00194, lr: 5.04E-06,                   \n",
            "                             _patience: 10                                      \n",
            "[01/25/21 20:57:24] INFO     Epoch: 27 | train_loss: 0.00029,       train.py:144\n",
            "                             val_loss: 0.00188, lr: 5.04E-06,                   \n",
            "                             _patience: 9                                       \n",
            "[01/25/21 20:57:25] INFO     Epoch: 28 | train_loss: 0.00027,       train.py:144\n",
            "                             val_loss: 0.00184, lr: 5.04E-06,                   \n",
            "                             _patience: 8                                       \n",
            "[01/25/21 20:57:27] INFO     Epoch: 29 | train_loss: 0.00027,       train.py:144\n",
            "                             val_loss: 0.00182, lr: 5.04E-06,                   \n",
            "                             _patience: 7                                       \n",
            "[01/25/21 20:57:28] INFO     Epoch: 30 | train_loss: 0.00028,       train.py:144\n",
            "                             val_loss: 0.00180, lr: 5.04E-06,                   \n",
            "                             _patience: 6                                       \n",
            "[01/25/21 20:57:29] INFO     Epoch: 31 | train_loss: 0.00026,       train.py:144\n",
            "                             val_loss: 0.00180, lr: 5.04E-06,                   \n",
            "                             _patience: 5                                       \n",
            "[01/25/21 20:57:31] INFO     Epoch: 32 | train_loss: 0.00027,       train.py:144\n",
            "                             val_loss: 0.00180, lr: 7.20E-08,                   \n",
            "                             _patience: 4                                       \n",
            "[01/25/21 20:57:32] INFO     Epoch: 33 | train_loss: 0.00027,       train.py:144\n",
            "                             val_loss: 0.00180, lr: 7.20E-08,                   \n",
            "                             _patience: 3                                       \n",
            "[01/25/21 20:57:34] INFO     Epoch: 34 | train_loss: 0.00027,       train.py:144\n",
            "                             val_loss: 0.00180, lr: 7.20E-08,                   \n",
            "                             _patience: 2                                       \n",
            "[01/25/21 20:57:35] INFO     Epoch: 35 | train_loss: 0.00026,       train.py:144\n",
            "                             val_loss: 0.00180, lr: 7.20E-08,                   \n",
            "                             _patience: 1                                       \n",
            "[01/25/21 20:57:36] INFO     Stopping early!                        train.py:139\n",
            "[01/25/21 20:57:41] INFO                                            train.py:441\n",
            "                             Trial 85:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 107,                               \n",
            "                               \"embedding_dim\": 239,                            \n",
            "                               \"num_filters\": 258,                              \n",
            "                               \"hidden_dim\": 395,                               \n",
            "                               \"dropout_p\": 0.4198256670030058,                 \n",
            "                               \"lr\": 0.00035365462936147175,                    \n",
            "                               \"lr_factor\": 0.014586033720332634,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"patience\": 20                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 107,                               \n",
            "                               \"embedding_dim\": 239,                            \n",
            "                               \"num_filters\": 258,                              \n",
            "                               \"hidden_dim\": 395,                               \n",
            "                               \"dropout_p\": 0.4198256670030058,                 \n",
            "                               \"lr\": 0.00035365462936147175,                    \n",
            "                               \"lr_factor\": 0.014586033720332634,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 20,                                  \n",
            "                               \"threshold\": 0.2809818983078003                  \n",
            "                             }                                                  \n",
            "[01/25/21 20:57:43] INFO     Epoch: 1 | train_loss: 0.00537,        train.py:144\n",
            "                             val_loss: 0.00411, lr: 3.54E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:57:44] INFO     Epoch: 2 | train_loss: 0.00372,        train.py:144\n",
            "                             val_loss: 0.00278, lr: 3.54E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:57:46] INFO     Epoch: 3 | train_loss: 0.00305,        train.py:144\n",
            "                             val_loss: 0.00264, lr: 3.54E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:57:47] INFO     Epoch: 4 | train_loss: 0.00267,        train.py:144\n",
            "                             val_loss: 0.00248, lr: 3.54E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:57:49] INFO     Epoch: 5 | train_loss: 0.00236,        train.py:144\n",
            "                             val_loss: 0.00228, lr: 3.54E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:57:50] INFO     Epoch: 6 | train_loss: 0.00209,        train.py:144\n",
            "                             val_loss: 0.00210, lr: 3.54E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:57:51] INFO     Epoch: 7 | train_loss: 0.00180,        train.py:144\n",
            "                             val_loss: 0.00195, lr: 3.54E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:57:53] INFO     Epoch: 8 | train_loss: 0.00159,        train.py:144\n",
            "                             val_loss: 0.00186, lr: 3.54E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:57:54] INFO     Epoch: 9 | train_loss: 0.00141,        train.py:144\n",
            "                             val_loss: 0.00180, lr: 3.54E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:57:56] INFO     Epoch: 10 | train_loss: 0.00126,       train.py:144\n",
            "                             val_loss: 0.00172, lr: 3.54E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:57:57] INFO     Epoch: 11 | train_loss: 0.00111,       train.py:144\n",
            "                             val_loss: 0.00170, lr: 3.54E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:57:59] INFO     Epoch: 12 | train_loss: 0.00101,       train.py:144\n",
            "                             val_loss: 0.00167, lr: 3.54E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:58:00] INFO     Epoch: 13 | train_loss: 0.00088,       train.py:144\n",
            "                             val_loss: 0.00162, lr: 3.54E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:58:01] INFO     Epoch: 14 | train_loss: 0.00078,       train.py:144\n",
            "                             val_loss: 0.00162, lr: 3.54E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:58:03] INFO     Epoch: 15 | train_loss: 0.00068,       train.py:144\n",
            "                             val_loss: 0.00163, lr: 3.54E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:58:04] INFO     Epoch: 16 | train_loss: 0.00061,       train.py:144\n",
            "                             val_loss: 0.00162, lr: 3.54E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:58:06] INFO     Epoch: 17 | train_loss: 0.00054,       train.py:144\n",
            "                             val_loss: 0.00163, lr: 3.54E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:58:07] INFO     Epoch: 18 | train_loss: 0.00051,       train.py:144\n",
            "                             val_loss: 0.00166, lr: 3.54E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:58:09] INFO     Epoch: 19 | train_loss: 0.00043,       train.py:144\n",
            "                             val_loss: 0.00168, lr: 3.54E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:58:10] INFO     Epoch: 20 | train_loss: 0.00039,       train.py:144\n",
            "                             val_loss: 0.00172, lr: 3.54E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:58:11] INFO     Epoch: 21 | train_loss: 0.00037,       train.py:144\n",
            "                             val_loss: 0.00181, lr: 3.54E-04,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 20:58:13] INFO     Epoch: 22 | train_loss: 0.00033,       train.py:144\n",
            "                             val_loss: 0.00181, lr: 3.54E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 20:58:14] INFO     Epoch: 23 | train_loss: 0.00030,       train.py:144\n",
            "                             val_loss: 0.00178, lr: 3.54E-04,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 20:58:16] INFO     Epoch: 24 | train_loss: 0.00027,       train.py:144\n",
            "                             val_loss: 0.00177, lr: 5.16E-06,                   \n",
            "                             _patience: 12                                      \n",
            "[01/25/21 20:58:17] INFO     Epoch: 25 | train_loss: 0.00025,       train.py:144\n",
            "                             val_loss: 0.00178, lr: 5.16E-06,                   \n",
            "                             _patience: 11                                      \n",
            "[01/25/21 20:58:18] INFO     Epoch: 26 | train_loss: 0.00024,       train.py:144\n",
            "                             val_loss: 0.00179, lr: 5.16E-06,                   \n",
            "                             _patience: 10                                      \n",
            "[01/25/21 20:58:20] INFO     Epoch: 27 | train_loss: 0.00023,       train.py:144\n",
            "                             val_loss: 0.00180, lr: 5.16E-06,                   \n",
            "                             _patience: 9                                       \n",
            "[01/25/21 20:58:21] INFO     Epoch: 28 | train_loss: 0.00024,       train.py:144\n",
            "                             val_loss: 0.00180, lr: 5.16E-06,                   \n",
            "                             _patience: 8                                       \n",
            "[01/25/21 20:58:23] INFO     Epoch: 29 | train_loss: 0.00024,       train.py:144\n",
            "                             val_loss: 0.00180, lr: 5.16E-06,                   \n",
            "                             _patience: 7                                       \n",
            "[01/25/21 20:58:24] INFO     Epoch: 30 | train_loss: 0.00023,       train.py:144\n",
            "                             val_loss: 0.00180, lr: 5.16E-06,                   \n",
            "                             _patience: 6                                       \n",
            "[01/25/21 20:58:26] INFO     Epoch: 31 | train_loss: 0.00022,       train.py:144\n",
            "                             val_loss: 0.00180, lr: 5.16E-06,                   \n",
            "                             _patience: 5                                       \n",
            "[01/25/21 20:58:27] INFO     Epoch: 32 | train_loss: 0.00023,       train.py:144\n",
            "                             val_loss: 0.00180, lr: 7.52E-08,                   \n",
            "                             _patience: 4                                       \n",
            "[01/25/21 20:58:28] INFO     Epoch: 33 | train_loss: 0.00023,       train.py:144\n",
            "                             val_loss: 0.00180, lr: 7.52E-08,                   \n",
            "                             _patience: 3                                       \n",
            "[01/25/21 20:58:30] INFO     Epoch: 34 | train_loss: 0.00022,       train.py:144\n",
            "                             val_loss: 0.00180, lr: 7.52E-08,                   \n",
            "                             _patience: 2                                       \n",
            "[01/25/21 20:58:31] INFO     Epoch: 35 | train_loss: 0.00023,       train.py:144\n",
            "                             val_loss: 0.00180, lr: 7.52E-08,                   \n",
            "                             _patience: 1                                       \n",
            "[01/25/21 20:58:33] INFO     Stopping early!                        train.py:139\n",
            "[01/25/21 20:58:37] INFO                                            train.py:441\n",
            "                             Trial 86:                                          \n",
            "[01/25/21 20:58:38] INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 102,                               \n",
            "                               \"embedding_dim\": 252,                            \n",
            "                               \"num_filters\": 270,                              \n",
            "                               \"hidden_dim\": 397,                               \n",
            "                               \"dropout_p\": 0.4573843290061926,                 \n",
            "                               \"lr\": 0.0002780775776068278,                     \n",
            "                               \"lr_factor\": 0.01787709170846034,                \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"patience\": 20                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 102,                               \n",
            "                               \"embedding_dim\": 252,                            \n",
            "                               \"num_filters\": 270,                              \n",
            "                               \"hidden_dim\": 397,                               \n",
            "                               \"dropout_p\": 0.4573843290061926,                 \n",
            "                               \"lr\": 0.0002780775776068278,                     \n",
            "                               \"lr_factor\": 0.01787709170846034,                \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 20,                                  \n",
            "                               \"threshold\": 0.3322778046131134                  \n",
            "                             }                                                  \n",
            "[01/25/21 20:58:39] INFO     Epoch: 1 | train_loss: 0.00530,        train.py:144\n",
            "                             val_loss: 0.00544, lr: 2.78E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:58:41] INFO     Epoch: 2 | train_loss: 0.00384,        train.py:144\n",
            "                             val_loss: 0.00343, lr: 2.78E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:58:42] INFO     Epoch: 3 | train_loss: 0.00321,        train.py:144\n",
            "                             val_loss: 0.00316, lr: 2.78E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:58:44] INFO     Epoch: 4 | train_loss: 0.00281,        train.py:144\n",
            "                             val_loss: 0.00315, lr: 2.78E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:58:45] INFO     Epoch: 5 | train_loss: 0.00254,        train.py:144\n",
            "                             val_loss: 0.00292, lr: 2.78E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:58:47] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 87:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 107,                               \n",
            "                               \"embedding_dim\": 246,                            \n",
            "                               \"num_filters\": 261,                              \n",
            "                               \"hidden_dim\": 390,                               \n",
            "                               \"dropout_p\": 0.4337301031118548,                 \n",
            "                               \"lr\": 0.0003459189420207156,                     \n",
            "                               \"lr_factor\": 0.014735404295232972,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"patience\": 19                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 107,                               \n",
            "                               \"embedding_dim\": 246,                            \n",
            "                               \"num_filters\": 261,                              \n",
            "                               \"hidden_dim\": 390,                               \n",
            "                               \"dropout_p\": 0.4337301031118548,                 \n",
            "                               \"lr\": 0.0003459189420207156,                     \n",
            "                               \"lr_factor\": 0.014735404295232972,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 19,                                  \n",
            "                               \"threshold\": 0.3322778046131134                  \n",
            "                             }                                                  \n",
            "[01/25/21 20:58:49] INFO     Epoch: 1 | train_loss: 0.00526,        train.py:144\n",
            "                             val_loss: 0.00417, lr: 3.46E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:58:50] INFO     Epoch: 2 | train_loss: 0.00369,        train.py:144\n",
            "                             val_loss: 0.00275, lr: 3.46E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:58:51] INFO     Epoch: 3 | train_loss: 0.00307,        train.py:144\n",
            "                             val_loss: 0.00261, lr: 3.46E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:58:53] INFO     Epoch: 4 | train_loss: 0.00264,        train.py:144\n",
            "                             val_loss: 0.00246, lr: 3.46E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:58:54] INFO     Epoch: 5 | train_loss: 0.00232,        train.py:144\n",
            "                             val_loss: 0.00227, lr: 3.46E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:58:56] INFO     Epoch: 6 | train_loss: 0.00206,        train.py:144\n",
            "                             val_loss: 0.00211, lr: 3.46E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:58:57] INFO     Epoch: 7 | train_loss: 0.00178,        train.py:144\n",
            "                             val_loss: 0.00199, lr: 3.46E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:58:59] INFO     Epoch: 8 | train_loss: 0.00159,        train.py:144\n",
            "                             val_loss: 0.00189, lr: 3.46E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:59:00] INFO     Epoch: 9 | train_loss: 0.00143,        train.py:144\n",
            "                             val_loss: 0.00182, lr: 3.46E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:59:02] INFO     Epoch: 10 | train_loss: 0.00127,       train.py:144\n",
            "                             val_loss: 0.00177, lr: 3.46E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:59:03] INFO     Epoch: 11 | train_loss: 0.00115,       train.py:144\n",
            "                             val_loss: 0.00173, lr: 3.46E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:59:05] INFO     Epoch: 12 | train_loss: 0.00104,       train.py:144\n",
            "                             val_loss: 0.00167, lr: 3.46E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:59:06] INFO     Epoch: 13 | train_loss: 0.00092,       train.py:144\n",
            "                             val_loss: 0.00168, lr: 3.46E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:59:07] INFO     Epoch: 14 | train_loss: 0.00082,       train.py:144\n",
            "                             val_loss: 0.00164, lr: 3.46E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:59:09] INFO     Epoch: 15 | train_loss: 0.00075,       train.py:144\n",
            "                             val_loss: 0.00167, lr: 3.46E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 20:59:10] INFO     Epoch: 16 | train_loss: 0.00065,       train.py:144\n",
            "                             val_loss: 0.00168, lr: 3.46E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 20:59:12] INFO     Epoch: 17 | train_loss: 0.00059,       train.py:144\n",
            "                             val_loss: 0.00167, lr: 3.46E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 20:59:13] INFO     Epoch: 18 | train_loss: 0.00053,       train.py:144\n",
            "                             val_loss: 0.00175, lr: 3.46E-04,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 20:59:15] INFO     Epoch: 19 | train_loss: 0.00049,       train.py:144\n",
            "                             val_loss: 0.00175, lr: 3.46E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 20:59:16] INFO     Epoch: 20 | train_loss: 0.00044,       train.py:144\n",
            "                             val_loss: 0.00177, lr: 3.46E-04,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 20:59:18] INFO     Epoch: 21 | train_loss: 0.00040,       train.py:144\n",
            "                             val_loss: 0.00178, lr: 3.46E-04,                   \n",
            "                             _patience: 12                                      \n",
            "[01/25/21 20:59:19] INFO     Epoch: 22 | train_loss: 0.00036,       train.py:144\n",
            "                             val_loss: 0.00176, lr: 5.10E-06,                   \n",
            "                             _patience: 11                                      \n",
            "[01/25/21 20:59:21] INFO     Epoch: 23 | train_loss: 0.00032,       train.py:144\n",
            "                             val_loss: 0.00176, lr: 5.10E-06,                   \n",
            "                             _patience: 10                                      \n",
            "[01/25/21 20:59:22] INFO     Epoch: 24 | train_loss: 0.00033,       train.py:144\n",
            "                             val_loss: 0.00175, lr: 5.10E-06,                   \n",
            "                             _patience: 9                                       \n",
            "[01/25/21 20:59:23] INFO     Epoch: 25 | train_loss: 0.00031,       train.py:144\n",
            "                             val_loss: 0.00175, lr: 5.10E-06,                   \n",
            "                             _patience: 8                                       \n",
            "[01/25/21 20:59:25] INFO     Epoch: 26 | train_loss: 0.00030,       train.py:144\n",
            "                             val_loss: 0.00175, lr: 5.10E-06,                   \n",
            "                             _patience: 7                                       \n",
            "[01/25/21 20:59:26] INFO     Epoch: 27 | train_loss: 0.00029,       train.py:144\n",
            "                             val_loss: 0.00175, lr: 5.10E-06,                   \n",
            "                             _patience: 6                                       \n",
            "[01/25/21 20:59:28] INFO     Epoch: 28 | train_loss: 0.00029,       train.py:144\n",
            "                             val_loss: 0.00175, lr: 5.10E-06,                   \n",
            "                             _patience: 5                                       \n",
            "[01/25/21 20:59:29] INFO     Epoch: 29 | train_loss: 0.00029,       train.py:144\n",
            "                             val_loss: 0.00175, lr: 5.10E-06,                   \n",
            "                             _patience: 4                                       \n",
            "[01/25/21 20:59:31] INFO     Epoch: 30 | train_loss: 0.00030,       train.py:144\n",
            "                             val_loss: 0.00175, lr: 7.51E-08,                   \n",
            "                             _patience: 3                                       \n",
            "[01/25/21 20:59:32] INFO     Epoch: 31 | train_loss: 0.00030,       train.py:144\n",
            "                             val_loss: 0.00175, lr: 7.51E-08,                   \n",
            "                             _patience: 2                                       \n",
            "[01/25/21 20:59:34] INFO     Epoch: 32 | train_loss: 0.00030,       train.py:144\n",
            "                             val_loss: 0.00175, lr: 7.51E-08,                   \n",
            "                             _patience: 1                                       \n",
            "[01/25/21 20:59:35] INFO     Stopping early!                        train.py:139\n",
            "[01/25/21 20:59:40] INFO                                            train.py:441\n",
            "                             Trial 88:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 111,                               \n",
            "                               \"embedding_dim\": 240,                            \n",
            "                               \"num_filters\": 268,                              \n",
            "                               \"hidden_dim\": 405,                               \n",
            "                               \"dropout_p\": 0.4327743824164265,                 \n",
            "                               \"lr\": 0.0003104795564096688,                     \n",
            "                               \"lr_factor\": 0.013476559017360801,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"patience\": 20                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 111,                               \n",
            "                               \"embedding_dim\": 240,                            \n",
            "                               \"num_filters\": 268,                              \n",
            "                               \"hidden_dim\": 405,                               \n",
            "                               \"dropout_p\": 0.4327743824164265,                 \n",
            "                               \"lr\": 0.0003104795564096688,                     \n",
            "                               \"lr_factor\": 0.013476559017360801,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 20,                                  \n",
            "                               \"threshold\": 0.28940701484680176                 \n",
            "                             }                                                  \n",
            "[01/25/21 20:59:42] INFO     Epoch: 1 | train_loss: 0.00502,        train.py:144\n",
            "                             val_loss: 0.00436, lr: 3.10E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:59:43] INFO     Epoch: 2 | train_loss: 0.00385,        train.py:144\n",
            "                             val_loss: 0.00289, lr: 3.10E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:59:45] INFO     Epoch: 3 | train_loss: 0.00307,        train.py:144\n",
            "                             val_loss: 0.00266, lr: 3.10E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:59:46] INFO     Epoch: 4 | train_loss: 0.00266,        train.py:144\n",
            "                             val_loss: 0.00261, lr: 3.10E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:59:47] INFO     Epoch: 5 | train_loss: 0.00244,        train.py:144\n",
            "                             val_loss: 0.00242, lr: 3.10E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 20:59:49] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 89:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 101,                               \n",
            "                               \"embedding_dim\": 235,                            \n",
            "                               \"num_filters\": 256,                              \n",
            "                               \"hidden_dim\": 392,                               \n",
            "                               \"dropout_p\": 0.4054339922834824,                 \n",
            "                               \"lr\": 0.00021613013021938677,                    \n",
            "                               \"lr_factor\": 0.014418943441543226,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"patience\": 19                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 101,                               \n",
            "                               \"embedding_dim\": 235,                            \n",
            "                               \"num_filters\": 256,                              \n",
            "                               \"hidden_dim\": 392,                               \n",
            "                               \"dropout_p\": 0.4054339922834824,                 \n",
            "                               \"lr\": 0.00021613013021938677,                    \n",
            "                               \"lr_factor\": 0.014418943441543226,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 19,                                  \n",
            "                               \"threshold\": 0.28940701484680176                 \n",
            "                             }                                                  \n",
            "[01/25/21 20:59:50] INFO     Epoch: 1 | train_loss: 0.00484,        train.py:144\n",
            "                             val_loss: 0.00502, lr: 2.16E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:59:51] INFO     Epoch: 2 | train_loss: 0.00372,        train.py:144\n",
            "                             val_loss: 0.00351, lr: 2.16E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:59:53] INFO     Epoch: 3 | train_loss: 0.00304,        train.py:144\n",
            "                             val_loss: 0.00315, lr: 2.16E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:59:54] INFO     Epoch: 4 | train_loss: 0.00280,        train.py:144\n",
            "                             val_loss: 0.00313, lr: 2.16E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:59:55] INFO     Epoch: 5 | train_loss: 0.00258,        train.py:144\n",
            "                             val_loss: 0.00299, lr: 2.16E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 20:59:56] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 90:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 106,                               \n",
            "                               \"embedding_dim\": 238,                            \n",
            "                               \"num_filters\": 276,                              \n",
            "                               \"hidden_dim\": 381,                               \n",
            "                               \"dropout_p\": 0.48480336620446113,                \n",
            "                               \"lr\": 0.00025822533773264816,                    \n",
            "                               \"lr_factor\": 0.015963780578885322,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"patience\": 13                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 106,                               \n",
            "                               \"embedding_dim\": 238,                            \n",
            "                               \"num_filters\": 276,                              \n",
            "                               \"hidden_dim\": 381,                               \n",
            "                               \"dropout_p\": 0.48480336620446113,                \n",
            "                               \"lr\": 0.00025822533773264816,                    \n",
            "                               \"lr_factor\": 0.015963780578885322,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 13,                                  \n",
            "                               \"threshold\": 0.28940701484680176                 \n",
            "                             }                                                  \n",
            "[01/25/21 20:59:58] INFO     Epoch: 1 | train_loss: 0.00527,        train.py:144\n",
            "                             val_loss: 0.00536, lr: 2.58E-04,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 20:59:59] INFO     Epoch: 2 | train_loss: 0.00399,        train.py:144\n",
            "                             val_loss: 0.00339, lr: 2.58E-04,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 21:00:01] INFO     Epoch: 3 | train_loss: 0.00322,        train.py:144\n",
            "                             val_loss: 0.00318, lr: 2.58E-04,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 21:00:02] INFO     Epoch: 4 | train_loss: 0.00284,        train.py:144\n",
            "                             val_loss: 0.00312, lr: 2.58E-04,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 21:00:04] INFO     Epoch: 5 | train_loss: 0.00262,        train.py:144\n",
            "                             val_loss: 0.00304, lr: 2.58E-04,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 21:00:05] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 91:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 108,                               \n",
            "                               \"embedding_dim\": 228,                            \n",
            "                               \"num_filters\": 333,                              \n",
            "                               \"hidden_dim\": 373,                               \n",
            "                               \"dropout_p\": 0.44763754811388345,                \n",
            "                               \"lr\": 0.00036164702184447213,                    \n",
            "                               \"lr_factor\": 0.01391170911370316,                \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"patience\": 20                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 108,                               \n",
            "                               \"embedding_dim\": 228,                            \n",
            "                               \"num_filters\": 333,                              \n",
            "                               \"hidden_dim\": 373,                               \n",
            "                               \"dropout_p\": 0.44763754811388345,                \n",
            "                               \"lr\": 0.00036164702184447213,                    \n",
            "                               \"lr_factor\": 0.01391170911370316,                \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 20,                                  \n",
            "                               \"threshold\": 0.28940701484680176                 \n",
            "                             }                                                  \n",
            "[01/25/21 21:00:07] INFO     Epoch: 1 | train_loss: 0.00545,        train.py:144\n",
            "                             val_loss: 0.00417, lr: 3.62E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:00:09] INFO     Epoch: 2 | train_loss: 0.00389,        train.py:144\n",
            "                             val_loss: 0.00282, lr: 3.62E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:00:10] INFO     Epoch: 3 | train_loss: 0.00301,        train.py:144\n",
            "                             val_loss: 0.00262, lr: 3.62E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:00:12] INFO     Epoch: 4 | train_loss: 0.00267,        train.py:144\n",
            "                             val_loss: 0.00246, lr: 3.62E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:00:14] INFO     Epoch: 5 | train_loss: 0.00233,        train.py:144\n",
            "                             val_loss: 0.00226, lr: 3.62E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:00:16] INFO     Epoch: 6 | train_loss: 0.00201,        train.py:144\n",
            "                             val_loss: 0.00209, lr: 3.62E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:00:17] INFO     Epoch: 7 | train_loss: 0.00176,        train.py:144\n",
            "                             val_loss: 0.00195, lr: 3.62E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:00:19] INFO     Epoch: 8 | train_loss: 0.00156,        train.py:144\n",
            "                             val_loss: 0.00186, lr: 3.62E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:00:21] INFO     Epoch: 9 | train_loss: 0.00140,        train.py:144\n",
            "                             val_loss: 0.00178, lr: 3.62E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:00:22] INFO     Epoch: 10 | train_loss: 0.00121,       train.py:144\n",
            "                             val_loss: 0.00175, lr: 3.62E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:00:24] INFO     Epoch: 11 | train_loss: 0.00111,       train.py:144\n",
            "                             val_loss: 0.00172, lr: 3.62E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:00:26] INFO     Epoch: 12 | train_loss: 0.00094,       train.py:144\n",
            "                             val_loss: 0.00169, lr: 3.62E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:00:27] INFO     Epoch: 13 | train_loss: 0.00086,       train.py:144\n",
            "                             val_loss: 0.00166, lr: 3.62E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:00:29] INFO     Epoch: 14 | train_loss: 0.00074,       train.py:144\n",
            "                             val_loss: 0.00165, lr: 3.62E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:00:31] INFO     Epoch: 15 | train_loss: 0.00068,       train.py:144\n",
            "                             val_loss: 0.00160, lr: 3.62E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:00:32] INFO     Epoch: 16 | train_loss: 0.00060,       train.py:144\n",
            "                             val_loss: 0.00161, lr: 3.62E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:00:34] INFO     Epoch: 17 | train_loss: 0.00055,       train.py:144\n",
            "                             val_loss: 0.00164, lr: 3.62E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 21:00:36] INFO     Epoch: 18 | train_loss: 0.00049,       train.py:144\n",
            "                             val_loss: 0.00167, lr: 3.62E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 21:00:38] INFO     Epoch: 19 | train_loss: 0.00047,       train.py:144\n",
            "                             val_loss: 0.00173, lr: 3.62E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 21:00:39] INFO     Epoch: 20 | train_loss: 0.00040,       train.py:144\n",
            "                             val_loss: 0.00177, lr: 3.62E-04,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 21:00:41] INFO     Epoch: 21 | train_loss: 0.00037,       train.py:144\n",
            "                             val_loss: 0.00200, lr: 3.62E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 21:00:43] INFO     Epoch: 22 | train_loss: 0.00037,       train.py:144\n",
            "                             val_loss: 0.00228, lr: 3.62E-04,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 21:00:44] INFO     Epoch: 23 | train_loss: 0.00038,       train.py:144\n",
            "                             val_loss: 0.00233, lr: 5.03E-06,                   \n",
            "                             _patience: 12                                      \n",
            "[01/25/21 21:00:46] INFO     Epoch: 24 | train_loss: 0.00042,       train.py:144\n",
            "                             val_loss: 0.00226, lr: 5.03E-06,                   \n",
            "                             _patience: 11                                      \n",
            "[01/25/21 21:00:48] INFO     Epoch: 25 | train_loss: 0.00037,       train.py:144\n",
            "                             val_loss: 0.00214, lr: 5.03E-06,                   \n",
            "                             _patience: 10                                      \n",
            "[01/25/21 21:00:49] INFO     Epoch: 26 | train_loss: 0.00032,       train.py:144\n",
            "                             val_loss: 0.00203, lr: 5.03E-06,                   \n",
            "                             _patience: 9                                       \n",
            "[01/25/21 21:00:51] INFO     Epoch: 27 | train_loss: 0.00029,       train.py:144\n",
            "                             val_loss: 0.00195, lr: 5.03E-06,                   \n",
            "                             _patience: 8                                       \n",
            "[01/25/21 21:00:53] INFO     Epoch: 28 | train_loss: 0.00027,       train.py:144\n",
            "                             val_loss: 0.00189, lr: 5.03E-06,                   \n",
            "                             _patience: 7                                       \n",
            "[01/25/21 21:00:54] INFO     Epoch: 29 | train_loss: 0.00026,       train.py:144\n",
            "                             val_loss: 0.00186, lr: 5.03E-06,                   \n",
            "                             _patience: 6                                       \n",
            "[01/25/21 21:00:56] INFO     Epoch: 30 | train_loss: 0.00026,       train.py:144\n",
            "                             val_loss: 0.00184, lr: 5.03E-06,                   \n",
            "                             _patience: 5                                       \n",
            "[01/25/21 21:00:58] INFO     Epoch: 31 | train_loss: 0.00026,       train.py:144\n",
            "                             val_loss: 0.00183, lr: 7.00E-08,                   \n",
            "                             _patience: 4                                       \n",
            "[01/25/21 21:01:00] INFO     Epoch: 32 | train_loss: 0.00025,       train.py:144\n",
            "                             val_loss: 0.00183, lr: 7.00E-08,                   \n",
            "                             _patience: 3                                       \n",
            "[01/25/21 21:01:01] INFO     Epoch: 33 | train_loss: 0.00025,       train.py:144\n",
            "                             val_loss: 0.00183, lr: 7.00E-08,                   \n",
            "                             _patience: 2                                       \n",
            "[01/25/21 21:01:03] INFO     Epoch: 34 | train_loss: 0.00025,       train.py:144\n",
            "                             val_loss: 0.00183, lr: 7.00E-08,                   \n",
            "                             _patience: 1                                       \n",
            "[01/25/21 21:01:05] INFO     Stopping early!                        train.py:139\n",
            "[01/25/21 21:01:10] INFO                                            train.py:441\n",
            "                             Trial 92:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 108,                               \n",
            "                               \"embedding_dim\": 228,                            \n",
            "                               \"num_filters\": 346,                              \n",
            "                               \"hidden_dim\": 371,                               \n",
            "                               \"dropout_p\": 0.4493122095500274,                 \n",
            "                               \"lr\": 0.0002919271916712969,                     \n",
            "                               \"lr_factor\": 0.012309848160166843,               \n",
            "                               \"lr_patience\": 8,                                \n",
            "                               \"patience\": 20                                   \n",
            "                             }                                                  \n",
            "[01/25/21 21:01:11] INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 108,                               \n",
            "                               \"embedding_dim\": 228,                            \n",
            "                               \"num_filters\": 346,                              \n",
            "                               \"hidden_dim\": 371,                               \n",
            "                               \"dropout_p\": 0.4493122095500274,                 \n",
            "                               \"lr\": 0.0002919271916712969,                     \n",
            "                               \"lr_factor\": 0.012309848160166843,               \n",
            "                               \"lr_patience\": 8,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 20,                                  \n",
            "                               \"threshold\": 0.2732760012149811                  \n",
            "                             }                                                  \n",
            "[01/25/21 21:01:12] INFO     Epoch: 1 | train_loss: 0.00546,        train.py:144\n",
            "                             val_loss: 0.00456, lr: 2.92E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:01:14] INFO     Epoch: 2 | train_loss: 0.00403,        train.py:144\n",
            "                             val_loss: 0.00285, lr: 2.92E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:01:16] INFO     Epoch: 3 | train_loss: 0.00313,        train.py:144\n",
            "                             val_loss: 0.00265, lr: 2.92E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:01:18] INFO     Epoch: 4 | train_loss: 0.00278,        train.py:144\n",
            "                             val_loss: 0.00257, lr: 2.92E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:01:19] INFO     Epoch: 5 | train_loss: 0.00247,        train.py:144\n",
            "                             val_loss: 0.00238, lr: 2.92E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:01:21] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 93:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 103,                               \n",
            "                               \"embedding_dim\": 243,                            \n",
            "                               \"num_filters\": 333,                              \n",
            "                               \"hidden_dim\": 400,                               \n",
            "                               \"dropout_p\": 0.4202985026503084,                 \n",
            "                               \"lr\": 0.00032975328167180194,                    \n",
            "                               \"lr_factor\": 0.013640299445594637,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"patience\": 20                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 103,                               \n",
            "                               \"embedding_dim\": 243,                            \n",
            "                               \"num_filters\": 333,                              \n",
            "                               \"hidden_dim\": 400,                               \n",
            "                               \"dropout_p\": 0.4202985026503084,                 \n",
            "                               \"lr\": 0.00032975328167180194,                    \n",
            "                               \"lr_factor\": 0.013640299445594637,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 20,                                  \n",
            "                               \"threshold\": 0.2732760012149811                  \n",
            "                             }                                                  \n",
            "[01/25/21 21:01:23] INFO     Epoch: 1 | train_loss: 0.00545,        train.py:144\n",
            "                             val_loss: 0.00555, lr: 3.30E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:01:25] INFO     Epoch: 2 | train_loss: 0.00378,        train.py:144\n",
            "                             val_loss: 0.00347, lr: 3.30E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:01:26] INFO     Epoch: 3 | train_loss: 0.00308,        train.py:144\n",
            "                             val_loss: 0.00326, lr: 3.30E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:01:28] INFO     Epoch: 4 | train_loss: 0.00262,        train.py:144\n",
            "                             val_loss: 0.00318, lr: 3.30E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:01:30] INFO     Epoch: 5 | train_loss: 0.00231,        train.py:144\n",
            "                             val_loss: 0.00282, lr: 3.30E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:01:31] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 94:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 113,                               \n",
            "                               \"embedding_dim\": 234,                            \n",
            "                               \"num_filters\": 370,                              \n",
            "                               \"hidden_dim\": 338,                               \n",
            "                               \"dropout_p\": 0.3568816841465563,                 \n",
            "                               \"lr\": 0.0004146047332214895,                     \n",
            "                               \"lr_factor\": 0.014248321222959144,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"patience\": 20                                   \n",
            "                             }                                                  \n",
            "[01/25/21 21:01:32] INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 113,                               \n",
            "                               \"embedding_dim\": 234,                            \n",
            "                               \"num_filters\": 370,                              \n",
            "                               \"hidden_dim\": 338,                               \n",
            "                               \"dropout_p\": 0.3568816841465563,                 \n",
            "                               \"lr\": 0.0004146047332214895,                     \n",
            "                               \"lr_factor\": 0.014248321222959144,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 20,                                  \n",
            "                               \"threshold\": 0.2732760012149811                  \n",
            "                             }                                                  \n",
            "[01/25/21 21:01:34] INFO     Epoch: 1 | train_loss: 0.00608,        train.py:144\n",
            "                             val_loss: 0.00483, lr: 4.15E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:01:35] INFO     Epoch: 2 | train_loss: 0.00414,        train.py:144\n",
            "                             val_loss: 0.00283, lr: 4.15E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:01:37] INFO     Epoch: 3 | train_loss: 0.00314,        train.py:144\n",
            "                             val_loss: 0.00267, lr: 4.15E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:01:39] INFO     Epoch: 4 | train_loss: 0.00264,        train.py:144\n",
            "                             val_loss: 0.00249, lr: 4.15E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:01:41] INFO     Epoch: 5 | train_loss: 0.00231,        train.py:144\n",
            "                             val_loss: 0.00226, lr: 4.15E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:01:43] INFO     Epoch: 6 | train_loss: 0.00199,        train.py:144\n",
            "                             val_loss: 0.00206, lr: 4.15E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:01:44] INFO     Epoch: 7 | train_loss: 0.00174,        train.py:144\n",
            "                             val_loss: 0.00192, lr: 4.15E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:01:46] INFO     Epoch: 8 | train_loss: 0.00150,        train.py:144\n",
            "                             val_loss: 0.00184, lr: 4.15E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:01:48] INFO     Epoch: 9 | train_loss: 0.00129,        train.py:144\n",
            "                             val_loss: 0.00178, lr: 4.15E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:01:50] INFO     Epoch: 10 | train_loss: 0.00115,       train.py:144\n",
            "                             val_loss: 0.00174, lr: 4.15E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:01:52] INFO     Epoch: 11 | train_loss: 0.00098,       train.py:144\n",
            "                             val_loss: 0.00172, lr: 4.15E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:01:53] INFO     Epoch: 12 | train_loss: 0.00087,       train.py:144\n",
            "                             val_loss: 0.00170, lr: 4.15E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:01:55] INFO     Epoch: 13 | train_loss: 0.00075,       train.py:144\n",
            "                             val_loss: 0.00172, lr: 4.15E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:01:57] INFO     Epoch: 14 | train_loss: 0.00065,       train.py:144\n",
            "                             val_loss: 0.00172, lr: 4.15E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 21:01:59] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 95:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 108,                               \n",
            "                               \"embedding_dim\": 239,                            \n",
            "                               \"num_filters\": 354,                              \n",
            "                               \"hidden_dim\": 359,                               \n",
            "                               \"dropout_p\": 0.482646551764332,                  \n",
            "                               \"lr\": 0.000354544087944986,                      \n",
            "                               \"lr_factor\": 0.011366480302116393,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"patience\": 19                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 108,                               \n",
            "                               \"embedding_dim\": 239,                            \n",
            "                               \"num_filters\": 354,                              \n",
            "                               \"hidden_dim\": 359,                               \n",
            "                               \"dropout_p\": 0.482646551764332,                  \n",
            "                               \"lr\": 0.000354544087944986,                      \n",
            "                               \"lr_factor\": 0.011366480302116393,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 19,                                  \n",
            "                               \"threshold\": 0.2732760012149811                  \n",
            "                             }                                                  \n",
            "[01/25/21 21:02:01] INFO     Epoch: 1 | train_loss: 0.00588,        train.py:144\n",
            "                             val_loss: 0.00474, lr: 3.55E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:02:03] INFO     Epoch: 2 | train_loss: 0.00416,        train.py:144\n",
            "                             val_loss: 0.00282, lr: 3.55E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:02:04] INFO     Epoch: 3 | train_loss: 0.00321,        train.py:144\n",
            "                             val_loss: 0.00263, lr: 3.55E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:02:06] INFO     Epoch: 4 | train_loss: 0.00268,        train.py:144\n",
            "                             val_loss: 0.00251, lr: 3.55E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:02:08] INFO     Epoch: 5 | train_loss: 0.00238,        train.py:144\n",
            "                             val_loss: 0.00227, lr: 3.55E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:02:10] INFO     Epoch: 6 | train_loss: 0.00207,        train.py:144\n",
            "                             val_loss: 0.00213, lr: 3.55E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:02:11] INFO     Epoch: 7 | train_loss: 0.00182,        train.py:144\n",
            "                             val_loss: 0.00199, lr: 3.55E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:02:13] INFO     Epoch: 8 | train_loss: 0.00160,        train.py:144\n",
            "                             val_loss: 0.00189, lr: 3.55E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:02:15] INFO     Epoch: 9 | train_loss: 0.00142,        train.py:144\n",
            "                             val_loss: 0.00183, lr: 3.55E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:02:17] INFO     Epoch: 10 | train_loss: 0.00131,       train.py:144\n",
            "                             val_loss: 0.00177, lr: 3.55E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:02:18] INFO     Epoch: 11 | train_loss: 0.00113,       train.py:144\n",
            "                             val_loss: 0.00173, lr: 3.55E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:02:20] INFO     Epoch: 12 | train_loss: 0.00102,       train.py:144\n",
            "                             val_loss: 0.00172, lr: 3.55E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:02:22] INFO     Epoch: 13 | train_loss: 0.00090,       train.py:144\n",
            "                             val_loss: 0.00169, lr: 3.55E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:02:24] INFO     Epoch: 14 | train_loss: 0.00082,       train.py:144\n",
            "                             val_loss: 0.00173, lr: 3.55E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 21:02:25] INFO     Epoch: 15 | train_loss: 0.00073,       train.py:144\n",
            "                             val_loss: 0.00169, lr: 3.55E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:02:27] INFO     Epoch: 16 | train_loss: 0.00064,       train.py:144\n",
            "                             val_loss: 0.00176, lr: 3.55E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 21:02:29] INFO     Epoch: 17 | train_loss: 0.00057,       train.py:144\n",
            "                             val_loss: 0.00174, lr: 3.55E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 21:02:31] INFO     Epoch: 18 | train_loss: 0.00053,       train.py:144\n",
            "                             val_loss: 0.00169, lr: 3.55E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:02:32] INFO     Epoch: 19 | train_loss: 0.00048,       train.py:144\n",
            "                             val_loss: 0.00172, lr: 3.55E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 21:02:34] INFO     Epoch: 20 | train_loss: 0.00042,       train.py:144\n",
            "                             val_loss: 0.00178, lr: 3.55E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 21:02:36] INFO     Epoch: 21 | train_loss: 0.00038,       train.py:144\n",
            "                             val_loss: 0.00180, lr: 3.55E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 21:02:38] INFO     Epoch: 22 | train_loss: 0.00035,       train.py:144\n",
            "                             val_loss: 0.00184, lr: 3.55E-04,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 21:02:39] INFO     Epoch: 23 | train_loss: 0.00032,       train.py:144\n",
            "                             val_loss: 0.00190, lr: 3.55E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 21:02:41] INFO     Epoch: 24 | train_loss: 0.00030,       train.py:144\n",
            "                             val_loss: 0.00202, lr: 3.55E-04,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 21:02:43] INFO     Epoch: 25 | train_loss: 0.00028,       train.py:144\n",
            "                             val_loss: 0.00213, lr: 3.55E-04,                   \n",
            "                             _patience: 12                                      \n",
            "[01/25/21 21:02:45] INFO     Epoch: 26 | train_loss: 0.00026,       train.py:144\n",
            "                             val_loss: 0.00225, lr: 4.03E-06,                   \n",
            "                             _patience: 11                                      \n",
            "[01/25/21 21:02:47] INFO     Epoch: 27 | train_loss: 0.00028,       train.py:144\n",
            "                             val_loss: 0.00220, lr: 4.03E-06,                   \n",
            "                             _patience: 10                                      \n",
            "[01/25/21 21:02:48] INFO     Epoch: 28 | train_loss: 0.00026,       train.py:144\n",
            "                             val_loss: 0.00211, lr: 4.03E-06,                   \n",
            "                             _patience: 9                                       \n",
            "[01/25/21 21:02:50] INFO     Epoch: 29 | train_loss: 0.00023,       train.py:144\n",
            "                             val_loss: 0.00204, lr: 4.03E-06,                   \n",
            "                             _patience: 8                                       \n",
            "[01/25/21 21:02:52] INFO     Epoch: 30 | train_loss: 0.00022,       train.py:144\n",
            "                             val_loss: 0.00198, lr: 4.03E-06,                   \n",
            "                             _patience: 7                                       \n",
            "[01/25/21 21:02:54] INFO     Epoch: 31 | train_loss: 0.00021,       train.py:144\n",
            "                             val_loss: 0.00195, lr: 4.03E-06,                   \n",
            "                             _patience: 6                                       \n",
            "[01/25/21 21:02:55] INFO     Epoch: 32 | train_loss: 0.00021,       train.py:144\n",
            "                             val_loss: 0.00193, lr: 4.03E-06,                   \n",
            "                             _patience: 5                                       \n",
            "[01/25/21 21:02:57] INFO     Epoch: 33 | train_loss: 0.00022,       train.py:144\n",
            "                             val_loss: 0.00191, lr: 4.03E-06,                   \n",
            "                             _patience: 4                                       \n",
            "[01/25/21 21:02:59] INFO     Epoch: 34 | train_loss: 0.00021,       train.py:144\n",
            "                             val_loss: 0.00191, lr: 4.58E-08,                   \n",
            "                             _patience: 3                                       \n",
            "[01/25/21 21:03:01] INFO     Epoch: 35 | train_loss: 0.00021,       train.py:144\n",
            "                             val_loss: 0.00191, lr: 4.58E-08,                   \n",
            "                             _patience: 2                                       \n",
            "[01/25/21 21:03:02] INFO     Epoch: 36 | train_loss: 0.00022,       train.py:144\n",
            "                             val_loss: 0.00191, lr: 4.58E-08,                   \n",
            "                             _patience: 1                                       \n",
            "[01/25/21 21:03:04] INFO     Stopping early!                        train.py:139\n",
            "[01/25/21 21:03:10] INFO                                            train.py:441\n",
            "                             Trial 96:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 127,                               \n",
            "                               \"embedding_dim\": 256,                            \n",
            "                               \"num_filters\": 321,                              \n",
            "                               \"hidden_dim\": 371,                               \n",
            "                               \"dropout_p\": 0.47263738731915333,                \n",
            "                               \"lr\": 0.00038391160284337924,                    \n",
            "                               \"lr_factor\": 0.01647563278763633,                \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"patience\": 19                                   \n",
            "                             }                                                  \n",
            "[01/25/21 21:03:11] INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 127,                               \n",
            "                               \"embedding_dim\": 256,                            \n",
            "                               \"num_filters\": 321,                              \n",
            "                               \"hidden_dim\": 371,                               \n",
            "                               \"dropout_p\": 0.47263738731915333,                \n",
            "                               \"lr\": 0.00038391160284337924,                    \n",
            "                               \"lr_factor\": 0.01647563278763633,                \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 19,                                  \n",
            "                               \"threshold\": 0.2814006507396698                  \n",
            "                             }                                                  \n",
            "[01/25/21 21:03:12] INFO     Epoch: 1 | train_loss: 0.00602,        train.py:144\n",
            "                             val_loss: 0.00499, lr: 3.84E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:03:14] INFO     Epoch: 2 | train_loss: 0.00448,        train.py:144\n",
            "                             val_loss: 0.00294, lr: 3.84E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:03:16] INFO     Epoch: 3 | train_loss: 0.00345,        train.py:144\n",
            "                             val_loss: 0.00269, lr: 3.84E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:03:17] INFO     Epoch: 4 | train_loss: 0.00287,        train.py:144\n",
            "                             val_loss: 0.00265, lr: 3.84E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:03:19] INFO     Epoch: 5 | train_loss: 0.00261,        train.py:144\n",
            "                             val_loss: 0.00243, lr: 3.84E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:03:21] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 97:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 97,                                \n",
            "                               \"embedding_dim\": 236,                            \n",
            "                               \"num_filters\": 281,                              \n",
            "                               \"hidden_dim\": 327,                               \n",
            "                               \"dropout_p\": 0.443814855036018,                  \n",
            "                               \"lr\": 0.0003016568546753995,                     \n",
            "                               \"lr_factor\": 0.01291416857366702,                \n",
            "                               \"lr_patience\": 8,                                \n",
            "                               \"patience\": 20                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 97,                                \n",
            "                               \"embedding_dim\": 236,                            \n",
            "                               \"num_filters\": 281,                              \n",
            "                               \"hidden_dim\": 327,                               \n",
            "                               \"dropout_p\": 0.443814855036018,                  \n",
            "                               \"lr\": 0.0003016568546753995,                     \n",
            "                               \"lr_factor\": 0.01291416857366702,                \n",
            "                               \"lr_patience\": 8,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 20,                                  \n",
            "                               \"threshold\": 0.2814006507396698                  \n",
            "                             }                                                  \n",
            "[01/25/21 21:03:22] INFO     Epoch: 1 | train_loss: 0.00530,        train.py:144\n",
            "                             val_loss: 0.00460, lr: 3.02E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:03:24] INFO     Epoch: 2 | train_loss: 0.00377,        train.py:144\n",
            "                             val_loss: 0.00298, lr: 3.02E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:03:25] INFO     Epoch: 3 | train_loss: 0.00306,        train.py:144\n",
            "                             val_loss: 0.00283, lr: 3.02E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:03:27] INFO     Epoch: 4 | train_loss: 0.00273,        train.py:144\n",
            "                             val_loss: 0.00274, lr: 3.02E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:03:28] INFO     Epoch: 5 | train_loss: 0.00241,        train.py:144\n",
            "                             val_loss: 0.00254, lr: 3.02E-04,                   \n",
            "                             _patience: 20                                      \n",
            "[01/25/21 21:03:30] INFO     Unpromising trial pruned!              train.py:128\n",
            "                    INFO                                            train.py:441\n",
            "                             Trial 98:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 110,                               \n",
            "                               \"embedding_dim\": 233,                            \n",
            "                               \"num_filters\": 303,                              \n",
            "                               \"hidden_dim\": 346,                               \n",
            "                               \"dropout_p\": 0.4134902850759506,                 \n",
            "                               \"lr\": 0.000364031278679574,                      \n",
            "                               \"lr_factor\": 0.047786091061605626,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"patience\": 19                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 110,                               \n",
            "                               \"embedding_dim\": 233,                            \n",
            "                               \"num_filters\": 303,                              \n",
            "                               \"hidden_dim\": 346,                               \n",
            "                               \"dropout_p\": 0.4134902850759506,                 \n",
            "                               \"lr\": 0.000364031278679574,                      \n",
            "                               \"lr_factor\": 0.047786091061605626,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 19,                                  \n",
            "                               \"threshold\": 0.2814006507396698                  \n",
            "                             }                                                  \n",
            "[01/25/21 21:03:32] INFO     Epoch: 1 | train_loss: 0.00529,        train.py:144\n",
            "                             val_loss: 0.00419, lr: 3.64E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:03:33] INFO     Epoch: 2 | train_loss: 0.00371,        train.py:144\n",
            "                             val_loss: 0.00280, lr: 3.64E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:03:35] INFO     Epoch: 3 | train_loss: 0.00299,        train.py:144\n",
            "                             val_loss: 0.00264, lr: 3.64E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:03:36] INFO     Epoch: 4 | train_loss: 0.00258,        train.py:144\n",
            "                             val_loss: 0.00247, lr: 3.64E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:03:38] INFO     Epoch: 5 | train_loss: 0.00230,        train.py:144\n",
            "                             val_loss: 0.00227, lr: 3.64E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:03:39] INFO     Epoch: 6 | train_loss: 0.00201,        train.py:144\n",
            "                             val_loss: 0.00214, lr: 3.64E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:03:41] INFO     Epoch: 7 | train_loss: 0.00176,        train.py:144\n",
            "                             val_loss: 0.00200, lr: 3.64E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:03:43] INFO     Epoch: 8 | train_loss: 0.00154,        train.py:144\n",
            "                             val_loss: 0.00190, lr: 3.64E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:03:44] INFO     Epoch: 9 | train_loss: 0.00138,        train.py:144\n",
            "                             val_loss: 0.00183, lr: 3.64E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:03:46] INFO     Epoch: 10 | train_loss: 0.00124,       train.py:144\n",
            "                             val_loss: 0.00177, lr: 3.64E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:03:47] INFO     Epoch: 11 | train_loss: 0.00111,       train.py:144\n",
            "                             val_loss: 0.00176, lr: 3.64E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:03:49] INFO     Epoch: 12 | train_loss: 0.00100,       train.py:144\n",
            "                             val_loss: 0.00170, lr: 3.64E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:03:50] INFO     Epoch: 13 | train_loss: 0.00087,       train.py:144\n",
            "                             val_loss: 0.00166, lr: 3.64E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:03:52] INFO     Epoch: 14 | train_loss: 0.00079,       train.py:144\n",
            "                             val_loss: 0.00164, lr: 3.64E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:03:53] INFO     Epoch: 15 | train_loss: 0.00069,       train.py:144\n",
            "                             val_loss: 0.00169, lr: 3.64E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 21:03:55] INFO     Epoch: 16 | train_loss: 0.00062,       train.py:144\n",
            "                             val_loss: 0.00171, lr: 3.64E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 21:03:56] INFO     Epoch: 17 | train_loss: 0.00058,       train.py:144\n",
            "                             val_loss: 0.00170, lr: 3.64E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 21:03:58] INFO     Epoch: 18 | train_loss: 0.00051,       train.py:144\n",
            "                             val_loss: 0.00163, lr: 3.64E-04,                   \n",
            "                             _patience: 19                                      \n",
            "[01/25/21 21:04:00] INFO     Epoch: 19 | train_loss: 0.00046,       train.py:144\n",
            "                             val_loss: 0.00169, lr: 3.64E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 21:04:01] INFO     Epoch: 20 | train_loss: 0.00043,       train.py:144\n",
            "                             val_loss: 0.00176, lr: 3.64E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 21:04:03] INFO     Epoch: 21 | train_loss: 0.00038,       train.py:144\n",
            "                             val_loss: 0.00187, lr: 3.64E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 21:04:04] INFO     Epoch: 22 | train_loss: 0.00035,       train.py:144\n",
            "                             val_loss: 0.00206, lr: 3.64E-04,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 21:04:06] INFO     Epoch: 23 | train_loss: 0.00033,       train.py:144\n",
            "                             val_loss: 0.00209, lr: 3.64E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 21:04:07] INFO     Epoch: 24 | train_loss: 0.00032,       train.py:144\n",
            "                             val_loss: 0.00211, lr: 3.64E-04,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 21:04:09] INFO     Epoch: 25 | train_loss: 0.00027,       train.py:144\n",
            "                             val_loss: 0.00191, lr: 3.64E-04,                   \n",
            "                             _patience: 12                                      \n",
            "[01/25/21 21:04:10] INFO     Epoch: 26 | train_loss: 0.00026,       train.py:144\n",
            "                             val_loss: 0.00183, lr: 1.74E-05,                   \n",
            "                             _patience: 11                                      \n",
            "[01/25/21 21:04:12] INFO     Epoch: 27 | train_loss: 0.00023,       train.py:144\n",
            "                             val_loss: 0.00186, lr: 1.74E-05,                   \n",
            "                             _patience: 10                                      \n",
            "[01/25/21 21:04:13] INFO     Epoch: 28 | train_loss: 0.00021,       train.py:144\n",
            "                             val_loss: 0.00186, lr: 1.74E-05,                   \n",
            "                             _patience: 9                                       \n",
            "[01/25/21 21:04:15] INFO     Epoch: 29 | train_loss: 0.00020,       train.py:144\n",
            "                             val_loss: 0.00185, lr: 1.74E-05,                   \n",
            "                             _patience: 8                                       \n",
            "[01/25/21 21:04:16] INFO     Epoch: 30 | train_loss: 0.00020,       train.py:144\n",
            "                             val_loss: 0.00185, lr: 1.74E-05,                   \n",
            "                             _patience: 7                                       \n",
            "[01/25/21 21:04:18] INFO     Epoch: 31 | train_loss: 0.00019,       train.py:144\n",
            "                             val_loss: 0.00184, lr: 1.74E-05,                   \n",
            "                             _patience: 6                                       \n",
            "[01/25/21 21:04:19] INFO     Epoch: 32 | train_loss: 0.00019,       train.py:144\n",
            "                             val_loss: 0.00185, lr: 1.74E-05,                   \n",
            "                             _patience: 5                                       \n",
            "[01/25/21 21:04:21] INFO     Epoch: 33 | train_loss: 0.00019,       train.py:144\n",
            "                             val_loss: 0.00185, lr: 1.74E-05,                   \n",
            "                             _patience: 4                                       \n",
            "[01/25/21 21:04:22] INFO     Epoch: 34 | train_loss: 0.00020,       train.py:144\n",
            "                             val_loss: 0.00185, lr: 8.31E-07,                   \n",
            "                             _patience: 3                                       \n",
            "[01/25/21 21:04:24] INFO     Epoch: 35 | train_loss: 0.00019,       train.py:144\n",
            "                             val_loss: 0.00185, lr: 8.31E-07,                   \n",
            "                             _patience: 2                                       \n",
            "[01/25/21 21:04:26] INFO     Epoch: 36 | train_loss: 0.00019,       train.py:144\n",
            "                             val_loss: 0.00185, lr: 8.31E-07,                   \n",
            "                             _patience: 1                                       \n",
            "[01/25/21 21:04:27] INFO     Stopping early!                        train.py:139\n",
            "[01/25/21 21:04:33] INFO                                            train.py:441\n",
            "                             Trial 99:                                          \n",
            "                    INFO     {                                      train.py:442\n",
            "                               \"batch_size\": 115,                               \n",
            "                               \"embedding_dim\": 229,                            \n",
            "                               \"num_filters\": 340,                              \n",
            "                               \"hidden_dim\": 362,                               \n",
            "                               \"dropout_p\": 0.39368524315906983,                \n",
            "                               \"lr\": 0.00043692839961937714,                    \n",
            "                               \"lr_factor\": 0.015216118713701779,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"patience\": 10                                   \n",
            "                             }                                                  \n",
            "                    INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 115,                               \n",
            "                               \"embedding_dim\": 229,                            \n",
            "                               \"num_filters\": 340,                              \n",
            "                               \"hidden_dim\": 362,                               \n",
            "                               \"dropout_p\": 0.39368524315906983,                \n",
            "                               \"lr\": 0.00043692839961937714,                    \n",
            "                               \"lr_factor\": 0.015216118713701779,               \n",
            "                               \"lr_patience\": 7,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 10,                                  \n",
            "                               \"threshold\": 0.29145777225494385                 \n",
            "                             }                                                  \n",
            "[01/25/21 21:04:34] INFO     Epoch: 1 | train_loss: 0.00577,        train.py:144\n",
            "                             val_loss: 0.00423, lr: 4.37E-04,                   \n",
            "                             _patience: 10                                      \n",
            "[01/25/21 21:04:36] INFO     Epoch: 2 | train_loss: 0.00393,        train.py:144\n",
            "                             val_loss: 0.00287, lr: 4.37E-04,                   \n",
            "                             _patience: 10                                      \n",
            "[01/25/21 21:04:38] INFO     Epoch: 3 | train_loss: 0.00313,        train.py:144\n",
            "                             val_loss: 0.00269, lr: 4.37E-04,                   \n",
            "                             _patience: 10                                      \n",
            "[01/25/21 21:04:39] INFO     Epoch: 4 | train_loss: 0.00264,        train.py:144\n",
            "                             val_loss: 0.00245, lr: 4.37E-04,                   \n",
            "                             _patience: 10                                      \n",
            "[01/25/21 21:04:41] INFO     Epoch: 5 | train_loss: 0.00232,        train.py:144\n",
            "                             val_loss: 0.00224, lr: 4.37E-04,                   \n",
            "                             _patience: 10                                      \n",
            "[01/25/21 21:04:42] INFO     Epoch: 6 | train_loss: 0.00198,        train.py:144\n",
            "                             val_loss: 0.00204, lr: 4.37E-04,                   \n",
            "                             _patience: 10                                      \n",
            "[01/25/21 21:04:44] INFO     Epoch: 7 | train_loss: 0.00171,        train.py:144\n",
            "                             val_loss: 0.00192, lr: 4.37E-04,                   \n",
            "                             _patience: 10                                      \n",
            "[01/25/21 21:04:46] INFO     Epoch: 8 | train_loss: 0.00144,        train.py:144\n",
            "                             val_loss: 0.00186, lr: 4.37E-04,                   \n",
            "                             _patience: 10                                      \n",
            "[01/25/21 21:04:47] INFO     Epoch: 9 | train_loss: 0.00127,        train.py:144\n",
            "                             val_loss: 0.00178, lr: 4.37E-04,                   \n",
            "                             _patience: 10                                      \n",
            "[01/25/21 21:04:49] INFO     Epoch: 10 | train_loss: 0.00112,       train.py:144\n",
            "                             val_loss: 0.00175, lr: 4.37E-04,                   \n",
            "                             _patience: 10                                      \n",
            "[01/25/21 21:04:51] INFO     Epoch: 11 | train_loss: 0.00098,       train.py:144\n",
            "                             val_loss: 0.00173, lr: 4.37E-04,                   \n",
            "                             _patience: 10                                      \n",
            "[01/25/21 21:04:52] INFO     Epoch: 12 | train_loss: 0.00084,       train.py:144\n",
            "                             val_loss: 0.00169, lr: 4.37E-04,                   \n",
            "                             _patience: 10                                      \n",
            "[01/25/21 21:04:54] INFO     Epoch: 13 | train_loss: 0.00076,       train.py:144\n",
            "                             val_loss: 0.00167, lr: 4.37E-04,                   \n",
            "                             _patience: 10                                      \n",
            "[01/25/21 21:04:56] INFO     Epoch: 14 | train_loss: 0.00064,       train.py:144\n",
            "                             val_loss: 0.00166, lr: 4.37E-04,                   \n",
            "                             _patience: 10                                      \n",
            "[01/25/21 21:04:57] INFO     Epoch: 15 | train_loss: 0.00057,       train.py:144\n",
            "                             val_loss: 0.00167, lr: 4.37E-04,                   \n",
            "                             _patience: 9                                       \n",
            "[01/25/21 21:04:59] INFO     Epoch: 16 | train_loss: 0.00051,       train.py:144\n",
            "                             val_loss: 0.00167, lr: 4.37E-04,                   \n",
            "                             _patience: 8                                       \n",
            "[01/25/21 21:05:01] INFO     Epoch: 17 | train_loss: 0.00045,       train.py:144\n",
            "                             val_loss: 0.00177, lr: 4.37E-04,                   \n",
            "                             _patience: 7                                       \n",
            "[01/25/21 21:05:02] INFO     Epoch: 18 | train_loss: 0.00041,       train.py:144\n",
            "                             val_loss: 0.00185, lr: 4.37E-04,                   \n",
            "                             _patience: 6                                       \n",
            "[01/25/21 21:05:04] INFO     Epoch: 19 | train_loss: 0.00034,       train.py:144\n",
            "                             val_loss: 0.00191, lr: 4.37E-04,                   \n",
            "                             _patience: 5                                       \n",
            "[01/25/21 21:05:05] INFO     Epoch: 20 | train_loss: 0.00031,       train.py:144\n",
            "                             val_loss: 0.00192, lr: 4.37E-04,                   \n",
            "                             _patience: 4                                       \n",
            "[01/25/21 21:05:07] INFO     Epoch: 21 | train_loss: 0.00029,       train.py:144\n",
            "                             val_loss: 0.00188, lr: 4.37E-04,                   \n",
            "                             _patience: 3                                       \n",
            "[01/25/21 21:05:09] INFO     Epoch: 22 | train_loss: 0.00027,       train.py:144\n",
            "                             val_loss: 0.00190, lr: 6.65E-06,                   \n",
            "                             _patience: 2                                       \n",
            "[01/25/21 21:05:10] INFO     Epoch: 23 | train_loss: 0.00025,       train.py:144\n",
            "                             val_loss: 0.00189, lr: 6.65E-06,                   \n",
            "                             _patience: 1                                       \n",
            "[01/25/21 21:05:12] INFO     Stopping early!                        train.py:139\n",
            "[01/25/21 21:05:18] INFO     Best value (`best_val_loss`):           main.py:155\n",
            "                             0.001545427250675857                               \n",
            "                    INFO     {                                       main.py:160\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 108,                               \n",
            "                               \"embedding_dim\": 219,                            \n",
            "                               \"num_filters\": 323,                              \n",
            "                               \"hidden_dim\": 258,                               \n",
            "                               \"dropout_p\": 0.7260450751601542,                 \n",
            "                               \"lr\": 0.00035139411956407017,                    \n",
            "                               \"lr_factor\": 0.04568234107529491,                \n",
            "                               \"lr_patience\": 6,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 18,                                  \n",
            "                               \"threshold\": 0.256205677986145                   \n",
            "                             }                                                  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOT46qHmD1ZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97cfa8e5-3356-4be0-d613-d59e0f088bfd"
      },
      "source": [
        "# Train best model (saving artifacts this time)\n",
        "main.train_model()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[01/25/21 21:14:13] INFO     Arguments: {                           train.py:397\n",
            "                               \"seed\": 1234,                                    \n",
            "                               \"cuda\": true,                                    \n",
            "                               \"shuffle\": true,                                 \n",
            "                               \"num_samples\": 0,                                \n",
            "                               \"min_tag_freq\": 30,                              \n",
            "                               \"lower\": true,                                   \n",
            "                               \"stem\": false,                                   \n",
            "                               \"train_size\": 0.7,                               \n",
            "                               \"char_level\": true,                              \n",
            "                               \"max_filter_size\": 10,                           \n",
            "                               \"batch_size\": 108,                               \n",
            "                               \"embedding_dim\": 219,                            \n",
            "                               \"num_filters\": 323,                              \n",
            "                               \"hidden_dim\": 258,                               \n",
            "                               \"dropout_p\": 0.7260450751601542,                 \n",
            "                               \"lr\": 0.00035139411956407017,                    \n",
            "                               \"lr_factor\": 0.04568234107529491,                \n",
            "                               \"lr_patience\": 6,                                \n",
            "                               \"num_epochs\": 200,                               \n",
            "                               \"patience\": 18,                                  \n",
            "                               \"threshold\": 0.256205677986145                   \n",
            "                             }                                                  \n",
            "[01/25/21 21:14:14] INFO     Epoch: 1 | train_loss: 0.00705,        train.py:144\n",
            "                             val_loss: 0.00443, lr: 3.51E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 21:14:16] INFO     Epoch: 2 | train_loss: 0.00513,        train.py:144\n",
            "                             val_loss: 0.00303, lr: 3.51E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 21:14:18] INFO     Epoch: 3 | train_loss: 0.00385,        train.py:144\n",
            "                             val_loss: 0.00273, lr: 3.51E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 21:14:19] INFO     Epoch: 4 | train_loss: 0.00327,        train.py:144\n",
            "                             val_loss: 0.00267, lr: 3.51E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 21:14:21] INFO     Epoch: 5 | train_loss: 0.00301,        train.py:144\n",
            "                             val_loss: 0.00255, lr: 3.51E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 21:14:22] INFO     Epoch: 6 | train_loss: 0.00280,        train.py:144\n",
            "                             val_loss: 0.00245, lr: 3.51E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 21:14:24] INFO     Epoch: 7 | train_loss: 0.00255,        train.py:144\n",
            "                             val_loss: 0.00232, lr: 3.51E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 21:14:26] INFO     Epoch: 8 | train_loss: 0.00240,        train.py:144\n",
            "                             val_loss: 0.00220, lr: 3.51E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 21:14:27] INFO     Epoch: 9 | train_loss: 0.00227,        train.py:144\n",
            "                             val_loss: 0.00209, lr: 3.51E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 21:14:29] INFO     Epoch: 10 | train_loss: 0.00211,       train.py:144\n",
            "                             val_loss: 0.00203, lr: 3.51E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 21:14:31] INFO     Epoch: 11 | train_loss: 0.00200,       train.py:144\n",
            "                             val_loss: 0.00194, lr: 3.51E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 21:14:32] INFO     Epoch: 12 | train_loss: 0.00185,       train.py:144\n",
            "                             val_loss: 0.00192, lr: 3.51E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 21:14:34] INFO     Epoch: 13 | train_loss: 0.00175,       train.py:144\n",
            "                             val_loss: 0.00188, lr: 3.51E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 21:14:36] INFO     Epoch: 14 | train_loss: 0.00160,       train.py:144\n",
            "                             val_loss: 0.00185, lr: 3.51E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 21:14:37] INFO     Epoch: 15 | train_loss: 0.00151,       train.py:144\n",
            "                             val_loss: 0.00181, lr: 3.51E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 21:14:39] INFO     Epoch: 16 | train_loss: 0.00145,       train.py:144\n",
            "                             val_loss: 0.00175, lr: 3.51E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 21:14:41] INFO     Epoch: 17 | train_loss: 0.00132,       train.py:144\n",
            "                             val_loss: 0.00170, lr: 3.51E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 21:14:42] INFO     Epoch: 18 | train_loss: 0.00126,       train.py:144\n",
            "                             val_loss: 0.00176, lr: 3.51E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 21:14:44] INFO     Epoch: 19 | train_loss: 0.00115,       train.py:144\n",
            "                             val_loss: 0.00175, lr: 3.51E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 21:14:46] INFO     Epoch: 20 | train_loss: 0.00115,       train.py:144\n",
            "                             val_loss: 0.00174, lr: 3.51E-04,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 21:14:47] INFO     Epoch: 21 | train_loss: 0.00108,       train.py:144\n",
            "                             val_loss: 0.00166, lr: 3.51E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 21:14:49] INFO     Epoch: 22 | train_loss: 0.00101,       train.py:144\n",
            "                             val_loss: 0.00176, lr: 3.51E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 21:14:51] INFO     Epoch: 23 | train_loss: 0.00094,       train.py:144\n",
            "                             val_loss: 0.00168, lr: 3.51E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 21:14:52] INFO     Epoch: 24 | train_loss: 0.00092,       train.py:144\n",
            "                             val_loss: 0.00167, lr: 3.51E-04,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 21:14:54] INFO     Epoch: 25 | train_loss: 0.00091,       train.py:144\n",
            "                             val_loss: 0.00171, lr: 3.51E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 21:14:56] INFO     Epoch: 26 | train_loss: 0.00086,       train.py:144\n",
            "                             val_loss: 0.00171, lr: 3.51E-04,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 21:14:57] INFO     Epoch: 27 | train_loss: 0.00081,       train.py:144\n",
            "                             val_loss: 0.00164, lr: 3.51E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 21:14:59] INFO     Epoch: 28 | train_loss: 0.00077,       train.py:144\n",
            "                             val_loss: 0.00177, lr: 3.51E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 21:15:00] INFO     Epoch: 29 | train_loss: 0.00070,       train.py:144\n",
            "                             val_loss: 0.00161, lr: 3.51E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 21:15:02] INFO     Epoch: 30 | train_loss: 0.00068,       train.py:144\n",
            "                             val_loss: 0.00166, lr: 3.51E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 21:15:04] INFO     Epoch: 31 | train_loss: 0.00068,       train.py:144\n",
            "                             val_loss: 0.00159, lr: 3.51E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 21:15:05] INFO     Epoch: 32 | train_loss: 0.00065,       train.py:144\n",
            "                             val_loss: 0.00167, lr: 3.51E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 21:15:07] INFO     Epoch: 33 | train_loss: 0.00060,       train.py:144\n",
            "                             val_loss: 0.00156, lr: 3.51E-04,                   \n",
            "                             _patience: 18                                      \n",
            "[01/25/21 21:15:09] INFO     Epoch: 34 | train_loss: 0.00064,       train.py:144\n",
            "                             val_loss: 0.00160, lr: 3.51E-04,                   \n",
            "                             _patience: 17                                      \n",
            "[01/25/21 21:15:10] INFO     Epoch: 35 | train_loss: 0.00059,       train.py:144\n",
            "                             val_loss: 0.00157, lr: 3.51E-04,                   \n",
            "                             _patience: 16                                      \n",
            "[01/25/21 21:15:12] INFO     Epoch: 36 | train_loss: 0.00067,       train.py:144\n",
            "                             val_loss: 0.00166, lr: 3.51E-04,                   \n",
            "                             _patience: 15                                      \n",
            "[01/25/21 21:15:14] INFO     Epoch: 37 | train_loss: 0.00070,       train.py:144\n",
            "                             val_loss: 0.00173, lr: 3.51E-04,                   \n",
            "                             _patience: 14                                      \n",
            "[01/25/21 21:15:15] INFO     Epoch: 38 | train_loss: 0.00075,       train.py:144\n",
            "                             val_loss: 0.00287, lr: 3.51E-04,                   \n",
            "                             _patience: 13                                      \n",
            "[01/25/21 21:15:17] INFO     Epoch: 39 | train_loss: 0.00101,       train.py:144\n",
            "                             val_loss: 0.00271, lr: 3.51E-04,                   \n",
            "                             _patience: 12                                      \n",
            "[01/25/21 21:15:18] INFO     Epoch: 40 | train_loss: 0.00138,       train.py:144\n",
            "                             val_loss: 0.00176, lr: 1.61E-05,                   \n",
            "                             _patience: 11                                      \n",
            "[01/25/21 21:15:20] INFO     Epoch: 41 | train_loss: 0.00132,       train.py:144\n",
            "                             val_loss: 0.00180, lr: 1.61E-05,                   \n",
            "                             _patience: 10                                      \n",
            "[01/25/21 21:15:22] INFO     Epoch: 42 | train_loss: 0.00071,       train.py:144\n",
            "                             val_loss: 0.00222, lr: 1.61E-05,                   \n",
            "                             _patience: 9                                       \n",
            "[01/25/21 21:15:23] INFO     Epoch: 43 | train_loss: 0.00068,       train.py:144\n",
            "                             val_loss: 0.00227, lr: 1.61E-05,                   \n",
            "                             _patience: 8                                       \n",
            "[01/25/21 21:15:25] INFO     Epoch: 44 | train_loss: 0.00063,       train.py:144\n",
            "                             val_loss: 0.00210, lr: 1.61E-05,                   \n",
            "                             _patience: 7                                       \n",
            "[01/25/21 21:15:27] INFO     Epoch: 45 | train_loss: 0.00059,       train.py:144\n",
            "                             val_loss: 0.00197, lr: 1.61E-05,                   \n",
            "                             _patience: 6                                       \n",
            "[01/25/21 21:15:28] INFO     Epoch: 46 | train_loss: 0.00059,       train.py:144\n",
            "                             val_loss: 0.00194, lr: 1.61E-05,                   \n",
            "                             _patience: 5                                       \n",
            "[01/25/21 21:15:30] INFO     Epoch: 47 | train_loss: 0.00059,       train.py:144\n",
            "                             val_loss: 0.00195, lr: 7.33E-07,                   \n",
            "                             _patience: 4                                       \n",
            "[01/25/21 21:15:31] INFO     Epoch: 48 | train_loss: 0.00056,       train.py:144\n",
            "                             val_loss: 0.00195, lr: 7.33E-07,                   \n",
            "                             _patience: 3                                       \n",
            "[01/25/21 21:15:33] INFO     Epoch: 49 | train_loss: 0.00055,       train.py:144\n",
            "                             val_loss: 0.00195, lr: 7.33E-07,                   \n",
            "                             _patience: 2                                       \n",
            "[01/25/21 21:15:35] INFO     Epoch: 50 | train_loss: 0.00054,       train.py:144\n",
            "                             val_loss: 0.00195, lr: 7.33E-07,                   \n",
            "                             _patience: 1                                       \n",
            "[01/25/21 21:15:36] INFO     Stopping early!                        train.py:139\n",
            "[01/25/21 21:15:42] INFO     {                                        main.py:87\n",
            "                               \"precision\": 0.882797046765664,                  \n",
            "                               \"recall\": 0.49729312491012,                      \n",
            "                               \"f1\": 0.6060952005221534,                        \n",
            "                               \"num_samples\": 474.0                             \n",
            "                             }                                                  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8Wm1xPl0HyF"
      },
      "source": [
        "## Download"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJrowj_lzvtz"
      },
      "source": [
        "Download and transfer files to your local system and run the command `tagifai set-artifact-metadata` to match all metadata as if it were run from your machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEkEtbaX0LbU"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJeRbLxh0NxV"
      },
      "source": [
        "# Download\n",
        "!zip -r best.zip assets/experiments/1\n",
        "files.download('best.zip') \n",
        "files.download('assets/experiments/trials.csv')\n",
        "files.download('config/args.json') "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}