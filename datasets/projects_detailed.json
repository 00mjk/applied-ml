[{"id":2438,"title":"How to Deal with Files in Google Colab: What You Need to Know","description":"How to supercharge your Google Colab experience by reading external files or data in Google Colab and writing from Google Colab to those external data sources.","tags":["article","google-colab","colab","file-system"],"details":"In this post we address practical issues when working with Google Colab notebooks. We focus on the data management topics, and how to work with some clouds providers and Kaggle.\r\n\r\n#### Data management\r\n\r\n* Directory and File operations in Google Colab\r\n* How to Upload files to, and Download files from Google Colab\r\n* Accessing Local File System to Google Colab\r\n* Accessing Google Drive from Google Colab\r\n* Accessing Google Sheets from Google Colab\r\n* Accessing MySQL databases from Google Colab\r\n\r\n\r\n\r\n#### Working with cloud and Kaggle\r\n\r\n* Accessing Google Cloud Storage (GCS) from Google Colab\r\n* Accessing AWS S3 from Google Colab\r\n* Accessing Kaggle datasets from Google Colab","links":[{"article_link":"https://neptune.ai/blog/google-colab-dealing-with-files?utm_source=madewithml&utm_medium=post&utm_campaign=blog-google-colab-dealing-with-files","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://neptune.ai/blog/google-colab-dealing-with-files?utm_source=madewithml&utm_medium=post&utm_campaign=blog-google-colab-dealing-with-files"}]},{"id":2437,"title":"Rasoee","description":"A powerful web and mobile application that identifies food dishes from a given input image, and provides an ingredient list along with relevant recipes.","tags":["api","article","code","dataset","paper","research","django","pytorch","food","computer-vision","web-app","cooking","mobile","demo","android","efficient-net","kotlin"],"details":"# Highlighted Features:\r\nRasoee takes an input image of a food dish and\r\n\r\n* Identifies the dish in the image\r\n* Provides the user with an ingredient list of the identified dish\r\n* Provides the user with relevant recipes of the identified dish\r\n\r\nRasoee also takes in a text input of a cuisine + description and \r\n\r\n* Recommends a dish based on the user's input\r\n\r\n# How it Works:\r\nRasoee can be divided into 4 main sections:\r\n\r\n# 1. Rasoee - Image Detection Model\r\n* The model was based primarily on the Efficient-Net B2 architecture\r\n* It was built using PyTorch on Tesla P100 GPUs\r\n* Efficient-Net B2 was specifically chosen as it gave us a good accuracy on our dataset [91.31%] and it was of a suitable size to run on edge devices like a smartphone\r\n* We trained the model using SGD with momentum and used a steady learning rate decay\r\n* Training Notebook available [here](https://github.com/DevChuriwala/Rasoee/blob/master/EfficientNetB2%20Training.ipynb)\r\n\r\n# 2. Rasoee - Dataset\r\n* The dataset consists of 308 different dishes from 6+ cuisines\r\n* There are 500 images in each class with slightly noisy data and some outliers too\r\n* All the images were processed to the same size [600 x 600] \r\n* Fixed split into train, test, and validation in a 8:1:1 ratio\r\n* The data was scraped using the Bing image API \r\n* Dataset available [here](https://www.kaggle.com/synysterjeet/food-classification)\r\n\r\n# 3. Rasoee - Android App\r\n* The Rasoee App uses the PyTorch Mobile API to execute ML models on the edge to reduce latency and preserve privacy\r\n* It uses the Model-view-viewmodel (MVVM) architecture, which separates the UI from the data\r\n* It uses a web-based API to find appropriate recipes and display up to 10 of them in the app\r\n* Being an edge-based model, it can identify the dish without being connected to the internet\r\n* App available [here](https://github.com/ameyalaad/Rasoee/releases/download/v1.0/rasoee.apk)\r\n\r\n# 4. Rasoee - Web App\r\n* The Rasoee Web App was made using Django and SQL\r\n* We used the Recipe Puppy API to retrieve the ingredients list and relevant recipes\r\n* The Web App uses Pytorch to load and deploy the model \r\n* Website - [Rasoee](http://rasoee.herokuapp.com/)\r\n\r\n\r\n# Rasoee's Development - About Us:\r\nWe are a group of friends studying together, and we all happen to be foodies. So this is a project quite close to our heart, or maybe stomach.\r\n\r\nSo, all of us had varying levels of familiarity with Machine Learning and PyTorch as well as knowledge in other fields, and so we divided the tasks among ourselves accordingly. One guy made the website, one guy made the app, the others looked for datasets and models that we could train to make this work. We wanted to be ambitious enough to make out own dataset despite there being Food-101 available online, so we went ahead with that and scraped to the best of our abilities to make a workable dataset. The cleaning of the dataset was quite a grueling task, followed by the question of which model to use. We tested a few small scale models as we wanted this to be deployable on mobile devices, and in the end got a good enough accuracy with one to go ahead. This was followed by the usual nitpicking in the looks of the website and the application along with the addition of auxiliary features like provision of recipe and list of ingredients.\r\n\r\nFinally we made something, that we are proud of, and hope it prevents many food lovers out there from racking their brains during identifying dishes, and use more of their time eating!\r\n\r\nCheers!","links":[{"article_link":"https://github.com/ameyalaad/Rasoee/releases/download/v1.0/rasoee.apk","code_link":"https://github.com/DevChuriwala/Rasoee","research_link":"https://github.com/DevChuriwala/Rasoee/blob/master/README.md","media_link":"https://youtu.be/wgwRnuQ0R7g","dataset_link":"https://www.kaggle.com/synysterjeet/food-classification","demo_link":"http://rasoee.herokuapp.com/","other_link":""}]},{"id":2436,"title":"Machine Learning Methods Explained (+ Examples)","description":"Most common techniques used in data science projects; get to know them through easy-to-understand examples and put them into practice in your own ML projects!","tags":["article","deep-learning","machine-learning","dimensionality-reduction","reinforcement-learning","unsupervised-learning","artificial-intelligence","neptune-ai","neptune"],"details":"We present, methods most commonly used in machine learning projects (with examples), categorized into three types of learning:\r\n\r\n#### Supervised Learning\r\n* Regression\r\n* Classification\r\n* Ensemble Learning\r\n\r\n![mapping](https://lh3.googleusercontent.com/dVBGq2Ku83IoI6oaP0CH4DdRqgPjHLY1Dmq3theq2vXvyc7yfRP_u9rNy0ICSwlIzxHJVshPQxHBuPSju8Qu2ZMIdcn_TJL_t8v4x2q0_EUPHHi14fhtoPW4GbdheZQw9MbhioEX)\r\n\r\n---\r\n\r\n#### Unsupervised Learning\r\n* Clustering, \r\n* Dimensionality Reduction\r\n\r\n![clusters](https://lh4.googleusercontent.com/jLL4OMGeCSTtNscgQ-fiANLOiR888h0foZ2YPfmG_ZD2G7xQuev-dcXhA949HxiKlM7JcDrfacND9mG75Z49IjKGPqURt7aAEqEMxQl3BLB2hmXtcqJWMllcLKEGqGs8VgQM6hCB)\r\n\r\n---\r\n\r\n#### Reinforcement Learning\r\n![mario](https://i2.wp.com/neptune.ai/wp-content/uploads/mario-mission.png?resize=232%2C227&ssl=1)\r\n","links":[{"article_link":"https://neptune.ai/blog/machine-learning-methods?utm_source=madewithml&utm_medium=post&utm_campaign=blog-machine-learning-methods","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://neptune.ai/blog/machine-learning-methods?utm_source=madewithml&utm_medium=post&utm_campaign=blog-machine-learning-methods"}]},{"id":2435,"title":"Top \u201cApplied Data Science\u201d Papers from ECML-PKDD 2020","description":"Explore the innovative world of Machine Learning with these inspiring Applied Data Science papers from this year\u2019s ECML-PKDD 2020 Conference!","tags":["article","deep-learning","machine-learning","advertising","computer-hardware","healthcare","sports","transportation","anomaly-detection","data-science"],"details":"### ECML-PKDD 2020\r\n\r\nECML-PKDD is one of the premier conferences on Machine Learning in Europe. It showcases a large number of new ideas and inspiring developments in the ML field.\r\n\r\nWe bring you top research papers, which are divided into the following categories:\r\n\r\n* Sports \r\n* Hardware and manufacturing \r\n* Transportation \r\n* Anomaly detection \r\n* Advertisement \r\n* Web mining \r\n* Computational social science \r\n* E-commerce and finance \r\n* Social good\r\n\r\n![img](https://i2.wp.com/neptune.ai/wp-content/uploads/ECML-top-applied-papers.jpg?w=1920&ssl=1)","links":[{"article_link":"https://neptune.ai/blog/ecml-pkdd-2020-applied-data-science?utm_source=madewithml&utm_medium=post&utm_campaign=blog-ecml-pkdd-2020-applied-data-science","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://neptune.ai/blog/ecml-pkdd-2020-applied-data-science?utm_source=madewithml&utm_medium=post&utm_campaign=blog-ecml-pkdd-2020-applied-data-science"}]},{"id":2434,"title":"OpenMMLab Computer Vision","description":"MMCV is a python library for CV research and supports many research projects such as object detection, segmentation, pose estimation, action classification.\r\n\r\n","tags":["article","code","pytorch","library","3d","computer-vision","image-classification","image-generation","object-detection","pose-estimation","super-resolution","3d-object-detection","pretraining","segmentation","inpainting","action-recognition","model-zoo","matting"],"details":"MMCV is a foundational python library for computer vision research and supports many research projects as below:\r\n\r\n- [MMDetection](https://github.com/open-mmlab/mmdetection): Detection toolbox and benchmark\r\n- [MMDetection3D](https://github.com/open-mmlab/mmdetection3d): General 3D object detection toolbox and benchmark\r\n- [MMSegmentation](https://github.com/open-mmlab/mmsegmentation): Semantic segmentation toolbox and benchmark\r\n- [MMEditing](https://github.com/open-mmlab/mmediting): Image and video editing toolbox\r\n- [MMPose](https://github.com/open-mmlab/mmpose): Pose estimation toolbox and benchmark\r\n- [MMAction2](https://github.com/open-mmlab/mmaction2): Action understanding toolbox and benchmark\r\n- [MMClassification](https://github.com/open-mmlab/mmclassification): Image classification toolbox and benchmark\r\n\r\nIt provides the following functionalities.\r\n\r\n- Universal IO APIs\r\n- Image/Video processing\r\n- Image and annotation visualization\r\n- Useful utilities (progress bar, timer, ...)\r\n- PyTorch runner with hooking mechanism\r\n- Various CNN architectures\r\n- High-quality implementation of common CUDA ops","links":[{"article_link":"https://mmcv.readthedocs.io/en/latest/","code_link":"https://github.com/open-mmlab/mmcv","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://openmmlab.com/"}]},{"id":2433,"title":"Understanding the receptive field of deep convolutional networks","description":"An intuitive guide on why it is important to inspect the receptive field, as well as how the receptive field affect the design choices of deep convolutional net","tags":["article","tutorial","convolutional-neural-networks","deep-learning","machine-learning"],"details":"In this article, we will discuss multiple perspectives that involve the receptive field of a deep convolutional architecture. We will address the influence of the receptive field starting for the human visual system. As you will see, a lot of terminology of deep learning comes from neuroscience. As a short motivation, convolutions are awesome but it is not enough just to understand how it works. The idea of the receptive field will help you dive into the architecture that you are using or developing. If you are looking for an in-depth analysis to understand how you can calculate the receptive field of your model as well as the most effective ways to increase it, this article was made for you. In the end, fundamentals are to be mastered!","links":[{"article_link":"https://theaisummer.com/receptive-field/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://theaisummer.com/skip-connections/"}]},{"id":2432,"title":"Topic Modeling with BERT","description":"Leveraging \ud83e\udd17 Transformers and a class-based TF-IDF to create dense clusters allowing for easily interpretable topics. ","tags":["article","code","tutorial","huggingface","attention","bert","transformers","library","natural-language-processing","topic-modeling"],"details":"BERTopic is a topic modeling technique that leverages BERT embeddings and c-TF-IDF to create dense clusters allowing for easily interpretable topics whilst keeping important words in the topic descriptions.\r\n\r\nThe initial purpose of this project was to generalize Top2Vec such that it could be used with state-of-art pre-trained transformer models. However, this proved difficult due to the different natures of Doc2Vec and transformer models. Instead, I decided to come up with a different algorithm that could use BERT and \ud83e\udd17 transformers embeddings. The results is BERTopic, an algorithm for generating topics using state-of-the-art embeddings.\r\n\r\n![](https://miro.medium.com/max/1400/1*W94GjvT6vBzDGY50qPHZDA.png)","links":[{"article_link":"https://towardsdatascience.com/topic-modeling-with-bert-779f7db187e6","code_link":"https://github.com/MaartenGr/BERTopic","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2431,"title":"A Survey of the State of Explainable AI for NLP","description":"Overview of the operations and explainability techniques currently available for generating explanations for NLP model predictions.","tags":["paper","research","interpretability","natural-language-processing","explainability","survey","xai","arxiv:2010.00711"],"details":"Recent years have seen important advances in the quality of state-of-the-art models, but this has come at the expense of models becoming less interpretable. This survey presents an overview of the current state of Explainable AI (XAI), considered within the domain of Natural Language Processing (NLP). We discuss the main categorization of explanations, as well as the various ways explanations can be arrived at and visualized. We detail the operations and explainability techniques currently available for generating explanations for NLP model predictions, to serve as a resource for model developers in the community. Finally, we point out the current gaps and encourage directions for future work in this important research area.","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2010.00711","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2430,"title":"Transection: Transformers for English to Chinese Translation \u57fa\u4e8et","description":"Tutorials on how to fine-tune a BART based transformer for English to Chinese translation.","tags":["code","tutorial","transformers","library","machine-translation","natural-language-processing","demo"],"details":"Transection: Transformers for English to Chinese Translation (\u57fa\u4e8etransformers\u4ece\u82f1\u6587\u5230\u4e2d\u6587\u7684\u7ffb\u8bd1\u5668).\r\n\r\n**Next steps**:\r\n\r\n* Train a sequence-to-sequence BART-base on the dataset from scratch rather than fine-tune from its checkpoint.\r\n* Fine-tune starting from MarianMT checkpoints.\r\n* Expand the dataset from various domains (i.e, makes it more general overall).\r\n* Train on smaller sequence to sequence transformers?","links":[{"article_link":"","code_link":"https://github.com/wangcongcong123/transection","research_link":"","media_link":"","dataset_link":"","demo_link":"https://github.com/wangcongcong123/transection/blob/main/demo.py","other_link":""}]},{"id":2429,"title":"Meta-learning for Few-shot Natural Language Processing: A Survey","description":"Clear definitions, progress summary and some common datasets of applying meta-learning to few-shot NLP.","tags":["paper","research","few-shot-learning","meta-learning","natural-language-processing","survey","arxiv:2007.09604"],"details":"Few-shot natural language processing (NLP) refers to NLP tasks that are accompanied with merely a handful of labeled examples. This is a real-world challenge that an AI system must learn to handle. Usually we rely on collecting more auxiliary information or developing a more efficient learning algorithm. However, the general gradient-based optimization in high capacity models, if training from scratch, requires many parameter-updating steps over a large number of labeled examples to perform well (Snell et al., 2017). If the target task itself cannot provide more information, how about collecting more tasks equipped with rich annotations to help the model learning? The goal of meta-learning is to train a model on a variety of tasks with rich annotations, such that it can solve a new task using only a few labeled samples. The key idea is to train the model's initial parameters such that the model has maximal performance on a new task after the parameters have been updated through zero or a couple of gradient steps. There are already some surveys for meta-learning, such as (Vilalta and Drissi, 2002; Vanschoren, 2018; Hospedales et al., 2020). Nevertheless, this paper focuses on NLP domain, especially few-shot applications. We try to provide clearer definitions, progress summary and some common datasets of applying meta-learning to few-shot NLP.","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2007.09604","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2428,"title":"Efficient Transformers: A Survey","description":"Characterizes a large and thoughtful selection of recent efficiency-flavored \"X-former\" models.","tags":["paper","research","transformers","natural-language-processing","survey","arxiv:2009.06732"],"details":"Transformer model architectures have garnered immense interest lately due to their effectiveness across a range of domains like language, vision and reinforcement learning. In the field of natural language processing for example, Transformers have become an indispensable staple in the modern deep learning stack. Recently, a dizzying number of \"X-former\" models have been proposed - Reformer, Linformer, Performer, Longformer, to name a few - which improve upon the original Transformer architecture, many of which make improvements around computational and memory efficiency. With the aim of helping the avid researcher navigate this flurry, this paper characterizes a large and thoughtful selection of recent efficiency-flavored \"X-former\" models, providing an organized and comprehensive overview of existing work and models across multiple domains.\r\n\r\n![](https://pbs.twimg.com/media/EibO6nAUMAIGnPR?format=jpg)","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2009.06732","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2427,"title":"Knowledge Transfer in Self Supervised Learning","description":"A general framework to transfer knowledge from deep self-supervised models to shallow task-specific models.","tags":["article","tutorial","knowledge-distillation","model-compression","self-supervised-learning"],"details":"Self Supervised Learning is an interesting research area where the goal is to learn rich representations from unlabeled data without any human annotation. This can be achieved by creatively formulating a problem such that you use parts of the data itself as labels and try to predict that. Such formulations are called pretext tasks.\r\n\r\nBy pre-training on the pretext task, the hope is that the model will learn useful representations. Then, we can finetune the model to downstream tasks such as image classification, object detection, and semantic segmentation with only a small set of labeled training data.\r\n\r\nThis blog post summarizes the findings in the paper \" \u201cBoosting Self-Supervised Learning via Knowledge Transfer\u201d.","links":[{"article_link":"https://amitness.com/knowledge-transfer/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2426,"title":"Free (0$) deep learning hardware?","description":"You don't have money but want to start learning deep learning? Take a look at this video for some tips!","tags":["tutorial","deep-learning","hardware","gpu","cloud","deep-learning-pc"],"details":"From Google Colab and Kaggle's P100s GPU all the way to whether you should build your personal deep learning rig.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://youtu.be/rcIrIhNAe_c","dataset_link":"","demo_link":"","other_link":""}]},{"id":2425,"title":"From Python to Julia & Learning by Doing","description":"A Case Study with an Opinion Dynamics Model Simulation.","tags":["article","tutorial","julia","simulation"],"details":"Rather than a full-on tutorial of how Julia works, what you will mostly find in this post is a documentation\u2014frankly, commentation\u2014mostly for myself of why and how I wrote the code I did, from the perspective of someone coming from Python.","links":[{"article_link":"https://unchitta.com/blog/2020/10/deffuant-weisbuch-julia/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2424,"title":"Principles and Practice of Explainable Machine Learning","description":"A survey to help industry practitioners understand the field of explainable machine learning better and apply the right tools.","tags":["paper","research","interpretability","explainability","survey","arxiv:2009.11698"],"details":"Here, we have undertaken a survey to help industry practitioners (but also data scientists more broadly) understand the field of explainable machine learning better and apply the right tools. Our latter sections build a narrative around a putative data scientist, and discuss how she might go about explaining her models by asking the right questions.\r\n\r\n![](https://dildehdrg5ol8.cloudfront.net/images/2424-8932c0032afd955aa1194a655bdc6c58.png)","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2009.11698","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2423,"title":"Imaginaire","description":"NVIDIA PyTorch GAN library with distributed and mixed precision support.","tags":["code","video","pytorch","generative-adversarial-networks","library","computer-vision","image-to-image-translation","nvidia","mixed-precision","imaginaire","model-zoo"],"details":"Imaginaire is a pytorch library that contains optimized implementation of several image and video synthesis methods developed at NVIDIA.\r\n\r\n![](https://camo.githubusercontent.com/faebd1e3636c45badb31da70e3e7224ac8ac230d/687474703a2f2f696d672e796f75747562652e636f6d2f76692f6a675458354f6e417359512f302e6a7067)\r\n\r\n","links":[{"article_link":"","code_link":"https://github.com/NVlabs/imaginaire","research_link":"","media_link":"https://www.youtube.com/watch?v=jgTX5OnAsYQ&feature=youtu.be","dataset_link":"","demo_link":"","other_link":"http://imaginaire.cc/"}]},{"id":2422,"title":"Pattern-Exploiting Training (PET)","description":"This repository contains the code for \"Exploiting Cloze Questions for Few-Shot Text Classification and Natural Language Inference\"","tags":["code","paper","research","few-shot-learning","natural-language-processing","text-classification","cloze-questions","arxiv:2001.07676"],"details":"This repository contains the code for [Exploiting Cloze Questions for Few-Shot Text Classification and Natural Language Inference](https://arxiv.org/abs/2001.07676) and [It's Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners](https://arxiv.org/abs/2009.07118). The papers introduce pattern-exploiting training (PET), a semi-supervised training procedure that reformulates input examples as cloze-style phrases. In low-resource settings, PET and iPET significantly outperform regular supervised training, various semi-supervised baselines and even GPT-3 despite requiring 99.9% less parameters. The iterative variant of PET (iPET) trains multiple generations of models and can even be used without any training data.\r\n\r\n* \ud83d\udd27 Setup\r\n* \ud83d\udcac CLI Usage\r\n* \ud83d\udcbb API Usage\r\n* \ud83d\udc36 Train your own PET\r\n* \ud83d\udcd5 Citation\r\n\r\n","links":[{"article_link":"","code_link":"https://github.com/timoschick/pet","research_link":"https://arxiv.org/abs/2001.07676","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2421,"title":"Q-Aid","description":"A comprehensive healthcare conversational agent powered by Visual QA and segmentation models.","tags":["api","article","code","dataset","paper","research","aws","fastapi","pytorch","react","health","computer-vision","medical-imaging","natural-language-processing","question-answering","segmentation","conversational-ai","visual-question-answering","mobile","xai"],"details":"#### Features\r\n\r\n- \ud83d\udd25 Collection of healthcare AI models under [core](https://github.com/medtorch/Q-Aid-Core/tree/master/core), created using PyTorch.\r\n- \ud83d\udd11 Served using [FastAPI](https://fastapi.tiangolo.com/).\r\n- \ud83c\udf00 Full deployment scripts for AWS.\r\n- \u26a1\ufe0f Compatible React-Native app under [app](https://github.com/medtorch/Q-Aid-App) folder.\r\n\r\n#### Additional resources\r\n\r\n* Read more about the models [here](https://github.com/medtorch/Q-Aid-Models).\r\n* Read more about the app [here](https://github.com/medtorch/Q-Aid-App).\r\n* Read more about the server setup [here](https://github.com/medtorch/Q-Aid-Core/blob/master/core/README.md).\r\n* Seet the [AWS README](aws_backend/README.md).\r\n\r\n#### What it does\r\nQ&AId solves this problem by:\r\n\r\n* providing the user answers to questions on clinical data,\r\n* providing the hospital with a transcript of what the patient needs, reducing the waiting time, and unloading the hospital triage.\r\n\r\n![](https://github.com/medtorch/Q-Aid-Motivation/raw/master/misc/demo.gif)\r\n\r\n![](https://raw.githubusercontent.com/medtorch/Q-Aid-Motivation/master/misc/flow.png)\r\n\r\n#### How we built it\r\nThere are three sections of the app that are worth mentioning:\r\n\r\n**Q-Aid-App**\r\n\r\n* Created using React-Native.\r\n* Authentication and database support by AWS Amplify.\r\n* Awesome chat created using GiftedChat.\r\n* Backed by the PyTorch core algorithms and models.\r\n\r\n**Q-Aid-Core**\r\n\r\n* Server built with FastAPI\r\n* DockerHub deployment as a docker image.\r\n* script that partially builds the following diagram:\r\n\r\n![](https://github.com/medtorch/Q-Aid-Core/raw/master/aws_backend/architecture.png)","links":[{"article_link":"https://github.com/medtorch/Q-Aid-Motivation","code_link":"https://github.com/medtorch/Q-Aid-Core","research_link":"","media_link":"","dataset_link":"https://github.com/medtorch/Q-Aid-Models","demo_link":"","other_link":"https://github.com/medtorch/Q-Aid-App"}]},{"id":2420,"title":"DVC Basics","description":"This tutorial is for total beginners to get started using DVC and Git to version data, models, and more. ","tags":["tutorial","video","git","dvc","versioning"],"details":"This tutorial is for total beginners to get started using DVC and Git to version data, models, and more. If you're completely new to DVC and want a gentle walkthrough of the basic features, this is for you!","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/playlist?list=PL7WG7YrwYcnDb0qdPl9-KEStsL-3oaEjg","dataset_link":"","demo_link":"","other_link":""}]},{"id":2419,"title":"GANs in Computer Vision Free Ebook / Article-series","description":"This free ebook/article-series follows the chronological order of 20 peer-reviewed highly-cited papers as they presented in a series of 6 articles.","tags":["article","code","paper","research","tutorial","generative-adversarial-networks","computer-vision","image-generation","demo"],"details":"This free ebook/article-series follows the chronological order of 20 peer-reviewed highly-cited papers as they presented in a series of 6 articles.","links":[{"article_link":"https://theaisummer.com/gan-computer-vision/","code_link":"https://github.com/The-AI-Summer/GANs-in-Computer-Vision","research_link":"https://theaisummer.com/gan-computer-vision-object-generation/","media_link":"","dataset_link":"","demo_link":"https://theaisummer.com/gan-computer-vision-video-synthesis/","other_link":"https://theaisummer.com/gan-computer-vision-semantic-synthesis/"}]},{"id":2418,"title":"Top Research Papers from the ECML-PKDD 2020 Conference","description":"ECML-PKDD -> selectionof the best reaesch papers","tags":["article","research","deep-learning","machine-learning","reinforcement-learning","data-science"],"details":"### ECML-PKDD 2020\r\n\r\n**The European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases** [ECML-PKDD] is one of the most recognized academic conferences on Machine Learning in Europe.\r\n\r\nECML-PKDD brings a large number of new ideas and inspiring developments in the ML field.\r\n\r\nWe bring you top research papers, which are divided into the following categories:\r\n\r\n* Reinforcement learning \r\n* Clustering \r\n* Architecture of neural networks \r\n* Transfer and multi-task learning \r\n* Federated learning and clustering \r\n* Network modeling \r\n* Graph neural networks \r\n* NLP \r\n* Time series and recurrent neural networks \r\n* Dimensionality reduction and auto-encoders \r\n* Large-scale optimization and differential privacy \r\n* Adversarial learning \r\n* Theory for deep learning \r\n* Computer vision / image processing \r\n* Optimization for deep learning","links":[{"article_link":"https://neptune.ai/blog/ecml-pkdd-2020-research?utm_source=madewithml&utm_medium=post&utm_campaign=blog-ecml-pkdd-2020-research","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://neptune.ai/blog/ecml-pkdd-2020-research?utm_source=madewithml&utm_medium=post&utm_campaign=blog-ecml-pkdd-2020-research"}]},{"id":2417,"title":"Parallelizing Prophet Cross-Validation with Dask","description":"Applied Example w/ Code","tags":["article","code","dataset","notebook","tutorial","python","forecasting","time-series","time-series-forecasting","prophet","hyperparameter-optimization","dask","cross-validation","nyc-taxi"],"details":"- Forecast Average Ride Distance by Day for New York City Yellow Cabs\r\n- Cross-Validate that Model in Parallel with Dask\r\n- Use Parallelized CV to Accelerate Prophet Hyperparameter Optimization","links":[{"article_link":"https://medium.com/dropout-analytics/cross-validating-prophet-at-scale-72b1a21b6433?source=friends_link&sk=e7b1201491dd528dfa3ad3b9a324518c","code_link":"https://github.com/gumdropsteve/intro_to_prophet/blob/master/prophet_with_dask.ipynb","research_link":"","media_link":"","dataset_link":"https://github.com/gumdropsteve/datasets/blob/master/yellow_cab_ymd_averages.csv","demo_link":"","other_link":""}]},{"id":2416,"title":"RecSys 2020 - Takeaways and Notable Papers","description":"Some observations and notes on papers I enjoyed from this year's RecSys 2020.","tags":["article","recommendation-systems","recsys","recsys-2020"],"details":"[RecSys 2020](https://recsys.acm.org/recsys20/) ran from 22nd - 26th September. It was a great opportunity to peek into some of the latest thinking about recommender systems from academia and industry. Here are some observations and notes on papers I enjoyed.\r\n\r\n**Some takeaways**:\r\n\r\n* Emphasis on ethics & bias\r\n* Offline evaluation is tricky\r\n* Dot product > learned similarities\r\n* Many examples of real-world recsys","links":[{"article_link":"https://eugeneyan.com/writing/recsys2020/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2415,"title":"Explainable ML Monitoring","description":"The video covers an overview of some of the risks of AI, the need for explainable monitoring, and what exactly we mean when we talk about it.","tags":["video","interpretability","monitoring"],"details":"This video introduces Explainable ML Monitoring, which extends traditional monitoring to provide deep model insights with actionable steps. With monitoring, users can understand the problem drivers, root cause issues, and analyze the model to prevent a repeat, saving considerable time and increasing trust in AI in production. ","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=1VGZdpipKpA","dataset_link":"","demo_link":"","other_link":"https://fiddler.ai"}]},{"id":2414,"title":"GenForce Lib for Generative Modeling","description":"GenForce: an efficient PyTorch library for deep generative modeling (StyleGANv1v2, PGGAN, etc).","tags":["code","pytorch","library","generative-modeling","genforce"],"details":"An efficient PyTorch library for deep generative modeling. May the Generative Force (GenForce) be with You.\r\n\r\n### Highlights\r\n\r\n- **Distributed** training framework.\r\n- **Fast** training speed.\r\n- **Modular** design for prototyping new models.\r\n- **Highly** reproducing the training of StyleGAN compared to [the official TensorFlow version](https://github.com/NVlabs/stylegan).\r\n- **Model zoo** containing a rich set of pretrained GAN models, with [Colab live demo](https://colab.research.google.com/drive/1ytdR30L7uXLaG_4Iph331o70wZWA-bkd?usp=sharing) to play.\r\n\r\nWe will also support following functions *in the very near future*. Please **STAY TUNED**.\r\n\r\n- Training of PGGAN and StyleGAN2 (and likely BigGAN too).\r\n- Benchmark on model training.\r\n- Training of GAN encoder from [In-Domain GAN Inversion](https://genforce.github.io/idinvert).\r\n- Other recent work from our [GenForce](http://genforce.github.io/).\r\n\r\n\r\n![](https://github.com/genforce/genforce/raw/master/teaser.gif)","links":[{"article_link":"","code_link":"https://github.com/genforce/genforce","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://genforce.github.io/"}]},{"id":2413,"title":"Keeping Data Pipelines healthy w/ Great Expectations GH Actions","description":"We show you how you can use GitHub Actions together with the open source project Great Expectations to automatically test, document, and profile data pipelines.","tags":["article","video","unit-tests","testing","data-pipelines","github-actions","great-expectations","data-quality"],"details":"In this post, we show you how you can use GitHub Actions together with the open source project [Great Expectations](https://greatexpectations.io/) to automatically test, document, and profile your data pipelines as part of your traditional CI workflows. Checking data in this way can help data teams save time and promote analytic integrity of their data. We\u2019ll also show how to generate dashboards that give you insight into data problems as part of your CI process. Below is a demonstration of this at work, triggered by a change to a SQL query in a pull request that causes a data integrity issue:","links":[{"article_link":"https://github.blog/2020-10-01-keeping-your-data-pipelines-healthy-with-the-great-expectations-github-action/","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=V2TgkoExzvA","dataset_link":"","demo_link":"","other_link":""}]},{"id":2412,"title":"Introduction to 3D Medical Imaging: Preprocessing & Augmentations","description":"Learn how to apply 3D transformations for medical image preprocessing and augmentation, to setup your awesome deep learning pipeline.","tags":["article","code","notebook","tutorial","deep-learning","machine-learning","health","computer-vision","data-augmentation","medical-imaging","preprocessing","demo"],"details":"**Contents**\r\n\r\n1. 2D planes visualization\r\n1. Medical image resizing (down/up-sampling)\r\n2. Medical image rescaling (zoom- in/out)\r\n3. 3D Medical image rotation\r\n4. 3D medical image flip\r\n5. Medical image shifting (displacement)\r\n6. Random 3D crop\r\n7. Clip intensity values (outliers)\r\n8. Intensity normalization in medical images\r\n8. Elastic deformation\r\n","links":[{"article_link":"https://theaisummer.com/medical-image-processing/","code_link":"https://colab.research.google.com/drive/1fyU_YaZUO3B5qVzBJwGoYZ6XVvVLog30","research_link":"","media_link":"","dataset_link":"","demo_link":"https://theaisummer.com/medical-image-deep-learning/","other_link":"https://theaisummer.com/medical-image-coordinates/"}]},{"id":2411,"title":"How to Make Sense of the Reinforcement Learning Agents?","description":"What and Why I Log During Training and Debug?","tags":["article","tutorial","deep-learning","machine-learning","reinforcement-learning","neptune-ai","neptune"],"details":"We discuss **what** and **why** to log during reinforcement learning experimentation. We focus on two questions:\r\n\r\n* **How to make sense of the reinforcement learning agents?**\r\n* **What and why to log during training and debug?**\r\n\r\n![humanoid](https://i1.wp.com/neptune.ai/wp-content/uploads/RL-humanoid-falling.gif?resize=390%2C392&ssl=1)\r\n\r\nWe dive deep into few categories to explain why to log particular metric:\r\n\r\n#### how is the agent doing?\r\n* Episode return\r\n* Episode length\r\n* Solve rate\r\n\r\n#### progress of training\r\n* Total environment steps\r\n* Training steps\r\n* Wall time\r\n* Steps per second\r\n\r\n#### what is the agent thinking/doing?\r\n* State/Action value function\r\n* Policy entropy\r\n\r\n#### how the training goes?\r\n* KL divergence\r\n* Network weights/gradients/activations histograms\r\n* Policy/Value/Quality/\u2026 heads losses\r\n\r\n#### Aggregated statistics\r\n* Average and standard deviation\r\n* Minimum/Maximum value\r\n* Median\r\n\r\n![aggregations](https://i1.wp.com/neptune.ai/wp-content/uploads/RL-training-results-6.png?w=512&ssl=1)\r\n","links":[{"article_link":"https://neptune.ai/blog/how-to-make-sense-of-the-reinforcement-learning-agents-what-and-why-i-log-during-training-and-debug?utm_source=madewithml&utm_medium=post&utm_campaign=blog-how-to-make-sense-of-the-reinforcement-learning-agents-what-and-why-i-log-during-training-and-debug","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://neptune.ai/blog/how-to-make-sense-of-the-reinforcement-learning-agents-what-and-why-i-log-during-training-and-debug?utm_source=madewithml&utm_medium=post&utm_campaign=blog-how-to-make-sense-of-the-reinforcement-learning-agents-what-and-why-i-log-during-training-and-debug"}]},{"id":2410,"title":"Serving PyTorch models in production with the Amazon SageMaker","description":"TorchServe is now natively supported in Amazon SageMaker as the default model server for PyTorch inference. ","tags":["article","tutorial","aws","pytorch","production","sagemaker","torchserve","serving"],"details":"You can use TorchServe natively with Amazon SageMaker through the following steps:\r\n\r\n* Create a model in Amazon SageMaker. \r\n* Create an endpoint configuration for an HTTPS endpoint. \r\n* Create an HTTPS endpoint. ","links":[{"article_link":"https://aws.amazon.com/blogs/machine-learning/serving-pytorch-models-in-production-with-the-amazon-sagemaker-native-torchserve-integration/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2409,"title":"Deploying Python FastAPI on Azure App Service","description":"A detailed walk through on how to deploy FastAPI on Azure App Service. This includes detailed article and a video demonstration","tags":["article","code","research","tutorial","video","azure","fastapi","python","architecture","devops","demo","ci-cd"],"details":"* Architectural Overview of Deploying FastAPI on Azure App Service\r\n* Create & Configure Azure Database for PostgreSQL server\r\n\t* Create PostgreSQL server on Azure\r\n\t* Configure Azure database for PostgreSQL server\r\n\t* Connect to Azure PostgreSQL Database server from pgAdmin\r\n* Create & Configure Azure App Service (Linux)\r\n\t* Create Azure App Service\r\n\t* Configure Azure App Service\r\n* Configure to Deploy FastAPI on Azure App Service from GitHub\r\n* [Video Tutorial](https://bit.ly/2HA6SUj)","links":[{"article_link":"https://www.tutlinks.com/deploy-fastapi-on-azure/","code_link":"https://github.com/windson/fastapi/tree/fastapi-postgresql-azure-deploy","research_link":"","media_link":"https://www.youtube.com/watch?v=oLdEI3zUcFg","dataset_link":"","demo_link":"","other_link":"www.tutlinks.com"}]},{"id":2408,"title":"Revelations of Gradients and Hessians.","description":"This blog post explores some of the insights gained from looking at gradients and Hessian matrices of the objective functions/loss functions. ","tags":["article","deep-learning"],"details":"1. This blog post aims at explaining Chapter 4 of the Deep learning textbook by Ian Goodfellow et.al in detail, and contains proofs for some theorems which were stated in the chapter.\r\n2. Contains plots which help in understanding the material through visual aid.","links":[{"article_link":"https://abhimanyu08.github.io/blog/deep-learning/mathematics/2020/07/20/final.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2406,"title":"Audio signal analysis and Feature extraction","description":"Extract features from audio signal as a part of Speech recognition task","tags":["code","research","tutorial","library","audio","feature-engineering","speech","speech-recognition","melspectrum","mfcc"],"details":"**Audio signal analysis and Feature extraction**\r\n\r\nMain aim of the project is to understand audio signals and extract features from the signals. Audio signals are periodic signal, hence, we can break the signal at  constant time-steps and extract features. These features at constant time steps are given as input to Deep learning models for Speech Recognition task. \r\n\r\n\r\n\r\n","links":[{"article_link":"","code_link":"https://github.com/savitha91/AudioSignal_FeatureExtraction","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2405,"title":"Scientific Computing in Python: Introduction to NumPy& Matplotlib","description":"Blog article with the embedded \u201cnarrated content\u201d for NumPy and Matplotlib notes.","tags":["article","code","tutorial","matplotlib","numpy"],"details":"* **4.1: NumPy Basics**\r\n\t* NumPy \u2013 Working with Numerical Arrays\r\n\t* Introduction to NumPy\r\n\t* Motivation: NumPy is fast!\r\n\t* N-dimensional Arrays\r\n* **4.2: NumPy Array Construction and Indexing**\r\n\t* Array Construction Routines\r\n\t* Array Indexing\r\n* **4.3: NumPy Array Math and Universal Functions**\r\n\t* Array Math and Universal Functions\r\n* **4.4: NumPy Broadcasting**\r\n\t* Broadcasting\r\n* **4.5: NumPy Advanced Indexing \u2013 Memory Views and Copies**\r\n\t* Advanced Indexing \u2013 Memory Views and Copies\r\n\t* Fancy Indexing\r\n\t* Boolean Masks for Indexing\r\n* **4.6: Random Number Generators**\r\n\t* Random Number Generators\r\n* **4.7: Reshaping NumPy Arrays**\r\n\t* Reshaping Arrays\r\n* **4.8: NumPy Comparison Operators and Masks**\r\n\t* Comparison Operators and Masks\r\n* **4.9: Linear Algebra with NumPy**\r\n\t* Linear Algebra with NumPy Arrays\r\n\t* SciPy\r\n* **4.10: Matplotlib**\r\n\t* What is Matplotlib?\r\n\t* Plotting Functions and Lines\r\n\t* Scatter Plots\r\n\t* Bar Plots\r\n\t* Histograms\r\n\t* Subplots\r\n\t* Colors and Markers\r\n\t* Saving Plots\r\n\t* Resources\r\n\r\n![](https://sebastianraschka.com/images/blog/2020/numpy-intro/matmatmul.png)","links":[{"article_link":"https://sebastianraschka.com/blog/2020/numpy-intro.html","code_link":"https://github.com/rasbt/numpy-intro-blogarticle-2020","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2404,"title":"12 Factors of Reproducible Machine Learning in Production","description":"We took our experience to deduce 12 factors (as a nod to the 12 factor app) that build the backbone of successful ML in production.","tags":["article","code","machine-learning","production","reproducability"],"details":"We\u2019ve faced all of these issues, and more, and now took our experience to deduce 12 factors (as a nod to the [12 factor app](https://12factor.net/)) that build the backbone of successful ML in production.\r\n\r\n* Versioning\r\n\t* You need to version your code, and you need to version your data.\r\n* Explicit feature dependencies\r\n\t* Make your feature dependencies explicit in your code.\r\n* Descriptive training and preprocessing\r\n\t* Write readable code and separate code from configuration.\r\n* Reproducibility of trainings\r\n\t* Use pipelines and automation.\r\n* Testing\r\n\t* Test your code, test your models.\r\n* Drift / Continuous training\r\n\t* If you data can change run a continuous training pipeline.\r\n* Tracking of results\r\n\t* Track results via automation.\r\n* Experimentation vs Production models\r\n\t* Notebooks are not production-ready, so experiment in pipelines early on.\r\n* Training-Serving-Skew\r\n\t* Correctly embed preprocessing to serving, and make sure you understand up- and downstream of your data.\r\n* Comparability\r\n\t* Build your pipelines so you can easily compare training results across pipelines.\r\n* Monitoring\r\n\t* Again: you build it, you run it. Monitoring models in production is a part of data science in production.\r\n* Deployability of Models\r\n\t* Every training pipeline needs to produce a deployable artefact, not \u201cjust\u201d a model.\r\n\r\n![](https://maiot.io/assets/core/arch-vert-lg.svg)","links":[{"article_link":"https://blog.maiot.io/12-factors-of-ml-in-production/","code_link":"https://docs.maiot.io/","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://maiot.io/"}]},{"id":2403,"title":"Easy Data Augmentation (EDA)","description":"Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks","tags":["article","code","library","data-augmentation","natural-language-processing","eda","text-augmentation"],"details":"We present EDA: easy data augmentation techniques for boosting performance on text classification tasks. EDA consists of four simple but powerful operations: synonym replacement, random insertion, random swap, and random deletion. On five text classification tasks, we show that EDA improves performance for both convolutional and recurrent neural networks. EDA demonstrates particularly strong results for smaller datasets; on average, across five datasets, training with EDA while using only 50% of the available training set achieved the same accuracy as normal training with all available data. We also performed extensive ablation studies and suggest parameters for practical use.\r\n\r\n![](https://miro.medium.com/max/778/1*y88F2-lpLQNxw_ubWoGctQ.png)","links":[{"article_link":"https://towardsdatascience.com/these-are-the-easiest-data-augmentation-techniques-in-natural-language-processing-you-can-think-of-88e393fd610","code_link":"https://github.com/jasonwei20/eda_nlp","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2402,"title":"Adapting Text Augmentation to Industry Problems","description":"In this post I will talk about the recent advances in exploiting language models for data generation and also show how, where we can implement them in Industry.","tags":["article","data-augmentation","language-modeling","natural-language-processing","pet","cbert","text-augmentaiton"],"details":"For this post, I would like to consider two Industrial tasks where we can use augmentation:\r\n\r\n> Categorizing complaints/survey-responses into specific categories. (Classification task)\r\n\r\nLet\u2019s say that you are a Computer Tech-Giant like HP/Microsoft and want to process your incoming messages into clear buckets like Hardware, Customer Care, Software, General Support, Tech Support, Refund etc.\r\n\r\n> Redacting sensitive information from the data. (Sequence Labeling task)\r\n\r\nLet\u2019s consider that you are an independent survey firm who\u2019s documenting the statistics of COVID-19. In this survey, to respect the privacy of individuals involved and to avoid targetted harassment by the public, few statements must be stripped of the key details.\r\n\r\n![](https://gitlost-murali.github.io/blogs/assets/images/dichotomy-pet-annot.png)","links":[{"article_link":"https://gitlost-murali.github.io/blogs/nlp/augmentation/exploiting-contextual-models-for-data","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2400,"title":"MLJ.jl","description":"A Julia machine learning framework.","tags":["code","julia","machine-learning","library"],"details":"MLJ (Machine Learning in Julia) is a toolbox written in Julia providing a common interface and meta-algorithms for selecting, tuning, evaluating, composing and comparing machine learning models written in Julia and other languages. MLJ is released under the MIT licensed and sponsored by the [Alan Turing Institute](https://www.turing.ac.uk/).\r\n\r\n![](https://github.com/alan-turing-institute/MLJ.jl/raw/master/material/MLJ_stack.svg)","links":[{"article_link":"","code_link":"https://github.com/alan-turing-institute/MLJ.jl","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://alan-turing-institute.github.io/MLJ.jl/dev/"}]},{"id":2399,"title":"Image Dehazing using GMAN net","description":"Single image dehazing using the GMAN network and its implementation in Tensorflow(version 2+).","tags":["article","code","dataset","research","tensorflow","deep-learning","dehazing"],"details":"Generic Model-Agnostic Convolutional Neural Network(GMAN) is a convolutional neural network proposed for haze removal and clear image restoration. It is an end-to-end deep learning system that employs the encoder-decoder network for denoising image. I've used Kaggle notebook for the purpose of implementation and training. Dataset used for training and validation is SOTS outdoor [available here](https://www.kaggle.com/wwwwwee/dehaze).","links":[{"article_link":"https://medium.com/@sanchitvj/gman-net-for-image-dehazing-65a2b3f679a5?source=---------2----------------------------","code_link":"https://github.com/sanchitvj/Image-Dehazing-using-GMAN-net","research_link":"","media_link":"","dataset_link":"https://www.kaggle.com/wwwwwee/dehaze","demo_link":"","other_link":""}]},{"id":2398,"title":"Deep Dive into TensorBoard: Tutorial With Examples","description":"There is a common business saying that you can\u2019t improve what you don\u2019t measure. This is true in machine learning as well. There are various tools for measuring","tags":["article","tutorial","tensorflow","tensorboard"],"details":"Here are some things we\u2019ll cover in this text:\r\n\r\n* Visualizing images in TensorBoard\r\n* Checking model weights and biases on TensorBoard\r\n* visualizing the model\u2019s architecture\r\n* sending a visual of the confusion matrix to TensorBoard\r\n* profiling your application so as to see its performance, and\r\n* using TensorBoard with Keras, PyTorch, and XGBoost","links":[{"article_link":"https://neptune.ai/blog/tensorboard-tutorial","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2397,"title":"Optimizing MobileDet for Mobile Deployments","description":"Learn about the criticalities of effectively optimizing MobileDet object detectors for mobile deployments.","tags":["article","code","notebook","paper","research","tutorial","tensorflow","computer-vision","object-detection","tensorflow-lite","edge-ai","arxiv:2004.14525"],"details":"This year researchers from the University of Wisconsin-Madison and Google published their work on MobileDet. MobileDet presents an architectural philosophy for designing object detectors specifically targeted toward running on mobile accelerators like DSP, EdgeTPU, and so on. MobileDet yields significant improvement over architectures MobileNetV2+SSDLite and MobileNetV3+SSDLite on the COCO object detection task with the same accelerated inference time. Long story cut short, if you are planning to use object detection models in mobile applications MobileDets may be an extremely good choice.\r\n\r\nOne fantastic thing about modern-day research is most of the time, the code and essential artifacts (like the trained models) are available publicly. MobileDet is no exception; the authors released their code and pre-trained models in TensorFlow Object Detection (TFOD) API. The model files come in three different variants:\r\n\r\n* Optimized for mobile CPU\r\n* Optimized for EdgeTPU\r\n* Optimized for DSP\r\n\r\nEach of these variants includes the pre-trained checkpoints, a TensorFlow Lite (TFLite) compatible model graph, a TFLite model file, a configuration file, and a graph proto. The models were pre-trained on the COCO dataset.\r\n\r\nIn this post, I am going to be revisiting the TFLite conversion from the pre-trained model checkpoints along with some of the non-trivial things that come up during the process. It is basically an extension of Khanh LeViet and my findings we shared over [this GitHub thread](https://github.com/ml-gde/e2e-tflite-tutorials/issues/21).","links":[{"article_link":"https://sayak.dev/mobiledet-optimization/","code_link":"https://colab.research.google.com/github/sayakpaul/Adventures-in-TensorFlow-Lite/blob/master/MobileDet_Conversion_TFLite.ipynb","research_link":"https://arxiv.org/abs/2004.14525","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2396,"title":"EfficientDet meets Pytorch Lightning","description":"Beginner friendly guide to object detection using EfficientDet.","tags":["article","tutorial","computer-vision","object-detection","efficientdet","pytroch","pytroch-lightning"],"details":"Welcome to this beginner friendly guide to object detection using EfficientDet. Similarly to what I have done in the NLP guide (check it [here](https://www.kaggle.com/yassinealouini/roberta-meets-tpus) if you haven't yet already), there will be a mix of theory, practice, and an application to the global wheat competition dataset.\r\n\r\nThis will be a very long notebook, so use the following table of content if necessary. Grab something to drink and enjoy!\r\n\r\n**Introduction**\r\n\r\n* Modern Computer Vision\r\n* Different Detection Tasks\r\n* Object Detection 101\r\n* Object Detection Models Zoology\r\n* EfficientDet Explained\r\n* EfficientNet as a Backbone\r\n* BiFPN as a Multi-Scale Fusion\r\n* Two Heads\r\n* Compound Scalings\r\n* Application: Global Wheat Detection\r\n\r\n**Understanding the Task**\r\n\r\n* Evaluation Metric\r\n* Data processing\r\n* The Model\r\n* The Dataset\r\n* Pytorch Complete Training Pipeline\r\n* Evaluation\r\n* Inference\r\n\r\n**Advanced Concepts**\r\n\r\n* Mosaic Augmentation\r\n* TTA\r\n* WBF","links":[{"article_link":"https://www.kaggle.com/yassinealouini/efficientdet-meets-pytroch-lightning","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2395,"title":"Python caching in GitHub Actions","description":"How to speed up slow Python builds in GitHub Actions with effective caching.","tags":["article","tutorial","mlops","github-actions","caching"],"details":"Now, I\u2019d like to say the switch over to GitHub Actions was all smooth sailing from the beginning, but that\u2019s not quite true. AllenNLP is a large project with some even larger dependencies, like PyTorch, which can lead to really slow builds when the Python environment needs to be set up from scratch.\r\n\r\nNaturally, the solution to this is dependency caching, but we quickly discovered that the recommended way of caching pip dependencies for Python was still too slow for us.","links":[{"article_link":"https://medium.com/ai2-blog/python-caching-in-github-actions-e9452698e98d","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2394,"title":"Why Data Quality is Key to Successful ML Ops","description":"A look at ML Ops and highlight how and why data quality is key to ML Ops workflows.","tags":["article","production","unit-tests","testing","mlops","great-expectations"],"details":"In this post, we are going to look at ML Ops, a recent development in ML that bridges the gap between ML and traditional software engineering, and highlight how data quality is key to ML Ops workflows in order to accelerate data teams and maintain trust in your data.\r\n\r\n![](https://greatexpectations.io/static/ab90fe5e5725a6cfe8b3aebccca58575/f570d/ml_workflow_validation.png)","links":[{"article_link":"https://greatexpectations.io/blog/ml-ops-data-quality/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2393,"title":"A Friendly Introduction to PCA","description":"After years of almost, but not quite fully understanding PCA, here is my attempt to explain it fully, hopefully leaving some of the magic intact.","tags":["article","dimensionality-reduction","unsupervised-learning","principal-component-analysis"],"details":"We will work from the outside in: we will view PCA first as a way of finding a smaller representation of a dataset. This is a typical machine learning problem: find a compressed representation of the data such that the reconstructions are as close to the original as possible. This is a simple view of PCA, an we\u2019ll be able to compute it with nothing more than gradient descent with a few extra tricks for satisfying constraints.\r\n\r\n","links":[{"article_link":"http://peterbloem.nl/blog/pca","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2392,"title":"Deep Learning with TensorFlow","description":"Learn Deep Learning with TensorFlow","tags":["video","keras","tensorflow"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=VhXitR_dfNo","dataset_link":"","demo_link":"","other_link":""}]},{"id":2391,"title":"Text Classification Using Long Short Term Memory & GloVe Embeddin","description":"Classify Text using Pre-trained Embeddings and Bidirectional LSTMs\r\n","tags":["article","tensorflow"],"details":"","links":[{"article_link":"https://heartbeat.fritz.ai/text-classification-using-long-short-term-memory-glove-embeddings-6894abb730e1","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2390,"title":"mini-pokedex end to end tutorial  -  Gotta classify 'em all!","description":"Build a Pokemon image classifier to classify the awesome starters Pikachu, Charmander, Squirtle, and Bulbasaur.","tags":["article","code","tutorial","azure","docker","fastai","computer-vision","image-classification","pokemons"],"details":"This is a practical tutorial of building and deploying deep learning model.\r\n\r\nThe goal of this article is to set up a deep learning workspace on azure, build and deploy end to end deep learning projects on azure. We will start by building a custom image data set, train the model using fastai and then deploy the model in production. \r\n\r\nRead the article here [End to End Deep Learning Tutorial using Azure](https://towardsdatascience.com/end-to-end-deep-learning-tutorial-using-azure-f7bb524f7277)","links":[{"article_link":"https://medium.com/@akshay090/end-to-end-deep-learning-tutorial-using-azure-f7bb524f7277","code_link":"https://github.com/Akshay090/pokedex-deploy","research_link":"","media_link":"https://player.vimeo.com/video/448258671","dataset_link":"","demo_link":"","other_link":""}]},{"id":2389,"title":"bingoset - CLI tool  to create image dataset.","description":"CLI Toolkit to quickly create an image dataset using Bing Image Search API.","tags":["code","library","computer-vision","image-classification","datasets","cli","bing-api","dataset-creation","bingoset"],"details":"Easy to use CLI tool to create image dataset using bing image search API.\r\n\r\nIt effectively handles edge cases for images when they are corrupted or have invalid source.\r\n\r\nUsage\r\n\r\n> bingoset q pikachu\r\n\r\nThis will download 250 (default) images of pikachu into a directory called dataset (default)\r\n","links":[{"article_link":"","code_link":"https://github.com/Akshay090/bingoset","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2388,"title":"SemTorch","description":"Different deep learning architectures definitions that can be applied to image segmentation.","tags":["code","fastai","pytorch","library","computer-vision","object-detection","semantic-segmentation","segmentation","instance-segmentation","salient-object-detection"],"details":"Different deep learning architectures definitions that can be applied to image segmentation. All the architectures are implemented in PyTorch and can been trained easily with FastAI 2.\r\n\r\nThese architectures are classified as:\r\n\r\n* **Semantic Segmentation**: each pixel of an image is linked to a class label. ![](https://raw.githubusercontent.com/WaterKnight1998/SemTorch/develop/readme_images/semantic_segmentation.png)\r\n* **Instance Segmentation**: is similar to semantic segmentation, but goes a bit deeper, it identifies , for each pixel, the object instance it belongs to. ![](https://raw.githubusercontent.com/WaterKnight1998/SemTorch/develop/readme_images/instance_segmentation.png)\r\n* **Salient Object Detection** (Binary clases only): detection of the most noticeable/important object in an image. ![](https://raw.githubusercontent.com/WaterKnight1998/SemTorch/develop/readme_images/salient_object_detection.png)","links":[{"article_link":"","code_link":"https://github.com/WaterKnight1998/SemTorch","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2387,"title":"GitHub Actions for Machine Learning","description":"This presentation discusses the use of GitHub Actions to automate certain steps of a toy ML project. ","tags":["code","github","tutorial","scikit-learn","wandb","mlops","github-actions"],"details":"In this deck I discuss the importance of incorporating CI/CD in ML engineering. We took a small demo that uses `scikit-learn` and **GitHub Actions** to automate certain parts of an ML Project and lets a bot comment on a PR with the latest experimental results.\r\n\r\nThis repository demonstrates how to integrate GitHub Actions to:\r\n\r\n**Upon a new commit** \r\n\r\n* Automatically authenticate wandb (Weights and Biases) using a custom GitHub secret.\r\n* Automatically train a small Random Forest Regressor model on the wine quality dataset.\r\n* Automatically log the training and other important model metrics to wandb.\r\n* Cache Python dependencies so that old dependencies do not get installed each time a run is triggered.\r\n* Generate a metrics.csv file after a run is successfully completed.\r\n\r\n**Upon a new pull request**\r\n\r\n* Fetch the latest wandb run URL and comment that on the PR.\r\n\r\n![](https://dildehdrg5ol8.cloudfront.net/images/2394-ee3a1eeceedeaaf705204bed3cd07c46.png)","links":[{"article_link":"","code_link":"https://github.com/sayakpaul/wine/","research_link":"","media_link":"http://bit.ly/ga-ml","dataset_link":"","demo_link":"","other_link":""}]},{"id":2386,"title":"Silero Models: pre-trained enterprise-grade STT models","description":"Silero Speech-To-Text models provide enterprise grade STT in a compact form-factor for several commonly spoken languages.","tags":["article","code","dataset","notebook","paper","research","onnx","pytorch","tensorflow","library","speech","speech-recognition","speech-to-text","demo"],"details":"Speech-to-text has traditionally had high barriers of entry due to a number or reasons:\r\n\r\n* Hard-to-collect data;\r\n* Costly annotation and high data requirements;\r\n* High compute requirements and adoption of obsolete hard to use technologies;\r\n\r\nHere are some of the typical problems that existing ASR solutions and approaches had before our release:\r\n\r\n* STT Research typically focused on huge compute budgets;\r\n* Pre-trained models and recipes did not generalize well, were difficult to use even as-is, relied on obsolete tech;\r\n* Until now STT community lacked easy to use high quality production grade STT models;\r\n\r\nFirst we tried to alleviate some of these problems for the community by publishing the largest Russian spoken corpus in the world. Now we try to solve these problems as follows:\r\n\r\n* We publish a set of pre-trained high-quality models for popular languages;\r\n* Our models are designed to be as robust to different domains as you can see in our benchmarks;\r\n* Our models are pre-trained on vast and diverse datasets;\r\n* Our models are fast and can be run on commodity hardware;\r\n* Our models are easy to use;\r\n\r\n**Future plans**:\r\n\r\n* Publish quantized models;\r\n*  Compress our Enterprise Edition models up to ~20 Megabytes without loss of fidelity;\r\n*   We also are planning to release Community Edition model for other popular languages;","links":[{"article_link":"https://medium.com/@aveysov/modern-google-level-stt-models-released-c6491019e30c?sk=0d51c5301da830c31dcd9d2de7171c17","code_link":"https://github.com/snakers4/silero-models","research_link":"https://thegradient.pub/towards-an-imagenet-moment-for-speech-to-text/","media_link":"","dataset_link":"https://github.com/snakers4/open_stt","demo_link":"https://colab.research.google.com/github/snakers4/silero-models/blob/master/examples.ipynb","other_link":"https://thegradient.pub/a-speech-to-text-practitioners-criticisms-of-industry-and-academia/"}]},{"id":2385,"title":"Beginner\u2019s Guide to Linear Regression with cuML","description":"Break down of simple & multiple linear regression and how to easily implement both in Python with RAPIDS AI\u2019s cuML","tags":["article","code","dataset","notebook","tutorial","python","linear-regression","machine-learning","regression","data-science","cuml","rapids"],"details":"![](https://miro.medium.com/max/1400/1*Zl_Z3bdXrJJWoycsJQhikg.png)","links":[{"article_link":"https://medium.com/future-vision/beginners-guide-to-linear-regression-in-python-with-cuml-30e2709c761?source=friends_link&sk=1da35920b9e2ffea59d5cb3c998bfeae","code_link":"https://raw.githubusercontent.com/Dropout-Analytics/cuml_linear_regression/master/linear_regression.ipynb","research_link":"","media_link":"","dataset_link":"https://raw.githubusercontent.com/scikit-learn/scikit-learn/master/sklearn/datasets/data/boston_house_prices.csv","demo_link":"","other_link":""}]},{"id":2384,"title":"Intro to Facebook Prophet","description":"Everything you need to know when starting out with Facebook\u2019s time series forecasting tool","tags":["article","code","dataset","tutorial","python","time-series","time-series-forecasting","prophet"],"details":"**Summary / TLDR**\r\n\r\n* how Prophet calculates these forecasts \u2014 `trend`, `seasonality`, `holidays`\r\n* installing Prophet with pip \u2014 `pip install fbprophet`\r\n* molding data to `.fit()` the model \u2014 ds, y\r\n* calling a model, fitting data, and making a simple forecast\r\n* understanding weekly, yearly, & overall trend \u2014 `.plot_components()`\r\n* examining accuracy with `cross_validation` & `performance_metrics`","links":[{"article_link":"https://medium.com/future-vision/intro-to-prophet-9d5b1cbd674e?source=friends_link&sk=5709431ddc156b076b3cc1c22be3dcbf","code_link":"https://github.com/gumdropsteve/intro_to_prophet","research_link":"","media_link":"","dataset_link":"https://raw.githubusercontent.com/gumdropsteve/intro_to_prophet/master/data/WMT.csv","demo_link":"","other_link":""}]},{"id":2383,"title":"Beginner\u2019s Guide to BlazingSQL","description":"Everything you need to know when starting out","tags":["article","code","dataset","notebook","tutorial","python","sql","gpu","rapids","blazingsql"],"details":"**Outline**\r\n\r\n* What is BlazingSQL?\r\n* How does BlazingSQL work?\r\n* Practice with BlazingSQL\r\n* 3.1 Installation & Imports\r\n* 3.2 Creating Tables\r\n* 3.3 Querying Tables\r\n* 3.4 Handing off Results","links":[{"article_link":"https://medium.com/dropout-analytics/beginners-guide-to-blazingsql-9ab6c2a9c6ad?source=friends_link","code_link":"https://raw.githubusercontent.com/gumdropsteve/silent-disco/master/beginners_guide_to_bsql.ipynb","research_link":"","media_link":"","dataset_link":"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page","demo_link":"","other_link":""}]},{"id":2382,"title":"Distributed SQL with Dask","description":"Scale your Python data science across multiple GPUs with BlazingSQL (w/ code + data)","tags":["article","code","dataset","notebook","tutorial","python","sql","gpu","dask","rapids","blazingsql"],"details":"Distributed SQL query execution is key in scaling the power of the RAPIDS community to the enterprise-level data challenges of today\u2019s market.\r\n\r\nBlazingSQL makes it easy by utilizing Dask and Dask-cuDF (dask_cudf), which means you can effortlessly conduct multiple GPUs through an intuitive Python API.","links":[{"article_link":"https://blog.blazingdb.com/distributed-sql-with-dask-2979262acc8a?source=friends_link&sk=077319064cd7d9e18df8c0292eb5d33d","code_link":"https://raw.githubusercontent.com/BlazingDB/Welcome_to_BlazingSQL_Notebooks/branch-0.15/blog_posts/distributed_sql_with_dask.ipynb","research_link":"","media_link":"","dataset_link":"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page","demo_link":"","other_link":""}]},{"id":2381,"title":"PySR","description":"Simple and fast symbolic regression in Python/Julia via regularized evolution and simulated annealing.","tags":["code","paper","research","julia","python","regression","library","genetic-algorithm","arxiv:2006.11287","symbolic-regression","pysr"],"details":"Symbolic regression built on Julia, and interfaced by Python. Uses regularized evolution, simulated annealing, and gradient-free optimization.\r\n\r\nSymbolic regression is a very interpretable machine learning algorithm for low-dimensional problems: these tools search equation space to find algebraic relations that approximate a dataset.\r\n\r\nOne can also extend these approaches to higher-dimensional spaces by using a neural network as proxy, as explained in https://arxiv.org/abs/2006.11287, where we apply it to N-body problems. Here, one essentially uses symbolic regression to convert a neural net to an analytic equation. Thus, these tools simultaneously present an explicit and powerful way to interpret deep models.","links":[{"article_link":"","code_link":"https://github.com/MilesCranmer/pysr","research_link":"https://arxiv.org/abs/2006.11287","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2380,"title":"Interact with PyTorch layers using Jupyter Widgets","description":"Build your understanding of PyTorch's ConvTranspose1d layer using interactive visualisations\r\n\r\n","tags":["article","code","notebook","convolutional-neural-networks","interactive","padding","stride"],"details":"Sometimes we want to see inputs and outputs of PyTorch layers to build an intuition of what they do. If I've read the docs and put a few tensors through the layer while checking the inputs and outputs shapes, generally that's enough.\r\n\r\nBut sometimes there's weird parameters that I can't get my head around or I just want to see it working, so building interactive widgets helps me grow my understanding.\r\n\r\nSo in this post I'll show you how I built an interactive widget to explore PyTorch's `ConvTranspose1d`, while explaining a bit about the layer itself. We'll use Anacondas's [HoloViz](https://holoviz.org/) tools (Holoviews, Panel and Bokeh) for the plotting and interactivity.\r\n\r\nThe end goal is to have a interactive plot for interacting with `ConvTranspose1d` parameters and seeing the output like this tweet.","links":[{"article_link":"https://www.scottcondron.com/jupyter/visualisation/ai/deep%20learning/2020/09/25/interact-with-pytorch-layers-with-jupyter-widgets.html","code_link":"https://github.com/scottire/fastpages/blob/master/_notebooks/2020-09-25-interact-with-pytorch-layers-with-jupyter-widgets.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2379,"title":"ML projects ideas! (I've got all these implemented on my GitHub)","description":"machine-learning/deep learning project ideas (mostly computer vision)","tags":["machine-learning","machine-learning-project-ideas"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://youtu.be/ynx48f7LhCc","dataset_link":"","demo_link":"","other_link":""}]},{"id":2376,"title":"colab-cli - sync jupyter notebooks with colab notebooks.","description":"Experience better workflow with google colab, local jupyter notebooks and git.You can now easily manage working with jupyter notebooks and google colab from cli","tags":["article","code","notebook","git","python","deep-learning","machine-learning","library","cli"],"details":"**Features**\r\n\r\n* \ud83e\udd20 Upload local jupyter notebook to gdrive from cli\r\n* \ud83d\ude06 Quick access to jupyter notebooks in gdrive from your cli\r\n* \ud83d\ude80 Keeps jupyter notebooks organized in gdrive by creating local file structure in gdrive\r\n* \ud83e\udd2f Sync local work on notebooks with gdrive\r\n* \ud83e\udd42 Git friendly, pull changes from gdrive and commit to git\r\n\r\nRead more [here](https://github.com/Akshay090/colab-cli)","links":[{"article_link":"https://akshay-ashok.now.sh/projects/colab-cli","code_link":"https://github.com/Akshay090/colab-cli","research_link":"","media_link":"https://asciinema.org/a/314749","dataset_link":"","demo_link":"","other_link":""}]},{"id":2375,"title":"How to do more with less data ?\u2014 Active learning","description":"An Article and demonstration on how to use only a fraction of data to achieve the same accuracy as on the full data using an intuitive active learning method.","tags":["article","code","notebook","tutorial","machine-learning","active-learning","annotation","semi-supervised-learning"],"details":"Objectives:\r\n\r\nAn Article and demonstration on how to use only a fraction of data to achieve the same accuracy as on the full data using an intuitive active learning method called \"Uncertainty sampling with entropy\".\r\n\r\nDemo:\r\n\r\nFor the demonstration, I have used Active learning to utilize only 23% of the actual training dataset ( ATIS intent classification dataset) to achieve the same result as training on 100% of the dataset.\r\n","links":[{"article_link":"https://towardsdatascience.com/how-to-do-more-with-less-data-active-learning-240ffe1f7cb9","code_link":"https://colab.research.google.com/drive/1BsTuFK8HcXS5WWlOCS1QHgvHRf2FK6aD","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2374,"title":"Extract Links from a Web Page using Python","description":"In this article we will discuss how to extract links from a URL using Python.","tags":["article","tutorial","python","program-development","web-services"],"details":"In this article we will discuss how to extract links from a URL using Python.\r\n\r\n**Table of Contents**\r\n\r\n* Introduction\r\n* Get HTML content from URL\r\n* Finding and extracting links from HTML\r\n* Complete Object-Oriented Programming Example\r\n* Conclusion","links":[{"article_link":"https://pyshark.com/extract-links-from-a-web-page-using-python/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2373,"title":"GraphNorm","description":"A Principled Approach to Accelerating Graph Neural Network Training.","tags":["code","paper","research","graph-neural-networks","graphnorm","arxiv:2009.03294"],"details":"GraphNorm is a principled normalization method that accelerates the GNNs training on graph classification tasks, where the key idea is to normalize all nodes for each individual graph with a learnable shift. Theoretically, we show that GraphNorm serves as a preconditioner that smooths the distribution of the graph aggregation's spectrum, and the learnable shift is used to improve the expressiveness of the networks. Empirically, we conduct experiments on several popular benckmark datasets, including the recently released Open Graph Benchmark. Results on datasets with different scale consistently show that GNNs with GraphNorm converge much faster and achieve better generalization performance.\r\n\r\n![](https://github.com/lsj2408/GraphNorm/raw/master/README.assets/Fig-Overview.png)","links":[{"article_link":"","code_link":"https://github.com/lsj2408/GraphNorm","research_link":"https://arxiv.org/abs/2009.03294","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2372,"title":" A spaced repetition app for keeping your reinforcement learning","description":"We aim to keep your reinforcement learning knowledge fresh by periodically reminding you of concepts making you a master of RL knowledge!!","tags":["article","reinforcement-learning"],"details":"Reinforcement Learning theory is expansive and has many moving parts. It is hard to remember equations and understand important RL concepts. We introduce a spaced repetition learning system to help you memorize reinforcement learning concepts. It basically reminds you of things that it suspects you have forgotten. The more you review cards the lesser you will see them. Spaced repetition systems has been shown to help users retain knowledge for years! We are excited to bring this concept to RL Learning.","links":[{"article_link":"https://masterrl.herokuapp.com/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://masterrl.herokuapp.com/"}]},{"id":2371,"title":"From Research to Production with Deep Semi-Supervised Learning","description":"Semi-Supervised Learning (SSL) has blossomed in the deep learning research community\u200a\u2014\u200awe share lessons learned over 15 months of taking SSL into production.","tags":["article","research","tutorial","deep-learning","machine-learning","production","semi-supervised-learning"],"details":"The success of most deep learning algorithms today is largely the result of decades of research, the growing availability of GPUs, and data. But not just any kind of data \u2014 the kind that is abundant, clean, and ***labeled***.\r\n\r\nDatasets like ImageNet, CIFAR10, SVHN, and others, have allowed researchers and practitioners to make remarkable progress on computer vision tasks and were immensely useful for our own experimentation. Yet the elephant in the room for many applications that seek to benefit from this progress, such as medicine, is precisely the fact that the data must be *abundant, clean, and labeled.*\r\n\r\n**Semi-supervised learning (SSL)**, a subfield that combines both supervised and unsupervised learning, has grown in popularity in the deep learning research community over the past few years. It\u2019s very possible that, at least in the short-term, SSL approaches could be the bridge between label-heavy supervised learning and a future of data-efficient modeling.\r\n\r\nIn this post, we talk about when you should consider using SSL approaches in your production environments and the lessons we\u2019ve learned using them to improve our object detection models at [Uizard](https://uizard.io). Of course, we\u2019ll do our best to share the big picture but keep some details of the wizardry to ourselves.\r\n\r\n***Our hope is that by displaying how and when SSL worked and didn\u2019t work for us and by sharing tips learned on our journey from research to production, we can inspire you to take a chance on SSL for your work and unlock the potential of your unlabeled data.***\r\n\r\nIn short, here are a few lessons we emphasize:\r\n\r\n* **Simplicity is king**. The most successful approaches in SSL that translated from research to production were those that were the simplest to reproduce. Specifically, we\u2019ll elaborate on how \u201cSelf-Training with Noisy Student\u201d ([Xie et al., 2019](https://arxiv.org/pdf/1911.04252.pdf)) worked for us.\r\n\r\n* **Pseudo-label refinement with heuristics can be extremely effective.** Pseudo-labeling is a popular component of SSL approaches \u2014 we find that using simple heuristics to refine our pseudo-labels in the unlabeled data improves performance across different sizes of unlabeled datasets.\r\n\r\n* **Progress in semi-supervised image classification is difficult to translate to object detection.** Much of the progress in SSL that we followed measured performance on image classification with promises of similar improvements on object detection, but we found it difficult to adapt them appropriately in practice. As a result, more work and research is needed in the semi-supervised object detection space.","links":[{"article_link":"https://medium.com/@nairvarun18/from-research-to-production-with-deep-semi-supervised-learning-7caaedc39093?source=friends_link&sk=5df3a09a0961c88b122684f5f71f4ec8","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2370,"title":"The Maker Philosophy with ML APIs","description":"Practising being a maker with Google Cloud Platform\u2019s ML APIs.","tags":["article","code","tutorial","gcp","apis","vision-api"],"details":"In this post, I discuss how I used several Google Cloud Platform (GCP) APIs to turn two ideas into small prototypes. It includes my thought process, the problems I ran into while developing the prototypes, and my approach toward tackling them. All the code discussed in the post is available in [this repository](https://github.com/sayakpaul/GCP-ML-API-Demos).","links":[{"article_link":"https://sayak.dev/mlapis-maker/","code_link":"https://github.com/sayakpaul/GCP-ML-API-Demos","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2369,"title":"GP-GAN: Towards Realistic High-Resolution Image Blending","description":"Blending composite images using a generative model and a Gaussian-Poisson equation with a Laplacian Pyramid","tags":["code","paper","research","pytorch","convolutional-neural-networks","deep-learning","generative-adversarial-networks","computer-vision","demo","laplacian-pyramid","image-blending","arxiv:1703.07195"],"details":"**Please click the thumbnail to view it clearly**.\r\n\r\n### Gaussian-Poisson-GANs-For-Image-Blending\r\n\r\nThis project implements an algorithm for blending composite images(copy-paste images/foreign objects in a scene) using a Wasserstein Generative Adversarial Network(GAN) and the Gaussian-Poisson equation.\r\n\r\n#### An overview of the algorithm\r\n\r\n* The GAN is trained to give a very low-resolution blend(eg. 64 x 64), given the composite image.\r\n* The low-resolution image is used as a color constaint in the Gaussian-Poisson equation proposed in [1]. An optimization problem is solved to estimate the low-frequency signals(i.e. using a Gaussian blur) of the GAN's output and to estimate the high-frequency signals(i.e. image gradient) of the composite(copy-paste) image using a Laplacian pyramid.\r\n\r\n* **[PyTorch code](https://github.com/aiarjun/Gaussian-Poisson-GANs-For-Image-Blending)** & **[Slides](https://drive.google.com/file/d/1SBwlqkelJqXrfwxZ5_uFK6QVXZYSJBxp/view)** by me ([aiarjun](https://github.com/aiarjun)).\r\n* **[Demo](http://wuhuikai.me/DeepJS/)** and **[Research](https://arxiv.org/abs/1703.07195)** are by the original authors of the algorithm. ","links":[{"article_link":"","code_link":"https://github.com/aiarjun/Gaussian-Poisson-GANs-For-Image-Blending","research_link":"https://arxiv.org/abs/1703.07195","media_link":"https://drive.google.com/file/d/1SBwlqkelJqXrfwxZ5_uFK6QVXZYSJBxp/view","dataset_link":"","demo_link":"http://wuhuikai.me/DeepJS/","other_link":""}]},{"id":2368,"title":"TableQA","description":"AI tool for querying  natural language on tabular data like csvs and other dataframes.","tags":["code","notebook","tutorial","databases","sql","natural-language-processing","question-answering","conversational-ai","demo","tabular"],"details":"**Features**:\r\n\r\n* Supports detection from multiple csvs\r\n* Support FuzzyString implementation. i.e, incomplete csv values in query can be automatically detected and filled in the query.\r\n* Open-Domain, No training required.\r\n* Add manual schema for customized experience\r\n* Auto-generate schemas in case schema not provided\r\n\r\n**Next Steps**:\r\n\r\n* Host  a web app for consumers.\r\n* Support more dataframes and databases.   \r\n* Support for more complex queries.\r\n* Support for automatic data visualisations\r\n\r\nBuilt with the help of QA models of [HuggingFace transformers](https://huggingface.co/transformers/examples.html).\r\n\r\n","links":[{"article_link":"","code_link":"https://github.com/abhijithneilabraham/tableQA","research_link":"","media_link":"","dataset_link":"","demo_link":"https://colab.research.google.com/drive/1Bgd3L-839NVZiP3QqWfpkYIufQIm4Rar","other_link":""}]},{"id":2367,"title":"Interactive Analysis of Sentence Embeddings","description":"Learn how to interactively explore sentence embedding and labels in Tensorflow Embedding Projector.","tags":["article","tutorial","tensorflow","tensorflow-js","contextualized-embeddings","embeddings","natural-language-processing","visualization"],"details":"[Embedding Projector](https://projector.tensorflow.org/) is a free web application for visualizing high-dimensional data. It has built-in demos for visualizing word embeddings in NLP and image embeddings for MNIST in Computer Vision.\r\n\r\nI recently experimented with a way to load sentence embeddings along with the class labels into this tool and explore them interactively. In this blog post, I will explain the end-to-end process with an example dataset.","links":[{"article_link":"https://amitness.com/interactive-sentence-embeddings/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2366,"title":"Help-Me-Read: Text Summarization using Flask and HuggingFace.","description":"Text summarization, translation and Questions Answers generation using HuggingFace and deployed using Flask, Streamlit. Detailed guide on github. ","tags":["code","docker","huggingface","natural-language-processing","streamlit"],"details":"Help me read is created to help user read long text posts by making use of machine learning to summarize text and generate relevant question answers.  The app can be deployed using Flask, streamlit and also one can use  colab link from my github.  I have added installation documentation and a dockerfile for simple usage. I have a bit less experience in NLP, so if you have any suggestion on improvements/optimization please let me know. ","links":[{"article_link":"","code_link":"https://github.com/Anku5hk/Help-Me-Read","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2365,"title":"How to build a production-ready Deep Learning Training loop","description":"Building a custom training loop in Tensorflow and Python with checkpoints and Tensorboards visualizations","tags":["article","code","tutorial","deep-learning","machine-learning","computer-software","training","computer-vision","production","segmentation","demo"],"details":"","links":[{"article_link":"https://theaisummer.com/tensorflow-training-loop/","code_link":"https://github.com/The-AI-Summer/Deep-Learning-In-Production","research_link":"","media_link":"","dataset_link":"","demo_link":"https://theaisummer.com/data-preprocessing/","other_link":"https://theaisummer.com/best-practices-deep-learning-code/"}]},{"id":2364,"title":"Annotated Research Papers","description":"Finding papers hard to read? Read the annotated version with me","tags":["code","paper","research"],"details":"## Why annotated papers?\r\n\r\nDo you love reading research papers? Or do you find reading papers intimidating? Or are you looking for annotated research papers that are much easier to understand?\r\n\r\nIf you are in any of the categories listed above, then you have arrived at the right place.  I spend a lot of time reading papers. It is a crucial part of my ML work. If you want to do research or you want to be a better ML engineer, then you should read papers. This habit of reading papers will help you to remain updated with the field. \r\n \r\n**Note:** I am a pen-paper guy. Nothing beats that pen-paper reading experience, but in the ongoing scenarios (pandemic, lockdown, etc.), I am not able to print the papers. Taking this as an opportunity to share my thought process, I will be sharing the annotated research papers in this repo. \r\n**The order of the papers won't strictly be according to the timeline on arXiv. Sometimes I put a paper on hold and read it after a while.**\r\n\r\n**PS:** I cannot annotate all the papers I read, but if I liked one, then that will be uploaded here. Also, there will be blog posts for a few research papers that are really important.\r\n\r\n![](https://github.com/AakashKumarNain/annotated_research_papers/raw/master/img/papers.gif)","links":[{"article_link":"","code_link":"https://github.com/AakashKumarNain/annotated_research_papers","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2363,"title":"TensorFlow Recommenders","description":"An open-source TensorFlow package that makes building, evaluating, and serving sophisticated recommender models easy.","tags":["article","code","tensorflow","library","recommendation-systems"],"details":"Built with TensorFlow 2.x, TFRS makes it possible to:\r\n\r\n* Build and evaluate flexible candidate nomination models;\r\n* Freely incorporate item, user, and context information into recommendation models;\r\n* Train multi-task models that jointly optimize multiple recommendation objectives;\r\n\r\n![](https://1.bp.blogspot.com/-ww8cKT3nIb8/X2pdWAWWNmI/AAAAAAAADl8/pkeFRxizkXYbDGbOcaAnZkorjEuqtrabgCLcBGAsYHQ/s0/TF%2BRecommenders%2B06.gif)\r\n\r\nEfficiently serve the resulting models using TensorFlow Serving.\r\nTFRS is based on TensorFlow 2.x and Keras, making it instantly familiar and user-friendly. It is modular by design (so that you can easily customize individual layers and metrics), but still forms a cohesive whole (so that the individual components work well together). Throughout the design of TFRS, we've emphasized flexibility and ease-of-use: default settings should be sensible; common tasks should be intuitive and straightforward to implement; more complex or custom recommendation tasks should be possible.","links":[{"article_link":"https://blog.tensorflow.org/2020/09/introducing-tensorflow-recommenders.html","code_link":"https://github.com/tensorflow/recommenders","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.tensorflow.org/recommenders"}]},{"id":2362,"title":"Deploy Flask app in Heroku","description":"Base project, with mandatory files and folders for deploying Flask apps in Heroku","tags":["code","tutorial","flask","machine-learning","ci-cd"],"details":"Flask is a light-weight API. Heroku is a PAAS , which helps developers to build, run, and operate applications entirely in the cloud. This project consists of mandatory files and folders required for deploying Flask apps in Heroku. Users can clone the project and start building their application and deploy in Heroku (Deployment commands available in the README).","links":[{"article_link":"","code_link":"https://github.com/savitha91/Flask_HerokuDeploy","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2361,"title":"Deploy streamlit app in Heroku","description":"Base project, with mandatory files and folders for deploying streamlit apps in Heroku","tags":["code","machine-learning","streamlit","heroku","ci-cd"],"details":"This project consists of mandatory files and folders required for deploying streamlit apps in Heroku. Users can clone the project and start building their application and deploy in Heroku (Deployment commands available in the README).  \r\n","links":[{"article_link":"","code_link":"https://github.com/savitha91/Streamlit_HerokuDeploy","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2360,"title":"3D Face: Fast, Accurate and Stable Reconstruction","description":"This work extends the previous work 3DDFA, named 3DDFA_V2, titled Towards Fast, Accurate and Stable 3D Dense Face Alignment, accepted by ECCV 2020. ","tags":["code","notebook","paper","research","pytorch","library","computer-vision","3d-face","face-aligment","arxiv:2009.09960"],"details":"## Introduction\r\n![stars](https://img.shields.io/github/stars/cleardusk/3DDFA_V2.svg?style=flat) [![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1OKciI0ETCpWdRjP-VOGpBulDJojYfgWv)\r\n\r\n<p align=\"center\">\r\n  <img src=\"https://raw.githubusercontent.com/cleardusk/3DDFA_V2/master/docs/images/webcam.gif\" alt=\"demo\" width=\"512px\">\r\n</p>\r\n\r\nThis work extends [3DDFA](https://github.com/cleardusk/3DDFA), named **[3DDFA_V2](https://github.com/cleardusk/3DDFA_V2)**, titled [Towards Fast, Accurate and Stable 3D Dense Face Alignment](https://arxiv.org/abs/2009.09960), accepted by [ECCV 2020](https://eccv2020.eu/). \r\nCompared to [3DDFA](https://github.com/cleardusk/3DDFA), 3DDFA\\_V2 achieves better performance and stability. Besides, 3DDFA\\_V2 incorporates the fast face detector [FaceBoxes](https://github.com/zisianw/FaceBoxes.PyTorch) instead of Dlib. A simple 3D render written by c++ and cython is also included. If you are interested in this repo, just try it on this **[google colab](https://colab.research.google.com/drive/1OKciI0ETCpWdRjP-VOGpBulDJojYfgWv)**!\r\n\r\n## Getting started\r\n\r\nThe usage is very simple. \r\n\r\n1. Clone this repo\r\n\r\n```\r\ngit clone https://github.com/cleardusk/3DDFA_V2.git\r\ncd 3DDFA_V2\r\n```\r\n\r\n2. Build the cython version of NMS, and Sim3DR\r\n\r\n```\r\nsh ./build.sh\r\n```\r\n\r\n3. Run demos\r\n\r\n```\r\npython3 demo.py -f examples/inputs/emma.jpg  # -o [2d_sparse, 2d_dense, 3d, depth, pncc, pose, uv_tex, ply, obj]\r\npython3 demo_video.py -f examples/inputs/videos/214.avi\r\npython3 demo_video_smooth.py -f examples/inputs/videos/214.avi\r\npython3 demo_webcam_smooth.py\r\n```\r\n\r\nFor example, running `python3 demo.py -f examples/inputs/emma.jpg -o 3d` will give the result below:\r\n\r\n<p align=\"center\">\r\n  <img src=\"https://raw.githubusercontent.com/cleardusk/3DDFA_V2/master/docs/images/emma_3d.jpg\" alt=\"demo\" width=\"640px\">\r\n</p>\r\n\r\nMore demos:\r\n<p align=\"center\">\r\n  <img src=\"https://raw.githubusercontent.com/cleardusk/3DDFA_V2/master/docs/images/out.gif\" alt=\"demo\" width=\"640px\">\r\n</p>\r\n\r\nMore features to see [here](https://github.com/cleardusk/3DDFA_V2#features-up-to-now).\r\n\r\n","links":[{"article_link":"","code_link":"https://github.com/cleardusk/3DDFA_V2","research_link":"https://arxiv.org/abs/2009.09960","media_link":"https://guojianzhu.com/assets/videos/3162-supp.mp4","dataset_link":"","demo_link":"","other_link":"https://colab.research.google.com/drive/1OKciI0ETCpWdRjP-VOGpBulDJojYfgWv"}]},{"id":2359,"title":"Supermarket System","description":"A web application for supermarket to manage all details.","tags":["code","css","html","javascript","sql","web-design"],"details":"","links":[{"article_link":"","code_link":"https://github.com/NishanthSV/Supermarket-System","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2358,"title":"Student Dropout Prediction","description":"It is a machine learning based web app to predict whether a student get dropout from college based on his academic and financial details.","tags":["code","machine-learning","random-forests","decision-tree"],"details":"","links":[{"article_link":"","code_link":"https://github.com/NishanthSV/DropoutPrediction","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2357,"title":"Sudoku Solver","description":"Solving Sudoku by extracting the puzzle from photo using Computer Vision and OCR and solving it.","tags":["code","machine-learning","computer-vision","optical-character-recognition"],"details":"The input sudoku photo is converted to grayscale, blurred, and the contours are found and before dividing the image into 81 squares using OpenCV. \r\n\r\nLater pytesseract is used to detect the numbers from each of these squares and stored in a matrix which is solved using backtracking to give the result.","links":[{"article_link":"","code_link":"https://github.com/SurajSubramanian/SudokuSolver","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2356,"title":"Part 2: Deep Representations, a way towards neural style transfer","description":"A top-down approach to conceiving neural style transfer","tags":["article","code","tutorial","keras","computer-vision","wandb","neural-style-transfer","tensorflow2","wand"],"details":"This is the second part of the Neural Style Transfer blog post. Here we have tried bringing in the intuition of gram matrix, with which we can segregate the `style` and the `content` of the images. The blog post looks at\r\n- Style Representation\r\n- Neural Style Transfer\r\n- The game of mutual loss","links":[{"article_link":"https://wandb.ai/authors/nerual_style_transfer/reports/Part-2-Deep-Representations-a-way-towards-neural-style-transfer--VmlldzoyMjYyNzk","code_link":"https://github.com/ariG23498/NeuralStyleTransfer","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2355,"title":"\ud83d\udea7 Simple considerations for simple people building fancy NNs ","description":"I will try to highlight a few steps of my mental process when it comes to building and debugging neural networks. ","tags":["article","training","debugging","checklist","recipe"],"details":"I will try to highlight a few steps of my mental process when it comes to building and debugging neural networks. \r\n\r\n1. \ud83d\ude48 Start by putting machine learning aside\r\n2. \ud83d\udcda Continue as if you just started machine learning\r\n3. \ud83e\uddb8\u200d\u2640\ufe0f Don\u2019t be afraid to look under the hood of these 5-liners templates\r\n4. \ud83d\udc40 Tune but don\u2019t tune blindly","links":[{"article_link":"https://medium.com/huggingface/simple-considerations-for-simple-people-building-fancy-neural-networks-7abc3c0f0bd7","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2354,"title":"Data Scientist Portfolio ","description":"Template to Create a charming Data Science Portfolio.","tags":["article","code","github","data-science","portfolio","online"],"details":"A portfolio designed your way highlighting  key achievements and projects is very import aspect in Data Science Carrier. A good portfolio gives a 100x more impact than a resume.","links":[{"article_link":"https://99sbr.github.io","code_link":"https://github.com/99sbr/99sbr.github.io","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2353,"title":"TF Geometric","description":"Efficient and Friendly Graph Neural Network Library for TensorFlow 1.x and 2.x.","tags":["code","tensorflow","graph-convolutional-networks","library","graph-neural-networks","demo"],"details":"Efficient and Friendly Graph Neural Network Library for TensorFlow 1.x and 2.x. Inspired by [rusty1s/pytorch_geometric](https://github.com/rusty1s/pytorch_geometric), we build a GNN library for TensorFlow.\r\n\r\n### Demos\r\n\r\nWe recommend you to get started with some demo.\r\n\r\n#### Node Classification\r\n\r\n+ [Graph Convolutional Network (GCN)](demo/demo_gcn.py)\r\n+ [Multi-head Graph Attention Network (GAT)](demo/demo_gat.py)\r\n+ [GraphSAGE](demo/demo_graph_sage.py)\r\n+ [GIN](demo/demo_gin.py)\r\n+ [ChebyNet](demo/demo_chebynet.py)\r\n+ [SGC](demo/demo_sgc.py)\r\n+ [TAGCN](demo/demo_tagcn.py)\r\n\r\n\r\n#### Graph Classification\r\n\r\n+ [MeanPooling](demo/demo_mean_pool.py)\r\n+ [SAGPooling](demo/demo_sag_pool_h.py)\r\n\r\n\r\n#### Link Prediction\r\n\r\n+ [Graph Auto-Encoder (GAE)](demo/demo_gae.py)\r\n","links":[{"article_link":"","code_link":"https://github.com/CrawlScript/tf_geometric","research_link":"","media_link":"","dataset_link":"","demo_link":"https://github.com/CrawlScript/tf_geometric/tree/master/demo","other_link":"https://tf-geometric.readthedocs.io/en/latest/"}]},{"id":2352,"title":"Numpy Tricks and A Strong Baseline for Vector Index","description":"Tricks used to improve the index and query speed by 1.6x and 2.8x while keeping the memory footprint constant.","tags":["article","code","search","numpy","vector-index","memmap"],"details":"**Table of Contents**\r\n\r\n* The Scalability Problem\r\n* numpy.memmap Instead of numpy.frombuffer\r\n* Batching with Care\r\n* Lifecycle of memmap\r\n\t* Zero-copy slicing\r\n\t* Memory-efficient Euclidean and Cosine\r\n* Removing gzip compression\r\n* Summary\r\n\r\nOn the vector indexing and querying part, Jina has implemented a baseline vector indexer called `NumpyIndexer`, a vector indexer that is purely based on numpy. The implementation pretty straightforward: it writes vectors directly to the disk and queries nearest neighbors via dot product. It is simple, requires no extra dependencies, and the performance was reasonable on small data. As the default vector indexer, we have been using it since day one when showcasing quick demos, toy examples, and tutorials.\r\n\r\nRecently, this [community issue](https://github.com/jina-ai/jina/issues/929) has raised my attention. I realize there is a space of improvement, even for this baseline indexer. In the end, I manage to improve the index and query speed by 1.6x and 2.8x while keeping the memory footprint constant (i.e., invariant to the size of the index data). This blog post summarizes the tricks I used.","links":[{"article_link":"https://hanxiao.io/2020/09/21/Numpy-Tricks-and-A-Strong-Baseline-for-Vector-Index/","code_link":"https://gist.github.com/hanxiao/43cad33b60cadd34f45236993689e5d9","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2351,"title":"Simple Transformers: Transformers Made Easy","description":"Simple Transformers removes complexity and lets you get down to what matters \u2013 model training and experimenting with the Transformer model architectures.","tags":["article","code","notebook","tutorial","huggingface","transformers","natural-language-processing","text-classification","wandb","simple-transformers"],"details":"Simple Transformers, removes complexity and lets you get down to what matters - model training and experimenting with the Transformer model architectures. It helps you bypass all the complicated setups, boilerplate code, and all the other general unpleasantness by,\r\n\r\n* initializing a model in one line\r\n* training in the next\r\n* and evaluating in the third line.\r\n\r\n**Comparisons**:\r\n\r\n* [IMDB Classification using Hugging Face Transformers](https://colab.research.google.com/drive/1_VFmRNFZIWFstAJUCwN_X-OylH5Hers1)\r\n* [IMDB Classification using SimpleTransformers](https://colab.research.google.com/drive/1mcS-q1bwGxULd4bFDMB-Pc5IchTpOSBG)\r\n","links":[{"article_link":"https://wandb.ai/wandb/gallery/reports/SimpleTransformers-Transformers-Made-Easy--VmlldzoyNDQzNTg?accessToken=aakdmyety6dd614otlk7r0vt6dunjd2t82rqo6wig57aea4rqjac7b67i0oyd2kj","code_link":"https://colab.research.google.com/drive/1mcS-q1bwGxULd4bFDMB-Pc5IchTpOSBG","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2350,"title":"Part 1: Deep Representations, a way towards neural style transfer","description":"A top down approach to conceiving neural style transfer","tags":["article","code","tutorial","keras","computer-vision","wandb","neural-style-tranfer","tensorflow2"],"details":"Artistic style transfer is an algorithm proposed by Gatys et al. In [A Neural Algorithm of Artistic Style](https://arxiv.org/abs/1508.06576), the authors talk about the difficulties in segregating the content and style of an image. The content of an image refers to the discernible objects in an image. The style of an image, on the other hand, refers to the abstract configurations of the elements in the image that make it unique. The style and content segregation is difficult because of the unavailability of representations that hold the semantic understanding of images. Now, due to the advancement of convolutional neural networks, such semantic representations are possible.\r\nThis is part one of the two. This report will be structured as follows:\r\n1. Understanding deep image representations by inverting them.\r\n2. Normalized VGG16.\r\n3. Content representations.\r\n4. Amalgamation.\r\n","links":[{"article_link":"https://wandb.ai/authors/nerual_style_transfer/reports/Part-1-Deep-Representations-a-way-towards-neural-style-transfer--VmlldzoyMjQzNDY","code_link":"https://github.com/ariG23498/NeuralStyleTransfer","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2349,"title":"Self Supervised Learning Fastai Extension","description":"Implementation of popular SOTA self-supervised learning algorithms as Fastai Callbacks.","tags":["article","code","fastai","pytorch","library","self-supervised-learning","callbacks"],"details":"Here are the list of implemented algorithms:\r\n\r\n* [SimCLR](https://arxiv.org/pdf/2002.05709.pdf)\r\n* [BYOL](https://arxiv.org/pdf/2006.07733.pdf)\r\n* [SwAV](https://arxiv.org/pdf/2006.09882.pdf)\r\n\r\n![](https://pbs.twimg.com/media/EiZLod5UcAEpfjr?format=jpg&name=large)","links":[{"article_link":"https://keremturgutlu.github.io/self_supervised/","code_link":"https://github.com/keremturgutlu/self_supervised/","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2348,"title":"Layered Neural Rendering for Retiming People in Video","description":"Manipulating and editing the time in which different motions of individuals in the video occur.","tags":["article","paper","research","video","computer-vision","video-processing","retiming","layered-neural-rendering","arxiv:2009.07833"],"details":"We present a method for retiming people in an ordinary, natural video \u2014 manipulating and editing the time in which different motions of individuals in the video occur. We can temporally align different motions, change the speed of certain actions (speeding up/slowing down, or entirely \"freezing\" people), or \"erase\" selected people from the video altogether. We achieve these effects computationally via a dedicated learning-based layered video representation, where each frame in the video is decomposed into separate RGBA layers, representing the appearance of different people in the video. A key property of our model is that it not only disentangles the direct motions of each person in the input video, but also correlates each person automatically with the scene changes they generate \u2014 e.g., shadows, reflections, and motion of loose clothing. The layers can be individually retimed and recombined into a new video, allowing us to achieve realistic, high-quality renderings of retiming effects for real-world videos depicting complex actions and involving multiple individuals, including dancing, trampoline jumping, or group running.\r\n\r\n![](https://retiming.github.io/assets/teaser1.gif)\r\n\r\n**Making all children jump into the pool together \u2014 in post-processing!** In the original video (left) each child is jumping into the pool at a different time. In our computationally retimed video (right), the jumps are aligned such that all the children jump together into the pool (notice that the child on the left remains unchanged in the input and output videos). In this paper, we present a method to produce this and other people retiming effects in natural, ordinary videos.\r\n\r\n![](https://retiming.github.io/assets/teaser2.gif)\r\n\r\n**Decomposing a video into layers.** Our method is based on a novel deep neural network that learns a layered decomposition of the input video. Our model not only disentangles the motions of people in different layers, but can also capture the various scene elements that are correlated with those people (e.g., water splashes as the children hit the water, shadows, reflections). When people are retimed, those related elements are automatically retimed with them, which allows us to create realistic and faithful re-renderings of the video for a variety of retiming effects.","links":[{"article_link":"https://retiming.github.io/","code_link":"","research_link":"https://arxiv.org/abs/2009.07833","media_link":"https://www.youtube.com/watch?v=KAVCHR1mucw","dataset_link":"","demo_link":"","other_link":"https://retiming.github.io/supplementary/index.html"}]},{"id":2347,"title":"Ultimate Python Study Guide","description":"Ultimate Python study guide for newcomers and professionals alike.","tags":["code","tutorial","python"],"details":"## Table of contents\r\n\r\n\ud83d\udcda = External resource,\r\n\ud83c\udf70 = Beginner topic,\r\n\ud83e\udd2f = Advanced topic\r\n\r\n1. **About Python**\r\n    - Overview: [What is Python](https://github.com/trekhleb/learn-python/blob/master/src/getting_started/what_is_python.md) (\ud83d\udcda, \ud83c\udf70)\r\n    - Design philosophy: [The Zen of Python](https://www.python.org/dev/peps/pep-0020/) (\ud83d\udcda)\r\n    - Style guide: [Style Guide for Python Code](https://www.python.org/dev/peps/pep-0008/) (\ud83d\udcda, \ud83e\udd2f)\r\n    - Data model: [Data model](https://docs.python.org/3/reference/datamodel.html) (\ud83d\udcda, \ud83e\udd2f)\r\n    - Standard library: [The Python Standard Library](https://docs.python.org/3/library/) (\ud83d\udcda, \ud83e\udd2f)\r\n    - Built-in functions: [Built-in Functions](https://docs.python.org/3/library/functions.html) (\ud83d\udcda)\r\n2. **Syntax**\r\n    - Variable: [Built-in literals](ultimatepython/syntax/variable.py) (\ud83c\udf70)\r\n    - Expression: [Numeric operations](ultimatepython/syntax/expression.py) (\ud83c\udf70)\r\n    - Conditional: [if | if-else | if-elif-else](ultimatepython/syntax/conditional.py) (\ud83c\udf70)\r\n    - Loop: [for-loop | while-loop](ultimatepython/syntax/loop.py) (\ud83c\udf70)\r\n    - Function: [def | lambda](ultimatepython/syntax/function.py) (\ud83c\udf70)\r\n3. **Data Structures**\r\n    - List: [List operations](ultimatepython/data_structures/list.py) (\ud83c\udf70)\r\n    - Tuple: [Tuple operations](ultimatepython/data_structures/tuple.py)\r\n    - Set: [Set operations](ultimatepython/data_structures/set.py)\r\n    - Dict: [Dictionary operations](ultimatepython/data_structures/dict.py) (\ud83c\udf70)\r\n    - Comprehension: [list | tuple | set | dict](ultimatepython/data_structures/comprehension.py)\r\n    - String: [String operations](ultimatepython/data_structures/string.py) (\ud83c\udf70)\r\n    - Time complexity: [cPython operations](https://wiki.python.org/moin/TimeComplexity) (\ud83d\udcda, \ud83e\udd2f)\r\n4. **Classes**\r\n    - Basic class: [Basic definition](ultimatepython/classes/basic_class.py) (\ud83c\udf70)\r\n    - Abstract class: [Abstract definition](ultimatepython/classes/abstract_class.py)\r\n    - Exception class: [Exception definition](ultimatepython/classes/exception_class.py)\r\n    - Iterator class: [Iterator definition | yield](ultimatepython/classes/iterator_class.py) (\ud83e\udd2f)\r\n5. **Advanced**\r\n    - Decorator: [Decorator definition | wraps](ultimatepython/advanced/decorator.py) (\ud83e\udd2f)\r\n    - Metaclass: [Metaclass definition](ultimatepython/advanced/meta_class.py) (\ud83e\udd2f)\r\n    - Method resolution order: [mro](ultimatepython/advanced/mro.py) (\ud83e\udd2f)\r\n    - Asyncio: [async | await](ultimatepython/advanced/async.py) (\ud83e\udd2f)\r\n    - Weak reference: [weakref](ultimatepython/advanced/weak_ref.py) (\ud83e\udd2f)\r\n    - Benchmark: [cProfile | pstats](ultimatepython/advanced/benchmark.py) (\ud83e\udd2f)\r\n    - Context manager: [Context managers](ultimatepython/advanced/context_manager.py) (\ud83e\udd2f)\r\n    - Mocking: [MagicMock | PropertyMock | patch](ultimatepython/advanced/mocking.py) (\ud83e\udd2f)\r\n    - Regular expression: [search | findall | match | fullmatch](ultimatepython/advanced/regex.py) (\ud83e\udd2f)\r\n    - Data format: [json | xml | csv](ultimatepython/advanced/data_format.py) (\ud83e\udd2f)","links":[{"article_link":"","code_link":"https://github.com/huangsam/ultimate-python","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"http://ultimatepython.org/"}]},{"id":2346,"title":"What happens to developers in 2020?","description":"Complete Data Science approach to analyze programmer and programming language trends.","tags":["article","code","notebook","research","data-science"],"details":"Every year stack overflow organises a survey for developers all around the world. In this notebook I have analyzed the trends for the consecutive years 2018 and 2019. This is a small contribution from my side for the readers to understand the current situation of developers all around the world.\r\n\r\n![](https://miro.medium.com/max/1000/1*N_t2cmwjBKsgBv-8vfHDlg.png)\r\n\r\n![](https://miro.medium.com/max/2000/1*4t7D9oibmaoVREB28ZxJsw.png)\r\n\r\n![](https://miro.medium.com/max/2000/1*CvkS91zasA7WXouE0GxtiA.png)\r\n\r\n![](https://miro.medium.com/max/2000/1*DX0lVyadkrRzr9Opt48qOg.png)","links":[{"article_link":"https://medium.com/@pratikbaitha04/what-happens-to-programmers-in-2020-d04a6bd7452f?source=friends_link","code_link":"https://github.com/pr2tik1/developer-insights/blob/master/developer-insights.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2345,"title":"Remo","description":"\ud83d\udc30 Python lib for remo - the app for annotations and images management in Computer Vision.","tags":["article","code","notebook","library","annotation","computer-vision","image-classification","object-detection","demo","remo"],"details":"Remo is a web-based application to organize, annotate and visualize Computer Vision datasets.\r\n\r\nIt has been designed to be your team's private platform to manage images, in an end-to-end fashion.\r\n\r\nUse Remo to:\r\n\r\n* access your datasets from one place, avoiding scattered files and keeping data secure locally\r\n* quickly annotate your images. We designed our annotation tool from the ground-up\r\n* build better datasets and models, by exploring in depth your Images and Annotations data\r\n* collaborate with your team, accessing the same data remotely\r\n* Remo runs on Windows, Linux, Mac or directly in Google Colab Notebooks. It can also be served on a private server for team collaboration, or embedded in Jupyter Notebooks.\r\n\r\nThis repo is the open source repo for the Remo python library. To access the docs and try the online demo: https://remo.ai\r\n\r\n![](https://camo.githubusercontent.com/93ebe0d2d75c66c079967df0cfa0c979f78291b5/68747470733a2f2f692e696d6775722e636f6d2f34377745456f622e676966)\r\n\r\n**Features**\r\n\r\n*Integration from code*\r\n\r\n* Easily visualize and browse images, predictions and annotations\r\n* Flexibility in slicing data, without moving it around: you can create virtual train/test/splits, have data in different folders or even select specific images using tags\r\n* Allows for a more standardized code interface across tasks\r\n\r\n*Annotation*\r\n\r\n* Faster annotation thanks to an annotation tool we designed from the ground-up\r\n* Manage annotation progress: organize images by status (to do, done, on hold) and track % completion\r\n* One-click edits on multiple objects: rename or delete all the objects of a class, duplicate sets of annotation","links":[{"article_link":"https://remo.ai/docs/sdk-intro/","code_link":"https://github.com/rediscovery-io/remo-python","research_link":"","media_link":"","dataset_link":"","demo_link":"https://github.com/rediscovery-io/remo-python/blob/master/examples/intro_to_remo-python.ipynb","other_link":"https://remo.ai/"}]},{"id":2344,"title":"Labelai","description":"Labelai is an online tool designed to label images, useful for training AI models.","tags":["article","code","library","annotation","computer-vision","image-classification","object-detection","demo"],"details":"Labelai is an online tool designed to label images, useful for training AI models.\r\n\r\nIt's totally client-side, there is no request to any server. It is implemented with Next.js + Preact.\r\n\r\nAnnotations are saved as XML files in PASCAL VOC format, the format used by ImageNet. Besides, it also supports YOLO format.\r\n\r\nIt's strongly inspired by [labelImg](https://github.com/tzutalin/labelImg).\r\n\r\n![](https://github.com/aralroca/labelai/raw/master/public/demo.gif)\r\n\r\nLabelai doesn't require any installation \ud83d\ude1c. In order to start:\r\n\r\n* Open the web app https://labelai.vercel.app/\r\n* Click 'Open'. Here you can import 3 file types: Images (.png, .jpg, .gif, .svg...), XML (PascalVOC labels) and TXT (YOLO labels). Surely the first time you are only interested in importing images, since you will not have any label saved yet. Important: if you want to import already saved labels, you must import it together with the images at the same time. In the case of YOLO, you also must import the classes.txt file.\r\n* Click and release left mouse to select a region to annotate the rect box. Then, you can name that label or select one of the already used names.\r\n* Update rect boxes. Once you already labeled a part of the image, you can resize it by clicking on a box corner, move the box using drag & drop, duplicate it (Ctrl + d) or even remove it (\u232b Delete).\r\n* Move through images. Once you finish annotating all the labels of an image, you can press to the Next and Prev button to move through images and start anottating another image. You can also use the arrows \u2192 and \u2190.\r\n* Save your changes. You can save the labels of the current file or the labels of all files. At this point, you can decide in which format you want to save them (XML for ImageNet or TXT for YOLO). In the case of YOLO, a file named classes.txt is saved too and it defines the list of class names that your YOLO label refers to.","links":[{"article_link":"https://aralroca.com/blog/labelai","code_link":"https://github.com/aralroca/labelai","research_link":"","media_link":"","dataset_link":"","demo_link":"https://labelai.vercel.app/","other_link":"https://labelai.vercel.app/"}]},{"id":2343,"title":"Pytorch Basics","description":"This Repo Contains beginner's guide to Pytorch implementation.","tags":["code","tutorial","pytorch","deep-learning","machine-learning"],"details":"","links":[{"article_link":"","code_link":"https://github.com/99sbr/pytorch_tutorials","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2342,"title":"Norfair","description":"Lightweight Python library for adding real-time 2D object tracking to any detector.","tags":["code","library","computer-vision","object-detection","object-tracking","norfair"],"details":"Norfair is a customizable lightweight Python library for real-time 2D object tracking. Using Norfair, you can add tracking capabilities to any detector with just a few lines of code.\r\n\r\n![](https://github.com/tryolabs/norfair/raw/master/docs/traffic.gif)\r\n\r\n**Features**:\r\n\r\n* Any detector expressing its detections as a series of (x, y) coordinates can be used with Norfair. This includes detectors performing object detection, pose estimation, and instance segmentation.\r\n* The function used to calculate the distance between tracked objects and detections is defined by the user, making the tracker extremely customizable. This function can make use of any extra information, such as appearance embeddings, which can heavily improve tracking performance.\r\n* Modular. It can easily be inserted into complex video processing pipelines to add tracking to existing projects. At the same time it is possible to build a video inference loop from scratch using just Norfair and a detector.\r\n* Fast. The only thing bounding inference speed will be the detection network feeding detections to Norfair.","links":[{"article_link":"","code_link":"https://github.com/tryolabs/norfair","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://tryolabs.com/"}]},{"id":2341,"title":"PyTorch Forecasting","description":"Time series forecasting with PyTorch.","tags":["code","pytorch","library","forecasting","time-series","pytorch-lightning"],"details":"Pytorch Forecasting aims to ease timeseries forecasting with neural networks for both real-world cases and research alike. Specifically, the package provides:\r\n\r\n* A timeseries dataset class which abstracts handling variable transformations, missing values, randomized subsampling, multiple history lengths, etc.\r\n* A base model class which provides basic training of timeseries models along with logging in tensorboard and generic visualizations such actual vs predictions and dependency plots\r\n* Multiple neural network architectures for timeseries forecasting that have been enhanced for real-world deployment and come with in-built interpretation capabilities\r\n* Multi-horizon timeseries metrics\r\n* Ranger optimizer for faster model training\r\n* Hyperparameter tuning with optuna","links":[{"article_link":"","code_link":"https://github.com/jdb78/pytorch-forecasting","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://pytorch-forecasting.readthedocs.io/en/latest/"}]},{"id":2340,"title":"Clumper","description":"A small python library that can clump lists of data together.","tags":["article","code","python","library","data-structures","clumper"],"details":"**Features**: \r\n\r\n* This library has no dependencies besides a modern version of python.\r\n* The library offers a pattern of verbs that are very expressive.\r\n* You can write code from top to bottom, left to right.\r\n* You can read in many json/yaml/csv files by using a wildcard.\r\n* MIT License\r\n\r\n![](https://github.com/koaning/clumper/raw/master/docs/img/groupby.png)","links":[{"article_link":"https://koaning.github.io/clumper/","code_link":"https://github.com/koaning/clumper/","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2339,"title":"Neural CDEs for Long Time-Series via the Log-ODE Method","description":"NCDEs for Long Time-Series via the Log-ODE Method.","tags":["code","paper","research","time-series","neural-cde","log-ode","arxiv:2009.08295"],"details":"Neural Controlled Differential Equations (Neural CDEs) are the continuous-time analogue of an RNN. However, as with RNNs, training can quickly become impractical for long time series. Here we show that a pre-existing mathematical tool - the log-ODE method - can allow us to take integration steps larger than the discretisation of the data, resulting in significantly faster training times, with retainment (and often even improvements) in model performance.\r\n\r\n","links":[{"article_link":"","code_link":"https://github.com/jambo6/neuralCDEs-via-logODEs","research_link":"https://arxiv.org/abs/2009.08295","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2338,"title":"CS 860 - Algorithms for Private Data Analysis - Fall 2020","description":"This course is on algorithms for differentially private analysis of data.","tags":["course","video","privacy","differential-privacy"],"details":"This course is on algorithms for differentially private analysis of data. As necessitated by the nature of differential privacy, this course will be theoretically and mathematically based. References to practice will be provided as relevant, especially towards the end of the course. Prerequisites include an undergraduate understanding of algorithms, comfort with probability, and mathematical maturity.\r\n","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=FJMjNOcIqkc&list=PLmd_zeMNzSvRRNpoEWkVo6QY_6rR3SHjp","dataset_link":"","demo_link":"","other_link":"http://www.gautamkamath.com/CS860-fa2020.html"}]},{"id":2337,"title":"3 Machine Learning Projects For Beginners","description":"here I give 3 simple yet highly rewarding ML projects you could start your ML journey with.","tags":["tutorial","machine-learning","machine-learning-projects","beginner-friendly-ml"],"details":"I got asked a lot this question, how can I start?\r\n\r\nWhich ML projects do you recommend I start with?\r\n\r\nHere is my best attempt at answering that question.\r\n\r\nWe're highly visual living beings so I thought computer vision ML projects could be really interesting!","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://youtu.be/yhhSYk9zt1w","dataset_link":"","demo_link":"","other_link":""}]},{"id":2336,"title":"G-SimCLR","description":"TensorFlow implementation of G-SimCLR. ","tags":["code","paper","research","tensorflow","deep-learning","computer-vision","self-supervised-learning","arxiv:2009.12007"],"details":"In the realms of computer vision, it is evident that deep neural networks perform better in a supervised setting with a large amount of labeled data. The representations learned with supervision are not only of high quality but also helps the model in enhancing its accuracy. However, the collection and annotation of a large dataset are costly and time-consuming. To avoid the same, there has been a lot of research going on in the field of unsupervised visual representation learning especially in a self-supervised setting. Amongst the recent advancements in self-supervised methods for visual recognition, in SimCLR Chen et al. shows that good quality representations can indeed be learned without explicit supervision. In SimCLR, the authors maximize the similarity of augmentations of the same image and minimize the similarity of augmentations of different images. A linear classifier trained with the representations learned using this approach yields 76.5% top-1 accuracy on the ImageNet ILSVRC-2012 dataset. In this work, we propose that, with the normalized temperature-scaled cross-entropy (NT-Xent) loss function (as used in SimCLR), it is beneficial to not have images of the same category in the same batch. In an unsupervised setting, the information of images pertaining to the same category is missing. We use the latent space representation of a denoising autoencoder trained on the unlabeled dataset and cluster them with k-means to obtain pseudo labels. With this apriori information we batch images, where no two images from the same category are to be found. We report comparable performance enhancements on the CIFAR10 dataset and a subset of the ImageNet dataset. We refer to our method as G-SimCLR.\r\n\r\n*The paper is accepted at [ICDM 2020](http://icdm2020.bigke.org/) for the [Deep Learning for Knowledge Transfer (DLKT)](https://fuzhenzhuang.github.io/DLKT2020/index.html) workshop.* ","links":[{"article_link":"","code_link":"https://github.com/ariG23498/G-SimCLR","research_link":"https://arxiv.org/abs/2009.12007","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2335,"title":"GitHub CLI 1.0: All you need to know","description":"GitHub CLI basically brings GitHub to your terminal.","tags":["article","github","cli","github-cli"],"details":"GitHub CLI basically brings GitHub to your terminal. With GitHub CLI, developers can check the status of GitHub issues and pull requests, search for a specific issue or PR, create/fork a repo, or create new issues and pull requests right from the command line.\r\n\r\nIt reduces context switching, helps you focus, and enables you to more easily script and create your own workflows.\r\n\r\nWhat will be covered in this blog post:\r\n\r\n* What Is GitHub CLI\r\n* How to download and Authenticate\r\n* Managing GitHub Repositories using GitHub CLI\r\n* Working with Pull Requests using GitHub CLI\r\n* Managing GitHub Issues using GitHub CLI\r\n* Working with GitHub gist using GitHub CLI\r\n* GitHub alias using GitHub CLI","links":[{"article_link":"https://ayushi7rawat.hashnode.dev/github-cli-10-all-you-need-to-know","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2334,"title":"Python 3.9: All You need to know","description":"The next version of Python brings a faster release schedule, performance boosts, handy new string functions, dictionary union operators, and more stable APIs.","tags":["article","python"],"details":"The next version of Python brings a faster release schedule, performance boosts, handy new string functions, dictionary union operators, and more consistent and stable internal APIs.\r\n\r\nThis Blog post will cover:\r\n\r\n- Dictionary Unions and Update with Iterables\r\n- String methods\r\n- Type hinting\r\n- New math Functions\r\n- New parser\r\n- IPv6 Scoped Addresses\r\n- New Module: Zoneinfo\r\n- Other Language Changes\r\n\r\n![](https://dev-to-uploads.s3.amazonaws.com/i/58uaf41f6uw8zaeq4bfw.png)","links":[{"article_link":"https://ayushi7rawat.hashnode.dev/python-39-all-you-need-to-know","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2333,"title":"Machine Learning-Enabled Design of Point Defects in 2D Materials ","description":"Using deep transfer learning, machine learning, and quantum mechanical calculations we predict key properties of point defects in 2D materials.","tags":["article","code","dataset","paper","research","deep-learning","machine-learning","transfer-learning"],"details":"**Objectives**\r\n\r\n* Develop a machine learning approach to predict key properties in two-dimensional materials for emerging nanotechnologies\r\n* Construct a machine-learnable representation of defects in nanomaterials\r\n\r\n**Highlights**\r\n\r\n* Evaluated over 1,000 defect structures with machine learning and quantum mechanical simulations\r\n*  Identified over 100 promising defect structures for quantum and neuromorphic information applications\r\n\r\n**Takeaways**\r\n\r\n* Deep transfer learning can be used to make predictions on small nanomaterials datasets\r\n* Machine learning enables rapid evaluation of candidate nanomaterials for future technologies\r\n\r\n**Next Steps**\r\n\r\n* Active learning to efficiently identify optimal materials for desired applications\r\n* Incorporate more complex physics-based modeling to predict other properties of interest ","links":[{"article_link":"https://medium.com/@ncfrey/quantum-and-brain-like-technologies-with-defective-materials-a685ee5bb47c","code_link":"https://github.com/ncfrey/defect-design","research_link":"https://pubs.acs.org/doi/abs/10.1021/acsnano.0c05267","media_link":"","dataset_link":"https://figshare.com/collections/Defect_design/4946874","demo_link":"","other_link":""}]},{"id":2332,"title":"Recurrent Neural Networks: building GRU cells VS LSTM cells ","description":"What are the advantages of RNN\u2019s over transformers? When to use GRU\u2019s over LSTM? What are the equations of GRU really mean? How to build a GRU cell in Pytorch?","tags":["article","code","tutorial","deep-learning","gated-recurrent-units","lstm","machine-learning","recurrent-neural-networks","sequence-to-sequence","transformers","natural-language-processing"],"details":"","links":[{"article_link":"https://theaisummer.com/gru/","code_link":"https://github.com/The-AI-Summer/RNN_tutorial","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://theaisummer.com/understanding-lstm/"}]},{"id":2331,"title":"Distributed Linear Regression with cuML","description":"How to scale GPU machine learning with Dask (w/ code + data)","tags":["article","code","notebook","tutorial","linear-regression","machine-learning","regression","gpu","dask","data-science","cuml","rapids"],"details":"","links":[{"article_link":"https://medium.com/dropout-analytics/distributed-linear-regression-with-cuml-b4f32d727e22?source=friends_link&sk=458531bdbb4cf88060d06736f2d4c646","code_link":"https://github.com/Dropout-Analytics/cuml_linear_regression/blob/master/distributed/distributed_linear_regression.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2330,"title":"Beginner\u2019s Guide to Logistic Regression with cuML","description":"What is Logistic Regression? And how to implement it in Python with RAPIDS cuML","tags":["article","code","dataset","notebook","logistic-regression","machine-learning","regression","gpu","data-science","cuml","rapids"],"details":"","links":[{"article_link":"https://medium.com/dropout-analytics/beginners-guide-to-logistic-regression-with-cuml-5061086d8694?source=friends_link&sk=2d8d0f7ddd43ccaaf264afcbadeea231","code_link":"https://github.com/Dropout-Analytics/cuml_logistic_regression/blob/master/logistic_regression.ipynb","research_link":"","media_link":"","dataset_link":"https://raw.githubusercontent.com/gumdropsteve/datasets/master/dog_or_horse.csv","demo_link":"","other_link":""}]},{"id":2329,"title":"Beginner\u2019s Guide to KNN with cuML","description":"What is K-Nearest Neighbors? And how to implement it in Python with RAPIDS cuML.","tags":["article","code","dataset","notebook","machine-learning","k-nearest-neighbors","open-source","gpu","data-science","cuml","rapids"],"details":"","links":[{"article_link":"https://medium.com/dropout-analytics/beginners-guide-to-knn-with-cuml-ddca099f9e9d?source=friends_link&sk=2c1ba843151c0c538fff7bd61fd6eeb1","code_link":"https://github.com/Dropout-Analytics/cuml_knn/blob/master/knn.ipynb","research_link":"","media_link":"","dataset_link":"https://raw.githubusercontent.com/gumdropsteve/datasets/master/iris.csv","demo_link":"","other_link":""}]},{"id":2328,"title":"Distilling Knowledge in Neural Networks","description":"This project demonstrates the compelling model optimization technique - knowledge distillation with code walkthroughs in TensorFlow. ","tags":["article","code","tutorial","tensorflow","computer-vision","wandb","model-optimization"],"details":"\u201cModel ensembles are a pretty much-guaranteed way to gain 2% of accuracy on anything.\u201d - Andrej Karpathy.\r\n\r\nI absolutely agree! However, deploying an ensemble of heavyweight models may not always be feasible in many cases. Sometimes, your single model could be so large (GPT-3, for example) that deploying it in resource-constrained environments is often not possible. This is why we have been going over some of model optimization recipes - Quantization and Pruning. This report is the last one in this series. In this report, we will discuss a compelling model optimization technique - knowledge distillation. I have structured the accompanying article into the following sections -\r\n\r\n* What is softmax telling us?\r\n* Using the softmax information for teaching - Knowledge distillation\r\n* Loss functions in knowledge distillation\r\n* A few training recipes\r\n* Experimental results\r\n* Conclusion","links":[{"article_link":"https://wandb.ai/authors/knowledge-distillation/reports/Distilling-Knowledge-in-Neural-Networks--VmlldzoyMjkxODk","code_link":"https://github.com/sayakpaul/Knowledge-Distillation-in-Keras","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2327,"title":"Paint with Machine Learning","description":"This web app allows you to create a landscape painting in the style of Bob Ross using a deep learning model served using a Spell model server.","tags":["article","pytorch","generative-adversarial-networks","web-design","computer-vision","image-classification","image-to-image-translation","interactive","demo"],"details":"This web app allows you to create a landscape painting in the style of Bob Ross using a deep learning model served using a Spell model server. To do so paint some shapes on the canvas with a set of thematic (trees, mountains, etcetera) brushes provided to you. The shapes you paint are sent to a model server endpoint, which computes an output and presents it on the other screen.","links":[{"article_link":"https://spell.ml/blog/paint-with-ml-deep-learning-X2ALJRAAACQAXYTZ","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"http://paintwith.spell.ml/","other_link":""}]},{"id":2326,"title":"NLP for Developers: Multilingual NLP | Rasa","description":"In this video, Rasa Developer Advocate Rachael will talk about common approaches to handle language input in more than one language.","tags":["video","multilingual","natural-language-processing","rasa"],"details":"In this video, Rasa Developer Advocate Rachael will talk about common approaches to handle language input in more than one language.\r\n\r\n- \u201c[A Multilingual DemoBot, deployable on Heroku](https://rasa.com/showcase/multilingual-demobot)\u201d by Thomas Zezula\r\n- \u201c[Challenges of Computational Processing of Code-Switching](https://www.aclweb.org/anthology/W16-5801/)\u201d by \u00d6zlem \u00c7etino\u011flu, Sarah Schulz and Ngoc Thang Vu from Proceedings of the Second Workshop on Computational Approaches to Code Switching, 2016","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=jMGgT4lgI28","dataset_link":"","demo_link":"","other_link":""}]},{"id":2325,"title":"Implementing Content-Based Image Retrieval with Siamese Networks","description":"With content-based image retrieval, we refer to the task of finding images containing attributes which are not in the image metadata, but in its visual content.","tags":["article","pytorch","siamese-networks","computer-vision","image-similarity-search","image-retrieval"],"details":"In this post we:\r\n\r\n* explain the theoretical concepts behind content-based image retrieval,  \r\n* show step by step how to build a content-based image retrieval system with PyTorch, addressing a specific application: finding face images with a set of given face attributes (i.e. male, blond, smiling).\r\n\r\n![](https://i0.wp.com/neptune.ai/wp-content/uploads/content-based-image-retrieval.jpg?w=755&ssl=1)","links":[{"article_link":"https://neptune.ai/blog/content-based-image-retrieval-with-siamese-networks","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2324,"title":"Character level language model RNN","description":"This is a commentary of the min char language model of [@karpathy](https://twitter.com/karpathy).","tags":["article","tutorial","recurrent-neural-networks"],"details":"[@karpathy](https://twitter.com/karpathy) has been a legend with making intuitive models. His famous blog on Recurrent Neural Network, [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) is one of the best there is. While explaining RNNs he links the readers to his famous gist on [character level language model](https://gist.github.com/karpathy/d4dee566867f8291f086). I have gone a little further to add commentary to the code. The losses being derived provides further intuition to the code.","links":[{"article_link":"https://arig23498.github.io/char-level-language-model","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2323,"title":"DeepTrain","description":"Abstract away boilerplate train loop and data loading code, without making it into a black box. ","tags":["code","tensorflow","library","template","deeptrain"],"details":"DeepTrain is founded on control and introspection: full knowledge and manipulation of the train state.\r\n\r\n### What does it do?\r\nAbstract away boilerplate train loop and data loading code, without making it into a black box. Code is written intuitively and fully documented. Everything about the train state can be seen via dedicated attributes; which batch is being fit and when, how long until an epoch ends, intermediate metrics, etc.\r\n\r\nDeepTrain is not a \u201cwrapper\u201d around TF; while currently only supporting TF, fitting and data logic is framework-agnostic.\r\n\r\n![](https://raw.githubusercontent.com/OverLordGoldDragon/deeptrain/master/docs/source/_images/train_loop.png)\r\n\r\n\r\n### Features\r\n\r\n**Train Loop**\r\n\r\n* Control: iteration-, batch-, epoch-level customs\r\n* Resumability: interrupt-protection, can pause mid-training\r\n* Tracking & reproducibility: save & load model, train state, random seeds, and hyperparameter info\r\n* Callbacks at any stage of training or validation\r\n\r\n**Data Pipeline**\r\n\r\n* AutoData: need only path to directory, the rest is inferred (but can customize)\r\n* Faster SSD loading: load larger batches to maximize read speed utility\r\n* Flexible batch size: can differ from that of loaded files, will split/combine\r\n* Stateful timeseries: splits up a batch into windows, and reset_states() (RNNs) at end\r\n* Iter-level preprocessor: pass batch & labels through Preprocessor() before feeding to model\r\n* Loader function: define custom data loader for any file extension, handled by DataLoader()\r\n\r\n**Introspection**\r\n\r\n* Data: batches and labels are enumerated by \u201cset nums\u201d; know what\u2019s being fit and when\r\n* Model: auto descriptive naming; gradients, weights, activations visuals\r\n* Train state: single-image log of key attributes & hyperparameters for easy reference\r\n\r\n**Utilities**\r\n\r\n* Preprocessing: batch-making and format conversion methods\r\n* Calibration: classifier prediction threshold; best batch subset selection (for e.g. ensembling)\r\n* Algorithms: convenience methods for object inspection & manipulation\r\n* Callbacks: reusable methods with other libraries supporting callbacks","links":[{"article_link":"","code_link":"https://github.com/OverLordGoldDragon/deeptrain","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://deeptrain.readthedocs.io/en/latest/index.html"}]},{"id":2322,"title":"Tic Tac Toe - Trainable AI","description":"Teach a website TicTacToe by playing games and asking the neural network to learn from previous games.  You can watch it learn.","tags":["article","code","javascript","react","tensorflow","tensorflow-js","machine-learning"],"details":"Using a simple perceptron based neural network, can you teach an AI to play tictactoe, effectively overfitting the data.  Ultimately, the simple sequential model learns how to play perfect games.","links":[{"article_link":"https://twitter.com/GantLaborde/status/1304063504526258178?s=20","code_link":"https://github.com/GantMan/tictactoe-ai-tfjs","research_link":"","media_link":"https://youtu.be/1zdHZvRbHwE","dataset_link":"","demo_link":"","other_link":"https://www.tensorflowtictactoe.co/"}]},{"id":2321,"title":"Machine Learning Educators on Twitter","description":"A curated list of people who make Machine Learning concepts clear and accessible through their blog posts, videos, books and courses.","tags":["article","machine-learning"],"details":"","links":[{"article_link":"https://twitter.com/i/lists/1236654402338820104","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2320,"title":"Getting Oriented in the RAPIDS Distributed ML Ecosystem, ETL","description":"This blog post, the first of two exploring this emerging ecosystem, is an introduction to distributed ETL using the dask, cudf, and dask_cudf APIs.","tags":["article","pandas","cudf","gpu","dask","exploratory-data-analysis","rapids"],"details":"For a long time being a data scientist that worked with large datasets and/or models meant mastering two sets of tools, one for local work and one for \"big data\". `pandas`, `numpy`, and `scikit-learn` make it easy to do stuff on your local machine, but can\u2019t handle anything too big to fit in RAM. Once data gets too big, or training too costly, you have to move on to a \"big data\" tool that pools the resources of several machines together to get the job done. This traditionally meant Apache Spark, which, though powerful, requires learning a brand new API and maybe even a brand new language (performance Spark code is written in Scala).\r\n\r\nEnter Dask. Dask is a distributed ETL tool that\u2019s tightly integrated into the Python data science ecosystem. Dask is extremely popular among data scientists because its core API is a subset of the `pandas`, `numpy`, and `scikit-learn` APIs. This flattens the learning curve considerably: most Pythonistas can be productive with Dask almost immediately.\r\n\r\nAs part of its RAPIDS initiative, NVIDIA is going one step further, partnering with the community to build an ecosystem for distributed data science on GPUs on top of Dask. Their new `cudf` Python package already boasts some pretty impressive results\u200a\u2014\u200alike this one from Capital One Labs showing a log-scale speedup for an internal ETL job that was previously being run on CPU.\r\n\r\nThis blog post, the first of two exploring this emerging ecosystem, is an introduction to distributed ETL using the dask, cudf, and dask_cudf APIs. We build the following mental map of the ecosystem:\r\n\r\n![](https://images.prismic.io/spell/b01d766c-4bb5-494f-ad9f-dc8cf2786023_mentalmodel.png)","links":[{"article_link":"https://spell.ml/blog/getting-oriented-in-the-rapids-distributed-ml-ecosystem-part-1-X1gixBIAAJ7nyzHa","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2319,"title":"Cartoonizer with TensorFlow.js","description":"An app to turn your photos into cartoon-styled images \ud83c\udfa8 within your browsers using White-box Cartoonization GAN.","tags":["code","tensorflow","tensorflow-js","generative-adversarial-networks","computer-vision","image-to-image-translation","demo"],"details":"**[App preview][liveapp]**: Upload an image or try examples\r\n\r\n[![demo](https://raw.githubusercontent.com/pratapvardhan/cartoonizer-with-tfjs/master/assets/demo.jpg)][liveapp]\r\n\r\n- Try demo: https://gramener.com/cartoonizer/\r\n- All your data stays in your browser\r\n- Uses #TensorFlowJS WebAssembly\r\n- Model size ~1.5MB\r\n- Takes 5-10s in CPU browsers\r\n\r\nWe used Generative Adversarial Network (GAN) model proposed in \r\n[Learning to Cartoonize Using White-box Cartoon Representations][cvpr2020] (CVPR 2020) by Xinrui Wang and Jinze Yu.\r\n\r\nOur idea was to test if it is reasonably possible to perform model inferences in\r\nthe browser clients with CPUs only. Without needing to send any of user's data (images) to servers.\r\n\r\nHere's the application flow and architecture:\r\n\r\n<p align=\"center\">\r\n  <img src=\"https://github.com/pratapvardhan/cartoonizer-with-tfjs/raw/master/assets/flow.jpg\" style=\"max-width:650px;width:100%;\"/>\r\n</p>\r\n\r\nThis work was possible due to \r\n- [Margaret Maynard-Reid](https://twitter.com/margaretmz) and [Sayak Paul](https://twitter.com/RisingSayak)'s work on [How to Create a Cartoonizer with TensorFlow Lite](https://blog.tensorflow.org/2020/09/how-to-create-cartoonizer-with-tf-lite.html)\r\n- [Xinrui Wang](https://github.com/SystemErrorWang/) and Jinze Yu's original work on [White-box CartoonGAN][cvpr2020]\r\n\r\n#### Citation\r\nXinrui Wang and Jinze Yu are the original authors of [White-box CartoonGAN][cvpr2020].\r\n```\r\n@InProceedings{Wang_2020_CVPR,   \r\nauthor = {Wang, Xinrui and Yu, Jinze,     \r\ntitle = {Learning to Cartoonize Using White-Box Cartoon Representations,   \r\nbooktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},   \r\nmonth = {June}, year = {2020} }\r\n```\r\n\r\n#### Links\r\n\r\n- Original [White-box Cartoonization Repo](https://github.com/SystemErrorWang/White-box-Cartoonization)\r\n- Cartoonizer with [TensorFlow Lite Repo](https://github.com/margaretmz/Cartoonizer-with-TFLite)\r\n- [Live application][liveapp]\r\n- [Repo](https://github.com/pratapvardhan/cartoonizer-with-tfjs/), [Notebook](https://github.com/pratapvardhan/cartoonizer-with-tfjs/blob/master/White_box_Cartoonization.ipynb), [Colab](https://colab.research.google.com/github/pratapvardhan/cartoonizer-with-tfjs/blob/master/White_box_Cartoonization.ipynb)\r\n- [Tweet](https://twitter.com/PratapVardhan/status/1305489788976484354)\r\n\r\n[cvpr2020]: https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Learning_to_Cartoonize_Using_White-Box_Cartoon_Representations_CVPR_2020_paper.pdf\r\n[liveapp]: https://gramener.com/cartoonizer/\r\n[repo]: https://github.com/pratapvardhan/cartoonizer-with-tfjs/","links":[{"article_link":"","code_link":"https://github.com/pratapvardhan/cartoonizer-with-tfjs/","research_link":"","media_link":"","dataset_link":"","demo_link":"https://gramener.com/cartoonizer/","other_link":""}]},{"id":2318,"title":"Jepto - Digital Marketing Analytics","description":"KPI Prediction and Anomaly Detection of digital marketing data for both technical and non-technical marketers and business owners.","tags":["article","anomaly-detection","time-series","time-series-forecasting"],"details":"Under the hood we are using Facebook's Prophet and Twitter's Seasonal Hybrid-ESD algorithms and then created a GUI for non technical marketers to apply them. We expose all of the hyper parameters so users can fine tune and see the results in real time.","links":[{"article_link":"https://www.jepto.com","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2317,"title":"End-to-end Object Detection in TensorFlow Lite","description":"This project shows how to train a custom detection model with the TFOD API, optimize it with TFLite, and perform inference with the optimized model.","tags":["code","tutorial","tensorflow","computer-vision","object-detection","tensorflow-lite"],"details":"The project shows how to train a custom detection model with the **[TFOD API](https://github.com/tensorflow/models/tree/master/research/object_detection)** (TF2 and TF1), optimize it with TFLite, and perform inference with the optimized model. It contains the following notebooks (pardon the naming) - \r\n\r\n* `Training_a_pets_detector_model_within_minutes_with_TFOD_API.ipynb`: Shows how to train a custom object detection model on the Pets dataset (non-eager mode) with Cloud TPUs. Note that it does not use TPUs offered by Colab.\r\n* `Running_inference_with_a_custom_TFOD_API_model.ipynb`: Shows how to export a SavedModel graph from the trained checkpoint files, and run inference.\r\n* `Object_Detection_in_TFLite.ipynb`: Shows how to quantize the original model, generate a TFLite model, and run inference.\r\n* `Training_MobileDet_Custom_Dataset.ipynb`: Shows how to train a custom object detection model on the Pets dataset (non-eager mode) on Colab (GPU), optimize the fine-tuned model with TFLite, and perform inference with the optimized model. ","links":[{"article_link":"","code_link":"https://github.com/sayakpaul/E2E-Object-Detection-in-TFLite/","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2316,"title":"Transformers are Graph Neural Networks","description":"My engineering friends often ask me: deep learning on graphs sounds great, but are there any real applications?","tags":["article","transformers","graph-neural-networks","natural-language-processing"],"details":"While Graph Neural Networks are used in recommendation systems at Pinterest, Alibaba and Twitter, a more subtle success story is the Transformer architecture, which has taken the NLP world by storm. Through this post, I want to establish a link between Graph Neural Networks (GNNs) and Transformers. I'll talk about the intuitions behind model architectures in the NLP and GNN communities, make connections using equations and figures, and discuss how we can work together to drive future progress. Let's start by talking about the purpose of model architectures\u2014representation learning.","links":[{"article_link":"https://thegradient.pub/transformers-are-graph-neural-networks/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2315,"title":"The Curse of Dimensionality\u2026 minus the curse of jargon","description":"In a nutshell, it\u2019s all about loneliness\r\n","tags":["article","dimensionality-reduction","curse-of-dimensionality"],"details":"The **curse of dimensionality**! What on earth is that? Besides being a prime example of shock-and-awe names in machine learning jargon (which often sound far fancier than they are), it\u2019s a reference to the effect that adding more features has on your dataset. In a nutshell, the curse of dimensionality is all about loneliness.","links":[{"article_link":"https://towardsdatascience.com/the-curse-of-dimensionality-minus-the-curse-of-jargon-520da109fc87","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2314,"title":"The Sorcerer\u2019s Apprentice Guide to Training LSTMs","description":"Tricks of the trade for training Long Short-Term Memory networks.","tags":["article","lstm","recurrent-neural-networks","tips"],"details":"Last year, I took a course at the Johannes Kepler University in Linz, Austria on the topic of Recurrent Neural Networks and Long Short-Term Memory Networks. There, Sepp Hochreiter shared some of the \u201cmagic tricks\u201d he and his team employ for training LSTMs. This blog post is the accumulation of some of my notes.\r\n\r\nFor this post, I assume you are already familiar with LSTMs. If not, I suggest you begin with Chris Olah\u2019s [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) and then go on to read the original LSTM work [1] .","links":[{"article_link":"https://www.niklasschmidinger.com/posts/2020-09-09-lstm-tricks/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2313,"title":"DCGAN, cGAN, vGAN in PyTorch (beginner-friendly)","description":"Beginner friendly, PyTorch implementation of various GAN architectures.","tags":["code","tutorial","deep-learning","generative-adversarial-networks"],"details":"It's beginner-friendly in the sense that all of the major design decisions are explicitly communicated through comments, and I've tried to make it as clean and readable as possible.","links":[{"article_link":"","code_link":"https://github.com/gordicaleksa/pytorch-gans","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2312,"title":"Codequestion","description":"Ask coding questions directly from the terminal.","tags":["article","code","dataset","fasttext","library","embeddings","natural-language-processing","question-answering","sentence-embeddings"],"details":"codequestion is a Python application that allows a user to ask coding questions directly from the terminal. Many developers will have a web browser window open while they develop and run web searches as questions arise. codequestion attempts to make that process faster so you can focus on development.\r\n\r\n![](https://raw.githubusercontent.com/neuml/codequestion/master/demo.gif)","links":[{"article_link":"https://towardsdatascience.com/building-a-sentence-embedding-index-with-fasttext-and-bm25-f07e7148d240","code_link":"https://github.com/neuml/codequestion","research_link":"","media_link":"","dataset_link":"https://archive.org/details/stackexchange","demo_link":"","other_link":""}]},{"id":2311,"title":"PyTorch vs TensorFlow?","description":"Make a data-driven decision about which one you should be using.","tags":["tutorial","pytorch","tensorflow","deep-learning"],"details":"Oh the epic battle, the age-old question (= 4 years old) which deep learning framework should I be using?\r\n\r\nPyTorch or TensorFlow?\r\n\r\nIf PyTorch, why? The same goes for TF.\r\n\r\nIn this video, I do some data-driven analysis and make some suggestions on what you should be using depending on your context.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://youtu.be/NuJB-RjhMH4","dataset_link":"","demo_link":"","other_link":""}]},{"id":2310,"title":"Image Super-Resolution","description":"In this project we learn how to train a super-resolution model ESPCN on DIV2K dataset to upscale images using AI by 3x","tags":["article","research","tutorial","artificial-general-intelligence","deep-learning","machine-learning","computer-vision","super-resolution"],"details":"Deep learning techniques have been fairly successful in solving the problem of image and video super-resolution. In this project we will discuss the theory involved, various techniques used, loss functions, metrics, and relevant datasets. You can  run the code for one of the models we'll cover, ESPCN for free on the ML Showcase.\r\n\r\nThere are many methods used to solve this task. We will cover the following:\r\n\r\n* Pre-Upsampling Super Resolution\r\n* Post-Upsampling Super Resolution\r\n* Residual Networks\r\n* Multi-Stage Residual Networks\r\n* Recursive Networks\r\n* Progressive Reconstruction Networks\r\n* Multi-Branch Networks\r\n* Attention-Based Networks\r\n* Generative Models\r\nWe'll look at several example algorithms for each.\r\n\r\nThe content of the article is available at https://blog.paperspace.com/image-super-resolution/","links":[{"article_link":"https://blog.paperspace.com/image-super-resolution/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://ml-showcase.paperspace.com/projects/image-super-resolution"}]},{"id":2309,"title":"Bike rental count prediction'","description":"Bike-rental-count-prediction\r\nThe objective of this Case is to Prediction of bike rental count on daily basis on the environmental and seasonal settings.","tags":["code","decision-trees","machine-learning","random-forests","decision-tree"],"details":"**Bike-rental-count-prediction**\r\nThe objective of this Case is to Prediction of bike rental count on daily basis on the environmental and seasonal settings.\r\n\r\n**Problem Statement**\r\nA bike rental is a bicycle business that rents bikes for short periods of time.\r\nMost rentals are provided by bike shops as a sideline to their main businesses of sales and service, but some shops specialize in rentals.\r\nBike rental shops rent by the day orweek as well as by the hour, and these provide an excellent opportunity for people who don't have access to a vehicle, typically travelers and particularly tourists.\r\n\r\nSpecialized bike rental shops thus typically operate at beaches, parks, or other locations that tourists frequent. In this case, the fees are set to encourage renting the bikes for a few hours at a time, rarely more than a day.\r\n\r\n**Objective**\r\nThe objective of this Case is to predict the bike rental count based on the environmental and seasonal settings, Sothat required bikes would be arranged and managed by the shops according to environmental and seasonal conditions.\r\n\r\n**Data**\r\nOur task is to build regression models which will predict the count of bike rented depending on various environmental and seasonal conditions Given below is a sample of the data set that we are using to predict the count of bike rents:\r\nVariables present in given dataset are instant, dteday, season, yr, mnth, holiday,weekday, workingday, weathersit, temp, atemp, hum, windspeed, casual,registered, cnt The details of variable present in the dataset are as follows -\r\n\r\ninstant: Record index\r\n\r\ndteday: Date\r\n\r\nseason: Season (1:springer, 2:summer, 3:fall, 4:winter)\r\n\r\nyr: Year (0: 2011, 1:2012)\r\n\r\nmnth: Month (1 to 12)\r\n\r\nhr: Hour (0 to 23)\r\n\r\nholiday: weather day is holiday or not (extracted fromHoliday Schedule)\r\n\r\nweekday: Day of the week\r\n\r\nworkingday: If day is neither weekend nor holiday is 1, otherwise is 0.\r\n\r\nweathersit: (extracted fromFreemeteo)\r\n\r\n1: Clear, Few clouds, Partly cloudy, Partly cloudy\r\n\r\n2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\r\n\r\n3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\r\n\r\n4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog temp:\r\nNormalized temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-8, t_max=+39 (only in hourly scale)\r\n\r\natemp: Normalized feeling temperature in Celsius. The values are derived via (t-t_min)/(t_maxt_min), t_min=-16, t_max=+50 (only in hourly scale)\r\n\r\nhum: Normalized humidity. The values are divided to 100 (max)\r\n\r\nwindspeed: Normalized wind speed. The values are divided to 67 (max)\r\n\r\ncasual: count of casual users\r\n\r\nregistered: count of registered users\r\n\r\ncnt: count of total rental bikes including both casual and registeredregisteredregisteredregistered","links":[{"article_link":"","code_link":"https://github.com/tanya9691/Bike-rental-count-prediction","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2308,"title":"ExplainX","description":"ExplainX is an explainable AI framework for data scientists to explain any black-box model behavior to business stakeholders.\r\n\r\n","tags":["code","video","library","interpretability","explainx"],"details":"ExplainX.ai is a fast, scalable and end-to-end Explainable AI framework for data scientists & machine learning engineers. With explainX, you can understand overall model behavior, get the reasoning behind model predictions, remove biases and create convincing explanations for your business stakeholders. \r\n\r\n![](https://github.com/explainX/explainx/raw/master/started_example.png)\r\n\r\nEssential for:\r\n\r\n* Model debugging - Why did my model make a mistake? How can I improve the accuracy of the model?\r\n* Detecting fairness issues - Is my model biased? If yes, where?\r\n* Human-AI cooperation - How can I understand and trust the model's decisions?\r\n* Regulatory compliance - Does my model satisfy legal & regulatory requirements?\r\n* High-risk applications - Healthcare, Financial Services, FinTech, Judicial, Security etc.\r\n\r\n![](https://github.com/explainX/explainx/raw/master/demo-explainx-with-sound.gif)","links":[{"article_link":"","code_link":"https://github.com/explainX/explainx","research_link":"","media_link":"https://www.youtube.com/watch?v=X3fk-r2G15k","dataset_link":"","demo_link":"","other_link":"https://www.explainx.ai/"}]},{"id":2307,"title":"Target Encoding with RAPIDS cuML: Do More with Categorical Data","description":"Walk through the design of target encoding with RAPIDS cuML.","tags":["article","code","notebook","encoder","cuml","rapids","categorical-data"],"details":"We are happy to announce that TargetEncoder has come to RAPIDS cuML 0.15 with a simple scikit-learn transformer-style API and 100x speedup with a single GPU. In this blog, we will discuss how to use the new TargetEncoder feature in cuML and show that it could boost both accuracy and performance significantly. The [full notebook](https://github.com/rapidsai/cuml/blob/branch-0.16/notebooks/target_encoder_walkthrough.ipynb) can be found in cuML\u2019s repo.","links":[{"article_link":"https://medium.com/rapids-ai/target-encoding-with-rapids-cuml-do-more-with-your-categorical-data-8c762c79e784","code_link":"https://github.com/rapidsai/cuml/blob/branch-0.16/notebooks/target_encoder_walkthrough.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2306,"title":"Optimus","description":"\ud83d\ude9a Agile Data Preparation Workflows made easy with dask, cudf, dask_cudf and pyspark.","tags":["code","library","preprocessing","cudf","dask","pyspark","exploratory-data-analysis","optimus"],"details":"Optimus is the missing framework to profile, clean, process and do ML in a distributed fashion using Apache Spark(PySpark).\r\n\r\n![](https://ucarecdn.com/eb8852bf-856b-43fa-a09d-d9165bd3b60f/image.png)","links":[{"article_link":"","code_link":"https://github.com/ironmussa/Optimus","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://hi-optimus.com/"}]},{"id":2305,"title":"DeepSpeed: Extreme-scale model training for everyone","description":"DeepSpeed is a deep learning optimization library that makes distributed training easy, efficient, and effective.","tags":["article","code","pytorch","library","distributed-training","gpu","deepspeed"],"details":"DeepSpeed is a deep learning optimization library that makes distributed training easy, efficient, and effective.\r\n\r\n* 10x Larger Models\r\n* 10x Faster Training\r\n* Minimal Code Change\r\n\r\nDeepSpeed delivers extreme-scale model training for everyone, from data scientists training on massive supercomputers to those training on low-end clusters or even on a single GPU:\r\n\r\n* **Extreme scale**: Using current generation of GPU clusters with hundreds of devices, 3D parallelism of DeepSpeed can efficiently train deep learning models with trillions of parameters.\r\n* **Extremely memory efficient**: With just a single GPU, ZeRO-Offload of DeepSpeed can train models with over 10B parameters, 10x bigger than the state of arts, democratizing multi-billion-parameter model training such that many deep learning scientists can explore bigger and better models.\r\n* **Extremely long sequence length**: Sparse attention of DeepSpeed powers an order-of-magnitude longer input sequence and obtains up to 6x faster execution comparing with dense transformers.\r\n* **Extremely communication efficient**: 3D parallelism improves communication efficiency allows users to train multi-billion-parameter models 2\u20137x faster on clusters with limited network bandwidth. 1-bit Adam reduces communication volume by up to 5x while achieving similar convergence efficiency to Adam, allowing for scaling to different types of GPU clusters and networks.","links":[{"article_link":"https://www.microsoft.com/en-us/research/blog/deepspeed-extreme-scale-model-training-for-everyone/","code_link":"https://github.com/microsoft/DeepSpeed","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.deepspeed.ai/"}]},{"id":2304,"title":"Graph Neural Networks","description":"A descriptive guide for Graph Neural Networks.","tags":["article","tutorial","graph-neural-networks"],"details":"","links":[{"article_link":"https://medium.com/@parthplc/a-visual-guide-to-graph-neural-network-fcda66fff3e1","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2303,"title":"Doodle Recognition using PyTorch","description":"Multi-Class Image Classification using CNN ","tags":["article","research","tutorial","python","pytorch","convolutional-neural-networks","deep-learning","dimensionality-reduction"],"details":"","links":[{"article_link":"https://pr2tik1.github.io/blog/pytorch/cnn/pca/t-sne/2020/09/08/Sketch-Recognition.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2302,"title":"Recurrent neural networks: building a custom LSTM cell in Pytorch","description":"Are you interested to see how RNN's process sequences under the hood? That\u2019s what this article is all about. We are going build our our own custom LSTM model.","tags":["article","code","notebook","deep-learning","machine-learning","recurrent-neural-networks"],"details":"An infinite amount of times I have found myself in desperate situations because I had no idea what was happening under the hood. And, for a lot of people in the computer vision community, recurrent neural networks (RNNs) are like this. More or less, another black box in the pile.\r\n\r\nHowever, in this tutorial, we will attempt to open the RNN magic black box and unravel its mysteries!\r\n\r\nEven though I have come across hundreds of tutorials on LSTM\u2019s out there, I felt there was something missing. Therefore, I honestly hope that this tutorial serves as a modern guide to RNNs. We try to deal with multiple details of practical nature. To this end, we will build upon their fundamental concepts.","links":[{"article_link":"https://theaisummer.com/understanding-lstm/","code_link":"https://colab.research.google.com/drive/1Rb8OiF-AZ_Y3uFj1O2S0IyocFMhHoTCV","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://theaisummer.com/Bitcon_prediction_LSTM/"}]},{"id":2301,"title":"Unsupervised Visual Representation Learning with SwAV","description":"In this report, we explore the SwAV framework, as presented in \"Unsupervised Learning of Visual Features by Contrasting Cluster Assignments\" by Caron et al.","tags":["article","code","research","tutorial","tensorflow","contrastive-loss","self-supervised-learning","unsupervised-learning","wandb","visual-representation-learning"],"details":"Here's the content of the article:\r\n\r\n* Common problems in existing self-supervised methods (for visual representation learning)\r\n* SwAV at a high-level\r\n* Multi-crop augmentation policy and its promise\r\n* Contrasting the cluster assignments \r\n   * Cluster assignment as an optimal transport problem\r\n   * Swapped prediction problem to enforce consistency\r\n* A single forward pass in SwAV\r\n* Experimental results\r\n* Conclusion","links":[{"article_link":"https://app.wandb.ai/authors/swav-tf/reports/Unsupervised-Visual-Representation-Learning-with-SwAV--VmlldzoyMjg3Mzg","code_link":"https://github.com/ayulockin/SwAV-TF","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2300,"title":"Real Python Recommendation Engine","description":"A full stack data science project that performs document similarity on RealPython.com content. Content recommendations are implemented via a Chrome extension.","tags":["code","fastapi","spacy","full-stack","library","natural-language-processing","data-science","demo"],"details":"The ultimate goal for this project was to create an article (or content) recommendation engine for the [RealPython.com](https://realpython.com/) website.  As a frequent consumer of their tutorials, I found myself finishing tutorials and looking for more content, but didn't know how to find it. \r\n\r\nI hope other ML users will find this design pattern useful in their own projects.\r\n\r\nHere's how the app is implemented:\r\n\r\n\r\n1. **SCRAPE** Real Python articles nightly with [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\r\n2. **STORE** raw text in a Postgres database\r\n3. **PROCESS** text in an NLP pipeline with [spacy](https://spacy.io/)\r\n4. **MODEL** document similarity using [doc2vec](https://radimrehurek.com/gensim/models/doc2vec.html)\r\n5. **STORE** document similarity scores in the database\r\n6. **SERVE** document similarity scores using [fastAPI](https://fastapi.tiangolo.com/)\r\n7. **DEPLOY** the back end to a free Heroku dyno ([see the fastAPI swagger UI interface](http://realpython-recommender.herokuapp.com/docs#/))\r\n8. **ACCESS** document similarity scores [via a Chrome extension](https://chrome.google.com/webstore/detail/real-python-content-recom/abkpmgoodjgfkhjkkbaiogkomehhokoc?hl=en&authuser=0) (front end).\r\n\r\n**Disclaimer: This extension is not an official realpython.com project nor is it affiliated with realpython.com**\r\n\r\n","links":[{"article_link":"","code_link":"https://github.com/arvkevi/rprec","research_link":"","media_link":"","dataset_link":"","demo_link":"https://chrome.google.com/webstore/detail/real-python-content-recom/abkpmgoodjgfkhjkkbaiogkomehhokoc?hl=en&authuser=0","other_link":"https://github.com/arvkevi/rprec-chrome-extension"}]},{"id":2299,"title":"Latent graph neural networks: Manifold learning 2.0?","description":"Parallels between recent works on latent graph learning and older techniques of manifold learning.","tags":["article","graph-neural-networks","graphs","representation-learning","graph-representation-learning","manifold"],"details":"Graph neural networks exploit relational inductive biases for data that come in the form of a graph. However, in many cases we do not have the graph readily available. Can graph deep learning still be applied in this case? In this post, I draw parallels between recent works on latent graph learning and older techniques of manifold learning.\r\n\r\n![](https://miro.medium.com/max/700/0*Z9NUpmdj4-7Kx1bi)","links":[{"article_link":"https://towardsdatascience.com/manifold-learning-2-99a25eeb677d","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2298,"title":"torchCDE","description":"Differentiable controlled differential equation solvers for PyTorch with GPU support and memory-efficient adjoint backpropagation.","tags":["code","pytorch","library","time-series","neural-ode","torchcde"],"details":"This library provides differentiable GPU-capable solvers for controlled differential equations (CDEs). Backpropagation through the solver or via the adjoint method is supported; the latter allows for improved memory efficiency.\r\n\r\nIn particular this allows for building [Neural Controlled Differential Equation](https://github.com/patrick-kidger/NeuralCDE) models, which are state-of-the-art models for (arbitrarily irregular!) time series. Neural CDEs can be thought of as a \"continuous time RNN\".\r\n\r\n_Powered by the [`torchdiffeq`](https://github.com/rtqichen/torchdiffeq) library._","links":[{"article_link":"","code_link":"https://github.com/patrick-kidger/torchcde","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2297,"title":"Fast Block Sparse Matrices for Pytorch","description":"Enables networks which are both smaller and faster to let anybody use neural networks in production at low cost, and to improve the experience for the end user.","tags":["article","code","pytorch","library","gpu","efficiency","sparsity"],"details":"This PyTorch extension provides a **drop-in replacement** for torch.nn.Linear using block sparse matrices instead of dense ones. It enables very easy experimentation with sparse matrices since you can directly replace Linear layers in your model with sparse ones.\r\n\r\nBlog posts:\r\n\r\n1. [Block Sparse Matrices for Smaller and Faster Language Models](https://huggingface.co/blog/pytorch_block_sparse)\r\n1. [Is the future of Neural Networks Sparse? An Introduction (1/N)](https://medium.com/huggingface/is-the-future-of-neural-networks-sparse-an-introduction-1-n-d03923ecbd70)\r\n1. [Sparse Neural Networks (2/N): Understanding GPU Performance](https://medium.com/huggingface/sparse-neural-networks-2-n-gpu-performance-b8bc9ce950fc)","links":[{"article_link":"https://huggingface.co/blog/pytorch_block_sparse","code_link":"https://github.com/huggingface/pytorch_block_sparse","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2296,"title":"How to Test Machine Learning Code and Systems","description":"\ud83d\udea6 Minimal examples of testing machine learning for correct implementation, expected learned behaviour, and model performance.\r\n\r\n","tags":["article","code","tutorial","unit-tests","testing"],"details":"ML testing involves checks on model behaviour. Pre-train tests\u2014which can be run without trained parameters\u2014check if our written logic is correct. For example, is classification probability between 0 to 1? Post-train tests check if the learned logic is expected. For example, on the Titanic dataset, we should expect females to have a higher survival probability (relative to males).","links":[{"article_link":"https://eugeneyan.com/writing/testing-ml/","code_link":"https://github.com/eugeneyan/testing-ml","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2295,"title":"How to Create a Cartoonizer with TensorFlow Lite?","description":"An end-to-end tutorial on how to convert to TensorFlow Lite (TFLite) model and deploy it to an Android app for cartoonizing an image captured by camera.","tags":["article","code","generative-adversarial-networks","computer-vision","tensorflow-lite"],"details":"This is an end-to-end tutorial [published on the official TensorFlow blog](https://blog.tensorflow.org/2020/09/how-to-create-cartoonizer-with-tf-lite.html), on how to convert a TensorFlow model to TensorFlow Lite (TFLite) and deploy it to an Android app for cartoonizing an image captured by the camera. \r\n\r\nThe tutorial covers the following: \r\n\r\n- Export model checkpoints as SavedModel with TF 1.x\r\n- Convert the SavedModel to a TFLite model in TF 2.x with different quantization recipes\r\n- Model inference in Python\r\n- Add metadata to the TFLite models\r\n- Benchmark the TFLite models\r\n- Deploy TFLite model to Android in just a few lines of code with ML Model Binding\r\n","links":[{"article_link":"https://blog.tensorflow.org/2020/09/how-to-create-cartoonizer-with-tf-lite.html","code_link":"https://github.com/margaretmz/Cartoonizer-with-TFLite","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://twitter.com/TensorFlow/status/1303727371841875969"}]},{"id":2294,"title":"Getting started with large-scale ETL jobs using Dask and AWS EMR","description":"EMR is AWS\u2019s distributed data platform, which we can interact with and submit jobs to from a JupyterLab notebook running on our local machine.","tags":["article","notebook","aws","dask","mlops","exploratory-data-analysis","etl","mapreduce","elastic-mapreduce"],"details":"In this tutorial, we will walk through setting up a Dask cluster on top of EMR (Elastic MapReduce), AWS\u2019s distributed data platform, that we can interact with and submit jobs to from a JupyterLab notebook running on our local machine.","links":[{"article_link":"https://spell.ml/blog/large-scale-etl-jobs-using-dask-Xyl8GhEAACQAjK6h","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2293,"title":"Machine Learning Tutorials","description":"Introduce machine learning contents. The content aims to strike a good balance between mathematical notations, hands-on implementation. Primarily in Python3.","tags":["code","tutorial","python","machine-learning"],"details":"","links":[{"article_link":"","code_link":"https://github.com/ethen8181/machine-learning","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2292,"title":"Training on larger batches with less memory in AllenNLP","description":"Several options available in AllenNLP that will allow you to train with larger batches by saving memory.","tags":["article","allennlp","allenai","batch-size"],"details":"Batch size is an important hyperparameter to tune when training deep neural networks. Using the largest batch size that fits in memory on your GPU is often a good starting point, but as state-of-the-art models get bigger and bigger, the hardware many of us have available can be limited, forcing us to use smaller batches.\r\n\r\nNow, small batches aren\u2019t necessarily bad. But the smaller batch, the less information it contains, and so the gradient estimates coming from each batch will be less accurate. This can sometimes make it difficult for your model to converge.\r\n\r\nFortunately, there are several options available in AllenNLP that will allow you to train with larger batches by saving memory.\r\nIn this post, we will go through 3 of these options and show you how you can utilize them in your experiments.\r\n\r\n* Gradient accumulation (GA)\r\n* Gradient checkpointing (GC)\r\n* Automatic mixed precision (AMP)\r\n\r\n![](https://miro.medium.com/max/541/1*WfizUwplzHUMVQ9m5nWDAw.gif)","links":[{"article_link":"https://medium.com/ai2-blog/tutorial-training-on-larger-batches-with-less-memory-in-allennlp-1cd2047d92ad","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2291,"title":"Understanding Entanglement With SVD","description":"Schmidt rank in the hopes of helping the math of entanglement feel a little less... tangly.","tags":["article","singular-value-decomposition","entanglement"],"details":"Quantum entanglement is, as you know, a phrase that's jam-packed with meaning in physics. But what you might not know is that the linear algebra behind it is quite simple. If you're familiar with singular value decomposition (SVD), then you're 99% there. My goal for this post is to close that 1% gap. In particular, I'd like to explain something called the Schmidt rank in the hopes of helping the math of entanglement feel a little less... tangly. And to do so, I'll ask that you momentarily forget about the previous sentences. Temporarily ignore the title of this article. Forget we're having a discussion about entanglement. Forget I mentioned that word. And let's start over. Let's just chat math.\r\n\r\n","links":[{"article_link":"https://www.math3ma.com/blog/understanding-entanglement-with-svd","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2290,"title":"Fine-tune a non-English GPT-2 Model with Huggingface","description":" In this tutorial, we are going to use the transformers library by Huggingface. We will use the new Trainer class and fine-tune out GPT-2 model.","tags":["article","code","notebook","tutorial","huggingface","gpt","transformers","fine-tuning","natural-language-processing","gpt-2"],"details":" In this tutorial, we are going to use the transformers library by Huggingface in their newest version (3.1.0). We will use the new Trainer class and fine-tune our GPT-2 Model with German recipes from chefkoch.de.","links":[{"article_link":"https://www.philschmid.de/fine-tune-a-non-english-gpt-2-model-with-huggingface","code_link":"https://colab.research.google.com/drive/1B3rgV5maqb-5ZabRBm9eN4wMrSQw0Uni","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2289,"title":"ElasticTransformers","description":"Making BERT stretchy. Semantic Elasticsearch with Sentence Transformers.","tags":["article","code","huggingface","attention","bert","transformers","library","natural-language-processing","search","elastic-search","elastictransformers"],"details":"Semantic Elasticsearch with Sentence Transformers. We will use the power of Elastic and the magic of BERT to idnex a million articles and perform lexical and semantic search on them. The purpose is to provide an ease-of-use way of setting up your own Elasticsearch with near state of the art capabilities of contextual embeddings / semantic search using NLP transformers.","links":[{"article_link":"https://medium.com/@mihail.dungarov/elastic-transformers-ae011e8f5b88","code_link":"https://github.com/md-experiments/elastic_transformers","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2288,"title":"Which GPU(s) to Get for Deep Learning","description":"My Experience and Advice for Using GPUs in Deep Learning.","tags":["article","tutorial","hardware","gpu"],"details":"This blog post is designed to give you different levels of understanding about GPUs and the new Ampere series GPUs from NVIDIA. You have the choice: \r\n\r\n1. If you are not interested in the details of how GPUs work, what makes a GPU fast, and what is unique about the new NVIDIA RTX 30s Ampere series, you can skip right to the performance and performance per dollar charts and the recommendation section. These form the core of the blog post and the most valuable content.\r\n2. If you worry about specific questions, I have answered and addressed the most common questions and misconceptions in the later part of the blog post.\r\n3. If you want to get an in-depth understanding of how GPUs and Tensor Cores work, the best is to read the blog post from start to finish. You might want to skip a section or two based on your understanding of the presented topics.\r\n\r\n","links":[{"article_link":"https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2287,"title":"omega|ml - building and deploying ML models the easy way","description":"Deploying  ML is hard. It should not be. omega|ml makes it a breeze.","tags":["article","code","library","production","mlops","omega"],"details":"Unique features of omega|ml:\r\n\r\n1. Instant deployment of models and datasets,\r\n1. most things work with a single line of code, e.g. store and access larger-than memory dataframes\r\n1. models are versioned automatically\r\n1. It is extensible to work with any ML framework, on any cloud\r\n\r\nDetails:\r\n\r\n**Instant deployment:** With omega|ml, deployment of ML models, pipelines, datasets, full apps takes seconds instead of hours, weeks or even months. No engineering required, it just works. Cloud based REST and Python APIs are instantly available (instant = as soon as it is saved, there is zero wait time).\r\n\r\n**Single line of code:** A single line of code will deploy scikit-learn, Tensorflow, Keras, PyTorch and any other Python-serializable model. Same for datasets, notebooks and any pip-installable Python package, saving a dataset or a script is a single line of code. Also larger than memory dataframes and other datasets are possible out of the box. It works from laptop to cloud, with any cloud.\r\n\r\n**Automatic model versioning:** Every model is automatically versioned, and accessing any version is as simple as specifying its version tag. The \"model as data, not code\" means models are stored in the database, not as part of a deployed docker image like everyone else is doing it (treating models as code is fundamentally flawed - after all, models are data, not code).\r\n\r\n**Extensible:**omega|ml is easy to extend thanks to its plugin architecture. Actually most of the standard features are built as plugins.\r\n\r\nAlso omega|ml is built on well known and wide-spread open source technology, namely Python, PyData, RabbitMQ and MongoDB. This means it is easy to run anywhere, using existing skills and infrastructure.\r\n\r\nOpen source, Apache 2.0 licensed.","links":[{"article_link":"https://towardsdatascience.com/omega-ml-deploying-data-machine-learning-pipelines-the-easy-way-a3d281569666","code_link":"https://github.com/omegaml/omegaml","research_link":"","media_link":"https://static.wixstatic.com/media/2defe3_a0ff7cac62cd4299b5ea3fa1133df351~mv2.gif/v1/fit/w_250,h_135,q_30,blur_30/2defe3_a0ff7cac62cd4299b5ea3fa1133df351~mv2.gif","dataset_link":"","demo_link":"","other_link":"https://omegaml.io"}]},{"id":2286,"title":"Beginner-friendly PyTorch GANs repository","description":"Implementation of various GAN architectures starting with the original GAN paper.","tags":["code","tutorial","pytorch","deep-learning","generative-adversarial-networks","education"],"details":"The goal of this repo is to create well-commented, clean PyTorch GANs repository which could be super useful as a supplement to GAN theory.","links":[{"article_link":"","code_link":"https://github.com/gordicaleksa/pytorch-gans","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2285,"title":"Images of radio boxes","description":"I have collected about 15+k raw images of radio boxes across 500+ forms and hand-picked 200+  images that can be used to determine if a radio box is checked.","tags":["code","dataset","video","computer-vision","image-classification"],"details":"I built a solution using preexisting Form Recognizer solution, however it did not support check-box and radio box support.\r\n\r\nHowever, most valuable data is check-boxes and radio boxes, so I built a custom vision model, that can recognize if a radio box is recognized.\r\n\r\nThe provided GitHub currently only have images and the YouTube video shows what I tried to make it work and on 57:00 I show how to replicate my success in ML.NET Model Builder.\r\n\r\nAt later date, I'll add a pre-built ML.NET model as well as C# project to run it.","links":[{"article_link":"","code_link":"https://github.com/jernejk/ml-radioboxes-model","research_link":"","media_link":"https://www.youtube.com/watch?v=OpSXbHUYTAQ&feature=youtu.be&t=2906","dataset_link":"https://github.com/jernejk/ml-radioboxes-model/tree/main/TrainingData","demo_link":"","other_link":""}]},{"id":2284,"title":"electra_pytorch:  ELECTRA in PyTorch (fastai + huggingface)","description":"Unofficial reimplementation of <ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators>","tags":["code","paper","research","fastai","huggingface","pytorch","deep-learning","natural-language-processing","pretraining","arxiv:2003.10555"],"details":"I pretrain ELECTRA-small from scratch and has successfully replicate the paper's results on GLUE. \r\n\r\n![test_results](https://pbs.twimg.com/media/EhOR-t4UwAAXjpU?format=jpg&name=medium)\r\n\r\nResults for models on the GLUE test set.\r\n\r\ndetails:  \r\n\r\npost (fastai forum): https://discuss.huggingface.co/t/electra-training-reimplementation-and-discussion/1004\r\n\r\npost (huggingface forum): https://forums.fast.ai/t/electra-training-reimplementation-and-discussion/78280\r\n\r\ntweet: https://twitter.com/_RichardWang_/status/1302545459374772224?s=20","links":[{"article_link":"","code_link":"https://github.com/richarddwang/electra_pytorch","research_link":"https://arxiv.org/abs/2003.10555","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2283,"title":"Data analysis made easy: Text2Code for Jupyter notebook","description":"A jupyter notebook extension for Text2Code for basic pandas and plotly commands","tags":["article","code","tutorial","video","spacy","library","named-entity-recognition","natural-language-processing","pandas","jupyter","visualization","exploratory-data-analysis","fiass","universal-sentence-encoder"],"details":"![](https://github.com/deepklarity/jupyter-text2code/blob/master/mopp-demo.gif?raw=true)\r\n\r\nA ready-to-install jupyter extension which converts english queries into relevant code. Built as a proof of concept for the problem we personally face of **forgetting less-used syntaxes of pandas and plotly libraries** which is often used in Exploratory Data Analysis. This tool allows us to query in a generic language without having to remember the syntax.\r\n\r\nInspired by cool GPT-3 demos and not having the access to the API, here is an attempt by us to build a Text2Code extension using publicly available libraries. The approach isn't generative, but relies on identifying & matching from a set of predefined *intents* and generating the relevant code by extracting relevant entities and inserting them in a template. Adding new intents and extending the functionality is easy once the pipeline is in place. \r\n\r\nTechnologies used:\r\n\r\n* Universal Sentence Encoder\r\n* Spacy\r\n* Faiss\r\n* Jupyter extension\r\n","links":[{"article_link":"https://towardsdatascience.com/data-analysis-made-easy-text2code-for-jupyter-notebook-5380e89bb493","code_link":"https://github.com/deepklarity/jupyter-text2code","research_link":"","media_link":"https://www.youtube.com/watch?v=3gZ7_9W-TJs","dataset_link":"","demo_link":"","other_link":""}]},{"id":2282,"title":"Antialiased CNNs","description":"Making Convolutional Networks Shift-Invariant Again.","tags":["article","code","paper","research","video","convolutional-neural-networks","library","shift-invariant","arxiv:1904.11486"],"details":"Modern convolutional networks are not shift-invariant, as small input shifts or translations can cause drastic changes in the output. Commonly used downsampling methods, such as max-pooling, strided-convolution, and average-pooling, ignore the sampling theorem. The well-known signal processing fix is anti-aliasing by low-pass filtering before downsampling. However, simply inserting this module into deep networks degrades performance; as a result, it is seldomly used today. We show that when integrated correctly, it is compatible with existing architectural components, such as max-pooling and strided-convolution. We observe increased accuracy in ImageNet classification, across several commonly-used architectures, such as ResNet, DenseNet, and MobileNet, indicating effective regularization. Furthermore, we observe better generalization, in terms of stability and robustness to input corruptions. Our results demonstrate that this classical signal processing technique has been undeservingly overlooked in modern deep networks.\r\n\r\n![](https://richzhang.github.io/antialiased-cnns/resources/antialias_mod.jpg)","links":[{"article_link":"https://richzhang.github.io/antialiased-cnns/","code_link":"https://github.com/adobe/antialiased-cnns","research_link":"https://arxiv.org/abs/1904.11486","media_link":"https://www.youtube.com/watch?v=HjewNBZz00w","dataset_link":"","demo_link":"","other_link":""}]},{"id":2281,"title":"AutoScraper","description":"A Smart, Automatic, Fast and Lightweight Web Scraper for Python.","tags":["code","library","web-scraping","autoscraper"],"details":"This project is made for automatic web scraping to make scraping easy. It gets a url or the html content of a web page and a list of sample data which we want to scrape from that page. This data can be text, url or any html tag value of that page. It learns the scraping rules and returns the similar elements. Then you can use this learned object with new urls to get similar content or the exact same element of those new pages.\r\n\r\n","links":[{"article_link":"","code_link":"https://github.com/alirezamika/autoscraper","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2280,"title":"Top 10 Deep Learning Breakthroughs \u2014 Deep Reinforcement Learning","description":"The article unravels the journey behind reaching the point when Reinforcement Learning combined with Deep Learning defeated a Go player world champion.","tags":["article","tutorial","deep-learning","machine-learning","reinforcement-learning"],"details":"","links":[{"article_link":"https://medium.com/@zohebabai/top-10-deep-learning-breakthroughs-deep-reinforcement-learning-d2307ed8c27","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2279,"title":"Top 10 Deep Learning Breakthroughs \u2014 Family of SNGD Optimizers","description":"Choice of Optimization algorithms has always been the center of discussions and research inside the ML community. This article unravels the journey of optimizer","tags":["article","tutorial","deep-learning","machine-learning","library","optimizer"],"details":"","links":[{"article_link":"https://medium.com/@zohebabai/top-10-deep-learning-breakthroughs-family-of-sngd-optimizers-179b7cf114a","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2278,"title":"Top 10 Deep Learning Breakthroughs \u2014 AlexNet","description":"Details regarding AlexNet and its code implementation. ","tags":["article","code","tutorial","convolutional-neural-networks","deep-learning","machine-learning"],"details":"","links":[{"article_link":"https://medium.com/@zohebabai/top-10-deep-learning-breakthroughs-alexnet-291e16dbd679","code_link":"https://gist.github.com/ZohebAbai/25fc9e58c50c11f2826d20c5657d3211","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2277,"title":"Neural Network from scratch - Part 1/2","description":"A brief introduction to neural networks with implementation in NumPy.","tags":["article","tutorial","deep-learning","machine-learning","neural-networks"],"details":"We will be going from basics and covering all parts needed to understand neural networks in depth. This is part contains a brief introduction to neural networks, AI, and deep learning concepts.","links":[{"article_link":"https://medium.com/@pratikbaitha04/neural-networks-from-scratch-a-brief-introduction-for-beginners-d3776599aaac","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2275,"title":"hugdatafast: huggingface/nlp + fastai","description":"The elegant integration of huggingface/nlp and fastai2 and handy transforms using pure huggingface/nlp ","tags":["code","dataset","fastai","huggingface","transformers","natural-language-processing"],"details":"Doing NLP ?   \r\nSee if you can turn your data pipeline into just 3 lines. \ud83d\ude0e  \r\n\r\n\ud83d\udce5 pip install hugdatafast  \r\n\ud83d\udcd6 Documentation: https://hugdatafast.readthedocs.io/en/latest/\r\n\r\n![image](https://user-images.githubusercontent.com/17963619/92091020-be672f00-ee02-11ea-84c0-d54b4855ff4b.png)\r\n\r\n![transform](https://user-images.githubusercontent.com/17963619/92429054-685c0800-f1c3-11ea-8461-f05e0bf5b808.png)\r\n\r\nQ: What if my data is not in the huggingface/nlp datasets list ?  \r\nA: Not a problem. See this (https://twitter.com/Thom_Wolf/status/1296732565970321408?s=20)  \r\n\r\npost (fastai forum): https://forums.fast.ai/t/hugdatafast-hugginface-nlp-fastai/78142  \r\npost (huggingface forum): https://discuss.huggingface.co/t/hugdatafast-hugginface-nlp-fastai/986  ","links":[{"article_link":"","code_link":"https://github.com/richarddwang/hugdatafast","research_link":"","media_link":"https://user-images.githubusercontent.com/17963619/92091020-be672f00-ee02-11ea-84c0-d54b4855ff4b.png","dataset_link":"","demo_link":"","other_link":"https://hugdatafast.readthedocs.io/en/latest/"}]},{"id":2274,"title":"Transformer Reinforcement Learning","description":"Train transformer language models with reinforcement learning.","tags":["article","code","huggingface","transformers","library","language-modeling","natural-language-processing","reinforcement-learning","proximal-policy-optimization"],"details":"With trl you can train transformer language models with Proximal Policy Optimization (PPO). The library is built with the transformer library by \ud83e\udd17 Hugging Face (link). Therefore, pre-trained language models can be directly loaded via the transformer interface. At this point only GTP2 is implemented.\r\n\r\nHighlights:\r\n\r\n* GPT2 model with a value head: A transformer model with an additional scalar output for each token which can be used as a value function in reinforcement learning.\r\n* PPOTrainer: A PPO trainer for language models that just needs (query, response, reward) triplets to optimise the language model.\r\n* Example: Train GPT2 to generate positive movie reviews with a BERT sentiment classifier.","links":[{"article_link":"https://lvwerra.github.io/trl/","code_link":"https://github.com/lvwerra/trl","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2273,"title":"ONNX Transformers","description":"Accelerated NLP pipelines for fast inference \ud83d\ude80 on CPU. Built with \ud83e\udd17 Transformers and ONNX runtime.","tags":["code","onnx","transformers","library","natural-language-processing","inference"],"details":"Accelerated NLP pipelines for fast inference \ud83d\ude80 on CPU. Built with \ud83e\udd17 Transformers and [onnxruntime](https://github.com/microsoft/onnxruntime).\r\n\r\nModern NLP models are very large and take significant amount of time for inference on CPU's. onnxruntime provides optimizations to speed-up inference of these models. This library allows you to leverage onnxruntime for [transformer](https://github.com/huggingface/transformers) models, with the familiar `pipeline` API in just two lines of code.\r\n\r\nJust provide the path/url to the model and it'll download and automatically create onnx graph and run inference.\r\n\r\n```python\r\nfrom onnx_transformers import pipeline\r\n\r\n>>> nlp = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\", onnx=True)\r\n>>> nlp({\r\n  \"question\": \"What is ONNX Runtime ?\", \r\n  \"context\": \"ONNX Runtime is a highly performant single inference engine for multiple platforms and hardware\"\r\n})\r\n{'answer': 'highly performant single inference engine for multiple platforms and hardware', 'end': 94, 'score': 0.751201868057251, 'start': 18}\r\n```\r\n\r\nIt provides onnxruntime inference for following NLP tasks\r\n\r\n - `feature-extraction`: Generates a tensor representation for the input sequence\r\n - `ner`: Generates named entity mapping for each word in the input sequence.\r\n - `sentiment-analysis`: Gives the polarity (positive / negative) of the whole input sequence. Can be used for any text classification model.\r\n - `question-answering`: Provided some context and a question referring to the context, it will extract the answer to the question in the context.\r\n - `zero-shot-classification`: For zero shot text classification.\r\n\r\n### Speed up\r\n\r\n**Benchmark `feature-extraction` pipeline** \r\n\r\n![](https://github.com/patil-suraj/onnx_transformers/blob/master/data/feature_extraction_pipeline_benchmark.png?raw=True)\r\n\r\n\r\n**Benchmark `question-answering` pipeline**\r\n\r\n![](https://github.com/patil-suraj/onnx_transformers/blob/master/data/qa_pipeline_benchmark.png?raw=True)\r\n\r\nfor more details head over to the GitHub [repo](https://github.com/patil-suraj/onnx_transformers)","links":[{"article_link":"","code_link":"https://github.com/patil-suraj/onnx_transformers","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2272,"title":"Learn PyTorch","description":"3 steps to learn PyTorch","tags":["tutorial","pytorch","deep-learning","deep-learning-frameworks"],"details":"Here are 3 easy steps to get started quickly with the most popular deep learning framework - at least in the research community - PyTorch!","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://youtu.be/2n_uoGOPoVk","dataset_link":"","demo_link":"","other_link":""}]},{"id":2271,"title":"Latest advancements in video streaming with AI","description":"AI developments in video streaming using Super-resolution, Per-title encoding, P2P","tags":["article","tutorial","artificial-general-intelligence","deep-learning","machine-learning","computer-vision","super-resolution","video-classification"],"details":"85% of the data consumed over the internet is via videos. About 2.8 exabytes of data is transferred over the internet via streaming videos. This growth is driven by the advent of VOD platforms like Netflix, Video communication platforms like Zoom, Social platforms like Tiktok, esports, live streaming to name a few.\r\n\r\nCovid19 pandemic has accelerated the video consumption and has been the driving force of companies moving from offline mode to online live mode. With this explosion of the video consumption on a day-to-day basis we need to be prepared for the upcoming demand.\r\n\r\nIn this article we will be discussing what are the latest advancements in video streaming technology and how can they help in improving the streaming experience.","links":[{"article_link":"https://blog.peervadoo.com/2020-video-streaming-ai-p2p-technology-advancements.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2270,"title":"Deep Semi-Supervised Learning","description":"Discusses SSL in a deep learning setting and goes through some of the main deep learning SSL methods.","tags":["article","code","paper","research","semi-supervised-learning","arxiv:2006.05278"],"details":"Deep neural networks demonstrated their ability to provide remarkable performances on certain supervised learning tasks (e.g., image classification) when trained on extensive collections of labeled data (e.g. ImageNet). However, creating such large collections of data requires a considerable amount of resources, time, and effort. Such resources may not be available in many practical cases, limiting the adoption and application of many deep learning (DL) methods.\r\n\r\nIn a search for more data-efficient DL methods to overcome the need for large annotated datasets, we see a lot of research interest in recent years with regards to the application of semi-supervised learning (SSL) to deep neural nets as a possible alternative, by developing novel methods and adopting existing SSL frameworks for a deep learning setting. This post discusses SSL in a deep learning setting and goes through some of the main deep learning SSL methods.","links":[{"article_link":"https://yassouali.github.io/ml-blog/deep-semi-supervised/","code_link":"https://github.com/yassouali/awesome-semi-supervised-learning","research_link":"https://arxiv.org/abs/2006.05278","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2269,"title":"Learning to Summarize with Human Feedback","description":"Human feedback models outperform much larger supervised models and reference summaries on TL;DR","tags":["article","code","paper","research","natural-language-processing","text-summarization","openai","demo","human-feedback","feedback-loops","arxiv:2009.01325"],"details":"We\u2019ve applied reinforcement learning from human feedback to train language models that are better at summarization. Our models generate summaries that are better than summaries from 10x larger models trained only with supervised learning. Even though we train our models on the Reddit TL;DR dataset,1 the same models transfer to generate good summaries of CNN/DailyMail news articles2 without any further fine-tuning. Our techniques are not specific to summarization; in the long run, our goal is to make aligning AI systems with human preferences a central component of AI research and deployment in many domains.\r\n\r\n![](https://cdn.openai.com/learning-to-summarize-with-human-feedback/assets/approach-diagram-wide.svg)","links":[{"article_link":"https://openai.com/blog/learning-to-summarize-with-human-feedback/","code_link":"https://github.com/openai/summarize-from-feedback","research_link":"https://arxiv.org/abs/2009.01325","media_link":"","dataset_link":"","demo_link":"https://openaipublic.blob.core.windows.net/summarize-from-feedback/website/index.html","other_link":""}]},{"id":2268,"title":"NLP Course | For You","description":"This is an extension to the (ML for) Natural Language Processing course I teach at the Yandex School of Data Analysis (YSDA) since fall 2018. ","tags":["article","course","natural-language-processing"],"details":"This is an extension to the (ML for) Natural Language Processing course I teach at the Yandex School of Data Analysis (YSDA) since fall 2018. For now, only part of the topics is likely to be covered here.\r\n\r\nThis new format of the course is designed for:\r\n\r\n* Convenience: easy to find, learn or recap material (both standard and more advanced), and to try in practice.\r\n* Clarity: each part, from front to back, is a result of my care not only about what to say, but also how to say and, especially, how to show something.\r\n* You: I wanted to make these materials so that you (yes, you!) could study on your own, what you like, and at your pace. My main purpose is to help you enter your own very personal adventure. For you.\r\n","links":[{"article_link":"https://lena-voita.github.io/nlp_course.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2267,"title":"What Is MLOps?","description":"Machine learning operations, MLOps, are best practices for businesses to run AI successfully with help from an expanding software products and cloud services.","tags":["article","production","mlops"],"details":"Machine learning operations, MLOps, are best practices for businesses to run AI successfully with help from an expanding smorgasbord of software products and cloud services.\r\n\r\n![](https://blogs.nvidia.com/wp-content/uploads/2020/09/MLOps-Neal-Analytics-672x296.png.webp)\r\n\r\n* Data sources and the datasets created from them\r\n* A repository of AI models tagged with their histories and attributes\r\n* An automated ML pipeline that manages datasets, models and experiments through their lifecycles\r\n* Software containers, typically based on Kubernetes, to simplify running these jobs\r\n\r\n![](https://blogs.nvidia.com/wp-content/uploads/2020/09/MLOPS-process-Gartner-1280-640x500.png.webp)","links":[{"article_link":"https://blogs.nvidia.com/blog/2020/09/03/what-is-mlops/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2266,"title":"Wav2Lip: Accurately Lip-syncing Videos In The Wild","description":"A Lip Sync Expert Is All You Need for Speech to Lip Generation In the Wild","tags":["article","code","paper","research","video","audio","computer-vision","image-generation","demo","wav2lip","arxiv:2008.10010"],"details":"![](https://camo.githubusercontent.com/abd64aaf79252a9e9ceadd8bfd074560f4b4e1db/68747470733a2f2f64726976652e676f6f676c652e636f6d2f75633f6578706f72743d766965772669643d31576e3068506d706f3447526243494a523854663230416b7a646931716a6a4739)\r\n\r\n\r\n**Highlights**\r\n\r\n - Lip-sync videos to any target speech with high accuracy. Try our [interactive demo](https://bhaasha.iiit.ac.in/lipsync).\r\n - Works for any identity, voice, and language. Also works for CGI faces and synthetic voices.\r\n - Complete training code, inference code, and pretrained models are available.\r\n - Or, quick-start with the Google Colab Notebook: [Link](https://colab.research.google.com/drive/1tZpDWXz49W6wDcTprANRGLo2D_EbD5J8?usp=sharing)\r\n - Several new, reliable evaluation benchmarks and metrics [[`evaluation/` folder of this repo]](https://github.com/Rudrabha/Wav2Lip/tree/master/evaluation) released.\r\n - Code to calculate metrics reported in the paper is also made available.\r\n","links":[{"article_link":"https://bhaasha.iiit.ac.in/lipsync/","code_link":"https://github.com/Rudrabha/Wav2Lip","research_link":"https://arxiv.org/abs/2008.10010","media_link":"https://www.youtube.com/watch?v=0fXaDCZNOJc","dataset_link":"","demo_link":"http://bhaasha.iiit.ac.in/lipsync/","other_link":"https://www.youtube.com/watch?v=0fXaDCZNOJc&feature=youtu.be"}]},{"id":2265,"title":"Deploying a HuggingFace NLP Model with KFServing","description":"Modifying a Hugging Face pre-trained model to run as a KFServing hosted model.","tags":["article","tutorial","huggingface","transformers","natural-language-processing","production","kubeflow","serving","kfserving"],"details":"In this example we demonstrate how to take a [Hugging Face example](https://huggingface.co/transformers/usage.html) and modifying the pre-trained model to run as a [KFServing](https://github.com/kubeflow/kfserving) hosted model. The specific example we'll is the extractive question answering model from the Hugging Face transformer library. This model extracts answers from a text given a question.\r\n\r\n![](http://www.pattersonconsultingtn.com/blog/images/pct_ml_workflow_model_deploy.png)\r\n![](https://github.com/kubeflow/kfserving/raw/master/docs/diagrams/kfserving.png)","links":[{"article_link":"http://www.pattersonconsultingtn.com/blog/deploying_huggingface_with_kfserving.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2264,"title":"MushroomRL","description":"Python library for Reinforcement Learning.","tags":["code","pytorch","library","reinforcement-learning"],"details":"MushroomRL is a Python Reinforcement Learning (RL) library whose modularity allows to easily use well-known Python libraries for tensor computation (e.g. PyTorch, Tensorflow) and RL benchmarks (e.g. OpenAI Gym, PyBullet, Deepmind Control Suite). It allows to perform RL experiments in a simple way providing classical RL algorithms (e.g. Q-Learning, SARSA, FQI), and deep RL algorithms (e.g. DQN, DDPG, SAC, TD3, TRPO, PPO).","links":[{"article_link":"","code_link":"https://github.com/MushroomRL/mushroom-rl?fbclid=IwAR3Cty46KWambRbrzrbxkCQS96PzQyGL7ie4nbAYHNl-c7Tjcazp9h9smu4","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2263,"title":"TTT: Fine-tuning Transformers with TPUs or GPUs acceleration","description":"TTT is short for a package for fine-tuning \ud83e\udd17 Transformers with TPUs, written in Tensorflow2.0+.","tags":["article","code","notebook","research","tutorial","tensorflow","transformers","library","natural-language-processing","tpu","gpu","tensorflow-tpus"],"details":"## Features\r\n\r\n- Switch between TPUs and GPUs easily.\r\n- Stable training on TPUs.\r\n- Customize datasets or load from [the nlp library](https://huggingface.co/nlp/viewer/?dataset=aeslc).\r\n- Using pretrained tensorflow weights from the open-source library - [\ud83e\udd17 transformers](https://github.com/huggingface/transformers).\r\n- Fine-tuning BERT-like transformers (DistilBert, ALBERT, Electra, RoBERTa) using keras High-level API.\r\n- Fine-tuning T5-like transformers using customize training loop, written in tensorflow.\r\n- So far, this package mainly supports single-sequence classificaton based tasks. However, it can be easily extended to support other language tasks.\r\n\r\n![](https://ucdcs-student.ucd.ie/~cwang/ttt/ttt_demo.png)\r\n","links":[{"article_link":"https://colab.research.google.com/github/wangcongcong123/ttt/blob/master/ttt_notebook.ipynb","code_link":"https://github.com/wangcongcong123/ttt","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2262,"title":"R.U.Stoked","description":"NLP (Sentiment Analysis) project to demonstrate a pipeline of data from the very first stage of data collection through ML model deployment.","tags":["code","tutorial","aws","docker","machine-learning","natural-language-processing","sentiment-analysis","streamlit","github-actions","demo","deployment"],"details":"# R.U.Stoked\r\n![](https://media-exp1.licdn.com/dms/image/C5612AQEDRAO2g2AfWg/article-cover_image-shrink_720_1280/0?e=1604534400&v=beta&t=Msw6z0HU0z3FvEBlfbIOgwHubhnJCim8NDoAh_BM6uY)\r\n\r\n**RUStoked** is an experimental **NLP** (_Sentiment Analysis_) project. An effort to orchestrate a pipeline of data from the very first stage of data collection through ML model `deployment`.  \r\n\r\nThis post is more of a guide through the project stages, challenges, and lessons learned rather than a code review. The code is available on [GitHub](https://github.com/mohsen-saki/RUStoked) and I have tried to keep notebooks and code libraries _\"marked down\"_ and _\"commented\"_ as much as possible.  \r\n\r\n**`IMPORTANT NOTE : This project is yet under development and some parts of `repo` may get updated accordingly`**  \r\n\r\nThis [GitHub](https://github.com/mohsen-saki/RUStoked) `repo` consists of:\r\n\r\n* Folder [`data`](https://github.com/mohsen-saki/RUStoked/tree/master/data) which contains raw data and some lines of code for scraping data.\r\n* Folder [`rustoked`](https://github.com/mohsen-saki/RUStoked/tree/master/rustoked) which contains a library of core functions used during data exploration and model development\r\n* Folder [`notebooks`](https://github.com/mohsen-saki/RUStoked/tree/master/notebooks) which contains some notebooks to demonstrate data and model engineering process\r\n* Folder [`app`](https://github.com/mohsen-saki/RUStoked/tree/master/app) which contains codes and functions for a small [streamlit](https://www.streamlit.io/) application running and maintaining the model.\r\n* Folder [`withdrawn`](https://github.com/mohsen-saki/RUStoked/tree/master/withdrawn) which contains my first try to develop the model, not successful though.\r\n\r\n** --> And it is live [here](https://rustoked.herokuapp.com/) on Heroku.**\r\n\r\n\r\n# About the Project\r\n\r\n1 What about is this project?\r\n---\r\nR.U.Stoked is a **Natural Language Processing** (Sentiment Analysis Case) but _not a binary_ one. I focused on detecting a third group of sentiment which I call here after `\u201cDisengaged\u201d`;  a group of opinions which are neither `\u201cStoked\u201d` nor `\u201cDissatisfied\u201d`.  I think detecting this group of so to speak \"users / customers\" can create business values in problem cases such as **Churning** or targeting **prospect customers**. Actually this idea is also sort of supported by the data; almost exactly half of reviews rated `3` out of `5` recommended their experience to others and the other half suggested not to. \r\n\r\n2 Where does data come from?\r\n---\r\nThe [data](https://github.com/mohsen-saki/RUStoked/tree/master/data) has been collected from [SEEK](https://www.seek.com.au/). It comprises almost `13k` rows of data by which employees have expressed their feelings and opinions about their employers. I have just collected the data for a dozen of companies which have relatively had higher number of reviews.  And They mostly belong to two fields of FMCG retailers and Finance/Technology industries.\r\n\r\n3 What are challenges?\r\n---\r\n* Detecting a _neutral_ class of sentiment in between `positive` and `negative` ones has been a bit of challenge because exploring those reviews shows that the choice of words tends to be almost similar to either positive or negative reviews.\r\n* Many of the reviews are written by _not-native English speakers_ as they vary a lot in terms of word choices, sentence structures, comprehension, etc.\r\n* The SEEK template for registering reviews is asking for `pros` and `cons`. So, it has resulted in more of a list-like outcome rather than comprehensive opinions. For example in response to cons many may say \u201cmanagement\u201d which clearly lacks the sentiment compared to something like \u201cbad or poor management\u201d.\r\n* Another feature of SEEK\u2019s reviews is that the overall rating is not calculated as average of employees\u2019 ratings on some other subjects but it is acquired independently. This raised a bit of inconsistency between users' overall opinion of their client compared to their opinion on different aspects of their work paces.\r\n\r\n4 First try and failure\r\n---\r\nThere is a folder named \u201cwithdrawn\u201d in the repository which contains a few notebooks as my first approach to this project which I consider as a _failure_ not particularly for the outcomes but more because of my strategy. I was sort of rushing to wrap it up which was not really working out and this is why:\r\n* I did not collect enough data in terms of both the amount of data and the meta-data which help to explore and explain data beter.\r\n* I did not tackle the problem according to the best practices. I created a pipeline of different models with various features and used the grid search method to see which one results in the best accuracy score. Obviously I did not put any time into data exploration and feature engineering. As a result, It was more of a black box with no insight of what is going on under the model performance.  \r\n* I was not writing good codes. It was all in the notebooks (not reusable and  modular)  \r\n\r\nHowever, I came across this excellent book [\u201cBuilding Machine Learning Powered Applications\u201c](https://www.oreilly.com/library/view/building-machine-learning/9781492045106/) written by [Emmanuel Ameisen](https://www.linkedin.com/in/ameisen/). Reading this book is actually the reason to reconsider my approach and start this project over.\r\n\r\n5 What toolings/technologies have been used?\r\n---\r\n`pandas` to manipulate and explore the data  \r\n`matplotlib` and `bokeh` to visualise and explore the data  \r\n\r\n![](https://media-exp1.licdn.com/dms/image/C5612AQGLD_zXOjK0VA/article-inline_image-shrink_1000_1488/0?e=1604534400&v=beta&t=PEAG9BF8nEsotFO_zA7ukijM4i3Il_bxxAXJT5cAu0s)\r\n\r\n`TfifVectorizer` and in some cases `Spacy` to get the word vectors.  \r\n`Scikit-Learn` RandomForestClassifier and Naive Bayes as model/algorithm  \r\n\r\n6 How did it go?\r\n---\r\nFirst model trained on just the text data has performed pretty well on predicting positive and negative classes but poorly on the \u201cDisengaged\u201d labels.\r\n\r\n![](https://media-exp1.licdn.com/dms/image/C5612AQEZJGOsehUtfw/article-inline_image-shrink_1000_1488/0?e=1604534400&v=beta&t=k6TPifxZh4N75t0KZfWD2VJHSgEV70t1DkV-lYOzVek)\r\n\r\nTo tweak the model performance, I extracted some features from the data and plugged them into the vectors. Those features were selected to help the model detecting the sentiment better and distinguishing different labels easier such as:\r\n\r\n* Words `great` and `good` appear frequently in positive opinions\r\n* Words `poor`, `bad`, `not`, etc. appear frequently in negative opinions\r\n* The _count_ of above words appears to be an indication of sentiment in each piece of review.\r\n* The word `but` seems to have a higher frequency of occurring within \u201cDisengaged\u201d labels as it serves for changing the language tone from positive to negative or vice versa.  \r\n\r\nPlugging above candidate features in the word vectors and visualization shows some improvement in separating data clusters each containing the majority of one of the labels but for the \u201cDisengaged\u201d label it still does not show much improvement:\r\n\r\n![](https://media-exp1.licdn.com/dms/image/C5612AQETukIvAnD0dg/article-inline_image-shrink_1000_1488/0?e=1604534400&v=beta&t=pA8rHMQ6G5MxysnxdnJH_dW6hv_nTWcvc2EEVo7aC-M)\r\n\r\nAnd the outcome scores agree as well:\r\n\r\n![](https://media-exp1.licdn.com/dms/image/C5612AQHp2N_Lz9kJuA/article-inline_image-shrink_1000_1488/0?e=1604534400&v=beta&t=wol7H5E1YJwNdWyqN_Pbf-HCncTA8vh3QZOHIvKI0lg)\r\n\r\nWell, I would say **if features are too obvious, probably the model has already picked them**. Using `Naive Bayes` algorithm as recommended by Scikit-Learn ([Choosing the right estimator](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)) did not make a noticeable difference as expected (Normally a data problem results should not change considerably just by changing algorithm, if so, probably something is done wrong).\r\n\r\nHowever, using just features without the word vectors shows some improvement albeit at cost of model performance decrease on two other labels.\r\n\r\n![](https://media-exp1.licdn.com/dms/image/C5612AQGIImr7zmcRXA/article-inline_image-shrink_1000_1488/0?e=1604534400&v=beta&t=VOkn35ZhIuEgXDf7a8JJ8KajXKdG6JHs3s8rjXSOiNg)\r\n\r\n***Working more on generating and extracting features seems like a promising approach to take here.***\r\n\r\n7 [The Application](https://rustoked.herokuapp.com/)\r\n---\r\nI have recently been hearing a lot about [Streamlit](https://www.streamlit.io/) and I wanted to try something new. Although it may not be as sophisticated as some backend frameworks such as [Flask](https://flask.palletsprojects.com/en/1.1.x/) and [Django](https://www.djangoproject.com/), I should say that for a simple single-page webapp, [Streamlit](https://www.streamlit.io/) was super easy, extremely quick, and very cool.\r\n\r\n8 Deployment\r\n---\r\nI went with a [docker](https://www.docker.com/) image as it is quite standard and straight forward. Deployment has been automated through [GitHub Action](https://github.com/features/actions) to trigger some workflows on `push` and deploy to [AWS ECS Instance](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ECS_instances.html) and [HEROKU](https://www.heroku.com/free), not at the same time though (Heroku server port is not to select and is generated as an environment variable which make some adjusments necessary to Dockerfile).\r\n\r\nObviously AWS required a lot more work around to get it orchestrating right and it is much stronger for providing this level of access to tweak the environment, however I love HEROKU for being simple and free :) as far as it is not consuming resources like a commercial webapp.\r\n\r\nAnyway, it is live [here](https://rustoked.herokuapp.com/) on **heroku**\r\n\r\n9 What\u2019s next?\r\n---\r\n* Writing some tests and getting them to run through github actions.\r\n* More on model development focusing on extracting and generating features\r\n\r\n\r\n---\r\nThanks to open source and free world.\r\n![](https://media-exp1.licdn.com/dms/image/C5612AQGYwEuE0ZVyOg/article-inline_image-shrink_1500_2232/0?e=1604534400&v=beta&t=0KPfF9F_FZHtLvPukDNCmT7Q-Il-VqBVoCQmElkmpVM)","links":[{"article_link":"","code_link":"https://github.com/mohsen-saki/RUStoked","research_link":"","media_link":"","dataset_link":"","demo_link":"https://rustoked.herokuapp.com/","other_link":""}]},{"id":2261,"title":"A Framework For Contrastive Self-Supervised Learning","description":"A conceptual framework for characterizing contrastive self-supervised learning approaches.","tags":["article","paper","research","pytorch","contrastive-loss","self-supervised-learning","pytorch-lightning","contrastive-learning","arxiv:2009.00104"],"details":"In [our recent paper](https://arxiv.org/abs/2009.00104), we formulate a conceptual framework for characterizing contrastive self-supervised learning approaches. We used our framework to analyze three examples of these leading approaches, SimCLR, CPC, AMDIM, and show that although these approaches seem different on the surface, they are all in fact slight tweaks of one another.\r\nIn this blog we will:\r\n\r\n* Review self-supervised learning.\r\n* Review contrastive learning.\r\n* Propose a framework for comparing recent approaches.\r\n* Compare CPC, AMDIM, MOCO, SimCLR, and BYOL using our framework.\r\n* Formulate a new approach \u2014 YADIM \u2014 , using our framework.\r\n* Describe some of our results.\r\n* Describe the computational requirements to achieve these results.","links":[{"article_link":"https://medium.com/@_willfalcon/a-framework-for-contrastive-self-supervised-learning-and-designing-a-new-approach-3caab5d29619","code_link":"","research_link":"https://arxiv.org/abs/2009.00104","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2260,"title":"CVPR 2020: A Snapshot","description":"A snapshot of the conference by summarizing some papers (& listing some) that grabbed my attention.","tags":["article","research","computer-vision","cvpr-2020","conference"],"details":"The first virtual CVPR conference ended, with 1467 papers accepted, 29 tutorials, 64 workshops, and 7.6k virtual attendees. The huge number of papers and the new virtual version made navigating the conference overwhelming (and very slow) at times. To get a grasp of the general trends of the conference this year, I will present in this blog post a sort of a snapshot of the conference by summarizing some papers (& listing some) that grabbed my attention.\r\n\r\n* CVPR 2020 in numbers\r\n* Recognition, Detection and Segmentation\r\n* Generative models and image synthesis\r\n* Representation Learning\r\n* Computational photography\r\n* Transfer/Low-shot/Semi/Unsupervised Learning\r\n* Vision and Language\r\n* The rest","links":[{"article_link":"https://yassouali.github.io/ml-blog/cvpr2020/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2259,"title":"ECCV 2020: Some Highlights","description":"A sort of a snapshot of the conference by summarizing some papers (& listing some) that grabbed my attention.","tags":["article","research","computer-vision","eccv-2020","conference"],"details":"The 2020 European Conference on Computer Vision took place online, from 23 to 28 August, and consisted of 1360 papers, divided into 104 orals, 160 spotlights and the rest of 1096 papers as posters. In addition to 45 workshops and 16 tutorials. As it is the case in recent years with ML and CV conferences, the huge number of papers can be overwhelming at times. Similar to my CVPR2020 post, to get a grasp of the general trends of the conference this year, I will present in this blog post a sort of a snapshot of the conference by summarizing some papers (& listing some) that grabbed my attention.\r\n\r\n* General Statistics\r\n* Recognition, Detection, Segmentation and Pose Estimation\r\n* Semi-Supervised, Unsupervised, Transfer, Representation & Few-Shot Learning\r\n* 3D Computer Vision & Robotics\r\n* Image and Video Synthesis\r\n* Vision and Language\r\n* The Rest","links":[{"article_link":"https://yassouali.github.io/ml-blog/eccv2020/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2258,"title":"Graph Convolutions for dummies","description":"An article explaining Graph Convolutional Networks as simply as possible.","tags":["article","tutorial","graph-convolutional-networks","graph-neural-networks","graphs","geometric-deep-learning"],"details":"The article explains GCN in as simply as possible.  A basic knowledge in ML and matrix multiplication is needed to understand the article. Please refrain from directly copying content from the post. In case you want to use an excerpt or any original image, mention the link to the post.","links":[{"article_link":"https://thenlp.space/blog/graph-convolutional-network-for-dummies","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2257,"title":"Encrypt and Decrypt Files using Python","description":"Introduction to file encryption and decryption using Python. Detailed code examples with explanations and use of cryptography library.","tags":["article","tutorial","python","cyber-security","network-security","program-development","security"],"details":"In this article we will discuss how to encrypt and decrypt files using Python.\r\n\r\nTable of Contents:\r\n\r\n* Introduction\r\n* Creating a key\r\n* Loading a key\r\n* Encrypting a file\r\n* Decrypting a file\r\n* Complete Object-Oriented Programming Example\r\n* Conclusion","links":[{"article_link":"https://pyshark.com/encrypt-and-decrypt-files-using-python/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2256,"title":"VSCode on Google Colab","description":"Learn how to setup and use VSCode as an IDE on Google Colab","tags":["article","notebook","tutorial","colab","vscode","ngrok"],"details":"I recently discovered a way to setup VSCode on Google Colab and use it as an IDE to edit code and run experiments on the Colab VM.\r\n\r\nWith this setup, you can still prototype in the Colab Notebook while also using VSCode for all the advantages of an IDE. Here is how you can replicate my setup.","links":[{"article_link":"https://amitness.com/vscode-on-colab/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2255,"title":"Tensorflow, Pytorch, Transformer, Fastai, etc. Tutorials","description":"BERT Classification, Question Answering, Seq2Seq Machine Translation, Contextual Topic Modeling, Large Scale Multilabelclassification, etc","tags":["code","notebook","pytorch","tensorflow","attention","bert","transformers","natural-language-processing","text-classification","notebooks"],"details":"## Pytorch\r\n\r\n* BERT Fine-Tuning Tutorial [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ankur3107/colab_notebooks/blob/master/BERT_Fine_Tuning_Sentence_Classification_v2.ipynb)\r\n* Bert Classification [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ankur3107/colab_notebooks/blob/master/Bert_Classification_Pt.ipynb)\r\n* Generic Transformer Classification [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ankur3107/colab_notebooks/blob/master/Generic_Transformer_Classification.ipynb)\r\n* Question Answering with a Fine-Tuned BERT [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ankur3107/colab_notebooks/blob/master/Question_Answering_with_a_Fine_Tuned_BERT.ipynb)\r\n* Seq2Seq Machine Translation Transformer [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ankur3107/colab_notebooks/blob/master/Seq2Seq_Pytorch.ipynb)\r\n* Simpletransformers Tutorial [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ankur3107/colab_notebooks/blob/master/Simpletransformers_2.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ankur3107/large-scale-multi-label-classification/blob/master/simpletransformers_intro.ipynb) \r\n* Huggingface Transformer with Fastai Tutorial [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ankur3107/colab_notebooks/blob/master/SUsing_Transformers_with_Fastai_Tutorial.ipynb)\r\n* Contextual Topic Modeling [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ankur3107/colab_notebooks/blob/master/contextual_topic_modeling.ipynb)\r\n\r\n\r\n## Tensorflow\r\n\r\n* Large Scale Multilabelclassification [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ankur3107/large-scale-multi-label-classification/blob/master/simpletransformers_intro.ipynb)","links":[{"article_link":"","code_link":"https://github.com/Ankur3107/colab_notebooks","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://colab.research.google.com/github/Ankur3107/colab_notebooks/blob/master/BERT_Fine_Tuning_Sentence_Classification_v2.ipynb"}]},{"id":2254,"title":"PyTorch Performance Tuning Guide - Szymon Migacz, NVIDIA","description":"ECCV 2020 Tutorial on Accelerating Computer Vision with Mixed Precision","tags":["article","video","pytorch","demo","mixed-precision","eccv-2020"],"details":"Complete [**playlist**](https://www.youtube.com/playlist?list=PL6Rbs64R_CcPsJflYb2doIMmFaDyo-oIK) of all ECCV mixed precision talks now available.\r\n\r\nNew levels of accuracy in computer vision, from image recognition and detection, to generating images with GANs, have been achieved by increasing the size of trained models. Fast turn-around times while iterating on the design of such models would greatly improve the rate of progress in this new era of computer vision.\r\n\r\nThis tutorial will describe techniques that utilize half-precision floating point representations to allow deep learning practitioners to accelerate the training of large deep networks while also reducing memory requirements.\r\n\r\nThe talks and sessions below will provide a deep-dive into available software packages that enable easy conversion of models to mixed precision training, practical application examples, tricks of the trade (mixed precision arithmetic, loss scaling, etc.), as well as considerations relevant to training many popular models in commonly used deep learning frameworks including PyTorch and TensorFlow.","links":[{"article_link":"https://nvlabs.github.io/eccv2020-mixed-precision-tutorial/files/szymon_migacz-pytorch-performance-tuning-guide.pdf","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=9mS1fIYj1So","dataset_link":"","demo_link":"","other_link":"https://www.youtube.com/playlist?list=PL6Rbs64R_CcPsJflYb2doIMmFaDyo-oIK"}]},{"id":2253,"title":"Opacus","description":"A high-speed library for training PyTorch models with differential privacy.","tags":["article","code","pytorch","library","privacy","differential-privacy","opacus"],"details":"Opacus - a new high-speed library for training PyTorch models with differential privacy (DP) that\u2019s more scalable than existing state-of-the-art methods. Differential privacy is a mathematically rigorous framework for quantifying the anonymization of sensitive data. It\u2019s often used in analytics, with growing interest in the machine learning (ML) community. With the release of Opacus, we hope to provide an easier path for researchers and engineers to adopt differential privacy in ML, as well as to accelerate DP research in the field.\r\n\r\nOpacus provides:\r\n\r\n* **Speed**: By leveraging Autograd hooks in PyTorch, Opacus can compute batched per-sample gradients, resulting in an order of magnitude speedup compared with existing DP libraries that rely on microbatching.\r\n* **Safety**: Opacus uses a cryptographically safe pseudo-random number generator for its security-critical code. This is processed at high speed on the GPU for an entire batch of parameters.\r\n* **Flexibility**: Thanks to PyTorch, engineers and researchers can quickly prototype their ideas by mixing and matching our code with PyTorch code and pure Python code.\r\n* **Productivity**: Opacus comes with tutorials, helper functions that warn about incompatible layers before your training even starts, and automatic refactoring mechanisms.\r\n* **Interactivity**: Opacus keeps track of how much of your privacy budget (a core mathematical concept in DP) you are spending at any given point in time, enabling early stopping and real-time monitoring.\r\n\r\nOpacus defines a lightweight API by introducing the PrivacyEngine abstraction, which takes care of both tracking your privacy budget and working on your model\u2019s gradients. You don\u2019t need to call it directly for it to operate, as it attaches to a standard PyTorch optimizer. It works behind the scenes, making training with Opacus as easy as adding these lines of code at the beginning of your training code:","links":[{"article_link":"https://ai.facebook.com/blog/introducing-opacus-a-high-speed-library-for-training-pytorch-models-with-differential-privacy","code_link":"https://github.com/pytorch/opacus","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2252,"title":"Explore then Execute","description":"Adapting without Rewards via Factorized Meta-Reinforcement Learning","tags":["article","research","meta-learning","reinforcement-learning","meta-reinforcement-learning"],"details":"In this blog post, we\u2019ll cover and solve two key challenges about meta-exploration that keep humans in the kitchen.\r\n\r\n* First, we\u2019ll show that existing meta-reinforcement learning approaches suffer from a chicken-and-egg coupling problem: learning to explore and find the ingredients only helps a robot prepare a meal if it already knows how to cook, but the robot can only learn to cook if it already knows where the ingredients are. We\u2019ll avoid this cyclic dependence of learning to explore and learning to execute (solve the task) by proposing an objective to learn them independently of each other.\r\n* Second, we\u2019ll observe that the standard meta-reinforcement learning problem setting expects robots to cook the correct meal by trial-and-error, without even being told what meal to cook, which unnecessarily complicates the meta-exploration problem. To avoid this, we propose instruction-based meta-reinforcement learning, where the robot receives instructions specifying what meal to cook.","links":[{"article_link":"https://ai.stanford.edu/blog/meta-exploration/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2251,"title":"Practical AI: Using NLP word embeddings to solve localization ","description":"Using NLP word vectors (word2vec, glove, etc) in a novel way to solve the problem of localization in edtech.","tags":["article","notebook","tutorial","embeddings","natural-language-processing","word-embeddings","gensim","demo","word-vectors"],"details":"**King \u2014 Man + Woman = Queen**\r\n\r\nYou might have seen the traditional **word2vec** or **Glove** word embeddings examples that show **King -Man+Woman = Queen.**  In this will see how we can use this structure to solve a real-world problem of localization in edtech.\r\n\r\n\r\n\r\nAn **edtech** company in the **USA** wants to expand into **India** after being successful in its home market. It has a large set of questions in their **question bank** that it wants to use when it enters the Indian market.\r\n\r\nBut there is **one big** problem. A sample **third class** (grade) **math question** in their question bank looks like this \u2014\r\n\r\n> **Frank** lives in **San Francisco** and **Elizabeth** lives in **Los Angeles**. If the flight time is **2 hrs** when will **Elizabeth** reach **Frank** if she starts at **8am** in the morning?\r\n\r\n\r\nA **3rd-grade** kid living in **India** would not connect with this question as it has references to **names** and **locations** lesser know to him/her - Frank, San Franciso, Los Angeles, etc.\r\n\r\nSo it would be ideal if we can automatically change  the question to suit the **Indian context** and rephrase it as \u2014\r\n\r\n> **Sanjay Verma** lives in **Bangalore** and **Rekha** lives in **Mumbai**. If the flight time is **2 hrs** when will **Rekha** reach **Sanjay Verma** if she starts at **8am** in the morning?\r\n\r\n\r\nThis concept is called **localization**. It is the general concept of adopting a product or idea to a different country or region respecting local norms, customs, and any other preferences. \r\n\r\nIn this article we will see how **word embeddings** are used to achieve this **automatically** without manual intervention.\r\n","links":[{"article_link":"https://medium.com/@ramsrigouthamg/practical-ai-using-nlp-word-vectors-in-a-novel-way-to-solve-the-problem-of-localization-9de3e4fbf56f?source=friends_link","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"https://colab.research.google.com/drive/1oGqwDgDgtBeiXoeaq1uvX-_KxLY8FzXp","other_link":""}]},{"id":2250,"title":"Text Data Augmentation with MarianMT","description":"Learn how to use machine translation models in Hugging Face Transformers for data augmentation.","tags":["article","tutorial","huggingface","transformers","data-augmentation","natural-language-processing"],"details":"","links":[{"article_link":"https://amitness.com/back-translation/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2249,"title":"Heavy Metal Subgenre Classifier","description":"A music genre classifier trained to classify heavy metal subgenres.","tags":["article","code","dataset","convolutional-neural-networks","recurrent-neural-networks","music","audio-classification"],"details":"In this project, [a convolutional recurrent neural network (CRNN) ](https://arxiv.org/abs/1609.04243) was trained on a dataset of heavy metal track samples collected using Spotify's API.\r\n\r\nPeople who are not fans of a particular genre often struggle to distinguish between specific subgenres. The goal of this project was to see if a neural network could be trained to pick up on the subtle distinctions that a human with domain knowledge would be able to.\r\n\r\nA dataset was collected containing 100,000 track samples from Spotify. The dataset contained 20 classes made up of heavy metal subgenres. [Here's a guide to collecting track samples using Spotipy.](https://amontgomerie.github.io/2020/07/30/track_data_collection.html).\r\n\r\nThe final model was achieved 60% top 1 accuracy on the test set. (It was also able to get 80% top 1 accuracy on an easier dataset of more general genre categories.)","links":[{"article_link":"https://amontgomerie.github.io/2020/07/30/genre_classification.html","code_link":"https://github.com/AMontgomerie/genre_classifier","research_link":"","media_link":"","dataset_link":"https://drive.google.com/file/d/1Hv9AsEHdx5mKL7o6io_XegeQfVOPjP9g/view","demo_link":"","other_link":""}]},{"id":2248,"title":"Learn Machine Learning in 2020!","description":"Bunch of you asked me how to get started so here is the answer!","tags":["article","video","deep-learning","machine-learning"],"details":"I just made this YT video on how to get started with ML in 2020!\r\n\r\nI wrote the blog 2 years ago but it still contains relevant content.","links":[{"article_link":"https://medium.com/@gordicaleksa/get-started-with-ai-and-machine-learning-in-3-months-5236d5e0f230","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=7q_OJvQQ7vY","dataset_link":"","demo_link":"","other_link":""}]},{"id":2247,"title":"Unsupervised Keyphrase Extraction","description":"Learn about unsupervised algorithms for automatically extracting representative keyword and phrases from documents","tags":["article","tutorial","information-extraction","keyword-extraction","natural-language-processing","unsupervised-learning"],"details":"- Get a mental model of how keyword extraction pipeline works\r\n- Understand working mechanism and python implementation for some popular algorithms","links":[{"article_link":"https://amitness.com/keyphrase-extraction/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2246,"title":"Questgen- An NLP library for state-of-the-art Question Generation","description":"Questgen AI is an opensource, easy to use NLP library for Question generation. It can generate MCQs, Boolean (Yes/No), FAQs and also paraphrase any question.\r\n","tags":["code","notebook","research","huggingface","transformers","library","natural-language-processing","question-answering","question-generation","t5","demo"],"details":"https://questgen.ai/\r\n\r\nQuestgen AI is an opensource NLP library for state-of-the-art, easy to use Question generation algorithms. \r\nIt is on a quest build the world's most advanced question generation AI leveraging on state-of-the-art transformer models like T5, BERT and OpenAI GPT-2 etc.\r\n\r\nYou can generate different types of questions like MCQs, Boolean (Yes/No), FAQs, etc. You can also paraphrase any given question and do question answering.\r\n\r\nOur Github project has one of the cleanest ReadMe out there along with an easy to follow Google Colab notebook :) Do check it out.\r\n\r\n![](https://github.com/ramsrigouthamg/Questgen.ai/raw/master/quest.gif)\r\n\r\nCurrently Supported Question Generation Capabilities :\r\n\r\n```\r\n\r\n1. Multiple Choice Questions (MCQs)\r\n\r\n2. Boolean Questions (Yes/No)\r\n\r\n3. General FAQs\r\n\r\n4. Paraphrasing any Question  \r\n\r\n5. Question Answering.\r\n\r\n```\r\n\r\n","links":[{"article_link":"","code_link":"https://github.com/ramsrigouthamg/Questgen.ai","research_link":"","media_link":"","dataset_link":"","demo_link":"https://colab.research.google.com/drive/1CvgSjU48kN5jEtCU732soM723W1spGdm","other_link":"https://questgen.ai/"}]},{"id":2245,"title":"On the Bottleneck of Graph Neural Networks and its Implications","description":"The mechanism of propagating information between neighbors creates a bottleneck when every node aggregates messages from its neighbors.","tags":["code","paper","research","video","graph-neural-networks","graphs","bottleneck","arxiv:2006.05205"],"details":"Graph neural networks (GNNs) were shown to effectively learn from highly structured data containing elements (nodes) with relationships (edges) between them. GNN variants differ in how each node in the graph absorbs the information flowing from its neighbor nodes. In this paper, we highlight an inherent problem in GNNs: the mechanism of propagating information between neighbors creates a bottleneck when every node aggregates messages from its neighbors. This bottleneck causes the over-squashing of exponentially-growing information into fixed-size vectors. As a result, the graph fails to propagate messages flowing from distant nodes and performs poorly when the prediction task depends on long-range information. We demonstrate that the bottleneck hinders popular GNNs from fitting the training data. We show that GNNs that absorb incoming edges equally, like GCN and GIN, are more susceptible to over-squashing than other GNN types. We further show that existing, extensively-tuned, GNN-based models suffer from over-squashing and that breaking the bottleneck improves state-of-the-art results without any hyperparameter tuning or additional weights.","links":[{"article_link":"","code_link":"https://github.com/tech-srl/bottleneck","research_link":"https://arxiv.org/abs/2006.05205","media_link":"https://www.youtube.com/watch?v=vrLsEwzZTCQ","dataset_link":"","demo_link":"","other_link":"https://urialon.cswp.cs.technion.ac.il/wp-content/uploads/sites/83/2020/07/bottleneck_slides.pdf"}]},{"id":2244,"title":"Boost your Colab Notebooks with GCP and AWS Instances","description":"How to upgrade your Colab with Google Cloud Platform or Amazon Web Service Instance as a backend.","tags":["article","aws","gcp","gpu","google-cloud-platform","colab"],"details":"But sometimes you might require resources more than Colab typically offers, for example, you might require multi-GPUs or higher GPU RAM or maybe a better GPU to conclude successful DS experiments in your notebook. In this blog, I shall cover how to upgrade your Colab in a few minutes, without moving any of your code elsewhere, having Google Cloud Platform or Amazon Web Service Instance as a backend.","links":[{"article_link":"https://medium.com/@zohebabai/boost-your-colab-notebooks-with-gcp-and-aws-instance-within-a-few-minutes-a43ed37cd06d","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2243,"title":"SwAV","description":"Unsupervised Learning of Visual Features by Contrasting Cluster Assignments","tags":["article","paper","research","self-supervised-learning","unsupervised-learning","swav"],"details":"Self-supervised learning, semi-supervised learning, pretraining, self-training, robust representations, etc. are some of the hottest terms right now in the field of Computer Vision and Deep Learning. The recent progress in terms of self-supervised learning is astounding. Towards this end, researchers at FAIR have now come up with this new [paper](https://github.com/AakashKumarNain/annotated_research_papers/blob/master/self-supervised-learning/Swav.pdf) that introduces a new method to learn robust image representations.","links":[{"article_link":"https://medium.com/@nainaakash012/unsupervised-learning-of-visual-features-by-contrasting-cluster-assignments-fbedc8b9c3db","code_link":"","research_link":"https://github.com/AakashKumarNain/annotated_research_papers/blob/master/self-supervised-learning/Swav.pdf","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2242,"title":"Deep dive into ROI layer in Object Detection Models","description":"In this blog post we will implement in torch ROI Pool and ROI Align models from scratch.","tags":["article","tutorial","computer-vision","object-detection"],"details":"In this blog post we will implement in torch ROI Pool and ROI Align models from scratch.","links":[{"article_link":"https://medium.com/swlh/annotated-rpn-roi-pooling-and-roi-align-6a40ac5bbe1b","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2241,"title":"Objax","description":"Contraction of Object and JAX - a minimalist object-oriented design and a readable code base.","tags":["code","jax","library","demo","opjax"],"details":"[**Tutorials**](https://objax.readthedocs.io/en/latest/notebooks/Objax_Basics.html)\r\n| [**Install**](https://objax.readthedocs.io/en/latest/installation_setup.html)\r\n| [**Documentation**](https://objax.readthedocs.io/en/latest/)\r\n| [**Philosophy**](https://objax.readthedocs.io/en/latest/index.html#objax-philosophy)\r\n\r\nThis is not an officially supported Google product.\r\n\r\nObjax is an open source machine learning framework that accelerates research and learning thanks to a\r\nminimalist object-oriented design and a readable code base.\r\nIts name comes from the contraction of Object and [JAX](https://github.com/google/jax) -- a popular high-performance\r\nframework.\r\nObjax is designed **by researchers for researchers** with a focus on simplicity and understandability.\r\nIts users should be able to easily read, understand, extend, and modify it to fit their needs.\r\n\r\nThis is the developer repository of Objax, there is very little user documentation\r\nhere, for the full documentation go to [objax.readthedocs.io](https://objax.readthedocs.io/).\r\n\r\nYou can find READMEs in the subdirectory of this project, for example:\r\n\r\n* [Sample Code](examples/README.md)\r\n* [Writing documentation](docs/README.md)\r\n","links":[{"article_link":"","code_link":"https://github.com/google/objax","research_link":"","media_link":"","dataset_link":"","demo_link":"https://objax.readthedocs.io/en/latest/notebooks/Objax_Basics.html","other_link":"https://objax.readthedocs.io/en/latest/"}]},{"id":2240,"title":"Hopfield Networks is All You Need","description":"This blog post explains the paper Hopfield Networks is All You Need and the corresponding new PyTorch Hopfield layer.","tags":["article","code","paper","research","pytorch","hopfield-networks","arxiv:2008.02217"],"details":"This blog post explains the paper [Hopfield Networks is All You Need](https://arxiv.org/abs/2008.02217) and the corresponding new PyTorch [Hopfield layer](https://github.com/ml-jku/hopfield-layers).\r\n\r\nThis blog post is split into three parts. First, we make the transition from traditional Hopfield Networks towards modern Hopfield Networks and their generalization to continuous states through our new energy function. Second, the properties of our new energy function and the connection to the self-attention mechanism of transformer networks is shown. Finally, we introduce and explain a new PyTorch layer ([Hopfield layer](https://github.com/ml-jku/hopfield-layers)), which is built on the insights of our work. We show several practical use cases, i.e. [Modern Hopfield Networks and Attention for Immune Repertoire Classification](https://arxiv.org/abs/2007.13505), Hopfield pooling, and associations of two sets.","links":[{"article_link":"https://ml-jku.github.io/hopfield-layers/","code_link":"https://github.com/ml-jku/hopfield-layers","research_link":"https://arxiv.org/abs/2008.02217","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2239,"title":"An Introduction to Adversarial Examples in Deep Learning","description":"This report provides an intuitive introduction to adversarial examples, discusses a wide variety of different adversarial attacks and, most notably, provides ad","tags":["article","code","tutorial","deep-learning","computer-vision","wandb","adversarial-learning","adversarial-attacks"],"details":"","links":[{"article_link":"https://app.wandb.ai/authors/adv-dl/reports/An-Introduction-to-Adversarial-Examples-in-Deep-Learning--VmlldzoyMTQwODM","code_link":"https://github.com/sayakpaul/Image-Adversaries-101","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2238,"title":"Spinning Up in Deep RL (OpenAI)","description":"An educational resource to help anyone learn deep reinforcement learning.","tags":["code","tutorial","pytorch","tensorflow","reinforcement-learning","openai"],"details":"**Update**: Available in both TensorFlow and PyTorch.\r\n\r\nThis is an educational resource produced by OpenAI that makes it easier to learn about deep reinforcement learning (deep RL).\r\n\r\nFor the unfamiliar: [reinforcement learning](https://en.wikipedia.org/wiki/Reinforcement_learning) (RL) is a machine learning approach for teaching agents how to solve tasks by trial and error. Deep RL refers to the combination of RL with [deep learning](http://ufldl.stanford.edu/tutorial/).\r\n\r\nThis module contains a variety of helpful resources, including:\r\n\r\n- a short [introduction](https://spinningup.openai.com/en/latest/spinningup/rl_intro.html) to RL terminology, kinds of algorithms, and basic theory,\r\n- an [essay](https://spinningup.openai.com/en/latest/spinningup/spinningup.html) about how to grow into an RL research role,\r\n- a [curated list](https://spinningup.openai.com/en/latest/spinningup/keypapers.html) of important papers organized by topic,\r\n- a well-documented [code repo](https://github.com/openai/spinningup) of short, standalone implementations of key algorithms,\r\n- and a few [exercises](https://spinningup.openai.com/en/latest/spinningup/exercises.html) to serve as warm-ups.\r\n\r\nGet started at [spinningup.openai.com](https://spinningup.openai.com)!","links":[{"article_link":"","code_link":"https://github.com/openai/spinningup","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://spinningup.openai.com/en/latest/"}]},{"id":2237,"title":"Self-classifying MNIST Digits","description":"Achieving Distributed Coordination with Neural Cellular Automata\r\n\r\n","tags":["article","code","notebook","mnist","cellular-automata","self-classification","automata","distributed-coordination"],"details":"In this article, we use a variant of the neural cellular automata model described in [Growing Cellular Automata](https://doi.org/10.23915/distill.00023). We refer readers unfamiliar with its implementation to the original \u201d[Model](https://distill.pub/2020/growing-ca/#model)\u201d section. Here we will describe a few areas where our model diverges from the original.","links":[{"article_link":"https://distill.pub/2020/selforg/mnist/","code_link":"https://colab.research.google.com/github/google-research/self-organising-systems/blob/master/notebooks/mnist_ca.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2236,"title":"Git for Data: Not a Silver Bullet","description":"What we mean when we talk about version-control for data.","tags":["article","git","dvc","versioning","data"],"details":"I\u2019m broadly sympathetic to the goals that people who are working on \u201cgit for data\u201d projects have. However, I continue to believe that it\u2019s important to keep code separate from data and that if your data system is deterministic and append-only, then you can achieve all of your goals by using version-control for your code and then selectively applying transformations to subsets of the data to re-create the data state at any time. The motto remains:\r\n\r\n**Keep version control for your code, and keep a log for your data.**\r\n\r\nWorking on a version control system for data instead of solving the problem of not having an immutable log of your source data seems like investing a lot of time and tooling into solving the wrong problem (and is what I assume these systems are effectively doing under-the-hood-anyway).","links":[{"article_link":"https://locallyoptimistic.com/post/git-for-data-not-a-silver-bullet/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2235,"title":"Shift-Ctrl-F: Semantic Search for the Browser","description":"\ud83d\udd0e: Search the information available on a webpage using natural language instead of an exact string match.","tags":["code","javascript","tensorflow-js","attention","bert","transformers","library","natural-language-processing","question-answering","chrome-extension"],"details":"# Shift-Ctrl-F: Semantic Search for the Browser\r\n\r\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\r\n\r\nSearch the information available on a webpage using\r\nnatural language instead of an exact string match. Uses\r\n[MobileBERT](https://arxiv.org/abs/2004.02984)\r\nfine-tuned on\r\n[SQuAD](https://rajpurkar.github.io/SQuAD-explorer/)\r\nvia [TensorFlowJS](https://www.tensorflow.org/js) to\r\nsearch for answers and mark relevant elements on the web page.\r\n\r\n![Shift-Ctrl-F Demo](https://github.com/model-zoo/shift-ctrl-f/raw/master/assets/demo.gif)\r\n\r\n**This extension is an experiment.** Deep learning models like BERT are powerful\r\nbut may return unpredictable and/or biased results that are tough to interpret.\r\nPlease apply best judgement when analyzing search results.\r\n\r\n### Why?\r\n\r\nCtrl-F uses exact string-matching to find information within a webpage. String\r\nmatch is inherently a proxy heuristic for the true content -- in most cases it\r\nworks very well, but in some cases it can be a bad proxy.\r\n\r\nIn our example above we search\r\n[https://stripe.com/docs/testing](https://stripe.com/docs/testing), aiming to\r\nunderstand the **difference between test mode and live mode**. With string\r\nmatching, you might search through some relevant phrases `\"live mode\"`, `\"test\r\nmode\"`, and/or `\"difference\"` and scan through results. With semantic search, you\r\ncan directly phrase your question `\"What is the difference between live mode\r\nand test mode?\"`. We see that the model returns a relevant result, even though\r\nthe page does not contain the term \"`difference`\".\r\n\r\n### How It Works\r\n\r\nEvery time a user executes a search:\r\n\r\n1. The content script collects all `<p>`, `<ul>`, and `<ol>` elements on the\r\n   page and extracts text from each.\r\n2. The background script executes the question-answering model on every\r\n   element, using the query as the question and the element's text as the context.\r\n3. If a match is returned by the model, it is highlighted within the page along\r\n   with the confidence score returned by the model.\r\n\r\n### Architecture\r\n\r\nThere are three main components that interact via [Message\r\nPassing](https://developer.chrome.com/extensions/messaging) to orchestrate the\r\nextension:\r\n\r\n1. Popup (`popup.js`): React application that renders the search bar, controls\r\n   searching and iterating through the results.\r\n2. Content Script (`content.js`): Runs in the context of the current tab,\r\n   responsible for reading from and manipulating the DOM.\r\n3. Background (`background.js`): Background script that loads and executes the\r\n   TensorFlowJS model on question-context pairs.\r\n\r\n`src/js/message_types.js` contains the messages used to interact between these\r\nthree components.\r\n\r\n### Development\r\n\r\nMake sure you have these dependencies installed.\r\n\r\n1) [Node](https://nodejs.org/en/download/)\r\n2) [Yarn](https://classic.yarnpkg.com/en/docs/install)\r\n3) [Prettier](https://prettier.io/docs/en/install.html)\r\n\r\nThen run:\r\n\r\n```\r\nmake develop\r\n```\r\n\r\nThe unpacked extension will be placed inside of `build/`. See [Google Chrome\r\nExtension developer\r\ndocumentation](https://developer.chrome.com/extensions/getstarted) to load the\r\nunpacked extension into your Chrome browser in development mode.\r\n\r\n### Publishing\r\n\r\n```\r\nmake build\r\n```\r\n\r\nA zipped extension file ready for upload will be placed inside of `dist/`.","links":[{"article_link":"","code_link":"https://github.com/model-zoo/shift-ctrl-f","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2234,"title":"MTS (MLP-Torch-Sklearn): Pytorch MLP implementation for Sklearn","description":"Wanna play with Pytorch-based MLP implementation using datasets from the awesome sklearn library. This is made light-weight, simple and easy to run.","tags":["code","pytorch","scikit-learn","deep-learning","multilayer-perceptrons","classification-regression"],"details":"**Features**\r\n\r\n- Regression/classification using sklearn-like (numeric csv) datasets\r\n- Logging, model loading and saving, hyper-parameter tuning, easy model configuration.\r\n- Well-deigned for pytorch-preferred users who just stepped to the world of deep learning (DL) and want to understand important DL concepts with some toy examples (educational purpose).\r\n\r\n**Datasets available so far**\r\n\r\n- boston (regression)\r\n- covtype (classification)\r\n- digits (classification)\r\n- iris (classification)\r\n** This encourages the community to add more.\r\n![](https://raw.githubusercontent.com/wangcongcong123/mts/master/demo.png)","links":[{"article_link":"","code_link":"https://github.com/wangcongcong123/mts.git","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2233,"title":"A 2020 review of Handwritten Character Recognition","description":"Concept of handwritten text recognition,  relevant use-cases, different neural network architectures involved in achieving the results, training your own model","tags":["article","tutorial","convolutional-neural-networks","computer-vision","natural-language-processing","optical-character-recognition"],"details":"OCR is considered a solved problem in general but not in entirety \ud83c\udfaf\r\n\r\nA key component of it, HTR is still a challenging problem.\r\n\r\nHandwriting Text Recognition(HTR) is the task of recognizing handwritten human text \ud83c\udfab\r\n\r\nIt involves using both Computer Vision and NLP\r\n\r\nEvery person has a different style of handwriting \ud83d\udc83, thus solving HTR is much more difficult than OCR\r\n\r\nIn this article I cover the progress of techniques in solving HTR and various SOTA models\r\n\r\nIn addition I have discussed the way to train your own HTR model on your own dataset\r\n\r\nHappy to discuss more if you interested more to learn more about handwritten text recognition\r\n\r\n![](https://www.researchgate.net/profile/Satish_Kolhe/publication/226705617/figure/fig2/AS:349313004785675@1460294118937/mages-of-handwritten-bank-cheques-from-different-countries-a-Brazilian-1-b-American.png)\r\n","links":[{"article_link":"https://nanonets.com/blog/handwritten-character-recognition/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2232,"title":"GenRL","description":"GenRL is a PyTorch-First Reinforcement Learning library centered around reproducible and generalizable algorithm implementations.","tags":["code","research","tutorial","pytorch","deep-q-networks","library","multi-agent-reinforcement-learning","reinforcement-learning"],"details":"Reinforcement learning research is moving faster than ever before. In order to keep up with the growing trend and ensure that RL research remains reproducible, GenRL aims to aid faster paper reproduction and benchmarking by providing the following main features:\r\n\r\n* PyTorch-first: Modular, Extensible and Idiomatic Python\r\n* Tutorials and Documentation: We have over 20 tutorials assuming no knowledge of RL concepts. Basic explanations of algorithms in Bandits, Contextual Bandits, RL, Deep RL, etc.\r\n* Unified Trainer and Logging class: code reusability and high-level UI\r\n* Ready-made algorithm implementations: ready-made implementations of popular RL algorithms.\r\n* Faster Benchmarking: automated hyperparameter tuning, environment implementations etc.\r\n\r\nBy integrating these features into GenRL, we aim to eventually support any new algorithm implementation in less than 100 lines.\r\n\r\nCurrently, the library has implementations of popular classical and Deep RL agents that ready to be deployed. Apart from these, various Bandit algorithms are a part of GenRL. It has various abstraction layers that make the addition of new algorithms easy for the user.\r\n\r\nThe library aims to add other key research areas like Multi-agent RL, Evolutionary RL and hyperparameter optimization and provide extensive support for distributed training of agents.","links":[{"article_link":"","code_link":"https://github.com/SforAiDl/genrl","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://genrl.readthedocs.io"}]},{"id":2231,"title":"Which Debts Are Worth the Bank's Effort?","description":"Play bank data scientist and use regression discontinuity to see which debts are worth collecting.","tags":["code","machine-learning","banking","finance","data-summarization"],"details":"After a debt has been legally declared \"uncollectable\" by a bank, the account is considered to be \"charged-off.\" But that doesn't mean the bank simply walks away from the debt. They still want to collect some of the money they are owed. In this project, you will look at a situation where a bank assigned delinquent customers to different recovery strategies based on the expected amount the bank believed it would recover from the customer. The goal for the data scientist is to determine in this non-random assignment whether the incremental amount the bank earns exceeded the additional cost of assigning customers to a higher recovery strategy.\r\n\r\nThreshold assignments like this also one occur in medicine (above a certain temperature you get medicine), education (above a certain test score students get admitted to a special class), other areas of finance (above a certain wealth customers get different levels of service), and public sector (below a certain income someone is eligible for housing benefits). Regression discontinuity is an intuitive and useful analysis method in any situation of a threshold assignment.","links":[{"article_link":"","code_link":"https://github.com/OmarEltouny78/Banking","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2230,"title":"Disney Movies and Box Office Success","description":"In this project, you will analyze data to see how Disney movies have changed in popularity since its first movie release","tags":["code","machine-learning","classification","similarity-search","movies"],"details":"In this project, you will analyze data to see how Disney movies have changed in popularity since its first movie release","links":[{"article_link":"","code_link":"https://github.com/OmarEltouny78/Disney","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2229,"title":"Docker in Action","description":"Detailed notes from the book Docker In Action.","tags":["article","tutorial","docker"],"details":"Detailed notes from the book Docker In Action.","links":[{"article_link":"https://notes.hamel.dev/docs/docker/Docker-In-Action.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.manning.com/books/docker-in-action-second-edition"}]},{"id":2228,"title":"MiniTorch","description":"A teaching library for machine learning engineers who wish to learn about the internal concepts underlying deep learning systems.","tags":["article","code","deep-learning","library","minitorch"],"details":"MiniTorch is a teaching library for machine learning engineers who wish to learn about the internal concepts underlying deep learning systems. Specifically, it is a pure Python re-implementation of the Torch API designed to be simple, easy-to-read, tested, and incremental. The final library can run Torch code with minimal changes (at some efficiency cost). The project was developed for the course Machine Learning Engineering at Cornell Tech.","links":[{"article_link":"https://minitorch.github.io/","code_link":"https://github.com/minitorch/minitorch.github.io","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2227,"title":"Meta-Learning Is All You Need","description":"How can we design neural-based Bayesian meta-learning algorithms?","tags":["article","video","bayesian-deep-learning","meta-learning"],"details":"This post is part of a blog series on Meta-Learning that I\u2019m working on.\r\n\r\n* [Meta-Learning Is All You Need](https://medium.com/cracking-the-data-science-interview/meta-learning-is-all-you-need-3bd0bafdf289)\r\n* [Bayesian Meta-Learning Is All You Need](https://medium.com/cracking-the-data-science-interview/bayesian-meta-learning-is-all-you-need-1bcff6b889fc)\r\n* [Unsupervised Meta-Learning Is All You Need](https://medium.com/cracking-the-data-science-interview/unsupervised-meta-learning-is-all-you-need-71b6dfa29ccd)\r\n\r\n","links":[{"article_link":"https://medium.com/cracking-the-data-science-interview/unsupervised-meta-learning-is-all-you-need-71b6dfa29ccd","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=QY8JXpnllb0","dataset_link":"","demo_link":"","other_link":""}]},{"id":2226,"title":"Hyperparameter Optimization for \ud83e\udd17 Transformers: A Guide","description":"Basic grid search is not the most optimal, and in fact, the hyperparameters we choose can have a significant impact on our final model performance.","tags":["article","code","notebook","tutorial","transformers","natural-language-processing","ray","hyperparameter-optimization","ray-tune"],"details":"In this blog post, we\u2019ll show that basic grid search is not the most optimal, and in fact, the hyperparameters we choose can have a significant impact on our final model performance.\r\n\r\nWe fine-tune BERT using more advanced search algorithms like Bayesian Optimization and Population Based Training. As a result, we can:\r\n\r\n1. gain a better understanding of our hyperparameters and\r\n2. train a model with 5% better accuracy in the same amount of time.\r\n\r\n\r\nWe also conclude with a couple tips and tricks for hyperparameter tuning for \ud83e\udd17 Transformer models.","links":[{"article_link":"https://medium.com/distributed-computing-with-ray/hyperparameter-optimization-for-transformers-a-guide-c4e32c6c989b","code_link":"https://colab.research.google.com/drive/1tQgAKgcKQzheoh503OzhS4N9NtfFgmjF","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2225,"title":"Explainable and Reproducible ML modeling with DALEX and Neptune.","description":"DALEX-Neptune integration that allows users to easily add model's behavior explanations to experiments.","tags":["article","research","tutorial","deep-learning","machine-learning","demo","xai","explainable-ai"],"details":"Here, we present how the open source library DALEX (developed by a group of researchers ([dalex.drwhy.ai](http://dalex.drwhy.ai)) can be used for Explainable AI, focusing on predictions explanations.\r\n\r\nIt is a practical guide that shows how you can explain and explore models' behavior. Article focuses on:\r\n\r\n* explain machine learning models with **DALEX** explainers,\r\n* make your models versioned and experiments reproducible with **Neptune**,\r\n* automatically save model explainers and interactive explanation charts for every training run with **Neptune + DALEX integration**,\r\n* compare, debug, and audit every model you build with **versioned explainers**.\r\n\r\n","links":[{"article_link":"https://neptune.ai/blog/explainable-and-reproducible-machine-learning-with-dalex-and-neptune?utm_source=madewithml&utm_medium=post&utm_campaign=blog-explainable-and-reproducible-machine-learning-with-dalex-and-neptune","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"https://ui.neptune.ai/o/shared/org/dalex-integration/experiments?viewId=495b4a41-3424-4d01-9064-70be82716196?utm_source=madewithml&utm_medium=post&utm_campaign=blog-explainable-and-reproducible-machine-learning-with-dalex-and-neptune","other_link":"https://dalex.drwhy.ai/"}]},{"id":2224,"title":"Reducing Traffic Mortality in the USA","description":"How can we find a good strategy for reducing traffic-related deaths?","tags":["code","machine-learning","health","healthcare","mortality-prediction","data-science","exploratory-data-analysis"],"details":"Project Provided by DataCamp","links":[{"article_link":"","code_link":"https://github.com/OmarEltouny78/Traffic","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2223,"title":"AxCell","description":"Automatic Extraction of Results from Machine Learning Papers","tags":["article","code","paper","research","computer-vision","tabular","table-extraction","table-detection","arxiv:2004.14356"],"details":"Tracking progress in machine learning has become increasingly difficult with the recent explosion in the number of papers. In this paper, we present AxCell, an automatic machine learning pipeline for extracting results from papers. AxCell uses several novel components, including a table segmentation subtask, to learn relevant structural knowledge that aids extraction. When compared with existing methods, our approach significantly improves the state of the art for results extraction. We also release a structured, annotated dataset for training models for results extraction, and a dataset for evaluating the performance of models on this task. Lastly, we show the viability of our approach enables it to be used for semi-automated results extraction in production, suggesting our improvements make this task practically viable for the first time. ","links":[{"article_link":"https://deepmind.com/research/publications/AxCell-Automatic-Extraction-of-Results-from-Machine-Learning-Papers","code_link":"https://github.com/paperswithcode/axcell","research_link":"https://arxiv.org/abs/2004.14356","media_link":"","dataset_link":"","demo_link":"","other_link":"https://paperswithcode.com/paper/axcell-automatic-extraction-of-results-from"}]},{"id":2222,"title":"How Batch Normalization Works","description":"The article covers how Batch Normalization works and how it \"normalizes\" different input distributions to make gradient propagation easier.","tags":["article","code","notebook","convolutional-neural-networks","batch-normalization","batchnorm"],"details":"Batch normalization is an element-by-element shift (adding a constant) and scaling (multiplying by a constant) so that the mean of each element's values is zero and the variance of each element's values is one within a batch. It's typically inserted before the nonlinearity layer in a neural network. It works quite well. But we're still trying to figure out why.","links":[{"article_link":"https://e2eml.school/batch_normalization.html","code_link":"https://colab.research.google.com/github/davidcpage/cifar10-fast/blob/master/batch_norm_post.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2221,"title":"NewsBERT","description":" Using BERT & other transformer models for organizing RSS feed data ","tags":["code","notebook","library","zero-shot-learning","demo"],"details":"# NewsBERT\r\nIf you want to stay up to date on technical discussions, you probably browse different sources of information like reddit, twitter, medium and various programming blogs.\r\n\r\n## Inspiration\r\n\r\nIn the recent two years there was lots of progress made in NLP because of transformer models. One remarkable feature of these pretrained language models can be used for tasks like Zero-Shot Learning.\r\n\r\nZero-shot learning for text mining is basically unsupervised classification where the classes are text themselves.\r\nWhat it does\r\n\r\nWe tackle the problem of organizing information from different social media feeds in single wall that can be sorted by topics.\r\n\r\nThe app pulls articles from RSS feeds and lets the user filter the articles by topic classes.\r\n## How we built it\r\n\r\nThe app is built using streamlit. We used pretrained models from huggingface transformers and haystack libraries to extract topic scores.\r\n\r\nMore precisely we use Natural Language Inference models and construct pairs (text, \"text is on {topic}\") for given topics. The score gives the confidence that text entails the sentence \"text is on {topic}\" for each topic. This is used as our topic match score.\r\n\r\nOur implementation uses deepset's haystack library to reduce zero-shot learning to search problem: for each topic we find top k documents that match query \"text is on {topic}\".\r\n## What's next for NewsBERT\r\n\r\nWe need to research ways to get better topic scores, for example using approaches similar to ones proposed in Pattern-Exploiting Training.\r\n\r\nWe also want to check whether classes specified by topic names correspond to something that can be extracted using topic modeling.","links":[{"article_link":"","code_link":"github.com/lambdaofgod/pytorch_hackathon","research_link":"","media_link":"","dataset_link":"","demo_link":"https://colab.research.google.com/github/lambdaofgod/pytorch_hackathon/blob/master/notebooks/NewsBERT_on_Colab.ipynb","other_link":""}]},{"id":2220,"title":"Table Detection, Information Extraction and Structuring using ML","description":"Table Extraction (TE) is the task of detecting and decomposing table information in a document.","tags":["article","tutorial","information-retrieval","natural-language-processing","table-extraction","table-detection"],"details":"The amount of data being collected is drastically increasing day-by-day with lots of applications, tools, and online platforms booming in the present technological era. To handle and access this humongous data productively, it\u2019s necessary to develop valuable information extraction tools. One of the sub-areas that\u2019s demanding attention in the Information Extraction field is the fetching and accessing of data from tabular forms.\r\n\r\n![](https://nanonets.com/blog/content/images/2020/01/Comp-5.gif)","links":[{"article_link":"https://nanonets.com/blog/table-extraction-deep-learning/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2219,"title":"Probabilistic Machine Learning 4 Trading + Business Understanding","description":"You will learn how to structure a trading problem in a probabilistic way using real Binance data, also improve your feature engineering process.","tags":["article","code","machine-learning","random-forests","decision-tree","trading"],"details":"In this post you will learn:\r\n\r\n* How to define (a little part) of the risk management procedures understanding the importance of the expected return.\r\n* You will learn the impact that fees make on our decisions.\r\n* We will see why it was important to choose class-probability estimation models for this task.\r\n* We will understand how to improve our feature engineering based on business concepts, achieving a better success rate where it matters.\r\n* You will see  cool motion visualizations!\r\n","links":[{"article_link":"https://towardsdatascience.com/probabilistic-machine-learning-approach-to-trading-macd-business-understanding-6b81f465aef6?source=---------2------------------","code_link":"https://github.com/MauricioLetelier/Trading_And_Visualizations","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2218,"title":"CascadeTabNet","description":"An approach for end-to-end table detection and structure recognition from image-based documents\r\n","tags":["code","notebook","paper","research","video","computer-vision","demo","table-extraction","arxiv:2004.12629","table-detection"],"details":"CascadTabNet is an automatic table recognition method for interpretation of tabular data in document images. We present an improved deep learning-based end to end approach for solving both problems of table detection and structure recognition using a single Convolution Neural Network (CNN) model. CascadeTabNet is a Cascade mask Region-based CNN High-Resolution Network (Cascade mask R-CNN HRNet) based model that detects the regions of tables and recognizes the structural body cells from the detected tables at the same time. We evaluate our results on ICDAR 2013, ICDAR 2019 and TableBank public datasets. We achieved 3rd rank in ICDAR 2019 post-competition results for table detection while attaining the best accuracy results for the ICDAR 2013 and TableBank dataset. We also attain the highest accuracy results on the ICDAR 2019 table structure recognition dataset.\r\n\r\n![](https://github.com/DevashishPrasad/CascadeTabNet/raw/master/imgs/CVPR%20Teaser.gif)\r\n\r\n![](https://github.com/DevashishPrasad/CascadeTabNet/raw/master/imgs/main_res.png)","links":[{"article_link":"","code_link":"https://github.com/DevashishPrasad/CascadeTabNet","research_link":"https://arxiv.org/abs/2004.12629","media_link":"https://www.youtube.com/watch?v=6rovEyWKZw8","dataset_link":"","demo_link":"https://colab.research.google.com/drive/1lzjbBQsF4X2C2WZhxBJz0wFEQor7F-fv","other_link":""}]},{"id":2217,"title":"neptune-contrib: Neptune contributions library","description":"Tools, helpers and everything else that helps you work with Neptune.","tags":["code","python","deep-learning","machine-learning","library","neptune"],"details":"## Intro\r\n**Neptune contrib** is a `pip-installable` library, developed by Neptune team, together with external contributors.\r\nIt is a collection of helpers and extensions that make working with Neptune faster and more effective.\r\n\r\n## About neptune-contrib\r\nNeptune contrib consist of few modules, each touches different aspects of machine learning experimentation.\r\n\r\nMajor modules are:\r\n\r\n* `api` -> that extends standard api provided by the parent library [neptune-client](https://github.com/neptune-ai/neptune-client).\r\n* `monitoring` -> with callbacks that let you monitor training of the lightGBM, XGBoost or fastai models.\r\n* `hpo` -> for running hyper parameter sweeps in scikit-optimize, hyperopt or any other tool you like.\r\n* `viz` -> with few ML-specific visualizations like [parallel coordinates plot](https://docs.neptune.ai/integrations/hiplot.html).\r\n\r\nThere is much more to discover, visit [documentation](https://neptune-contrib.readthedocs.io/) to learn more.\r\n\r\n## Just one example :)\r\nTake a look at one example utility, that allows you to interactively explore multiple experiments runs. You can find more info in the [docs](https://docs.neptune.ai/integrations/hiplot.html).\r\n\r\n![hiplot-integration](https://docs.neptune.ai/_images/example_hiplot_1.gif)\r\n","links":[{"article_link":"","code_link":"https://github.com/neptune-ai/neptune-contrib","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://neptune-contrib.readthedocs.io"}]},{"id":2216,"title":"Simple Ways to Tackle Class Imbalance","description":"Various methods used to counter class imbalance in image classification problems \u2013 class weighting, oversampling, under sampling, and two-phase learning.","tags":["article","code","notebook","tutorial","keras","tensorflow","wandb","class-imbalance"],"details":"**Problem:**\r\nSo let\u2019s draw an analogy here and understand what is up. With a neural network, there are weights and biases, which can be thought of as knobs on a radio. We turn the knob to tune the frequency of our radio. We keep turning the knob both ways until we find the perfect spot. In the neural network, the weights and biases are tuned until the sweet spot is found. The sweet spot for the knobs depends on what we want from the network. For the classification task, this sweet spot would be such that the network builds a function that can map input data to its proper class. Now that the foundation is laid, what would happen if the model (the neural network) sees one of the classes a lot compared to the other? The knobs would be tuned such that the predictions are leaned towards the majority class.\r\n\r\nTackling class imabalance in vision tasks.\r\nPointers:\r\n\r\n* Class Weights\r\n* Oversampling\r\n* Undersampling\r\n* Two-phase learning","links":[{"article_link":"https://app.wandb.ai/authors/class-imbalance/reports/Simple-Ways-to-Tackle-Class-Imbalance--VmlldzoxODA3NTk","code_link":"https://colab.research.google.com/drive/1VMo2CH6-2hJVyoeyomRYmfqnWQ9_Z_ZN","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2215,"title":"vedastr","description":"vedastr is an open source scene text recognition toolbox based on PyTorch.","tags":["code","pytorch","transformers","computer-vision","natural-language-processing","optical-character-recognition","scene-text-recognition"],"details":"## Introduction\r\nvedastr is an open source scene text recognition toolbox based on PyTorch. It is designed to be flexible\r\nin order to support rapid implementation and evaluation for scene text recognition task.  \r\n\r\n## Features\r\n- **Modular design**\r\n  We decompose the scene text recognition framework into different components and one can \r\n  easily construct a customized scene text recognition framework by combining different modules.\r\n  \r\n- **Flexibility**\r\n  vedastr is flexible enough to be able to easily change the components within a module.\r\n\r\n- **Module expansibility**\r\n  It is easy to integrate a new module into the vedastr project. \r\n\r\n- **Support of multiple frameworks**\r\n  The toolbox supports several popular scene text recognition framework, e.g., [CRNN](https://arxiv.org/abs/1507.05717),\r\n   [TPS-ResNet-BiLSTM-Attention](https://github.com/clovaai/deep-text-recognition-benchmark), Transformer, etc.\r\n\r\n- **Good performance**\r\n  We re-implement the best model in  [deep-text-recognition-benchmark](https://github.com/clovaai/deep-text-recognition-benchmark)\r\n  and get better average accuracy. What's more, we implement a simple baseline(ResNet-FC)\r\n   and the performance is acceptable.","links":[{"article_link":"","code_link":"https://github.com/Media-Smart/vedastr","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2214,"title":"vedaseg","description":"vedaseg is an open source semantic segmentation toolbox based on PyTorch.","tags":["code","pytorch","computer-vision","semantic-segmentation","segmentation"],"details":"## Introduction\r\nvedaseg is an open source semantic segmentation toolbox based on PyTorch.\r\n\r\n## Features\r\n\r\n- **Modular Design**\r\n\r\n  We decompose the semantic segmentation framework into different components. The flexible and extensible design make it easy to implement a customized semantic segmentation project by combining different modules like building Lego.\r\n\r\n- **Support of several popular frameworks**\r\n\r\n  The toolbox supports several popular and semantic segmentation frameworks out of box, *e.g.* DeepLabv3+, DeepLabv3, U-Net, PSPNet, FPN, etc.\r\n\r\n- **Deployment and acceleration**\r\n\r\n  The toolbox can automatically transform and accelerate PyTorch, Onnx and Tensorflow models with TensorRT, can also automatically generate benchmark with given model.\r\n\r\n- **Different training modes**\r\n    \r\n  The toolbox supports both single-label training and multi-label training.","links":[{"article_link":"","code_link":"https://github.com/Media-Smart/vedaseg","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2213,"title":"Towards representation learning for an image retrieval task","description":"This project explains self-supervised and regularized supervised image retrieval with the help of the latent space of an autoencoder.","tags":["article","code","tutorial","tensorflow","autoencoders","representation-learning","wandb","image-retrieval"],"details":"In this project, we approach the `image retrieval` problem from an unsupervised perspective. The foundation of our work lies in the latent space representation of the images learned through a self-supervised learning task. The goal here is to capture the latent space embeddings of images and then try to determine the distance among them in the latent space. With this approach, we are focusing on the perceptual realm of an image. We validate the quality of the learned representations through a Clustering task and measure its performance through the normalized mutual information score & rand index. Then we identify the issues in learning in a purely unsupervised scenario and show the enhancement in the information content of the learned representations with a hint of supervision. We train a regularised autoencoder with the supervised information. We validate the performance in a retrieval framework for the test set.","links":[{"article_link":"https://app.wandb.ai/authors/image-retrieval/reports/Towards-Representation-Learning-for-an-Image-Retrieval-Task--VmlldzoxOTY4MDI","code_link":"https://github.com/ariG23498/ImageRetrieval/","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2212,"title":"Visualizing Class Activation Maps for CNNs","description":"Visualizing Class Activation Maps for Convolutional Neural Networks","tags":["code","research","tutorial","tensorflow","convolutional-neural-networks","interpretability","visualization","activation-maps"],"details":"### Visualizing Class Activation Maps for CNNs\r\n\r\n**Run it now**\r\n\r\n<a href=\"https://colab.research.google.com/drive/16CpcQR8YaGa4MtryfDsVEQqAFJFKcxKa\" target=\"_parent\">\r\n    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\"/>\r\n</a>\r\n\r\n**Running Locally**\r\n\r\n1.Installing requirements and dependencies\r\n\r\n```\r\ngit clone https://github.com/saadhaxxan/Visualizing-Class-Activation-Maps-for-CNN.git\r\ncd Visualizing-Class-Activation-Maps-for-CNN\r\npip install -r requirements.txt\r\n```\r\n\r\n2.Running the Script\r\n\r\n```\r\npython class_activation_maps_resnet50.py\r\n```\r\n\r\n**Author**\r\nYou can get in touch with me on my LinkedIn Profile:\r\n\r\nSaad Hassan\r\n[![LinkedIn Link](https://img.shields.io/badge/Connect-saadhaxxan-blue.svg?logo=linkedin&longCache=true&style=social&label=Connect\r\n)](https://www.linkedin.com/in/saadhaxxan)\r\n\r\nYou can also follow my GitHub Profile to stay updated about my latest projects: [![GitHub Follow](https://img.shields.io/badge/Connect-saadhaxxan-blue.svg?logo=Github&longCache=true&style=social&label=Follow)](https://github.com/saadhaxxan)\r\n\r\nIf you liked the repo then kindly support it by giving it a star \u2b50!\r\n","links":[{"article_link":"","code_link":"https://github.com/saadhaxxan/Visualizing-Class-Activation-Maps-for-CNN","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2211,"title":"The Neural Network, A Visual Introduction","description":"Uncovering the deeper intuitions to build foundational knowledge on neural networks. ","tags":["code","tutorial","video","neural-networks","visualization","illustrated"],"details":"Uncovering the deeper intuitions to build foundational knowledge on neural networks. ","links":[{"article_link":"","code_link":"https://github.com/vivek3141/dl-visualization","research_link":"","media_link":"https://www.youtube.com/watch?v=UOvPeC8WOt8","dataset_link":"","demo_link":"","other_link":""}]},{"id":2210,"title":"KD Lib","description":"A PyTorch library to easily facilitate knowledge distillation for custom deep learning models.","tags":["code","paper","research","pytorch","library","knowledge-distillation","model-compression"],"details":"A PyTorch library to easily facilitate knowledge distillation for custom deep learning models.\r\n\r\nSome benchmark results can be found in the [logs.rst](https://github.com/SforAiDl/KD_Lib/blob/master/logs.rst) file.\r\n\r\n* Distilling the Knowledge in a Neural Network               https://arxiv.org/abs/1503.02531 \r\n* Improved Knowledge Distillation via Teacher Assistant      https://arxiv.org/abs/1902.03393 \r\n* Relational Knowledge Distillation                          https://arxiv.org/abs/1904.05068 \r\n* Distilling Knowledge from Noisy Teachers                   https://arxiv.org/abs/1610.09650 \r\n* Paying More Attention To The Attention                     https://arxiv.org/abs/1612.03928 \r\n* Revisit Knowledge Distillation: a Teacher-free Framework   https://arxiv.org/abs/1909.11723 \r\n* Mean Teachers are Better Role Models                       https://arxiv.org/abs/1703.01780 \r\n* Knowledge Distillation via Route Constrained Optimization  https://arxiv.org/abs/1904.09149 \r\n* Born Again Neural Networks                                 https://arxiv.org/abs/1805.04770 \r\n* Preparing Lessons: Improve Knowledge Distillation with     https://arxiv.org/abs/1911.07471 \r\n* Improving Generalization Robustness with Noisy             https://arxiv.org/abs/1910.05057 \r\n* Distilling Task-Specific Knowledge from BERT into          https://arxiv.org/abs/1903.12136 \r\n* Deep Mutual Learning  https://arxiv.org/abs/1706.00384 \r\n* The Lottery Ticket Hypothesis: Finding https://arxiv.org/abs/1803.03635","links":[{"article_link":"","code_link":"https://github.com/SforAiDl/KD_Lib","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://kd-lib.readthedocs.io/"}]},{"id":2209,"title":"Benchmarking nearest neighbors","description":"Benchmarks of approximate nearest neighbor libraries in Python\r\n\r\n","tags":["code","library","embeddings","similarity-search","k-nearest-neighbors","benchmark"],"details":"Doing fast searching of nearest neighbors in high dimensional spaces is an increasingly important problem, but so far there has not been a lot of empirical attempts at comparing approaches in an objective way.\r\n\r\nThis project contains some tools to benchmark various implementations of approximate nearest neighbor (ANN) search for different metrics. We have pregenerated datasets (in HDF5) formats and we also have Docker containers for each algorithm. There's a test suite that makes sure every algorithm works.\r\n\r\n### Evaluated\r\n\r\n* [Annoy](https://github.com/spotify/annoy)\r\n* [FLANN](http://www.cs.ubc.ca/research/flann/)\r\n* [scikit-learn](http://scikit-learn.org/stable/modules/neighbors.html): LSHForest, KDTree, BallTree\r\n* [PANNS](https://github.com/ryanrhymes/panns)\r\n* [NearPy](http://pixelogik.github.io/NearPy/)\r\n* [KGraph](https://github.com/aaalgo/kgraph)\r\n* [NMSLIB (Non-Metric Space Library)](https://github.com/nmslib/nmslib): SWGraph, HNSW, BallTree, MPLSH\r\n* [hnswlib (a part of nmslib project)](https://github.com/nmslib/hnsw)\r\n* [RPForest](https://github.com/lyst/rpforest)\r\n* [FAISS](https://github.com/facebookresearch/faiss.git)\r\n* [DolphinnPy](https://github.com/ipsarros/DolphinnPy)\r\n* [Datasketch](https://github.com/ekzhu/datasketch)\r\n* [PyNNDescent](https://github.com/lmcinnes/pynndescent)\r\n* [MRPT](https://github.com/teemupitkanen/mrpt)\r\n* [NGT](https://github.com/yahoojapan/NGT): ONNG, PANNG\r\n* [SPTAG](https://github.com/microsoft/SPTAG)\r\n* [PUFFINN](https://github.com/puffinn/puffinn)\r\n* [N2](https://github.com/kakao/n2)\r\n* [ScaNN](https://github.com/google-research/google-research/tree/master/scann)\r\n\r\n![](https://camo.githubusercontent.com/027adff014f63209dba16e348304d523fb33812e/68747470733a2f2f7261772e6769746875622e636f6d2f6572696b6265726e2f616e6e2d62656e63686d61726b732f6d61737465722f726573756c74732f676c6f76652d3130302d616e67756c61722e706e67)","links":[{"article_link":"","code_link":"https://github.com/erikbern/ann-benchmarks","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2208,"title":"Non-Metric Space Library (NMSLIB)","description":"An efficient similarity search library and a toolkit for evaluation of k-NN methods for generic non-metric spaces.","tags":["code","library","embeddings","similarity-search","k-nearest-neighbors"],"details":"Non-Metric Space Library (NMSLIB) is an efficient cross-platform similarity search library and a toolkit for evaluation of similarity search methods. The core-library does not have any third-party dependencies. It has been gaining popularity recently. In particular, it has become a part of Amazon Elasticsearch Service.\r\n\r\nThe goal of the project is to create an effective and comprehensive toolkit for searching in generic and non-metric spaces. Even though the library contains a variety of metric-space access methods, our main focus is on generic and approximate search methods, in particular, on methods for non-metric spaces. NMSLIB is possibly the first library with a principled support for non-metric space searching.\r\n\r\nNMSLIB is an extendible library, which means that is possible to add new search methods and distance functions. NMSLIB can be used directly in C++ and Python (via Python bindings). In addition, it is also possible to build a query server, which can be used from Java (or other languages supported by Apache Thrift). Java has a native client, i.e., it works on many platforms without requiring a C++ library to be installed.\r\n\r\n* NMSLIB is generic but fast, see the results of ANN benchmarks.\r\n* A standalone implementation of our fastest method HNSW also exists as a header-only library.\r\n* All the documentation (including using Python bindings and the query server, description of methods and spaces, building the library, etc) can be found on this page.\r\n* For generic questions/inquiries, please, use the Gitter chat: GitHub issues page is for bugs and feature requests.\r\n","links":[{"article_link":"","code_link":"https://github.com/nmslib/nmslib","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2207,"title":"Rules of Machine Learning: Best Practices for ML Engineering","description":"A basic knowledge of machine learning get the benefit of best practices in machine learning from around Google.","tags":["article","product-management","production","monitoring"],"details":"This document is intended to help those with a basic knowledge of machine learning get the benefit of best practices in machine learning from around Google. It presents a style for machine\r\nlearning, similar to the Google C++ Style Guide and other popular guides to practical programming. If you have taken a class in machine learning, or built or worked on a machine\u00adlearned model, then you have the necessary background to read this document.","links":[{"article_link":"http://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf","code_link":"","research_link":"","media_link":"https://anvaka.github.io/rules-of-ml/","dataset_link":"","demo_link":"","other_link":""}]},{"id":2206,"title":"People + AI Guidebook","description":"The People + AI Guidebook was written to help user experience (UX) professionals and product managers follow a human-centered approach to AI.","tags":["article","design","product-management","ux","book","ui","user-experience"],"details":"The People + AI Guidebook was written to help user experience (UX) professionals and product managers follow a human-centered approach to AI.\r\n\r\nThe Guidebook\u2019s recommendations are based on data and insights from over a hundred individuals across Google product teams, industry experts, and academic research.\r\n\r\nThese six chapters follow the product development flow, and each one has a related worksheet to help turn guidance into action.","links":[{"article_link":"https://pair.withgoogle.com/guidebook/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2205,"title":"Machine Learning for Product Managers","description":"A product-centric overview of machine learning.\r\n","tags":["article","product-management"],"details":"**Part 1**: Machine learning, without the math\r\n\r\n* Unsupervised learning is about identifying patterns\r\n* Supervised learning is about predicting an outcome\r\n* Supervised & unsupervised learning often looks similar in products\r\n* There are technical terms for what products are trying to do\r\n\r\n**Part 2**: Using ML in products\r\n\r\n* Does the ML fit the product goal?\r\n* How does the product behave \u201caround\u201d the ML?\r\n* How should a product start using ML?\r\n* What are you comparing with?\r\n* How quickly should this product change?\r\n* What interactions, actions, & control do users have?\r\n* How could the product fail catastrophically?","links":[{"article_link":"https://medium.com/@neal_lathia/machine-learning-for-product-managers-ba9cf8724e57","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2204,"title":"Tensorflow Object Detection with Tensorflow 2","description":"Object Detection with Tensorflow 2 and the Tensorflow Object Detection API ","tags":["article","code","tutorial","tensorflow","computer-vision","object-detection"],"details":"In this step-by-step guide you'll learn how to create your own custom object detection model with Tensorflow 2 and the Tensorflow Object Detection API.","links":[{"article_link":"https://gilberttanner.com/blog/tensorflow-object-detection-with-tensorflow-2-creating-a-custom-model","code_link":"https://github.com/TannerGilbert/Tensorflow-Object-Detection-API-Train-Model","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2203,"title":"Image Similarity Search in PyTorch","description":"Simple Convolutional Auto-encoder based image similarity\r\nsearch to find similar images to given image or features.\r\nFully written in PyTorch.","tags":["article","code","tutorial","pytorch","autoencoders","convolutional-neural-networks","computer-vision","image-similarity-search","representation-learning","similarity-search","demo","image-retrieval"],"details":"### Image Similarity using PyTorch\r\n\r\n![CI Tests](https://github.com/oke-aditya/image_similarity/workflows/CI%20Tests/badge.svg)\r\n![Check Formatting](https://github.com/oke-aditya/image_similarity/workflows/Check%20Formatting/badge.svg)\r\n![Deploy mkdocs](https://github.com/oke-aditya/image_similarity/workflows/Deploy%20mkdocs/badge.svg)\r\n![PyPi Release](https://github.com/oke-aditya/image_similarity/workflows/PyPi%20Release/badge.svg)\r\n![Install Package](https://github.com/oke-aditya/image_similarity/workflows/Install%20Package/badge.svg)\r\n\r\n#### Auto-encoder based Image-Similarity Engine\r\n\r\n- Builds a simple Convolutional Auto-encoder based Image similarity engine.\r\n- This solves the problem of finding similar images using unsupervised learning. There are no labels for images.\r\n\r\nTasks that it can do.\r\n\r\n- [x] Similar images using Auto-encoders.\r\n- [x] Similar image search from image features.\r\n- [x] Clustering similar images.\r\n\r\n#### Repostory Structure.\r\n```\r\n=== data                        Read data from here. It is in gitignore so it won't appear here.\r\n=== docs                        Documentation using mkdocs.\r\n=== image_similarity\r\n====== cluster_images.py        Clusters the embeddings learnt using PCA and T-SNE.\r\n====== torch_data.py            Contains Dataset class to create PyTorch dataset from folder.\r\n====== torch_model.py           Convolutional Auto-enocder Model.\r\n====== torch_engine.py          Train_step and validation_step for training.\r\n====== torch_train.py           Trainng script. Trains Auto-enocder and saves the embeddings.\r\n====== torch_infer.py           Contains inference code\r\n====== config.py                Configurations of models and paths.\r\n====== torch_inference.ipynb    Inference code in .ipynb to play with.\r\n====== torch_train.ipynb        Stand-alone code to train in Jupyter.\r\n=== tests                       Contains tests for CI\r\n```\r\n","links":[{"article_link":"https://medium.com/pytorch/image-similarity-search-in-pytorch-1a744cf3469","code_link":"https://github.com/oke-aditya/image_similarity","research_link":"","media_link":"","dataset_link":"","demo_link":"https://oke-aditya.github.io/image_similarity","other_link":""}]},{"id":2202,"title":"Graph Representation Learning Book","description":"Introduction to graph representation learning, including methods for embedding graph data, graph neural networks, and deep generative models of graphs.","tags":["article","embeddings","graph-neural-networks","graphs","knowledge-graphs","representation-learning","book","graph-representation-learning"],"details":"The field of graph representation learning has grown at an incredible (and sometimes unwieldy) pace over the past seven years, transforming from a small subset of researchers working on a relatively niche topic to one of the fastest growing sub-areas of deep learning.\r\n\r\nThis book is my attempt to provide a brief but comprehensive introduction to graph representation learning, including methods for embedding graph data, graph neural networks, and deep generative models of graphs.\r\n\r\n**Contents and Chapter Drafts**\r\n\r\n* Chapter 1: [Introduction and Motivations](https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book-Chapter_1-Intro.pdf)\r\n* Chapter 2: [Background and Traditional Approaches](https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book-Chapter_2-Background.pdf)\r\n* Part I: Node Embeddings\r\n\t* Chapter 3: [Neighborhood Reconstruction Methods](https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book-Chapter_3-Node_Embeddings.pdf)\r\n\t* Chapter 4: [Multi-Relational Data and Knowledge Graphs](https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book-Chapter_4-Knowledge_Graphs.pdf)\r\n* Part II: Graph Neural Networks\r\n\t* Chapter 5: [The Graph Neural Network Model](https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book-Chapter_5-GNNs.pdf)\r\n\t* Chapter 6: [Graph Neural Networks in Practice](https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book-Chapter_6-GNNs_in_Practice.pdf)\r\n\t* Chapter 7: [Theoretical Motivations](https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book-Chapter_7-GNN_Theory.pdf)\r\n* Part III: Generative Graph Models\r\n\t* Chapter 8: [Traditional Graph Generation Approaches](https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book-Chapter_8-Traditional_Graph_Generation.pdf)\r\n\t* Chapter 9: [Deep Generative Models](https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book-Chapter_9-Deep_Graph_Generation.pdf)\r\n* [Bibliography](https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book-Bibliography.pdf)","links":[{"article_link":"https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book.pdf","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.cs.mcgill.ca/~wlh/grl_book/"}]},{"id":2201,"title":"Configuring Google Colab Like A Pro","description":"How to Do Research Quality Machine Learning on a Budget.","tags":["article","code","notebook","tutorial","jupyter","gpu","google-colab","colab"],"details":"**Table of Contents:**\r\n\r\n* Make sure you don\u2019t get disconnected\r\n* Mount your drive for fast, responsible access to your datasets\r\n* Use wget to download datasets to your drive\r\n* Use Gdown to grab publicly available Google Drive files\r\n* The best way to connect your Github\r\n* Remote in through VSCode using SSH and ngrok\r\n* Run Tensorboard in Colab or in the browser\r\n* Use fastprogress when your code will take a while\r\n* Setup a telegram bot to update you during setup and training\r\n* Some paid addons worth considering\r\n* Addendum and extras","links":[{"article_link":"https://medium.com/@robertbracco1/configuring-google-colab-like-a-pro-d61c253f7573","code_link":"https://colab.research.google.com/drive/1yD_BhN7qSsp1auYNC-TET8gjP3ji8rOq","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2200,"title":"Bad passwords and the NIST guidelines","description":"Example project provided by DataCamp. In this project, you will write code that  automatically detects and flags the bad passwords.","tags":["code","tutorial","machine-learning","natural-language-processing","exploratory-data-analysis"],"details":"To complete this project, you need to know how to manipulate strings in pandas DataFrames and be familiar with regular expressions","links":[{"article_link":"","code_link":"https://github.com/OmarEltouny78/Bad_Passwords/tree/gh-pages","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2199,"title":"How to Set Up Continuous Integration for Machine Learning","description":"How to Set Up Continuous Integration for Machine Learning with Github Actions and Neptune: Step by Step Guide.","tags":["article","code","tutorial","deep-learning","experiment-tracking","mlops","github-actions","ci-cd","neptune"],"details":"In this step-by-step guide you will learn about how to set up a **CI pipeline for machine learning project** that automates the following scenario.\r\n\r\nSpecifically, on every Pull Request from branch `develop` to `master`:\r\n\r\n* Run model training and log all the experiment information to Neptune for both branches\r\n* Create a comment that contains a table showing diffs in parameters, properties, and metrics, links to experiments and experiment comparison in Neptune.","links":[{"article_link":"https://neptune.ai/blog/continuous-integration-for-machine-learning-with-github-actions-and-neptune","code_link":"https://github.com/neptune-ai/neptune-action","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2198,"title":"How to use Colab with GIT on your local machine","description":"In this post you will learn a very efficient way to use Colab when working on a project that will allow you control the files locally on your own computer.","tags":["article","git","colab"],"details":"Improve efficiency when working using Colab together with git.","links":[{"article_link":"https://medium.com/@hershkoy/how-to-use-colab-with-git-on-your-local-machine-1c95586967e","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2197,"title":"Volksdep","description":"An open-source toolbox for deploying and accelerating PyTorch, Onnx and Tensorflow models with TensorRT.","tags":["code","keras","onnx","pytorch","tensorflow","library","tensorrt"],"details":"volksdep is an open-source toolbox for deploying and accelerating PyTorch, Onnx and Tensorflow models with TensorRT.\r\n\r\n**Features**\r\n\r\n* Auto transformation and acceleration\r\nvolksdep can automatically transform and accelerate PyTorch, Onnx and Tensorflow models with TensorRT by writing only some few codes.\r\n* Auto benchmark\r\nvolksdep can automatically generate benchmark with given model.","links":[{"article_link":"","code_link":"https://github.com/Media-Smart/volksdep","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2196,"title":"Superconductor Analysis and Prediction","description":"TensorFlow is used to predict the critical temperature of superconductors.  This model gets an r-squared score of 96.11% with the predicted and actual results.","tags":["code","dataset","python","tensorflow","materials","streamlit","demo"],"details":"The objective of this was to understand TensorFlow and to use it in a scientific application in a domain that I understood.  I found the data from the UCI  ML data repository and I thought this was a great dataset to use.\r\n\r\nThe TensorFlow Neural Network contains 4 hidden layers and is a rather basic.  This does achieve an r-squared score 96.11%.  This is presented with Streamlit and is interactive to the extent of exploring finding a material that your are interested in and a table is shown with the actual and predicted critical temperatures.\r\n\r\nThere are interactive visualizations as well in the Streamlit app that explores the actual and predicted temperatures and an exploration of the entire dataset with the relevant information.\r\n\r\nThe next steps would be to apply Tensorflow to more datasets with classification, NLP, and recommendation objectives and projects in mind. ","links":[{"article_link":"","code_link":"https://github.com/AymanSulaiman/superconductor-analysis-and-prediction","research_link":"","media_link":"","dataset_link":"https://archive.ics.uci.edu/ml/datasets/Superconductivty+Data","demo_link":"https://superconductor-analysis.herokuapp.com/","other_link":""}]},{"id":2195,"title":"Streamlit Terran Timeline","description":"A face-recognition timeline generator tool for any kind of video!","tags":["code","library","computer-vision","face-detection","facial-recognition","streamlit","youtube","terran"],"details":"Creating face-recognition timelines on videos has never been so easy! Using the power of Terran we can easily build these timelines.\r\n\r\n![](https://raw.githubusercontent.com/pento-group/streamlit-terran-timeline/master/resources/animation.gif)","links":[{"article_link":"","code_link":"https://github.com/pento-group/streamlit-terran-timeline","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2194,"title":"Behavioral Testing of NLP Models","description":"Beyond Accuracy: Behavioral Testing of NLP models with CheckList.","tags":["code","paper","research","library","natural-language-processing","unit-tests","testing","checklist"],"details":"Although measuring held-out accuracy has\r\nbeen the primary approach to evaluate generalization, it often overestimates the performance\r\nof NLP models, while alternative approaches\r\nfor evaluating models either focus on individual tasks or on specific behaviors. Inspired\r\nby principles of behavioral testing in software\r\nengineering, we introduce CheckList, a taskagnostic methodology for testing NLP models. CheckList includes a matrix of general\r\nlinguistic capabilities and test types that facilitate comprehensive test ideation, as well as a\r\nsoftware tool to generate a large and diverse\r\nnumber of test cases quickly. We illustrate the\r\nutility of CheckList with tests for three tasks,\r\nidentifying critical failures in both commercial\r\nand state-of-art models. In a user study, a team\r\nresponsible for a commercial sentiment analysis model found new and actionable bugs in\r\nan extensively tested model. In another user\r\nstudy, NLP practitioners with CheckList created twice as many tests, and found almost\r\nthree times as many bugs as users without it.\r\n\r\n![](https://github.com/marcotcr/checklist/raw/master/notebooks/tutorials/visual_suggest.gif)","links":[{"article_link":"","code_link":"https://github.com/marcotcr/checklist","research_link":"https://homes.cs.washington.edu/~marcotcr/acl20_checklist.pdf","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2193,"title":"Effective testing for machine learning systems","description":"Why testing machine learning systems can be different, and discuss some strategies for writing effective tests for machine learning systems.","tags":["article","e2e-tests","unit-tests","testing","regression-tests"],"details":"In this blog post, we'll cover what testing looks like for traditional software development, why testing machine learning systems can be different, and discuss some strategies for writing effective tests for machine learning systems. We'll also clarify the distinction between the closely related roles of evaluation and testing as part of the model development process. By the end of this blog post, I hope you're convinced of both the extra work required to effectively test machine learning systems and the value of doing such work.\r\n\r\n![](https://dildehdrg5ol8.cloudfront.net/images/2193-4f414644b23e6687614b7f563d11306f.png)","links":[{"article_link":"https://www.jeremyjordan.me/testing-ml/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2192,"title":"PencilSketcher App - Web App using Streamlit, OpenCV, Python","description":"Built front-end using streamlit and then use Pencil Sketch Code (opencv) to build the back-end function  create a full-stack PencilSketcher Web App","tags":["code","tutorial","video","web-services","opencv","streamlit"],"details":"","links":[{"article_link":"","code_link":"https://github.com/amrrs/youtube-r-snippets/blob/master/pencilsketch_webapp.py","research_link":"","media_link":"https://www.youtube.com/watch?v=Q3f693wLkfc","dataset_link":"","demo_link":"","other_link":""}]},{"id":2191,"title":"Image Caption Generation","description":"Image Caption Generation is a challenging task where a textual description is generated given a picture. It needs both methods from Computer Vision and Natural ","tags":["code","tutorial","pytorch","convolutional-neural-networks","deep-learning","computer-vision","image-captioning","natural-language-processing"],"details":"- Quality Code\r\n- Proper project structure\r\n- Documentation\r\n\r\n![](https://github.com/msank00/image_caption_gen/raw/master/asset/experiment_flow.png)","links":[{"article_link":"","code_link":"https://github.com/msank00/image_caption_gen","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2190,"title":"Practical Data Ethics","description":"Course covering disinformation, bias, ethical foundations, privacy & surveillance, silicon valley ecosystem, and algorithmic colonialism.","tags":["course","surveillance","fairness","bias","ethics","ethical-ml","disinformation"],"details":"**Topics covered**:\r\n\r\n* Disinformation\r\n* Bias & Fairness\r\n* Ethical Foundations & Practical Tools\r\n* Privacy & surveillance\r\n* Our Ecosystem: Metrics, Venture Capital, & Losing the Forest for the Trees\r\n* Algorithmic Colonialism, and Next Steps\r\n\r\nData ethics covers an incredibly broad range of topics, many of which are urgent, making headlines daily, and causing harm to real people right now. A meta-analysis of over 100 syllabi on tech ethics, titled \u201cWhat do we teach when we teach tech ethics?\u201d found that there was huge variation in which topics are covered across tech ethics courses (law & policy, privacy & surveillance, philosophy, justice & human rights, environmental impact, civic responsibility, robots, disinformation, work & labor, design, cybersecurity, research ethics, and more\u2013 far more than any one course could cover). These courses were taught by professors from a variety of fields. The area where there was more unity was in outcomes, with abilities to critique, spot issues, and make arguments being some of the most common desired outcomes for tech ethics course.\r\n\r\nIn this course, we will focus on topics that are both urgent and practical. In keeping with my teaching philosophy, we will begin with two active, real-world areas (disinformation and bias) to provide context and motivation, before stepping back in Lesson 3 to dig into foundations of data ethics and practical tools. From there we will move on to additional subject areas: privacy & surveillance, the role of the Silicon Valley ecosystem (including metrics, venture growth, & hypergrowth), and algorithmic colonialism. I realize this course still just covers a slice of what is a sprawling field, and I hope that it will be a helpful entry point for continued exploration.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"http://ethics.fast.ai/"}]},{"id":2188,"title":"Great Expectations","description":"Always know what to expect from your data.","tags":["code","video","library","unit-tests","pandas","testing","demo","tests","great-expectations","data-quality"],"details":"Great Expectations helps data teams eliminate pipeline debt, through data testing, documentation, and profiling.\r\n\r\nSoftware developers have long known that testing and documentation are essential for managing complex codebases. Great Expectations brings the same confidence, integrity, and acceleration to data science and data engineering teams.\r\n\r\n* **How it works**: https://www.youtube.com/watch?v=YLy4NsioUVI\r\n* **Demo**: https://www.youtube.com/watch?v=uM9DB2ca8T8\r\n\r\n\r\n![](https://github.com/great-expectations/great_expectations/raw/develop/readme_assets/datadocs.gif)","links":[{"article_link":"","code_link":"https://github.com/great-expectations/great_expectations","research_link":"","media_link":"https://www.youtube.com/watch?v=YLy4NsioUVI","dataset_link":"","demo_link":"https://www.youtube.com/watch?v=uM9DB2ca8T8","other_link":"https://docs.greatexpectations.io/en/latest/"}]},{"id":2186,"title":"AI in Medicine and Imaging - Stanford Symposium 2020","description":"Through the AIMI Symposium we hope to address gaps and barriers in the field and catalyze more evidence-based solutions to improve health for all.","tags":["article","video","health","medicine","computer-vision","medical-imaging","stanford","videos"],"details":"Advancements of machine learning and artificial intelligence into all areas of medicine are now a reality and they hold the potential to transform healthcare and open up a world of incredible promise for everyone. Sponsored by the Stanford Center for Artificial Intelligence in Medicine and Imaging, the \r\n2020 AIMI Symposium is a virtual conference convening experts from Stanford and beyond to advance the field of AI in medicine and imaging. This conference will cover everything from a survey of the latest machine learning approaches, many use cases in depth, unique metrics to healthcare, important challenges and pitfalls, and best practices for designing building and evaluating machine learning in healthcare applications.  \r\n\r\nOur goal is to make the best science accessible to a broad audience of academic, clinical, and industry attendees. Through the AIMI Symposium we hope to address gaps and barriers in the field and catalyze more evidence-based solutions to improve health for all.\r\n\r\nTopic covered include:\r\n\r\n* Democratizing Healthcare with AI\r\n* Regulatory Considerations for AI in Healthcare\r\n* Technical Advancements in Clinical ML - What's New in 2020\r\n* Fairness in Clinical Machine Learning\r\n* Bridging Innovation to Application\r\nand more!","links":[{"article_link":"https://aimi.stanford.edu/news-events/aimi-symposium/agenda","code_link":"","research_link":"","media_link":"https://www.youtube.com/playlist?list=PLe6zdIMe5B7IR0oDOobXBDBlYY1eqLYPx","dataset_link":"","demo_link":"","other_link":"https://aimi.stanford.edu/"}]},{"id":2185,"title":"Language Interpretability Tool (LIT)","description":"The Language Interpretability Tool (LIT) is a visual, interactive model-understanding tool for NLP models.","tags":["code","library","interpretability","natural-language-processing"],"details":"The Language Interpretability Tool (LIT) is a visual, interactive model-understanding tool for NLP models.\r\n\r\nLIT is built to answer questions such as:\r\n\r\n* What kind of examples does my model perform poorly on?\r\n* Why did my model make this prediction? Can this prediction be attributed to adversarial behavior, or to undesirable priors in the training set?\r\n* Does my model behave consistently if I change things like textual style, verb tense, or pronoun gender?\r\n\r\n![](https://github.com/PAIR-code/lit/raw/main/docs/images/figure-1.png)","links":[{"article_link":"","code_link":"https://github.com/pair-code/lit/","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2184,"title":"From Hours to Seconds: 100x Faster Boosting, Bagging, & Stacking","description":"100x Faster Boosting, Bagging, and Stacking with RAPIDS cuML and Scikit-learn Machine Learning Model Ensembling.","tags":["article","code","tutorial","scikit-learn","boosting","cuml","rapids","emsembling","bagging","stacking"],"details":"In this post, we\u2019ll walk through how you can now use RAPIDS cuML with scikit-learn\u2019s ensemble model APIs to achieve more than 100x faster boosting, bagging, stacking, and more. This is possible because of the well-defined interfaces and use of duck typing in the scikit-learn codebase. Using cuML estimators as drop-in replacements mean data scientists can have their cake and eat it, too.","links":[{"article_link":"https://medium.com/rapids-ai/100x-faster-machine-learning-model-ensembling-with-rapids-cuml-and-scikit-learn-meta-estimators-d869788ee6b1","code_link":"https://gist.github.com/beckernick/3e94c62a28a6c10c0dda9456ff6cf24b","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2183,"title":"Generating music in the waveform domain","description":"Overview of generative models applied to music generation.","tags":["article","autoencoders","generative-adversarial-networks","variational-autoencoders","audio","music-generation","wavenet","waveforms"],"details":"* Motivation\r\n* Generative models\r\n* Likelihood-based models of waveforms\r\n* Adversarial models of waveforms\r\n* Discussion\r\n* Conclusion\r\n* References","links":[{"article_link":"https://benanne.github.io/2020/03/24/audio-generation.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2182,"title":"CryptoCRIT","description":"CryptoCRIT is an open-source Cryptocurrency project which facilitates a Cryptocurrency wallet for making payments. The associated Cryptocurrency is called CritC","tags":["article","code","paper","research","library","blockchain","cryptocurrency"],"details":"CryptoCRIT is an open-source Cryptocurrency project which facilitates a Cryptocurrency wallet for making payments. The associated Cryptocurrency is called CritCoin.#","links":[{"article_link":"https://theabbie.github.io/blog/CryptoCRIT","code_link":"https://github.com/rgab1508/CryptoCRIT","research_link":"https://www.researchgate.net/project/CryptoCRIT","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2179,"title":"Google Stock Price Prediction","description":"Using ALPHA VANTAGE API to predict google stock price.","tags":["code","flask","python","pandas","pyspark","kafka-python","al","alpha-vantage","boto3"],"details":"# Google Stock Price Prediction\r\n![Python 3.6](https://img.shields.io/badge/python-3.6.9-orange) ![pip-3](https://img.shields.io/badge/pip-9.0.1-green) ![Python-Kafka 2.0.1](https://img.shields.io/badge/kafka--python-2.0.1-red) ![Pyspark 3.0.0](https://img.shields.io/badge/pyspark-3.0.0-yellowgreen) ![s3fs 0.4.2](https://img.shields.io/badge/s3fs-0.4.2-blue) ![pandas 1.0.5](https://img.shields.io/badge/pandas-1.0.5-green)\r\n![alpha-vantage 2.2.0](https://img.shields.io/badge/alpha--vantage-2.2.0-critical) ![boto3 1.14.16](https://img.shields.io/badge/boto3-1.14.16-ff69b4) ![Flask 1.1.2](https://img.shields.io/badge/Flask-1.1.2-009e73)\r\n![GIF](https://github.com/shivamgupta7/Google-Stock-Price-Prediction/blob/master/readme_resources/stock_graph.gif?raw=true)\r\nUsing ALPHA VANTAGE API to predict google stock price.\r\n\r\n- Using [ALPHA VANTAGE](https://www.alphavantage.co/) to genrate API Key.\r\n\r\n- Using this API key to Download Google Stock Price data for each 1 min interval.\r\n\r\n- [Create S3 bucket](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-example-creating-buckets.html) using boto3. (Boto is the Amazon Web Services (AWS) SDK for Python. It enables Python developers to create, configure, and manage AWS services, such as EC2 and S3. Boto provides an easy to use, object-oriented API, as well as low-level access to AWS services.)\r\n\r\n- After creating [bucket upload](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-uploading-files.html) **stock data** into bucket using boto3.\r\n\r\n-  Reading data from S3 and doing some preprocessing.\r\n\r\n- After preprocessing train a Linear Regression model and save model weights.\r\n\r\n- Installing [kafka and zookeeper](https://tecadmin.net/install-apache-kafka-ubuntu/) into system and install [python-kafka](https://pypi.org/project/kafka-python/)\r\n\r\n- Start zookeeper and kafka server into local system and connect python-kafka to local host.\r\n\r\n- **Create a Topic in Kafka**\r\n\r\n    Create a topic in kafka using below query. Before create kafka topic you go to kafka folder.\r\n    ```\r\n    $cd /usr/local/kafka/\r\n\r\n    $bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic stock_prices\r\n    ```\r\n The replication-factor describes how many copies of data will be created. As we are running with a single instance keep this value 1.\r\n\r\nSet the partitions options as the number of brokers you want your data to be split between. As we are running with a single broker keep this value 1.\r\n\r\nYou can create multiple topics by running the same command as above. After that, you can see the created topics on Kafka by the running below command:\r\n\r\n    ```\r\n    bin/kafka-topics.sh --list --zookeeper localhost:2181\r\n    ```\r\n\r\n- **Send Messages to Kafka**\r\n\r\nThe **producer** is the process responsible for put data into our Kafka. The Kafka comes with a command-line client that will take input from a file or from standard input and send it out as messages to the Kafka cluster. The default Kafka sends each line as a separate message.\r\n\r\n    ```\r\n    bin/kafka-console-producer.sh --broker-list localhost:9092 --topic stock_prices\r\n    ```\r\n\r\n- **Using Kafka Consumer**\r\n\r\n    Kafka also has a command-line consumer to read data from the Kafka cluster and display messages to standard output.\r\n\r\n    The first argument is the topic, numtest in our case.\r\n    \r\n    bootstrap_servers=[\u2018localhost:9092\u2019]: same as our producer\r\n\r\n    ```\r\n    bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic stock_prices --from-beginning\r\n    ```\r\n- **Now using python KafkaProducer to connect the local kafka host**\r\n\r\n    bootstrap_servers=[\u2018localhost:9092\u2019]: sets the host and port the producer should contact to bootstrap initial cluster metadata. It is not necessary to set this here, since the default is localhost:9092.\r\n\r\n- **Using KafkaConsumer to predict stocks data**\r\n\r\n    Using **KafkaConsumer** to get data from producer. After geting data we load save model which save previously when train the model. Using these model we predict close value.\r\n\r\n- **Create Flask API**\r\n\r\n    In flask I have created 3 URL:\r\n\r\n    1. \"/\" for main page which rander stockgraph.html template for showing predicting close and actual close value.\r\n    2. \"/model-train\" this URL is use for train model.\r\n    3. \"/data\" this is for send data to stockgraph.html page for showing graph.\r\n\r\n## How To Run\r\n\r\n- First start zookeeper and kafka server.\r\n- Run producer file. (``` python3 consumer.py ```)\r\n- Run app file. (``` python3 app.py ```)\r\n![](https://github.com/shivamgupta7/Google-Stock-Price-Prediction/raw/master/readme_resources/how_to_run_project_on_localhost.gif)","links":[{"article_link":"","code_link":"https://github.com/shivamgupta7/Google-Stock-Price-Prediction","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2178,"title":"FasterAI","description":"How to make your network smaller and faster with the use of fastai library.","tags":["article","fastai","knowledge-distillation","model-compression","pruning","batch-normalization","sparsifying","batch-normalization-folding"],"details":"FasterAI is a project that I started to make my smaller and faster with the use of the fastai library. The techniques implemented here can easily be used with plain Pytorch but the idea was to express them in an abstract and easy-to-use manner (\u00e0 la fastai).\r\n\r\nIn this article, we'll explain how to use FasterAI by going through an example use-case.\r\n\r\n* Knowledge Distillation\r\n* Sparsifying\r\n* Pruning\r\n* Batch Normalization Folding\r\n* Batch Normalization Folding\r\n* FC Layers Factorization\r\n* References\r\n\r\n![](https://nathanhubens.github.io/posts/images/copied_from_nb/images/fasterai/KD.png)\r\n\r\n![](https://nathanhubens.github.io/posts/images/copied_from_nb/images/pruning/schedules.png)","links":[{"article_link":"https://nathanhubens.github.io/posts/deep learning/2020/08/17/FasterAI.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2177,"title":"Universal Data Tool","description":"Collaborate & label any type of data, images, text, or documents, in an easy web interface or desktop app.","tags":["article","code","library","annotation"],"details":"Try it out at [universaldatatool.com](https://universaldatatool.com) or [download it here](https://github.com/UniversalDataTool/universal-data-tool/releases).\r\n\r\nThe Universal Data Tool is a web/desktop app for editing and annotating images, text, audio, documents and to view and edit any data defined in the extensible [.udt.json and .udt.csv standard](https://github.com/UniversalDataTool/udt-format). \r\nFor video tutorials [visit our Youtube channel](https://www.youtube.com/channel/UCgFkrRN7CLt7_iTa2WDjf2g).\r\n\r\n<!-- COMMUNITY-UPDATE:START !-->\r\n* [Community Update Video 2](https://youtu.be/3bq9N08oc-U)\r\n* [Community Update Video 1](https://www.youtube.com/watch?v=QW-s4XVK3Ok&feature=youtu.be) [(blog version)](https://universaldatatool.substack.com/p/community-update-1)\r\n<!-- COMMUNITY-UPDATE:END !-->","links":[{"article_link":"https://dev.to/wafaa_arbash/label-bounding-boxes-with-the-universal-data-tool-mcc","code_link":"https://github.com/UniversalDataTool/universal-data-tool","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2176,"title":"Audio Class","description":"Web-based tool for straight-forward class annotation of audio files.","tags":["code","flask","library","annotation","audio"],"details":"This project came to life when I was messing around with a prototype of a neural network for audio classification. I needed a way to annotate some scrapped data that I collected, but was too lazy to open each of the hundreds of files and manually write down their respective classifications.\r\n\r\nWhile there are some great audio annotation tools out there with great features such as diarization, waveform visualization, speaker identification, etc, all I needed was a quick and dirty way to separate audio files in classes.\r\n\r\nIf you need complex annotation features, checkout some projects such as Audino, audio-annotator and dynitag. If, like me, you want a simple way to classify your data with minimal setup, AudioClass is here for you :)","links":[{"article_link":"","code_link":"https://github.com/glefundes/audio-class","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2175,"title":"EfficientNet: Rethinking Model Scaling for CNNs","description":"We take a look at the superior performance of EfficientNets compared to their counterparts and understand why we are looking into EfficientNets.","tags":["article","convolutional-neural-networks","efficientnet"],"details":"It brings me great pleasure as I begin writing about EfficientNets for two reasons:\r\n\r\n* At the time of writing, F[ixing the train-test resolution discrepancy: FixEfficientNet](https://arxiv.org/abs/2003.08237) (family of EfficientNet) is the current State of Art on ImageNet with 88.5% top-1 accuracy and 98.7% top-5 accuracy.\r\n* This blog post also sets up the base for future blog posts on [Self-training with Noisy Student improves ImageNet classification](https://arxiv.org/abs/1911.04252), [Fixing the train-test resolution discrepancy ](https://arxiv.org/abs/1906.06423)and [Fixing the train-test resolution discrepancy: FixEfficientNet](https://arxiv.org/abs/2003.08237).","links":[{"article_link":"https://amaarora.github.io/2020/08/13/efficientnet.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2174,"title":"Why I stopped using GAN \u2014 ECCV 2020","description":"In this article, we show how we outperformed GAN with Normalizing Flow.","tags":["article","code","paper","research","gan","normalizing-flow","srflow"],"details":"GAN \u2014 vs \u2014 Normalizing Flow\r\nThe benefits of Normalizing Flow. In this article, we show how we outperformed GAN with Normalizing Flow. We do that based on the application super-resolution. There we describe SRFlow, a super-resolution method that outperforms state-of-the-art GAN approaches. We explain it in detail in our ECCV 2020 paper.\r\n\r\n* Sampling: SRFlow outputs many different images for a single input.\r\n* Stable Training: SRFlow has much fewer hyperparameters than GAN approaches, and we did not encounter training stability issues.\r\n* Convergence: While GANs cannot converge, conditional Normalizing Flows converge monotonic and stable.\r\n* Higher Consistency: When downsampling the super-resolution, one obtains almost the exact input.","links":[{"article_link":"https://medium.com/@CVZurich/why-i-stopped-using-gan-eccv2020-d2b20dcfe1d","code_link":"https://github.com/andreas128/SRFlow","research_link":"http://de.arxiv.org/pdf/2006.14200/","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2173,"title":"Fine-tuning with custom datasets","description":"This tutorial will take you through several examples of using \ud83e\udd17 Transformers models with your own datasets.","tags":["article","code","notebook","tutorial","huggingface","transformers","fine-tuning","natural-language-processing","custom-datasets"],"details":"This tutorial will take you through several examples of using \ud83e\udd17 Transformers models with your own datasets. The guide shows one of many valid workflows for using these models and is meant to be illustrative rather than definitive. We show examples of reading in several data formats, preprocessing the data for several types of tasks, and then preparing the data into PyTorch/TensorFlow Dataset objects which can easily be used either with Trainer/TFTrainer or with native PyTorch/TensorFlow.\r\n\r\n","links":[{"article_link":"https://huggingface.co/transformers/master/custom_datasets.html","code_link":"https://colab.research.google.com/github/huggingface/notebooks/blob/master/transformers_doc/custom_datasets.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2172,"title":"Compression of Deep Learning Models for Text: A Survey","description":"In this survey, we discuss six different types of methods for compression of such models to enable their deployment in real industry NLP projects.","tags":["paper","research","transformers","knowledge-distillation","model-compression","natural-language-processing","pruning","quantization","survey","parameter-sharing","tensor-decomposition","linear-transformers","arxiv:2008.05221"],"details":"In recent years, the fields of natural language processing (NLP) and information retrieval (IR) have made tremendous progress thanks to deep learning models like Recurrent Neural Networks (RNNs), Gated Recurrent Units (GRUs) and Long Short-Term Memory (LSTMs) networks, and Transformer based models like Bidirectional Encoder Representations from Transformers (BERT). But these models are humongous in size. On the other hand, real world applications demand small model size, low response times and low computational power wattage. In this survey, we discuss six different types of methods:\r\n\r\n* Pruning\r\n* Quantization\r\n* Knowledge Distillation\r\n* Parameter Sharing\r\n* Tensor Decomposition\r\n* Linear Transformer\r\n\r\nfor compression of such models to enable their deployment in real industry NLP projects. Given the critical need of building applications with efficient and small models, and the large amount of recently published work in this area, we believe that this survey organizes the plethora of work done by the 'deep learning for NLP' community in the past few years and presents it as a coherent story.\r\n","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2008.05221","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2171,"title":"Chex","description":"Chex is a library of utilities for helping to write reliable JAX code.","tags":["code","jax","library","unit-tests","testing","chex"],"details":"Chex is a library of utilities for helping to write reliable JAX code.\r\n\r\nThis includes utils to help:\r\n\r\n* Instrument your code (e.g. assertions)\r\n* Debug (e.g. transforming pmaps in vmaps within a context manager).\r\n* Test JAX code across many variants (e.g. jitted vs non-jitted).","links":[{"article_link":"","code_link":"https://github.com/deepmind/chex","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2170,"title":"TensorFlow.js + Firebase","description":"Use Firebase Hosting to deploy and host a machine learning model at scale.","tags":["article","tutorial","tensorflow","tensorflow-js","production","firebase","serving"],"details":"So you've created a custom machine learning model with TensorFlow.js but now you need to host it somewhere to use on a website of your choice. There are many options to do this, but today we shall see how easy it is to use [Firebase Hosting](https://firebase.google.com/docs/hosting) which can also give you some extra benefits such as versioning, serving models over a secure connection, and more out of the box.\r\n\r\n#### What you'll build\r\nIn this code lab you will create a full end to end system capable of hosting and running a custom saved TensorFlow.js model along with its related assets such as HTML, CSS, and JavaScript. We will make a very simple lightweight model that can predict a numerical output value given some input value (e.g. what is the price of a house given its square footage), and host it via Firebase Hosting so that it can be used at scale.\r\n\r\n#### What you'll learn\r\n* How to save a custom TensorFlow.js model in the right format\r\n* How to setup a Firebase account for hosting\r\n* How to deploy your assets to Firebase Hosting\r\n* How to deploy new versions of a model.","links":[{"article_link":"https://codelabs.developers.google.com/codelabs/tensorflowjs-firebase-hosting-model/index.html?index=../..index","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2169,"title":"Molemash","description":"A mole moves randomly in the canvas area. A touch of the mole results in a score value by one(1). There are four(4) different levels with different requirement.","tags":["research","python","demo"],"details":"The scope of this project is to develop a simple game called Mole Mash using the MIT App Inventor (https://appinventor.mit.edu/). MIT App Inventor provides a platform to drag and drop visual objects in order to create an application that can run on android devices.\r\nA mole pops up at random positions on a playing field, and the player scores points by hitting the mole before it jumps away. The game features various levels in which the background changes as the player proceeds through the game.\r\n","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"http://ai2.appinventor.mit.edu/?galleryId=5567159640391680","other_link":""}]},{"id":2168,"title":"Onceupon.space","description":"NLP experiment in story-telling  that creates illustrations (text to sketch) and content (text generation)","tags":["dataset","video","gpt","transformers","natural-language-processing","text-generation","demo"],"details":"Onceupon.space is the Lego for storybooks. It allows users to build their own characters of their stories from the ground up and with the magical help of NLP, express their stories through colorful illustrations.\r\n\r\n1. Text to sketch - An NLP engine that analyses the user's sentence to understand what characters and their qualities. Qualities of characters include metrics like how many? where? what size? what color etc. The NLP engine is deployed on a scalable serverless containers.\r\n2. Text generation engine - The text generation engine is a fine-tuned GPT2 model deployed on a scalable serverless container.\r\nOur system works with the following strategy, initially, the first step selects the best potential set of character from the given text input from which we can possibly generate the questions. The next step(second step) is to find the descriptive attributes around the subject (attributes like how many characters and the size). In the third step, we will convert the user given character to its correct grammatical singular form and check if that particular character is in the dataset. If it is present, the coordinates for the dataset are downloaded and are displayed on th canvas.\r\n\r\nFor text generation, the system sums up the story written so far and feeds it to the GPT2 model deployed on the serverless container with other attributes like output sequence length, temperature, samples to be regenerated, and size of the output samples.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://devmesh.intel.com/projects/onceupon-space-textgeneration-and-text2sketch","dataset_link":"https://quickdraw.withgoogle.com/","demo_link":"https://onceupon.space","other_link":"https://www.youtube.com/watch?v=o5z3stggmt8&t=1s"}]},{"id":2167,"title":"Insight","description":"Project Insight is designed to create NLP as a service with code base for both front end GUI (streamlit) and backend server (FastAPI) the usage of transformers ","tags":["api","code","docker","fastapi","huggingface","pytorch","attention","bert","transformers","named-entity-recognition","natural-language-processing","sentiment-analysis","text-summarization","transfer-learning","streamlit"],"details":"Project Insight is designed to create NLP as a service with code base for both front end GUI (streamlit)  and backend server (FastApi) the usage of transformers models on various downstream NLP task.\r\nThe downstream NLP tasks covered:\r\n\r\n\r\n1. News Classification\r\n2. Entity Recognition\r\n3. Sentiment Analysis\r\n4. Summarization\r\n5. Information Extraction (To Do)\r\n\r\n\r\nThe user can select different models from the drop down to run the inference.\r\nThe users can also directly use the backend fastapi server to have a command line inference.\r\n\r\nFeatures of the solution\r\n\r\n**Python Code Base**: Built using Fastapi and Streamlit making the complete code base in Python.\r\n\r\n**Expandable**: The backend is desinged in a way that it can be expanded with more Transformer based models and it will be available in the front end app automatically.","links":[{"article_link":"","code_link":"https://github.com/abhimishra91/insight","research_link":"","media_link":"https://youtu.be/xlJXtsH6_-s","dataset_link":"","demo_link":"","other_link":""}]},{"id":2166,"title":"Pix2Pix","description":"Tensorflow 2.0 Implementation of the paper Image-to-Image Translation using Conditional GANs by Philip Isola, Jun-Yan Zhu, Tinghui Zhou and Alexei A. Efros.","tags":["code","paper","research","keras","tensorflow","generative-adversarial-networks","computer-vision","pix2pix","activation-functions","arxiv:1611.07004","conditional-gan","mish"],"details":"# Pix2Pix\r\n\r\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/soumik12345/Pix2Pix/master)\r\n[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/image-to-image-translation-with-conditional/image-to-image-translation-on-aerial-to-map)](https://paperswithcode.com/sota/image-to-image-translation-on-aerial-to-map?p=image-to-image-translation-with-conditional)\r\n[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/image-to-image-translation-with-conditional/image-to-image-translation-on-cityscapes)](https://paperswithcode.com/sota/image-to-image-translation-on-cityscapes?p=image-to-image-translation-with-conditional)\r\n[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/image-to-image-translation-with-conditional/image-to-image-translation-on-cityscapes-1)](https://paperswithcode.com/sota/image-to-image-translation-on-cityscapes-1?p=image-to-image-translation-with-conditional)\r\n\r\n\r\nTensorflow 2.0 Implementation of the paper [Image-to-Image Translation using Conditional GANs](https://arxiv.org/abs/1611.07004) by [Philip Isola](https://arxiv.org/search/cs?searchtype=author&query=Isola%2C+P), [Jun-Yan Zhu](https://arxiv.org/search/cs?searchtype=author&query=Zhu%2C+J), [Tinghui Zhou](https://arxiv.org/search/cs?searchtype=author&query=Zhou%2C+T) and [Alexei A. Efros](https://arxiv.org/search/cs?searchtype=author&query=Efros%2C+A+A).\r\n\r\n## Experiments with Standard Architecture\r\n\r\n### Experiment 1\r\n\r\n**Resource Credits:** Trained on Nvidia Quadro M4000 provided by [Paperspace Gradient](https://gradient.paperspace.com/).\r\n\r\n**Dataset:** [Facades](https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/facades.tar.gz)\r\n\r\n**Result:**\r\n\r\n![Experiment 1 Result](https://raw.githubusercontent.com/soumik12345/Pix2Pix/master/assets/exp_1_gif.gif)\r\n\r\n### Experiment 2\r\n\r\n**Resource Credits:** Trained on Nvidia Quadro P5000 provided by [Paperspace Gradient](https://gradient.paperspace.com/).\r\n\r\n**Dataset:** [Maps](https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/maps.tar.gz)\r\n\r\n**Result:**\r\n\r\n![Experiment 2 Result](https://raw.githubusercontent.com/soumik12345/Pix2Pix/master/assets/exp_2_gif.gif)\r\n\r\n### Experiment 3\r\n\r\n**Resource Credits:** Trained on Nvidia Tesla V100 provided by [DeepWrex Technologies](https://deepwrex.com/).\r\n\r\n**Dataset:** [Cityscapes](https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/cityscapes.tar.gz)\r\n\r\n**Result:**\r\n\r\n![Experiment 3 Result](https://raw.githubusercontent.com/soumik12345/Pix2Pix/master/assets/exp_3_gif.gif)\r\n\r\n## Experiments with Mish Activation Function\r\n\r\n### [Experiment 1 Mish\r\n\r\n**Resource Credits:** Trained on Nvidia Quadro P5000 provided by [Paperspace Gradient](https://gradient.paperspace.com/).\r\n\r\n**Dataset:** [Facades](https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/facades.tar.gz)\r\n\r\n**Generator Architecture:**\r\n\r\n- The Generator is a Unet-Like model with skip connections between encoder and decoder.\r\n- Encoder Block is ```Convolution -> BatchNormalization -> Activation (Mish)```\r\n- Decode Blocks is ```Conv2DTranspose -> BatchNormalization -> Dropout (optional) -> Activation (Mish)```\r\n\r\n**Discriminator:**\r\n\r\n- PatchGAN Discriminator\r\n- Discriminator Block is ```Convolution -> BatchNormalization -> Activation (Mish)```\r\n\r\n**Result:**\r\n\r\n![Experiment 1 Mish Result](https://raw.githubusercontent.com/soumik12345/Pix2Pix/master/assets/mish_exp_1.gif)\r\n\r\n### [Experiment 2 Mish](./Pix2Pix_Maps_Mish.ipynb)\r\n\r\n**Resource Credits:** Trained on Nvidia Tesla P100 provided by [Google Colab](https://colab.research.google.com/).\r\n\r\n**Dataset:** [Facades](https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/maps.tar.gz)\r\n\r\n**Generator Architecture:**\r\n\r\n- The Generator is a Unet-Like model with skip connections between encoder and decoder.\r\n- Encoder Block is ```Convolution -> BatchNormalization -> Activation (Mish)```\r\n- Decode Blocks is ```Conv2DTranspose -> BatchNormalization -> Dropout (optional) -> Activation (Mish)```\r\n\r\n**Discriminator:**\r\n\r\n- PatchGAN Discriminator\r\n- Discriminator Block is ```Convolution -> BatchNormalization -> Activation (ReLU)```\r\n\r\n**Result:**\r\n\r\n![Experiment 2 Mish Result](https://raw.githubusercontent.com/soumik12345/Pix2Pix/master/assets/mish_exp_2.gif)\r\n\r\n### Experiment 3 Mish\r\n\r\n**Resource Credits:** Trained on Nvidia Quadro P5000 provided by [Paperspace Gradient](https://gradient.paperspace.com/).\r\n\r\n**Dataset:** [Facades](https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/maps.tar.gz)\r\n\r\n**Generator Architecture:**\r\n\r\n- The Generator is a Unet-Like model with skip connections between encoder and decoder.\r\n- Encoder Block is ```Convolution -> BatchNormalization -> Activation (Mish)```\r\n- Decode Blocks is ```Conv2DTranspose -> BatchNormalization -> Dropout (optional) -> Activation (Mish)``` for the first three blocks are ```Conv2DTranspose -> BatchNormalization -> Dropout (optional) -> Activation (ReLU)```\r\n\r\n**Discriminator:**\r\n\r\n- PatchGAN Discriminator\r\n- Discriminator Block is ```Convolution -> BatchNormalization -> Activation (ReLU)```\r\n\r\n**Result:**\r\n\r\n![Experiment 3 Mish Result](https://raw.githubusercontent.com/soumik12345/Pix2Pix/master/assets/mish_exp_3.gif)","links":[{"article_link":"","code_link":"https://github.com/soumik12345/Pix2Pix","research_link":"https://arxiv.org/abs/1611.07004","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2165,"title":"Implementing an Autoencoder in PyTorch","description":"Building an autoencoder model for reconstruction.","tags":["article","code","tutorial","pytorch","autoencoders","variational-autoencoders"],"details":"This is the PyTorch equivalent of my previous article on implementing an autoencoder in TensorFlow 2.0, which you may read through the following [link](http://towardsdatascience.com/implementing-an-autoencoder-in-tensorflow-2-0-5e86126e9f7).","links":[{"article_link":"https://medium.com/pytorch/implementing-an-autoencoder-in-pytorch-19baa22647d1","code_link":"https://gist.github.com/AFAgarap/4f8a8d8edf352271fa06d85ba0361f26","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2164,"title":"Intro to Autoencoders","description":"This tutorial introduces autoencoders with three examples: the basics, image denoising, and anomaly detection.","tags":["article","code","notebook","tutorial","tensorflow","autoencoders","anomaly-detection","computer-vision","denoising","time-series","image-denoising"],"details":"This tutorial introduces autoencoders with three examples: the basics, image denoising, and anomaly detection.\r\n\r\nAn autoencoder is a special type of neural network that is trained to copy its input to its output. For example, given an image of a handwritten digit, an autoencoder first encodes the image into a lower dimensional latent representation, then decodes the latent representation back to an image. An autoencoder learns to compress the data while minimizing the reconstruction error.\r\n\r\nTo learn more about autoencoders, please consider reading chapter 14 from [Deep Learning](https://www.deeplearningbook.org/) by Ian Goodfellow, Yoshua Bengio, and Aaron Courville.","links":[{"article_link":"https://www.tensorflow.org/tutorials/generative/autoencoder","code_link":"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/autoencoder.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2163,"title":"Safe Space - Github Action","description":"Github action that checks the toxicity level of comments and PR reviews to help make repos safe spaces.","tags":["code","tensorflow-js","natural-language-processing","sentiment-analysis","github-actions","demo","toxicity"],"details":"Github action that uses machine learning to detect potential toxic comments added to PRs and issues so authors can have a chance to edit them and keep repos a safe space.\r\n\r\nIt uses the [Tensorflow.js toxicity classification model](https://github.com/tensorflow/tfjs-models/tree/master/toxicity).\r\n\r\nIt currently works when comments are posted on issues and PRs, as well as when pull request reviews are submitted.\r\n\r\n![](https://github.com/charliegerard/safe-space/raw/master/demo.gif)","links":[{"article_link":"","code_link":"https://github.com/charliegerard/safe-space","research_link":"","media_link":"","dataset_link":"","demo_link":"https://github.com/charliegerard/safe-space/pull/1","other_link":"https://github.com/tensorflow/tfjs-models/tree/master/toxicity"}]},{"id":2161,"title":"ff-net","description":"Feedforward neural network learning in real time.","tags":["article","code","feed-forward-neural-networks","machine-learning","interactive","demo","ff-net"],"details":"A neural net adapting its weights to match a dataset you can modify in real time.","links":[{"article_link":"","code_link":"https://github.com/juniorrojas/ff-net","research_link":"","media_link":"","dataset_link":"","demo_link":"http://juniorrojas.com/ff-net/","other_link":""}]},{"id":2160,"title":"Optax","description":"Optax is a gradient processing and optimization library for JAX.","tags":["code","jax","library","optimization","gradients"],"details":"Optax is a gradient processing and optimization library for JAX.\r\n\r\nOptax is designed to facilitate research by providing building blocks that can be easily recombined in custom ways.\r\n\r\nOur goals are to:\r\n\r\n* provide simple, well-tested, efficient implementations of core components,\r\n* improve research productivity by enabling to easily combine low level ingredients into custom optimiser (or other gradient processing components).\r\n* accelerate adoption of new ideas by making it easy for anyone to contribute.","links":[{"article_link":"","code_link":"https://github.com/deepmind/optax","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2159,"title":"Solaris","description":"CosmiQ Works Geospatial Machine Learning Analysis Toolkit.","tags":["code","library","computer-vision","geospatial","gis","cosmiq"],"details":"This repository provides the source code for the CosmiQ Works solaris project, which provides software tools for:\r\n\r\n* Tiling large-format overhead images and vector labels\r\n* Converting between geospatial raster and vector formats and machine learning-compatible formats\r\n* Performing semantic and instance segmentation, object detection, and related tasks using deep learning models designed specifically for overhead image analysis\r\n* Evaluating performance of deep learning model predictions","links":[{"article_link":"","code_link":"https://github.com/CosmiQ/solaris","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://solaris.readthedocs.io/en/latest/"}]},{"id":2157,"title":"Gspread: Google Sheets API using Python","description":"Complete guide on how to access/edit Google Sheets using Python. Detailed code examples and explanations of gspread library.","tags":["api","article","code","tutorial","python","library","program-development","gspread"],"details":"In this article we will discuss how to access and edit Google Sheets using Python.\r\n\r\n**Table of Contents**\r\n\r\n* Introduction\r\n* Creating a sample Google Sheets document\r\n* Creating Google API credentials\r\n* Opening a Google sheet using Python\r\n* Selecting/creating/deleting a worksheet using Python\r\n* Editing data in a Google sheet using Python\r\n* Conclusion","links":[{"article_link":"https://pyshark.com/google-sheets-api-using-python/","code_link":"https://github.com/burnash/gspread","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://gspread.readthedocs.io/en/latest/"}]},{"id":2156,"title":"Energy Based Models (EBMs): A comprehensive introduction","description":"In this article, I describe the general concept of Energy Based Models (EBMs), and a specific family of EBM called Boltzmann Machine.","tags":["article","research","tutorial","energy","energy-based-models","graphical-models"],"details":"There exists a class of models conveniently represented by Undirected Graphical Models which are practiced relative less than modern methods of Deep Learning (DL) in the research community. They are also characterized as Energy Based Models (EBM), as we shall see, they rely on something called Energy Functions. In the early days of this Deep Learning renaissance, we discovered few extremely powerful models which helped DL to gain momentum. The class of models we are going to discuss has far more theoretical support than modern day Deep Learning, which as we know, largely relied on intuition and trial-and-error. In this article, I will introduce you to the general concept of Energy Based Models (EBMs), their difficulties and how we can get over them. Also, we will look at a specific family of EBM known as Boltmann Machines (BM) which are very well known in the literature.\r\n\r\n","links":[{"article_link":"https://dasayan05.github.io/blog-tut/2020/08/13/energy-based-models-one.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2155,"title":"GPT-3, The model simply knows!","description":"Brief Introduction about the gigantic GPT-3. a new leap in AI and Natural Language processing. ","tags":["article","tutorial","deep-learning","machine-learning","natural-language-processing","conversational-ai","data-science","openai","gpt3","blogpost"],"details":"","links":[{"article_link":"https://blog.datavalley.technology/2020/08/14/gpt-3-the-model-simply-knows/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2151,"title":"Drowsiness Detection System using OpenCV and Flask in Python ","description":"This system provides an overview of a system that detects whether a person is drowsy while driving and if so, alerts him by using voice messages in real-time. ","tags":["article","code","video","css","flask","html","python","computer-vision","opencv","demo","drowsiness-detection"],"details":"We are on our way to convert this to an android application for better reach.","links":[{"article_link":"https://towardsdatascience.com/drowsiness-detection-system-in-real-time-using-opencv-and-flask-in-python-b57f4f1fcb9e","code_link":"https://github.com/fear-the-lord/Drowsiness-Detection","research_link":"","media_link":"https://youtu.be/wG6EM2s9yNg","dataset_link":"","demo_link":"https://www.youtube.com/watch?v=YyIMsBBEukw&t=6s","other_link":""}]},{"id":2150,"title":"Let's Not Chuck ","description":"In the sport of cricket, throwing, commonly referred to as chucking, is an illegal bowling action which occurs when a bowler straightens the bowling arm when de","tags":["article","code","posenet","demo","ml5js"],"details":"","links":[{"article_link":"","code_link":"https://github.com/fear-the-lord/Lets-not-Chuck","research_link":"","media_link":"https://youtu.be/brfo2NRzb78","dataset_link":"","demo_link":"https://fear-the-lord.github.io/Lets-not-Chuck/","other_link":""}]},{"id":2149,"title":"Python Decorators 101","description":"In this course on Python decorators, you\u2019ll learn what they are and how to create and use them. ","tags":["article","course","tutorial","python","decorators"],"details":"In this course on Python decorators, you\u2019ll learn what they are and how to create and use them. Decorators provide a simple syntax for calling higher-order functions in Python. By definition, a decorator is a function that takes another function and extends the behavior of the latter function without explicitly modifying it.","links":[{"article_link":"https://realpython.com/courses/python-decorators-101/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2148,"title":"txtai: AI-powered search engine","description":"AI-powered search engine.","tags":["code","transformers","library","natural-language-processing","search","faiss"],"details":"txtai builds an AI-powered index over sections of text. txtai supports building text indices to perform similarity searches and create extractive question-answering based systems.\r\n\r\n#### Notebooks\r\n\r\n* [Introducing txtai](https://github.com/neuml/txtai/blob/master/examples/01_Introducing_txtai.ipynb)  | Overview of the functionality provided by txtai  \r\n* [Extractive QA with txtai](https://github.com/neuml/txtai/blob/master/examples/02_Extractive_QA_with_txtai.ipynb)  | Extractive question-answering with txtai  \r\n* [Build an Embeddings index from a data source](https://github.com/neuml/txtai/blob/master/examples/03_Build_an_Embeddings_index_from_a_data_source.ipynb)  | Embeddings index from a data source backed by word embeddings \r\n* [Extractive QA with Elasticsearch](https://github.com/neuml/txtai/blob/master/examples/04_Extractive_QA_with_Elasticsearch.ipynb)  | Extractive question-answering with Elasticsearch \r\n\r\n![](https://raw.githubusercontent.com/neuml/txtai/master/demo.gif)\r\n\r\nNeuML uses txtai and/or the concepts behind it to power all of our Natural Language Processing (NLP) applications. Example applications:\r\n\r\n- [cord19q](https://github.com/neuml/cord19q) - COVID-19 literature analysis\r\n- [paperai](https://github.com/neuml/paperai) - AI-powered literature discovery and review engine for medical/scientific papers\r\n- [neuspo](https://neuspo.com) - a fact-driven, real-time sports event and news site\r\n- [codequestion](https://github.com/neuml/codequestion) - Ask coding questions directly from the terminal\r\n\r\ntxtai is built on the following stack:\r\n\r\n- [sentence-transformers](https://github.com/UKPLab/sentence-transformers)\r\n- [transformers](https://github.com/huggingface/transformers)\r\n- [faiss](https://github.com/facebookresearch/faiss)\r\n- Python 3.6+\r\n","links":[{"article_link":"","code_link":"https://github.com/neuml/txtai","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2147,"title":"Practical Tips and Tricks for Successful Transfer Learning","description":"Training models to learn knowledge and skills from other related tasks that will transfer and boost performance on tasks of interest.","tags":["paper","research","tutorial","video","natural-language-processing","transfer-learning","pretraining","arxiv:2005.00628"],"details":"Yada Pruksachatkun (https://www.yadapruk.com/) presenting on transfer learning, which focuses on training models to learn knowledge and skills from other related tasks that will transfer and boost performance on tasks of interest. Yada is an incoming Applied Scientist at Amazon Alexa working on fairness and bias in NLU. She recently completed graduate school at NYU, where her research on transfer learning was recently presented at 2020 ACL (https://arxiv.org/abs/2005.00628).","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2005.00628","media_link":"https://www.youtube.com/watch?v=-Z6Ygh5zMvs","dataset_link":"","demo_link":"","other_link":""}]},{"id":2145,"title":"Predicting Credit Card Approvals","description":"Project provided by DataCamp. Automating  reviews for credit card applications","tags":["code","research","banking","finance"],"details":"Commercial banks receive a lot of applications for credit cards. Many of them get rejected for many reasons, like high loan balances, low income levels, or too many inquiries on an individual's credit report, for example. Manually analyzing these applications is mundane, error-prone, and time-consuming (and time is money!). Luckily, this task can be automated with the power of machine learning and pretty much every commercial bank does so nowadays. In this project, you will build an automatic credit card approval predictor using machine learning techniques, just like the real banks do.","links":[{"article_link":"","code_link":"https://github.com/OmarEltouny78/CreditCardPrediction","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2141,"title":"hloc - the hierarchical localization toolbox","description":"Visual localization made easy.","tags":["code","paper","research","video","convolutional-neural-networks","library","computer-vision","object-localization","localization","hierarchical-localization","arxiv:1812.03506"],"details":"This is `hloc`, a modular toolbox for state-of-the-art 6-DoF visual localization. It implements [Hierarchical Localization](https://arxiv.org/abs/1812.03506), leveraging image retrieval and feature matching, and is fast, accurate, and scalable. This codebase won the indoor/outdoor [localization challenge at CVPR 2020](https://sites.google.com/view/vislocslamcvpr2020/home), in combination with [SuperGlue](https://psarlin.com/superglue/), our graph neural network for feature matching.\r\n\r\nWith `hloc`, you can:\r\n\r\n- Reproduce [our CVPR 2020 winning results](https://www.visuallocalization.net/workshop/cvpr/2020/) on outdoor (Aachen) and indoor (InLoc) datasets\r\n- Run Structure-from-Motion with SuperPoint+SuperGlue to localize with your own datasets\r\n- Evaluate your own local features or image retrieval for visual localization\r\n- Implement new localization pipelines and debug them easily \ud83d\udd25\r\n\r\n![](https://github.com/cvg/Hierarchical-Localization/raw/master/doc/hloc.png)","links":[{"article_link":"","code_link":"https://github.com/cvg/Hierarchical-Localization/","research_link":"https://arxiv.org/abs/1812.03506","media_link":"https://www.youtube.com/watch?v=aOkLGcspoyY","dataset_link":"","demo_link":"","other_link":""}]},{"id":2140,"title":"EduKC","description":"Our app helps parents and kids to better choose and plan education programs outside of public-school systems using ML and DL to make personalized suggestions.","tags":["article","code","dataset","research","tutorial","angular","keras","latent-dirichlet-allocation","education","recommendation-systems","demo"],"details":"**EduKC**\r\n\r\nOur app helps parents and kids to better choose and plan education resources outside of public-school systems. This app will look like a trip planner: the user provides budget, time, locations, the kids\u2019 gender, age, and interest. The app can make recommendations on afterschool programs, particularly affordable or free programs to lower income families.\r\n\r\nThe family can use this app to choose available and affordable after school programs andmake their weekly or monthly schedule.\r\n\r\n![EduKC](https://user-images.githubusercontent.com/1732922/83943827-909f2980-a7c4-11ea-8529-777c6b61f97c.gif)\r\n\r\n[Demo](https://youtu.be/nHUPgjWIf2c) on YouTube","links":[{"article_link":"http://ocel.ai/machine-learning-applications-edukc/","code_link":"https://github.com/srichakradhar/Edu-KC","research_link":"","media_link":"https://drive.google.com/file/d/1ikD4B1K-AvZ9Ubu0ppNj6yw2YPmuIpUC/view?usp=sharing","dataset_link":"https://app.box.com/s/jjegtpjco9pwxwmw54fvhz8ki3gl7o7v","demo_link":"http://edukc.s3-website-us-east-1.amazonaws.com/","other_link":"http://ocel.ai/k-12-educational-camps-during-the-spring-break/"}]},{"id":2138,"title":"Extract Stock Sentiment from News Headlines","description":" In this project, you will generate investing insight by applying sentiment analysis on financial news headlines from Finviz. ","tags":["code","research","finance","natural-language-processing","sentiment-analysis"],"details":"The datasets used in this project are raw HTML files for the Facebook (FB) and Tesla (TSLA) stocks from FINVIZ.com, a popular website dedicated to stock information and news.","links":[{"article_link":"","code_link":"https://github.com/OmarEltouny78/Sentiment-Analysis","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2137,"title":"Unpopular Opinion - Data Scientists Should Be More End-to-End","description":"I believe data scientists can be more effective by being end-to-end.","tags":["article","full-stack","mlops","career"],"details":"IMHO, I believe data scientists can be more effective by being end-to-end. Here, I\u2019ll discuss the [benefits](https://eugeneyan.com/writing/end-to-end-data-science/#from-start-identify-the-problem-to-finish-solve-it) and [counter-arguments](https://eugeneyan.com/writing/end-to-end-data-science/#but-we-need-specialist-experts-too), [how to](https://eugeneyan.com/writing/end-to-end-data-science/#the-best-way-to-pick-it-up-is-via-learning-by-doing) become end-to-end, and the experiences of [Stitch Fix and Netflix](https://eugeneyan.com/writing/end-to-end-data-science/#end-to-end-in-stitch-fix-and-netflix).","links":[{"article_link":"https://eugeneyan.com/writing/end-to-end-data-science/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2136,"title":"Machine Learning Deployment: Shadow Mode","description":"\u201cHow do I test my new model in production?\u201d One answer, and a method I often employ when initially deploying models, is shadow mode.","tags":["article","production","deployment","shadow-mode"],"details":"Deploying a machine learning product so that it can be used is essential to getting value out of it. But it is one of the hardest parts of building the product.\r\n\r\nIn this post I will focus on a small piece of deployment: \u201cHow do I test my new model in production?\u201d One answer, and a method I often employ when initially deploying models, is **shadow mode**.\r\n\r\nShadow mode is a great way to test a few things:\r\n\r\n* **Engineering**: With a shadow model you can test that the \u201cpipeline\u201d is working: the model is getting the inputs it expects, and it is returning results in the correct format. You can also verify that the latency is not too high.\r\n* **Outputs**: You can verify that the distribution of results looks the way you expect (for example, your model is not reporting just a single value for all input).\r\n* **Performance**: You can verify that the shadow model is producing results that are comparable to or better than those of the live model.\r\n![](https://dildehdrg5ol8.cloudfront.net/images/2136-28de15a936f3454f3f065933d91f86e6.png)","links":[{"article_link":"https://alexgude.com/blog/machine-learning-deployment-shadow-mode/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2135,"title":"Temporal Convolutional Networks for Time-Series","description":"We introduce several novels using TCN, including improving traffic prediction, sound event localization & detection, and probabilistic forecasting.","tags":["article","temporal-cnn","forecasting","time-series","cnn","detection","localization"],"details":"We introduce several novels using TCN, including improving traffic prediction, sound event localization & detection, and probabilistic forecasting.","links":[{"article_link":"https://towardsdatascience.com/temporal-convolutional-networks-the-next-revolution-for-time-series-8990af826567","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2134,"title":"Machine Learning of Sets","description":"We will consider set-to-vector, vector-to-set, and set-to-set problems and provide implementations of simple algorithms in JAX and Haiku.","tags":["article","jax","machine-learning","haiku","iid","sets"],"details":"One of the main assumptions we rely on is that the pairs of (x, y) points are independent and identically distributed (i.i.d.) random variables. Let us unpack this a bit, starting from the end,\r\n\r\n* **random variable**: there exists some stochastic generative process from which the variables were randomly sampled,\r\n* **identically**: all samples come from the same probability distribution,\r\n* **independent**: the generative process has no memory of generated samples, and hence any generated sample does not change the distribution over future generated samples.\r\n\r\nHowever, if a data point is not a vector, matrix, or a sequence of vectors, but it is a set of vectors, these dependencies become less clear. In particular, elements in an input set resemble elements in a dataset (i.e., lack of order), but the critical difference is that they are not independent, therefore breaking the i.i.d. assumption. Accounting for this specific structure in inputs or outputs of an ML model leads to a family of set learning problems, which have recently gained considerable attention in the machine learning community. I thought it would be useful to delve into the machine learning of sets. In the following, we will consider set-to-vector, vector-to-set, and set-to-set problems and provide implementations of simple algorithms in JAX and haiku.","links":[{"article_link":"http://akosiorek.github.io/ml/2020/08/12/machine_learning_of_sets.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2132,"title":"Adversarial robustness as a prior for better transfer learning","description":"We find that adversarially robust models, while less accurate, often perform better than their standard-trained counterparts when used for transfer learning.","tags":["article","code","paper","research","transfer-learning","adversarial-learning","imagenet","arxiv:2007.08489"],"details":"We find that adversarially robust models, while less accurate, often perform better than their standard-trained counterparts when used for transfer learning.\r\n\r\nIn our work we focus on computer vision and consider a standard transfer learning pipeline: \u201cImageNet pretraining.\u201d This pipeline trains a deep neural network on ImageNet, then tweaks this pretrained model for another target task, ranging from image classification of smaller datasets to more complex tasks like object detection and image segmentation.\r\n\r\nRefining the ImageNet pretrained model can be done in several ways. In our work we focus on two common methods:\r\n\r\n* **Fixed-feature transfer**: we replace the last layer of the neural network with a new layer that fits the target task. Then we train the last layer on the target dataset while keeping the rest of the layers fixed.\r\n* **Full-network transfer**: we do the same as in fixed-feature, but instead of fine-tuning the last layer only, we fine-tune the full model.\r\n\r\nThe full-network transfer setting typically outperforms the fixed-feature strategy in practice.\r\n\r\n![](https://www.microsoft.com/en-us/research/uploads/prod/2020/08/1400x788_AirSim_noLogo5secs-1.gif)","links":[{"article_link":"https://www.microsoft.com/en-us/research/blog/adversarial-robustness-as-a-prior-for-better-transfer-learning/","code_link":"https://github.com/microsoft/robust-models-transfer","research_link":"https://arxiv.org/abs/2007.08489","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2131,"title":"How to Trust Your Deep Learning Code","description":"We will focus on how to write reusable unit tests, so that you \u201cDon\u2019t repeat yourself\u201d.","tags":["article","code","tutorial","unit-tests","testing"],"details":"Our example will test the components of a system written in PyTorch that trains a variational autoencoder (VAE) on MNIST (creative, I know). You can find all of the code from this article at https://github.com/tilman151/unittest_dl.","links":[{"article_link":"https://krokotsch.eu/cleancode/2020/08/11/Unit-Tests-for-Deep-Learning.html","code_link":"https://github.com/tilman151/unittest_dl","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2128,"title":"AlphaPy: AutoML for Data Scientists and Speculators","description":"AlphaPy is an automated machine learning (AutoML) Python framework for Data Scientists and Speculators.","tags":["code","keras","scikit-learn","sports","automl","alphapy"],"details":"**AlphaPy** is a machine learning framework for both speculators and\r\ndata scientists. It is written in Python with the ``scikit-learn``,\r\n``pandas``, and ``Keras`` libraries, as well as many other helpful\r\nlibraries for feature engineering and visualization. Here are just\r\nsome of the things you can do with AlphaPy:\r\n\r\n* Run machine learning models using ``scikit-learn``, ``xgboost``, and ``Keras``.\r\n* Generate blended or stacked ensembles.\r\n* Create models for analyzing the markets with *MarketFlow*.\r\n* Predict sporting events with *SportFlow*.\r\n* Develop trading systems and analyze portfolios using *MarketFlow*\r\n\r\n![](https://github.com/Alpha314/AlphaPy/raw/master/images/model_pipeline.png)","links":[{"article_link":"","code_link":"https://github.com/ScottfreeLLC/AlphaPy","research_link":"","media_link":"https://www.slideshare.net/RobertScott144/alphapy","dataset_link":"","demo_link":"","other_link":"https://alphapy.readthedocs.io/en/latest/"}]},{"id":2127,"title":"Number Prediction","description":"Deep learning model made from scratch,Trained on MNIST dataset","tags":["code","tutorial","deep-learning"],"details":"","links":[{"article_link":"","code_link":"https://github.com/codeanzh/Number-Prediction-ANN","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2126,"title":"Machine Learning Monthly July 2020","description":"A collection of the coolest machine learning resources for July 2020, including: GPT-3, self-supervised learning, AutoML-Zero and more! ","tags":["article","newsletter","tutorials"],"details":"Two things I'm noticing of late:\r\n\r\n1. Self-supervised learning takeover.\r\n2. AutoML takeover.\r\n\r\nBoth of these make sense. Automate the parts which can be automated and train with less data when possible (you won't always have access to massive amounts of labelled data).\r\n\r\nCheck out [Machine Learning Monthly July 2020](https://zerotomastery.io/blog/machine-learning-monthly-july-2020) for a collection of  resources related to the above and the [video walkthrough](https://youtu.be/3IKWukTiBfc) for additional commentary.","links":[{"article_link":"https://zerotomastery.io/blog/machine-learning-monthly-july-2020","code_link":"","research_link":"","media_link":"https://youtu.be/3IKWukTiBfc","dataset_link":"","demo_link":"","other_link":""}]},{"id":2124,"title":"Neural Architecture Search","description":"A look at neural architecture search w.r.t search space, search algorithms and evolution strategies.","tags":["article","automl","reinforcement-learning","evolution","neural-architecture-search"],"details":"Neural Architecture Search (NAS) automates network architecture engineering. It aims to learn a network topology that can achieve best performance on a certain task. By dissecting the methods for NAS into three components: search space, search algorithm and child model evolution strategy, this post reviews many interesting ideas for better, faster and more cost-efficient automatic neural architecture search.\r\n\r\nAs I started looking into NAS, I found this nice survey very helpful by Elsken, et al 2019. They characterize NAS as a system with three major components, which is clean & concise, and also commonly adopted in other NAS papers.\r\n\r\n* **Search space**: The NAS search space defines a set of operations (e.g. convolution, fully-connected, pooling) and how operations can be connected to form valid network architectures. The design of search space usually involves human expertise, as well as unavoidably human biases.\r\n* **Search algorithm**: A NAS search algorithm samples a population of network architecture candidates. It receives the child model performance metrics as rewards (e.g. high accuracy, low latency) and optimizes to generate high-performance architecture candidates.\r\n* **Evaluation strategy**: We need to measure, estimate, or predict the performance of a large number of proposed child models in order to obtain feedback for the search algorithm to learn. The process of candidate evaluation could be very expensive and many new methods have been proposed to save time or computation resources.","links":[{"article_link":"https://lilianweng.github.io/lil-log/2020/08/06/neural-architecture-search.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2123,"title":"Otto","description":"Otto makes machine learning an intuitive, natural language experience.","tags":["code","deep-learning","machine-learning","neural-networks","library","automl","assistant"],"details":"# Otto: Your friendly machine learning assistant.\r\n<a href=\"https://ottoml.online/\"><img src=\"https://github.com/KartikChugh/Otto/raw/master/logo.png\" width=\"750px\"></a>\r\n\r\n## Machine learning becomes an intuitive, natural language experience\r\nOtto is an intelligent chat application, designed to help aspiring machine learning engineers **go from idea to implementation with minimal domain knowledge**. **[Our website](https://ottoml.online/)** features easy model selection, insightful visualizations, and an intuitive natural language experience guiding you every step of the way. \r\n\r\n### _UPDATE: Otto is a winner at the Facebook AI Challenge!_\r\n\r\nWe're excited to share that Otto has received a **[third-place prize](https://devpost.com/software/otto-v05m26)** at the 2020 Facebook AI Challenge hackathon series for its innovative use of the [Wit.ai](https://wit.ai/) NLP platform. Congratulations to the other winners, and to everyone who participated!\r\n\r\n***\r\n\r\n#### Highlights\r\n\r\n- **Beginner-friendly design.** Otto is made for novices, as it assumes minimal familiarity with machine learning. Users simply describe their end goals to obtain intelligent recommendations, or can choose from sample datasets to harness our models in an instant.\r\n\r\n- **Powerful machine learning tools.** A range of machine learning capabilities are supported, including models for regression, classification and natural language processing, as well as preprocessors tailored to your problem. Play with neural networks, explore data visualizations, and generate ready-made Python code right in your browser!\r\n\r\n- **Educational experience.** Users are walked through each stage of the process, with Otto explaining terminology when needed. Annotated code blocks provide eager learners a high-level understanding of their end-to-end pipeline.\r\n\r\n***\r\n\r\n#### Quick Start\r\n\r\nTo demo some of Otto's core features, try out the following:\r\n\r\n- **Say: _I want to label flower species by petal length_** to watch Otto prefill your pipeline components and visualize a nearest neighbors classification for the popular Iris dataset.\r\n\r\n- **Select: _Regression > Sample Dataset_** to preview sample datasets for regression, and discover the strongest predictors using different best fit lines.\r\n\r\n- **Say: _Detect fraudulent credit card activity_** and select the Custom Dataset option to experience Otto-matic model recommendation and an interactive neural network designer.\r\n\r\n- **Say: _I'd like to interpret the mood of a review_** to query Wit-powered natural language models for live results.\r\n\r\nAnd feel free to get creative! Come up with your own machine learning goals and see where Otto takes you.\r\n\r\n#### Stages\r\n\r\nBelow is a step-by-step breakdown of how Otto works.\r\n\r\n##### Task \r\n\r\nOne of the biggest obstacles faced by those just getting started with ML is the abundance of jargon, from \u201closs functions\u201d to \u201ccontour boundaries\u201c \u2014 beginners can't be expected to decide what model to use based on cryptic terminology, let alone develop one from scratch! **Otto narrows down your options by inferring the high-level task at hand from a simple objective statement**.\r\n\r\n![taskInference](https://github.com/KartikChugh/Otto/raw/master/media/taskInference_hd_fast.gif)\r\n\r\nTask inference is powered by a Wit application (_Otto-Task_) trained on 300 such statements (e.g. \u201cI want to detect loan applications as fraudulent\u201d, \u201chelp me forecast stock prices\u201d, or \u201clet's summarize an article into a paragraph\u201d) derived from real-world machine learning research. _Otto-Task_ attempts to categorize the task intent as regression, classification, or natural language processing, and additionally extracts a subject entity embodying a streamlined form of the objective in order to filter out extraneous words. \r\n\r\nThe subject is parsed for keyword matches (\u201ctweets\u201d, \u201chousing\u201d, etc) against our database of sample datasets. If a relevant dataset is found, Otto pulls the optimal task, model, and preprocessors for the dataset and pre-selects them for the user throughout the pipeline-building process. Otherwise, Otto issues a task recommendation based on the recognized intent. And if no intent was identified, the user is provided with some tips to help them pick the best task themselves.\r\n\r\n##### Dataset\r\n\r\nUsers are recommended a specific sample dataset matching their subject, or otherwise offered to preview and choose one themselves. **Sample data allows beginners to prototype models quickly and easily**, without the complexity of finding a dataset and figuring out the relevant features among dozens. Users may also opt to with their own data, which they can include later on in the generated code. \r\n\r\n<p align=\"center\">\r\n  <img src=\"https://github.com/KartikChugh/Otto/raw/master/media/samplePreview_hd.gif\"> \r\n</p>\r\n\r\n##### Model\r\n\r\nIf the user opted for custom data, **Otto leverages Wit to perform the key step of selecting a classifier or regressor**. A Wit client (_Otto-Model_) parses a brief user description of their data for key phrases indicating the desirability of a particular model. _Otto-Model_ includes around 15 phrases and synonyms per model and performs fuzzy string matching, making it an effective and scalable technique for model recommendation.\r\n\r\nA characterization of the classification dataset as \u201csimple\u201d or having \u201cjust a few columns\u201d, would make the K-Nearest Neighbors algorithm a good choice, while a description of the regression data as \u201ccrime rates\u201d or \u201cannual consumer rankings\u201d would suggest a Poisson or ordinal model, respectively. If no phrase is flagged, Otto will default to the most general model available: a Neural Network for classification, or a linear fit for regression. \r\n\r\nIn the case of a natural language task, users can combine multiple models together for a more comprehensive analysis. Otto will recommend both sentiment analysis and entity recognition models, but provides users with information about both in case they'd like to adjust this. Our NLP models are built on a Wit backend (_Otto-NLP_) configured to identify [built-in traits and entities](https://wit.ai/docs/built-in-entities/20180601).\r\n\r\n#### Supported models:\r\n* K-Nearest Neighbors - Draws class regions by looking at surrounding data\r\n* Neural Network - Deep learning model suitable for complex datasets \r\n* Linear Regression - Ordinary linear relationship between variables  \r\n* Poisson Regression - Models count data, which tends to follow a Poisson distribution \r\n* Ordinal Regression - Learns rankings (e.g. \"on a scale of 1-5\")                       \r\n* Sentiment Analysis - Detects polarity, expressions of thanks, and greetings/goodbyes \r\n* Entity Recognition - Extracts structures such as people, times & locations, and works of art\r\n\r\n### Preprocessors\r\n\r\nWhat good is a fancy model if it takes ages to train? In this step, **Otto swoops in with handpicked preprocessors for the user's data and model selections**, abstracting away the intricacies of feature engineering and dimensionality reduction \u2014 machine learning techniques that optimize the data for efficient learning. As always, users can override the recommendations.\r\n\r\n#### Supported preprocessors:\r\n* Principal Component Analysis - Performs dimensionality reduction and/or feature selection  \r\n* Normalization - Scales data to have mean centered at 0 and unit variance  \r\n* Text Cleaning - Removes emojis, noisy symbols, and leading/trailing whitespace |\r\n\r\n### Visualization\r\n\r\nThe visualization stage activates for neural network design, or to render any models built on sample data.\r\n\r\n#### Neural Network\r\n\r\nSatisfy your curious mind with our fun, interactive network builder! \r\n\r\n![nn](https://github.com/KartikChugh/Otto/raw/master/media/nn_hd.gif)\r\n\r\nOtto preconfigures a standard model architecture with [research-based](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf) activations and initializers, but users are free to tinker with it layer by layer as they wish. Additionally, Otto can perform instant redesigns with the aid of a dedicated Wit model (**Otto-Net**) that translates user instructions into architecture changes.\r\n\r\n#### Model Visualization (Sample)\r\n\r\nInstantly explore how parameters affect KNN clusters and regression slopes!\r\n\r\n![linreg](https://github.com/KartikChugh/Otto/raw/master/media/linreg_hd.gif)\r\n\r\n![knn](https://github.com/KartikChugh/Otto/raw/master/media/knn_hd.gif)\r\n\r\n### Code Display\r\n\r\nAll done! With your data sorted out, preprocessors set, and model configured, Otto gives you a nice view of your work. For convenience, we offer buttons to copy the code to your clipboard, deploy it to a Google Colab notebook, or restart the process. \r\n\r\n<p align=\"center\">\r\n  <img src=\"https://github.com/KartikChugh/Otto/raw/master/media/codeGen_hd.gif\"> \r\n</p>\r\n\r\n***\r\n\r\n## What's Next for Otto?\r\n\r\nOtto's modular design makes it readibly extensible, and its use of Wit means its natural language capabilities can be extended to even more domains. Here are just a few things planned for Otto:\r\n\r\n- **More models**: logistic regression, support vector machines, decision trees\r\n- **New tasks**: data generation (e.g. GANs), speech recognition, clustering\r\n- **Smarter advice**: being able to ask Otto to explain machine learning concepts or describe the difference between options\r\n\r\n### Contributors\r\n\r\nContributions are welcome! Feel free to tackle any of the above items, or anything else. We'll be reviewing issues and PRs opened on this repo.\r\n\r\n## About\r\n\r\n### Creators\r\n\r\n<a href=\"https://www.linkedin.com/in/compscikartik/\"><img src=\"https://github.com/KartikChugh/Otto/raw/master/media/social_kartik_small.png\"></a> &nbsp; <a href=\"https://www.linkedin.com/in/sanujb/\"><img src=\"https://github.com/KartikChugh/Otto/raw/master/media/social_sanuj_small.png\"></a>\r\n\r\n**Kartik Chugh**\r\n\r\nKartik is a second-year at the University of Virginia and currently an intern at Amazon's Alexa team. An avid open-source contributor, he is passionate about API design and developing cool machine learning tools. \r\n\r\n**Sanuj Bhatia**\r\n\r\nSanuj is a software engineer at Facebook who loves building interactive React-based applications. When possible, he likes to introduce and then fix bugs for maximum impact ;)\r\n\r\n### Acknowledgements\r\n\r\nThanks to Sean Velhagen for designing the Otto logo!\r\n\r\n### Why Otto the Owl?\r\n\r\nThere's the alliteration, the portrait of the wise owl that comes to mind, the subtle use of [OttoML](https://en.wikipedia.org/wiki/Automated_machine_learning)..\r\n\r\n","links":[{"article_link":"","code_link":"https://github.com/KartikChugh/Otto","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://ottoml.online/"}]},{"id":2122,"title":"Libra","description":"An ergonomic machine learning API designed for non-technical users.\r\n\r\n","tags":["article","code","video","machine-learning","library","automl","demo","libra","low-code"],"details":"# Libra\r\n\r\n**An ergonomic machine learning library for non-technical users. Save time. Blaze through ML.**\r\n\r\n[![Build Status](https://travis-ci.org/Palashio/libra.svg?branch=master)](https://travis-ci.org/Palashio/libra)\r\n[![Downloads](https://pepy.tech/badge/libra)](https://pepy.tech/project/libra)\r\n[![Slack](https://img.shields.io/badge/slack-chat-green.svg?logo=slack)](https://join.slack.com/t/the-libra-team/shared_invite/zt-ek6bpd47-hdIxXlRAenKfy5JNWe8bgw)\r\n\r\n[![PyPi](https://img.shields.io/badge/pypi%20package-1.0.0-blue)](https://pypi.org/project/libra/)\r\n[![Release](https://img.shields.io/badge/Next%20Release-Aug%2012-green)](https://pypi.org/project/libra/)\r\n[![Website shields.io](https://img.shields.io/website-up-down-blue-red/http/shields.io.svg)](https://libradocs.github.io//)\r\n[![Issues](https://img.shields.io/github/issues/Palashio/libra)]()\r\n\r\n\r\n---\r\n\r\n## Trending Contributors\r\n\r\n[![](https://sourcerer.io/fame/anas-awadalla/Palashio/libra/images/0)](https://sourcerer.io/fame/anas-awadalla/Palashio/libra/links/0)[![](https://sourcerer.io/fame/anas-awadalla/Palashio/libra/images/1)](https://sourcerer.io/fame/anas-awadalla/Palashio/libra/links/1)[![](https://sourcerer.io/fame/anas-awadalla/Palashio/libra/images/2)](https://sourcerer.io/fame/anas-awadalla/Palashio/libra/links/2)[![](https://sourcerer.io/fame/anas-awadalla/Palashio/libra/images/3)](https://sourcerer.io/fame/anas-awadalla/Palashio/libra/links/3)[![](https://sourcerer.io/fame/anas-awadalla/Palashio/libra/images/4)](https://sourcerer.io/fame/anas-awadalla/Palashio/libra/links/4)[![](https://sourcerer.io/fame/anas-awadalla/Palashio/libra/images/5)](https://sourcerer.io/fame/anas-awadalla/Palashio/libra/links/5)[![](https://sourcerer.io/fame/anas-awadalla/Palashio/libra/images/6)](https://sourcerer.io/fame/anas-awadalla/Palashio/libra/links/6)[![](https://sourcerer.io/fame/anas-awadalla/Palashio/libra/images/7)](https://sourcerer.io/fame/anas-awadalla/Palashio/libra/links/7)\r\n\r\n\r\n## Installation\r\n\r\nInstall latest release version:\r\n\r\n```\r\npip install -U libra\r\n```\r\n\r\nInstall directory from github:\r\n\r\n```\r\ngit clone https://github.com/Palashio/libra.git\r\ncd libra\r\npip install .\r\n```\r\n\r\nAlternatively you can build and use the docker image locally with:\r\n\r\n```\r\ndocker build . -f docker/libra-normal/Dockerfile -t libra\r\ndocker run -v /path/to/my/data:/data -it --rm libra\r\n```\r\n\r\nOr if you have [nvidia-docker](https://github.com/NVIDIA/nvidia-docker) installed.\r\n\r\n```\r\ndocker build . -f docker/libra-gpu/Dockerfile -t libra-gpu\r\ndocker run -v /path/to/my/data:/data --gpus all -it --rm libra-gpu\r\n```\r\n## Usage: the basics\r\n\r\nThe core functionality of libra works through the `client` object. A new client object should be created for every dataset that you want to produce results for. All information about the models that're built, the plots that are generated, and the metrics are created will be stored in the object.\r\n\r\nYou can then call different queries on that client object, and the dataset you passed to it will be used. \r\n\r\n```python\r\nfrom libra import client\r\n\r\nnewClient = client('path/to/dataset') \r\nnewClient.neural_network_query('please model the median number of households')\r\n```\r\nNow, calling \r\n```python\r\nnewClient.info()\r\n```\r\nwill return a dictionary of all the information that was generated: \r\n\r\n```python\r\ndict_keys(['id', 'model', 'num_classes', 'plots', 'target', 'preprocesser', \r\n          'interpreter', 'test_data', 'losses', 'accuracy'])\r\n```\r\n\r\nOther queries can also be called on the same object, and will be appended to the `models` dictionary.\r\n\r\n```python\r\nnewClient.svm_query('predict the proximity to the ocean')\r\nnewClient.model().keys()\r\n\r\ndict_keys(['regression_ANN', svm'])\r\n```\r\n\r\n## Tutorials\r\n\r\n - Full documentation can be found at [libradocs.github.io](https://libradocs.github.io/). \r\n - A list of resources can be found on our [awesome-libra](https://github.com/Palashio/awesome-libra) repository. \r\n\r\n---\r\n \r\n\r\n## Asking for help\r\nWelcome to the Libra community!\r\n\r\nIf you have any questions, feel free to:\r\n1. [read the docs](https://libradocs.github.io/).\r\n2. [Search through the issues](https://github.com/Palashio/libra/issues?q=is%3Aissue+is%3Aclosed).\r\n3. [Ask on stackoverflow](https://stackoverflow.com/questions/ask?guided=false) with the tag libra.\r\n4. [Join our slack](https://join.slack.com/t/the-libra-team/shared_invite/zt-ek6bpd47-hdIxXlRAenKfy5JNWe8bgw).\r\n\r\n\r\n\r\n## Demos\r\n\r\n![alt-text](/tools/data/gh_images/gif.gif)\r\n\r\n## Contact\r\n\r\nShoot me an email at [ps9cmk@virginia.edu](mailto:ps9cmk@virginia.edu) if you'd like to get in touch!\r\n","links":[{"article_link":"https://medium.com/@funpalash/machine-learning-in-one-line-of-code-c2c7cdb4983e","code_link":"https://github.com/Palashio/libra","research_link":"","media_link":"https://www.youtube.com/watch?v=N_T_ljj5vc4","dataset_link":"","demo_link":"https://www.youtube.com/watch?v=N_T_ljj5vc4","other_link":"https://libradocs.github.io/"}]},{"id":2121,"title":"DeepR \u2014 Training TensorFlow Models for Production","description":"DeepR is a Python library to build complex pipelines as easily as possible on top of Tensorflow.","tags":["article","code","notebook","tensorflow","library","production","mlflow","demo","hadoop","pipelines","deepr","graphite"],"details":"DeepR is a library for Deep Learning on top of Tensorflow that focuses on production capabilities. It makes it easy to define pipelines (via the Job abstraction), preprocess data (via the Prepro abstraction), design models (via the Layer abstraction) and train them either locally or on a Yarn cluster. It also integrates nicely with MLFlow and Graphite, allowing for production ready logging capabilities.\r\n\r\nIt can be seen as a collection of generic tools and abstractions to be extended for more specific use cases.\r\n\r\nSubmitting jobs and defining flexible pipelines is made possible thanks to a config system based off simple dictionaries and import strings. It is similar to Thinc config system or gin config in a lot of ways.\r\n\r\n![](https://miro.medium.com/max/1400/1*1FWG0TDNEOoTA79Dq3JeMA.png)","links":[{"article_link":"https://medium.com/criteo-labs/deepr-training-tensorflow-models-for-production-dda34a914c3b?source=friends_link&sk=91949017f33714dba3323956035f76e0","code_link":"https://github.com/criteo/deepr","research_link":"","media_link":"","dataset_link":"","demo_link":"https://colab.research.google.com/github/criteo/deepr/blob/master/docs/movielens/movielens.ipynb","other_link":"https://criteo.github.io/deepr/"}]},{"id":2120,"title":"Model Agnostic Meta Learning (MAML) implemented in Flax","description":"Model Agnostic Meta Learning (MAML) implemented in Flax, the neural network library for JAX.","tags":["code","paper","research","jax","deep-learning","meta-learning","flax","arxiv:1703.03400","maml"],"details":"This repository implements a MAML example for sinusoid regression in Flax. The idea of MAML is to learn the initial weight values of a model that can quickly adapt to new tasks. For more information, check the [paper](https://arxiv.org/abs/1703.03400).\r\n\r\nThis implementation uses only default Flax components like `flax.nn.Model` and `flax.nn.Module`, showing that this kind of optimization-based Meta Learning algorithms can easily be implemented in Flax/JAX.\r\n\r\nIt is based on the [MAML implementation in JAX by Eric Jang](https://blog.evjang.com/2019/02/maml-jax.html) and updated to use Flax components. I have only implemented the sinusoid example so far, but I intend to add the Omniglot example too.\r\n\r\nThere is also an implementation of a model that fits just to one sinusoid, without meta learning, useful to see the difference between the two approaches. This approach is implemented in `main_wo_maml.py`.","links":[{"article_link":"","code_link":"https://github.com/gcucurull/maml_flax","research_link":"https://arxiv.org/abs/1703.03400","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2117,"title":"Structuring Unit Tests in Python","description":"Where to put tests, how to write fixtures and the awesomeness of test parametrization.","tags":["article","tutorial","unit-tests","pytest","testing"],"details":"Testing code is often pretty ugly: A lot of copy & paste, the code is all over the place and hard to understand. In this article you will learn how to structure unit testing code in Python.","links":[{"article_link":"https://medium.com/python-in-plain-english/unit-testing-in-python-structure-57acd51da923","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2116,"title":"Machine Learning Pipelines for Kubeflow.","description":"Kubeflow pipelines are reusable end-to-end ML workflows built using the Kubeflow Pipelines SDK.","tags":["code","tutorial","kuberflow","production","ci-cd","pipelines"],"details":"[Kubeflow](https://www.kubeflow.org/) is a machine learning (ML) toolkit that is dedicated to making deployments of ML workflows on Kubernetes simple, portable, and scalable. \r\n\r\n**Kubeflow pipelines** are reusable end-to-end ML workflows built using the Kubeflow Pipelines SDK.\r\n\r\nThe Kubeflow pipelines service has the following goals:\r\n\r\n* End to end orchestration: enabling and simplifying the orchestration of end to end machine learning pipelines\r\n* Easy experimentation: making it easy for you to try numerous ideas and techniques, and manage your various trials/experiments.\r\n* Easy re-use: enabling you to re-use components and pipelines to quickly cobble together end to end solutions, without having to re-build each time.\r\n\r\n\r\n**Blog posts**\r\n\r\n* [Getting started with Kubeflow Pipelines](https://cloud.google.com/blog/products/ai-machine-learning/getting-started-kubeflow-pipelines) (By Amy Unruh)\r\n* How to create and deploy a Kubeflow Machine Learning Pipeline (By Lak Lakshmanan)\r\n  * [Part 1: How to create and deploy a Kubeflow Machine Learning Pipeline](https://towardsdatascience.com/how-to-create-and-deploy-a-kubeflow-machine-learning-pipeline-part-1-efea7a4b650f) \r\n  * [Part 2: How to deploy Jupyter notebooks as components of a Kubeflow ML pipeline](https://towardsdatascience.com/how-to-deploy-jupyter-notebooks-as-components-of-a-kubeflow-ml-pipeline-part-2-b1df77f4e5b3)\r\n  * [Part 3: How to carry out CI/CD in Machine Learning (\u201cMLOps\u201d) using Kubeflow ML pipelines](https://medium.com/google-cloud/how-to-carry-out-ci-cd-in-machine-learning-mlops-using-kubeflow-ml-pipelines-part-3-bdaf68082112)","links":[{"article_link":"","code_link":"https://github.com/kubeflow/pipelines","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2115,"title":"GPU-Accelerated Single-Cell Genomics Analysis with RAPIDS","description":"Examples of single-cell genomic analysis accelerated with RAPIDS","tags":["code","clustering","dimensionality-reduction","genomics","rapids","gene-ranking"],"details":"We use RAPIDS to accelerate the analysis of a ~70,000-cell single-cell RNA sequencing dataset from human lung cells. This example includes preprocessing, dimension reduction, clustering, visualization and gene ranking.","links":[{"article_link":"","code_link":"https://github.com/clara-parabricks/rapids-single-cell-examples","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2114,"title":"tsaug","description":"A Python package for time series augmentation.","tags":["code","library","data-augmentation","time-series","tsaug"],"details":"tsaug is a Python package for time series augmentation. It offers a set of augmentation methods for time series, as well as a simple API to connect multiple augmenters into a pipeline.\r\n\r\nA first-time user may start with two examples:\r\n\r\n- [Augment a batch of multivariate time series](https://tsaug.readthedocs.io/en/stable/quickstart.html#augment-a-batch-of-multivariate-time-series)\r\n- [Augment a 2-channel audio sequence](https://tsaug.readthedocs.io/en/stable/quickstart.html#augment-a-2-channel-audio-sequence)\r\n\r\nExamples of every individual augmenter can be found [here](https://tsaug.readthedocs.io/en/stable/notebook/Examples%20of%20augmenters.html)\r\n\r\nFor full references of implemented augmentation methods, please refer to [References](https://tsaug.readthedocs.io/en/stable/references.html).","links":[{"article_link":"","code_link":"https://github.com/arundo/tsaug","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://tsaug.readthedocs.io/en/stable/"}]},{"id":2113,"title":"GAN-BERT","description":"Enhancing the BERT training with Semi-supervised Generative Adversarial Networks.","tags":["code","paper","research","video","attention","bert","generative-adversarial-networks","transformers","natural-language-processing","semi-supervised-learning"],"details":"GAN-BERT is an extension of BERT which uses a Generative Adversial setting to implement an effective semi-supervised learning schema. It allows training BERT with datasets composed of a limited amount of labeled examples and larger subsets of unlabeled material. GAN-BERT can be used in sequence classification tasks (also involings text pairs).","links":[{"article_link":"","code_link":"https://github.com/crux82/ganbert","research_link":"https://www.aclweb.org/anthology/2020.acl-main.191/","media_link":"https://www.youtube.com/watch?v=vAQsGi6NctY","dataset_link":"","demo_link":"","other_link":""}]},{"id":2112,"title":"Search for visual datasets","description":"By task, application, class, label or format.","tags":["library","computer-vision","datasets"],"details":"Bifrost Data Search makes it easy for data scientists, developers and engineers everywhere to find the data you need! Search from almost 2000 open-source datasets with previews and in-depth analysis. 100% free.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://datasets.bifrost.ai/"}]},{"id":2111,"title":"InvoiceNet","description":"Deep neural network to extract intelligent information from PDF invoice documents.\r\n","tags":["code","library","computer-vision","optical-character-recognition","text-extraction"],"details":"Deep neural network to extract intelligent information from PDF invoice documents.","links":[{"article_link":"","code_link":"https://github.com/naiveHobo/InvoiceNet","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2109,"title":"Live demo : State-of-the-art MCQ Generator from any content","description":"Demo for state-of-the-art MCQ (Multiple Choice Questions) generator from any content built using T5 transformer, HuggingFace, and Sense2vec\r\n","tags":["huggingface","transformers","natural-language-processing","question-generation","t5"],"details":"**Demo**\r\n\r\nhttp://questgen-mcq-demo-aug-2020.s3-website.us-east-2.amazonaws.com/","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"http://questgen-mcq-demo-aug-2020.s3-website.us-east-2.amazonaws.com/"}]},{"id":2106,"title":"Fast NST for Videos (+ person segmentation) \ud83c\udfa5 + \u26a1\ud83d\udcbb + \ud83c\udfa8 = \u2764\ufe0f","description":"Create NST videos and pick separate styles for the person in the video and for the background.","tags":["code","tutorial","video","computer-vision","style-transfer","neural-style-transfer"],"details":"Create naive (no temporal loss) NST for videos with person segmentation. Just place your videos in data/, run and you get your stylized and segmented videos.","links":[{"article_link":"","code_link":"https://github.com/gordicaleksa/pytorch-naive-video-nst","research_link":"","media_link":"https://www.youtube.com/watch?v=S78LQebx6jo&list=PLBoQnSflObcmbfshq9oNs41vODgXG-608","dataset_link":"","demo_link":"","other_link":""}]},{"id":2104,"title":"PyTorch Lightning 101 video series","description":"PyTorch Lightning Masterclass from basic PyTorch to advanced Lightnig models","tags":["code","research","tutorial","video","pytorch","deep-learning","machine-learning","distributed-training","pytorch-lightning"],"details":"In this 101 series William Falcon, PyTorch Lightning creator, and Alfredo Canziani, Computer Science professor at NYU, walk you through everything you need to know to scale your models the Lightning way. \r\nTune in to learn about implementing models in PyTorch, converting to Lightning, and using more advanced features that will make it easier for you to run even the most complex models, lightning speed.\r\nMake sure to subscribe, new episodes are coming very soon...","links":[{"article_link":"","code_link":"https://github.com/PyTorchLightning/pytorch-lightning","research_link":"","media_link":"https://www.youtube.com/playlist?list=PLaMu-SDt_RB5NUm67hU2pdE75j6KaIOv2","dataset_link":"","demo_link":"","other_link":""}]},{"id":2103,"title":"scikit-survival","description":"scikit-survival is a Python module for survival analysis built on top of scikit-learn. ","tags":["code","python","scikit-learn","machine-learning","library","survival-analysis"],"details":"The objective in survival analysis (also referred to as time-to-event or reliability analysis) is to establish a connection between covariates and the time of an event. What makes survival analysis differ from traditional machine learning is the fact that parts of the training data can only be partially observed \u2013 they are censored.\r\n\r\nFor instance, in a clinical study, patients are often monitored for a particular time period, and events occurring in this particular period are recorded. If a patient experiences an event, the exact time of the event can be recorded \u2013 the patient\u2019s record is uncensored. In contrast, right censored records refer to patients that remained event-free during the study period and it is unknown whether an event has or has not occurred after the study ended. Consequently, survival analysis demands for models that take this unique characteristic of such a dataset into account.","links":[{"article_link":"","code_link":"https://github.com/sebp/scikit-survival","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2102,"title":"lifelib: Actuarial models in Python","description":"An open-source library of life actuarial models written in Python.","tags":["code","python","actuarial","actuary"],"details":"An open-source library of life actuarial models written in Python. You can run the models right out of the box, customize them in any way you want, or create your own models from scratch.","links":[{"article_link":"","code_link":"https://github.com/fumitoh/lifelib","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2100,"title":"A 2020 guide to Semantic Segmentation","description":"Concept of image segmentation, discuss the relevant use-cases, different neural network architectures involved in achieving the results, metrics and datasets.","tags":["article","code","computer-vision","semantic-segmentation","segmentation"],"details":"Deep learning has been very successful when working with images as data and is currently at a stage where it works better than humans on multiple use-cases. The most important problems that humans have been  interested in solving with computer vision are image classification, object detection and segmentation in the increasing order of their difficulty.\r\n\r\nIn the plain old task of image classification we are just interested in getting the labels of all the objects that are present in an image. In object detection we come further a step and try to know along with what all objects that are present in an image, the location at which the objects are present with the help of bounding boxes. Image segmentation takes it to a new level by trying to find out accurately the exact boundary of the objects in the image.\r\n\r\n![](https://nanonets.com/blog/content/images/2020/08/1_Hz6t-tokG1niaUfmcysusw.jpeg)\r\n\r\nIn this article we will go through this concept of image segmentation, discuss the relevant use-cases, different neural network architectures involved in achieving the results, metrics and datasets to explore.","links":[{"article_link":"https://nanonets.com/blog/semantic-image-segmentation-2020/","code_link":"https://github.com/mrgloom/awesome-semantic-segmentation","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2099,"title":"PyTorch implementation of deep convolutional GANs","description":"This is a concise implementation of deep convolutional generative adversarial neural networks using PyTorch library","tags":["code","paper","research","pytorch","convolutional-neural-networks","generative-adversarial-networks","unsupervised-learning","arxiv:1511.06434"],"details":"","links":[{"article_link":"","code_link":"https://github.com/bipinKrishnan/Paper2code_DCGAN","research_link":"https://arxiv.org/abs/1511.06434","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2098,"title":"Digital Image Processing in Python","description":"Play around with pixel values with Python programming language.","tags":["article","code","research","tutorial","python","machine-learning","computer-vision","image-clustering"],"details":"","links":[{"article_link":"https://innat.github.io/innat.github.io/","code_link":"https://github.com/innat/DIP-In-Python","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2097,"title":"Machine Learning Resource ","description":"A concise resource repository for machine learning bookmarks. Concise but yet to comprehensive for machine learning resources and related stuff.","tags":["code","research","python","deep-learning","machine-learning"],"details":"","links":[{"article_link":"","code_link":"https://github.com/innat/ML-Bookmarks","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2064,"title":"Short Text Matching Hyperparameter Tuning","description":"This scenario shows how to tune a Frequently Asked Questions (FAQ) matching model that can be deployed as a web service to provide predictions for user question","tags":["code","azure","scikit-learn","hyperparameter-optimization"],"details":"","links":[{"article_link":"","code_link":"https://github.com/microsoft/MLHyperparameterTuning","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2063,"title":"Scikit-learn Advanced Features | Data Science","description":"It demonstrates some useful scikit-learn concepts in transforming features, pipelining, grid search, and much more.","tags":["article","tutorial","python","scikit-learn","machine-learning","feature-engineering","data-science","pipeline","grid-search"],"details":"","links":[{"article_link":"https://blog.datavalley.technology/2020/08/06/scikit-learn-advanced-features-data-science/?fbclid=IwAR2Kr0nxMqUUW7grC4DRN9Bm8H4XsJVhLe74umD9AX5diYQ4LoUApsrgBFU","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2062,"title":"Predict Vehicle Speed From Dash Cam Video","description":"A series of experiments attempting to predict vehicle speed from dash cam videos using optical flow and neural networks.","tags":["article","code","pytorch","autonomous-vehicles","computer-vision","computer-vis"],"details":"","links":[{"article_link":"https://antoninodimaggio.com/predict-vehicle-speed-using-dense-optical-flow.html","code_link":"https://github.com/antoninodimaggio/Voof","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2061,"title":"Detectron 2 Demo from Facebook","description":"This Project contains the process of getting started with Facebook FAIR's detectron2 project on windows 10 without any Nvidia GPU.","tags":["code","tutorial","computer-vision","image-classification","object-detection","segmentation","detectron"],"details":"### Facebook's Detectron2 Demo (Windows 10)\r\n\r\nThis repo contains the process of getting started with Facebook FAIR's detectron2 project on windows 10 without any Nvidia GPU.\r\n\r\n**Configuration and Installation steps**\r\n\r\nTo install Detectron2 you need to have Pytorch and Torchvision installed along with Pycocotools.\r\n\r\nTo install Pycocotools On Windows, you must have the Visual C++ 2015 build tools on your path. If you don't, make sure to install them from [here](https://go.microsoft.com/fwlink/?LinkId=691126):\r\n\r\nThen, run `visualcppbuildtools_full.exe` and select default options:\r\n\r\nAfter installing add them to your environment variables and run the command below:\r\n\r\n```\r\npip install git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI\r\n```\r\n\r\nThis will install pycocotools into your opreating system.\r\n\r\nAfter that install the requirements specified in the requirement file.\r\n\r\n```\r\npip install -r requirement.txt\r\n```\r\n\r\nTo build the Detectron2 you need fvcore \r\n\r\n```\r\ngit clone https://github.com/facebookresearch/fvcore\r\ncd fvcore\r\npython setup.py install \r\n```\r\n\r\nWhen all the requirements are installed clone the official repository of Detectron2 project from [here](https://github.com/facebookresearch/detectron2)\r\nor you can clone it by the process given below\r\n\r\n```\r\ngit clone https://github.com/facebookresearch/detectron2.git\r\ncd detectron2\r\npython setup.py build develop\r\n```\r\n\r\nAfter doing that all you need are pretrained models and pretrained weights.\r\n\r\nYou can get pre trained Mask RCNN model from [here](https://mega.nz/#!0nhxGKSA!GUOEjejGvy5sU5MZa8TFZUY0r4VT5al4Y_q0jZSiXW0) and pre trained weights from [here](https://mega.nz/#!cnZkQazC!Qp25xoks1OShLnXk_kIA6oniJ3q_yj7NYCU4fnZGRBs)\r\nPlace these models and weights in the working directory of the python script.\r\n\r\nAt Last you need to download the Base RCNN model from [here](https://mega.nz/#!xmAElA7A!fOHCnMQh6WzO1mcmktpyDh5D16AmqgC4fYp3tNwye_4)\r\nand you need to place this file out of the current working directory in the previous directory to use this base model.\r\n\r\nAfter configuring this just run the python script given in the code put your image name or path in the script and run this.\r\n\r\n\r\n----------------------------------------------------------------------------------------------------------------------------------------\r\n\r\n\r\n**Author**\r\nYou can get in touch with me on my LinkedIn Profile:\r\n\r\n#### Saad Hassan\r\n[![LinkedIn Link](https://img.shields.io/badge/Connect-saadhaxxan-blue.svg?logo=linkedin&longCache=true&style=social&label=Connect\r\n)](https://www.linkedin.com/in/saadhaxxan)\r\n\r\nYou can also follow my GitHub Profile to stay updated about my latest projects: [![GitHub Follow](https://img.shields.io/badge/Connect-saadhaxxan-blue.svg?logo=Github&longCache=true&style=social&label=Follow)](https://github.com/saadhaxxan)\r\n\r\nIf you liked the repo then kindly support it by giving it a star \u2b50!\r\n\r\n**Contributions Welcome**\r\n[![forthebadge](https://forthebadge.com/images/badges/built-with-love.svg)](#)\r\n\r\nIf you find any bug in the code or have any improvements in mind then feel free to generate a pull request.\r\n\r\n**Issues**\r\n[![GitHub Issues](https://img.shields.io/github/issues/saadhaxxan/Detectron2_Demo_Windows_10.svg?style=flat&label=Issues&maxAge=2592000)](https://www.github.com/saadhaxxan/Detectron2_Demo_Windows_10/issues)\r\n\r\nIf you face any issue, you can create a new issue in the Issues Tab and I will be glad to help you out.\r\n\r\n**License**\r\n[![MIT](https://img.shields.io/cocoapods/l/AFNetworking.svg?style=style&label=License&maxAge=2592000)](../master/LICENSE)\r\n\r\nCopyright (c) 2020 SAAD HASSAN   \r\n","links":[{"article_link":"","code_link":"https://github.com/saadhaxxan/Detectron2_Demo_Windows_10","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2060,"title":"einops","description":"Flexible and powerful tensor operations for readable and reliable code. Supports numpy, pytorch, tensorflow, and others.","tags":["article","code","pytorch","tensorflow","library","numpy","einops"],"details":"Tutorials are the most convenient way to see `einops` in action (and right now works as a documentation)\r\n\r\n- part 1: [einops fundamentals](https://github.com/arogozhnikov/einops/blob/master/docs/1-einops-basics.ipynb) \r\n- part 2: [einops for deep learning](https://github.com/arogozhnikov/einops/blob/master/docs/2-einops-for-deep-learning.ipynb)\r\n- part 3: [real code fragments improved with einops](https://arogozhnikov.github.io/einops/pytorch-examples.html) (so far only for pytorch)\r\n\r\n![](https://camo.githubusercontent.com/e3460351c8b1c70f1570b7709d57bc131542b517/687474703a2f2f61726f676f7a686e696b6f762e6769746875622e696f2f696d616765732f65696e6f70732f65696e6f70735f766964656f2e676966)","links":[{"article_link":"https://arogozhnikov.github.io/einops/pytorch-examples.html","code_link":"https://github.com/arogozhnikov/einops","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2059,"title":"How to Detect Data-Copying in Generative Models","description":"I propose some new definitions and test statistics for conceptualizing and measuring overfitting by generative models.","tags":["article","code","paper","research","autoencoders","generative-adversarial-networks","variational-autoencoders","generative-modeling","data-copying","over-representation","arxiv:2004.05675"],"details":"Detecting overfitting in generative models is an important challenge in machine learning. In this work, we formalize a form of overfitting that we call {\\em{data-copying}} -- where the generative model memorizes and outputs training samples or small variations thereof. We provide a three sample non-parametric test for detecting data-copying that uses the training set, a separate sample from the target distribution, and a generated sample from the model, and study the performance of our test on several canonical models and datasets.\r\n\r\n![](https://ucsdml.github.io/assets/2020-08-03-data-copying/unsupervised_setting_2.png)","links":[{"article_link":"https://ucsdml.github.io/jekyll/update/2020/08/03/how-to-detect-data-copying-in-generative-models.html","code_link":"https://github.com/casey-meehan/data-copying","research_link":"https://arxiv.org/abs/2004.05675","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2058,"title":"Hyperparameter Optimization for AllenNLP Using Optuna","description":"\ud83d\ude80 A demonstration of hyperparameter optimization using Optuna for models implemented with AllenNLP.\r\n\r\n","tags":["article","code","tutorial","library","allennlp","hyperparameter-optimization","allenai","optuna"],"details":"In this article, I introduced how to combine AllenNLP and Optuna, a neural network library for natural language processing, to optimize hyperparameters, which is easy to use with a few modifications to AllenNLP\u2019s Jsonnet file. As a demo, I worked on a polarity analysis of IMDb review data.","links":[{"article_link":"https://medium.com/p/54b4bfecd78b","code_link":"https://github.com/himkt/optuna-allennlp","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2057,"title":"Data Science Meets Devops: MLOps with Jupyter, Git, & Kubernetes","description":"An end-to-end example of deploying a machine learning product using Jupyter, Papermill, Tekton, GitOps and Kubeflow.","tags":["article","tutorial","devops","production","kubeflow","mlops","papermill","end-to-end","gitops","tekton"],"details":"Building ML products is a team effort. In order to move a model from a proof of concept to a shipped product, data scientists and devops engineers need to collaborate. To foster this collaboration, we believe it is important to allow data scientists and devops engineers to use their preferred tools. Concretely, we wanted to support the following tools for Data Scientists, Devops Engineers, and SREs:\r\n\r\n* Jupyter notebooks for developing models.\r\n* GitOps for continuous integration and deployment.\r\n* Kubernetes and managed cloud services for underlying infrastructure.\r\n\r\nTo maximize each team\u2019s autonomy and reduce dependencies on tools, our CI/CD process follows a decentralized approach. Rather than explicitly define a DAG that connects the steps, our approach relies on a series of controllers that can be defined and administered independently. We think this maps naturally to enterprises where responsibilities might be split across teams; a data engineering team might be responsible for turning weblogs into features, a modeling team might be responsible for producing models from the features, and a deployments team might be responsible for rolling those models into production.","links":[{"article_link":"https://blog.kubeflow.org/mlops/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2056,"title":"Fast Sentence Embeddings (fse)","description":"Fast Sentence Embeddings is a Python library that serves as an addition to Gensim.","tags":["code","library","embeddings","natural-language-processing","sentence-embeddings","gensim","demo","fse"],"details":"Fast Sentence Embeddings is a Python library that serves as an addition to Gensim. This library is intended to compute *sentence vectors* for large collections of sentences or documents. \r\n\r\nFind the corresponding blog post(s) here:\r\n\r\n- [Visualizing 100,000 Amazon Products](https://towardsdatascience.com/vis-amz-83dea6fcb059)\r\n- [Sentence Embeddings. Fast, please!](https://towardsdatascience.com/fse-2b1ffa791cf9)\r\n\r\n- **Announcment: Please understand, that I am at the end of my PhD and I do not have  many free minutes to fix issues or add features.**\r\n\r\n**fse** implements three algorithms for sentence embeddings. You can choose\r\nbetween *unweighted sentence averages*,  *smooth inverse frequency averages*, and *unsupervised smooth inverse frequency averages*. \r\n\r\nKey features of **fse** are: \r\n\r\n**[X]** Up to 500.000 sentences / second (1)\r\n\r\n**[X]** Supports Average, SIF, and uSIF Embeddings\r\n\r\n**[X]** Full support for Gensims Word2Vec and all other compatible classes\r\n\r\n**[X]** Full support for Gensims FastText with out-of-vocabulary words\r\n\r\n**[X]** Induction of word frequencies for pre-trained embeddings\r\n\r\n**[X]** Incredibly fast Cython core routines \r\n\r\n**[X]** Dedicated input file formats for easy usage (including disk streaming)\r\n\r\n**[X]** Ram-to-disk training for large corpora\r\n\r\n**[X]** Disk-to-disk training for even larger corpora\r\n\r\n**[X]** Many fail-safe checks for easy usage\r\n\r\n**[X]** Simple interface for developing your own models\r\n\r\n**[X]** Extensive documentation of all functions\r\n\r\n**[X]** Optimized Input Classes\r\n\r\n(1) May vary significantly from system to system (i.e. by using swap memory) and processing.\r\nI regularly observe 300k-500k sentences/s for preprocessed data on my Macbook (2016).\r\nVisit **Tutorial.ipynb** for an example.\r\n\r\nThings I will work on next:\r\n\r\n**[ ]** MaxPooling / Hierarchical Pooling Embedding\r\n\r\n**[ ]** Approximate Nearest Neighbor Search for SentenceVectors","links":[{"article_link":"","code_link":"https://github.com/oborchers/Fast_Sentence_Embeddings","research_link":"","media_link":"","dataset_link":"","demo_link":"https://towardsdatascience.com/vis-amz-83dea6fcb059","other_link":"https://towardsdatascience.com/fse-2b1ffa791cf9"}]},{"id":2055,"title":"Batch Normalization in Keras - Ablation Study","description":"Use BatchNormalization with Keras and observe the effect it has with the change in batch size, learning rates and add dropout.","tags":["article","code","notebook","keras","batch-normalization","wandb","ablation-studies"],"details":"","links":[{"article_link":"https://app.wandb.ai/authors/ayusht/reports/Batch-Normalization-in-Keras-An-Example--VmlldzoxNzI5NjQ","code_link":"https://colab.research.google.com/drive/1znvd2wt7oLDBskS6gBLhscAI1V-D9REb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2054,"title":"Dropout in PyTorch \u2013 An Example","description":"An example of adding Dropout to a PyTorch model, and observe the effect dropout has on the model's performance by tracking our models in Weights & Biases.","tags":["article","code","notebook","pytorch","computer-vision","image-classification","wandb","dropout"],"details":"","links":[{"article_link":"https://app.wandb.ai/authors/ayusht/reports/Dropout-in-PyTorch-An-Example--VmlldzoxNTgwOTE","code_link":"https://colab.research.google.com/drive/1uX4QhQ4levE1FMvFRlqzvYOeK-MBqtcu","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2053,"title":"Image Classification with Keras","description":"Build a pipeline to train an image classifier in Keras and tune hyperparameters to optimize the performance of our classifier.","tags":["article","code","notebook","keras","computer-vision","image-classification","wandb"],"details":"","links":[{"article_link":"https://app.wandb.ai/authors/ayusht/reports/Image-Classification-with-Keras--VmlldzoxNTgxNjc","code_link":"https://colab.research.google.com/drive/1s4UyRlzGwuMpD7ZuB8Lc7J5z2JL7drYu","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2052,"title":"Use GPUs with Keras","description":"This tutorial walks you through the Keras APIs that let you use and have more control over your GPU.","tags":["article","code","notebook","tutorial","keras","wandb","gpu"],"details":"","links":[{"article_link":"https://app.wandb.ai/authors/ayusht/reports/Use-GPUs-with-Keras--VmlldzoxNjEyNjE","code_link":"https://colab.research.google.com/drive/1BPO5n8wkcMXDlijasBbfXpI7HuBWDkUb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2051,"title":"MobyDick word frequency","description":"Getting the count of the words in Moby Dick story using both web scraping and NLP","tags":["code","notebook","research","natural-language-processing","data-science"],"details":"","links":[{"article_link":"","code_link":"https://github.com/OmarEltouny78/NLP-WebScrapper-MobyDick/blob/master/Moby.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2048,"title":"SadedeGel: An extraction based Turkish news summarizer","description":"\"Sadede Gel\" in Turkish, means \"cut to the chase\".  ","tags":["code","notebook","research","attention","bert","transformers","library","natural-language-processing","text-summarization","unsupervised-learning","demo"],"details":"## **SadedeGel**\r\n\r\nThe library and its sub-projects are developed for **Open Source Hackathon Program** hosted by [Turkey Open Source Platform](https://www.turkiyeacikkaynakplatformu.com)\r\n\r\nThough the library is developed for Turkish language, the support and documentation is provided in English to accommodate non-native researchers and enthusiasts. \r\n\r\nSadedeGel library mainly revolves around the task of extractive summarization. It wraps and provides tools for an end-to-end workflow for such task. \r\n\r\n* Dataset formation with scraper.\r\n* Label generation.\r\n* ML based sentence Boundary detection.\r\n* Summarizers.\r\n* Evaluator.\r\n* Server.\r\n* Chrome Extension.\r\n\r\nThe workflow is distributed to libraries below.\r\n\r\n* [SadedeGel Main Library](#sadedegel-main-library)\r\n* [SadedeGel Scraper](#sadedegel-scraper)\r\n* [SadedeGel Annotator](#sadedegel-annotator)\r\n* [SadedeGel Chrome Extension](#sadedegel-chrome-extension)\r\n\r\n### **SadedeGel Main Library**\r\n\r\n[GitHub Link](https://github.com/GlobalMaksimum/sadedegel)\r\n\r\nFeatures:\r\n\r\n* Several news datasets\r\n* ML based sentence boundary detector (SBD) trained for Turkish language (sadedegel.dataset)\r\n* Various baseline summarizers\r\n* Various unsupervised/supervised summarizers. (Embeddings generated with [BERTurk](https://github.com/stefan-it/turkish-bert))\r\n\r\n\r\n\r\nDetailed description of the metric and summarizer perfomances can be found at ```sadedegel.summarize``` [submodule](https://github.com/GlobalMaksimum/sadedegel/tree/master/sadedegel/summarize).\r\n\r\n### **SadedeGel Scraper**\r\n\r\nThis web scraper is developed to meet the data requirements of SadedeGel library. \r\n\r\n[GitHub Link](https://github.com/GlobalMaksimum/sadedegel-scraper)\r\n\r\nIt scrapes data from news websites and stores them as .txt files. \r\n\r\n* Gets author urls of given news website\r\n* Gets article urls of each author\r\n* Scrapes data from the article and write to a .txt file\r\n\r\n\r\n### **SadedeGel Annotator**\r\n\r\n[GitHub Link](https://github.com/GlobalMaksimum/sadedegel-annotator)\r\n\r\n\r\nSadedegel Annotator enables the user to summarize texts by eliminating sentences in rounds. At each round, user identifies the sentences that contain the least important information and selects them to be extracted from the text. For each sentence, the round it is eliminated in implies its level of importance.\r\n\r\n![](https://raw.githubusercontent.com/GlobalMaksimum/sadedegel-annotator/master/how-it-works.gif)\r\n\r\nGiven this **supervised labeling** approach, we use a ranking metric (Normalized Discounted Cumulative Gain) to evaluate different summarizers over independent dataset(s).\r\n\r\nNormalized Discounted Cumulative Gain is a very intuitive metric by its definition. It simply measures an algorithm's success based on the ratio of two things\r\n\r\n* Algorithm's choice of best k sentences among M sentences (total relevance score obtained with this k sentence).\r\n* Best k sentences among M sentences with respect to ground truth human annotation (Best possible total relevance score that can be obtained with k sentences).\r\n\r\n**Note:** Supervised label is the importance label assigned by the human annotator. In order to obtain labels for a very large corpus SadedeGel also uses **self-supervised labeling** where importance label of a sentence is its **```Rouge1('f1')```** overlap score with respect to the rest of the document. Rouge1 label of each sentence is calculated and stored when:\r\n\r\nNow you have an annotated Turkish News Dataset for extractive summarization task.\r\n\r\n### **SadedeGel Chrome Extension**\r\n\r\nSadedeGel Chrome Extension is a handy usage of SadedeGel library.\r\n\r\n[GitHub Link](https://github.com/GlobalMaksimum/sadedegel-chrome-extension)\r\n\r\nIt summarizes articles on authors page of supported news websites:\r\n\r\n* [hurriyet.com.tr](https://www.hurriyet.com.tr/yazarlar/)\r\n* [milliyet.com.tr](https://www.milliyet.com.tr/yazarlar/)\r\n* [sozcu.com.tr](https://www.sozcu.com.tr/kategori/yazarlar/)\r\n* [haberturk.com](https://www.haberturk.com/htyazarlar)\r\n* [sabah.com.tr](https://www.sabah.com.tr/yazarlar)\r\n\r\n![](https://raw.githubusercontent.com/GlobalMaksimum/sadedegel-chrome-extension/master/images/how-it-works.gif)","links":[{"article_link":"","code_link":"https://github.com/GlobalMaksimum/sadedegel","research_link":"","media_link":"","dataset_link":"","demo_link":"https://mybinder.org/v2/gh/GlobalMaksimum/sadedegel.git/master?filepath=notebook/Basics.ipynb","other_link":"https://sadedegel.ai/"}]},{"id":2047,"title":"Test-Time Data Augmentation","description":"Tutorial on how to properly implement test-time image data augmentation in a production environment with limited computational resources.","tags":["article","code","notebook","tutorial","keras","tensorflow","deep-learning","data-augmentation","production"],"details":"Proper *test-time data augmentation in production* usually does not apply the same augmentation pipeline as during training. In production, the *computational budget is usually limited* and we only have time to run inference on a few augmented images.\r\n\r\nTherefore, the random data augmentation that works well during model training is not ideal. It is important to get the *highest accuracy boost with only a few augmented samples*. In practice this means that the best test-time data augmentation has to be found using experimentation\r\n\r\nRun the Colab notebook to experiment for yourself and learn how to find the best augmentation parameters.","links":[{"article_link":"https://stepup.ai/test_time_data_augmentation/","code_link":"https://github.com/dufourpascal/stepupai/blob/master/tutorials/data_augmentation/test_time_data_augmentation.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2046,"title":"Sparkle: Combating Medication Non-adherence with ML","description":"Introducing Sparkle \u2728: a multi-platform medication monitoring system designed to promote medication adherence for ordinary people.","tags":["code","video","health","library","medicine","gradient-boosting"],"details":"# Sparkle: Mission Control For Medication Adherence\r\n\r\nWelcome to Sparkle \u2728! To learn more about us, feel free to peruse the sections below. Or if you're eager to jump right in, you can visit our website [sparklemed.com](https://www.sparklemed.com) and experience Sparkle firsthand.\r\n\r\n## What _Is_ Sparkle?\r\n\r\nSparkle grew out of an Apache Spark based research project, which used distributed machine learning and wearable technology to detect low pill counts in prescription containers, with the goal of automating the delivery of refillment medication. It has since grown into a comprehensive medication adherence platform for doctors and patients alike that seeks to provide an intelligent solution to the issue of medication adherence.  \r\n\r\nWhy? It's estimated that in developed countries approximately 50% of patients with chronic illnesses do not take their medication as prescribed. In the United States alone, hospitalizations due to medication non-adherence cost an estimated 289 billion dollars annually.  \r\n\r\nSparkle's mission is to eliminate medication non-adherence by providing a comprehensive multi-platform medication monitoring system.\r\n\r\n\r\n## How Does It Work?\r\n\r\nOur system joins patients and doctors in a single feedback loop in which:\r\n\r\n* Doctors upload patient medication information to our internal online portal, with end-to-end encryption of patient data.\r\n* Patient prescription schedules are automatically propagated to our mobile iOS and watchOS applications.\r\n* Patients are automatically notified on their AppleWatch when it's time to take their medication. No configuration required.\r\n* Pill intakes are recorded via AppleWatch sensors and sent to our web API, where intakes are verified and the number of pills remaining is estimated via a Gradient Boosted model.\r\n* Our online portal is updated with patient intakes. Doctors can view the adherence rates of individual patients and are immediately notified of any non-adhering patients so that they can intervene and help patients resume their prescribed course of treatment.\r\n\r\n\r\n## Why Sparkle?\r\n\r\nSparkle provides a comprehensive medication monitoring system that is unlike anything on the market to date. Whereas other medication adherence applications require users to manually input a detailed intake schedule for each prescription they take, Sparkle reverses this paradigm and leverages the patient information that doctors must already record in online medical record systems to ease the burden of medication adherence for patients at no added cost to medical professionals.\r\n\r\n\r\n## See Sparkle In Action\r\n\r\nWant to learn more more about Sparkle? Watch the video below for a live demo of how our iOS, watchOS, and web applications work together, or visit [our website](https://www.sparklemed.com) to experience Sparkle firsthand.\r\n\r\n[![Sparkle.ai](https://yt-embed.herokuapp.com/embed?v=3HuoyBIA94o)](https://www.youtube.com/watch?v=3HuoyBIA94o \"\")\r\n\r\n\r\n## About Sparkle\r\n\r\nSparkle was created and developed with :heart: over the course of seven weeks as part of the Product Analytics class at the University of San Francisco's Masters in Data Science Program.\r\n\r\nWant to learn more about our team? Feel free to reach out using the links below!  \r\n\r\n[Andy Cheon](https://www.linkedin.com/in/acheon/) | [Stephanie Jung](https://www.linkedin.com/in/yeojujung/) | [Collin Prather](https://www.linkedin.com/in/collin-prather/) | [Matthew Sarmiento](https://www.linkedin.com/in/msarmi9/) | [Kevin Wong](https://www.linkedin.com/in/kevinbw/)","links":[{"article_link":"","code_link":"https://github.com/msarmi9/Sparkle","research_link":"","media_link":"https://www.youtube.com/watch?v=3HuoyBIA94o","dataset_link":"","demo_link":"","other_link":"https://www.sparklemed.com/"}]},{"id":2045,"title":"Evaluation Metrics For Information Retrieval","description":"Learn about common metrics used to evaluate performance of information retrieval systems","tags":["article","tutorial","document-ranking","information-retrieval","metrics","natural-language-processing"],"details":"- Learn about evaluation metrics through two toy problem setup in information retrieval","links":[{"article_link":"https://amitness.com/2020/08/information-retrieval-evaluation/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2044,"title":"Neural Nets Aren\u2019t Black Boxes","description":"If you think neural nets are black boxes, you\u2019re not alone. Let\u2019s break this misconception down piece by piece as we build our own neural net from scratch.","tags":["article","code","tutorial","deep-learning","library"],"details":"In this post we'll write our own feedforward network from scratch in numpy, starting with binary logistic regression. We'll begin by deriving the back-prop equations for our particular scenario and in doing so we'll realize that what we've done generalizes immediately to networks with arbitrary layers and activations.\r\n\r\nThis post is the first of a series of posts in which we'll build our own DNN, CNN, and RNN in numpy. You can find the source code for this post at the [tinytorch repo](https://msarmi9.github.io/neural-nets-are-not-black-boxes/).","links":[{"article_link":"https://msarmi9.github.io/neural-nets-are-not-black-boxes/","code_link":"https://github.com/msarmi9/tinytorch","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2043,"title":"DeLighT: Very Deep and Light-weight Transformers","description":"Similar or better performance than transformer-based models with significantly fewer parameters","tags":["code","paper","research","transformers","model-compression","natural-language-processing","delight","dextra","arxiv:2008.00623"],"details":"In this repository, we share the source code of our paper DeLight, that delivers  similar or better performance than \r\ntransformer-based models with significantly fewer parameters. DeLighT more efficiently allocates parameters both (1) \r\nwithin each Transformer block using DExTra, a deep and light-weight transformation and (2) across blocks using \r\nblock-wise scaling, that allows for shallower and narrower DeLighT blocks near the input and wider and deeper \r\nDeLighT blocks near the output. Overall, DeLighT networks are 2.5 to 4 times deeper than standard transformer models \r\nand yet have fewer parameters and operations. For details, see our papers: [DeFINE](https://openreview.net/pdf?id=rJeXS04FPH) and \r\nand [DeLighT](https://arxiv.org/pdf/2008.00623.pdf).\r\n\r\n![](https://github.com/sacmehta/delight/raw/master/images/delight_unit.png)","links":[{"article_link":"","code_link":"https://github.com/sacmehta/delight","research_link":"https://arxiv.org/abs/2008.00623","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2042,"title":"ONNX T5","description":"Summarization, translation, Q&A, text generation and more at blazing speed using a T5 version implemented in ONNX.","tags":["article","code","paper","research","onnx","pytorch","transformers","library","natural-language-processing","t5","serving","arxiv:1910.10683"],"details":"Summarization, translation, Q&A, text generation and more at blazing speed using a T5 version implemented in ONNX. This package is still in alpha stage, therefore some functionalities such as beam searches are still in development.\r\n\r\n![](https://github.com/abelriboulot/onnxt5/raw/master/data/Embedding_benchmark.png?raw=true)\r\n\r\n![](https://github.com/abelriboulot/onnxt5/raw/master/data/Generation_benchmark.png?raw=true)","links":[{"article_link":"https://kta.io/posts/onnx_t5","code_link":"https://github.com/abelriboulot/onnxt5","research_link":"https://arxiv.org/abs/1910.10683","media_link":"","dataset_link":"","demo_link":"","other_link":"https://github.com/microsoft/onnxruntime"}]},{"id":2041,"title":"Fawkes vs Nic or Not","description":"Testing facial recognition against facial cloaking with Fawkes","tags":["article","tensorflow-js","facial-recognition"],"details":"Testing Fawkes facial cloaking against TensorFlow.js facial recognition with Nic or Not.com\r\n\r\n","links":[{"article_link":"https://shift.infinite.red/ai-face-off-fawkes-vs-nicornot-ef6b50b4ccb8","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://twitter.com/GantLaborde/status/1290711313262542851?s=20"}]},{"id":2040,"title":"A Barebones Image Retrieval System","description":"This project presents a simple framework to retrieve images similar to a query image.","tags":["code","tutorial","tensorflow","computer-vision","few-shot-learning","image-similarity-search","representation-learning","big-transfer","image-retrieval"],"details":"This project presents a simple framework to retrieve images similar to a query image. The framework is as follows:\r\n\r\n- Train a CNN model (A) on a set of labeled images with Triplet Loss (I used this one).\r\n- Use the trained CNN model (A) to extract features from the validation set.\r\n- Train a kNN model (B) on these extracted features with k set to the number of neighbors wanted.\r\n- Grab an image (I) from the validation set and extract its features using the same CNN model (A).\r\n- Use the same kNN model (B) to calculate the nearest neighbors of I.","links":[{"article_link":"","code_link":"https://github.com/sayakpaul/A-Barebones-Image-Retrieval-System","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2039,"title":"Tensorflow2 Object Detection Tutorial","description":"In this tutorial, we will be going step by step the complete training process of Tensorflow2 Object Detection. ","tags":["article","code","tutorial","tensorflow","tensorflow-js","convolutional-neural-networks","computer-vision","object-detection","tensorflow-lite"],"details":"In this tutorial we will be going to the detailed training process of a **custom object detection** model using **Tensorflow2.x** in Google Colab. All steps are mentioned with screenshots for easy reference.\r\nAt the end anyone can easily build an object detection model.\r\n\r\nAfter building a model one can easily build a web app or use the model in edge devices or mobiles.","links":[{"article_link":"https://sourangshupal.github.io/Tensorflow2-Object-Detection-Tutorial/","code_link":"https://github.com/sourangshupal/Tensorflow2-Object-Detection-Tutorial/blob/master/README.md","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2038,"title":"Curated papers & articles on DS & ML in production","description":"Learn how organizations & business solved machine learning problems, including problem statement, research, methodology, and results.","tags":["code","paper","machine-learning","production","data-science"],"details":"Figuring out how to implement your ML project? Learn from how other organizations have done it:\r\n\r\n* How the problem is framed \ud83d\udd0e(e.g., personalization as recsys vs. search vs. sequences)\r\n* What machine learning techniques worked \u2705 (and sometimes, what didn't \u274c)\r\n* Why it works, the science behind it with research, literature, and references \ud83d\udcc2\r\n* What real-world results were achieved (so you can better assess ROI \u23f0\ud83d\udcb0\ud83d\udcc8)","links":[{"article_link":"","code_link":"https://github.com/eugeneyan/applied-ml","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2037,"title":"Exploring Pruning as an Alternative to Knowledge Distillation","description":"Summary of  Poor Man\u2019s BERT: Smaller and Faster Transformer Models.","tags":["article","research","knowledge-distillation","model-compression","pruning"],"details":"**Pruning techniques**\r\n\r\nTo thoroughly examine the effect of dropping transformer layers, the authors propose five different strategies:\r\n\r\n1. Top-layer dropping. Remove the last layers of the network. Previous work has shown that later layers in the network specialize for the pre-training objective, which might not be helpful during the fine-tuning stage of training.\r\n2. Bottom-layer dropping. Remove the initial layers from the network. This form of pruning is included for completeness, even though previous work have shown that initial layers model the local interaction between tokens.\r\n3. Alternate dropping. Removes every other layer, either the even or odd ones, counting from the end of the network. These techniques aim to answer whether adjacent layers learn similar enough transforms for one of them to be removed.\r\n4. Symmetric dropping. Remove layers from the center of the network. The motivation is that these layers learn less important features compared to the bottom and top layers.\r\n5. Contribution-based dropping. Removes layers based on how much they modify their input. This is measured by averaging the cosine similarity between input and output embeddings. It seems reasonable to remove layers where this similarity is high, as that would indicate small changes.","links":[{"article_link":"https://medium.com/dair-ai/poor-mans-bert-why-pruning-is-better-than-knowledge-distillation-\ufe0f-f9652a1dc2bd","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2035,"title":"Act - GitHub Actions locally","description":"Run your GitHub Actions locally.","tags":["code","library","mlops","github-actions","demo","ci-cd"],"details":"Run your [GitHub Actions](https://developer.github.com/actions/) locally! Why would you want to do this? Two reasons:\r\n\r\n* **Fast Feedback** - Rather than having to commit/push every time you want to test out the changes you are making to your `.github/workflows/` files (or for any changes to embedded GitHub actions), you can use `act` to run the actions locally. The [environment variables](https://help.github.com/en/actions/configuring-and-managing-workflows/using-environment-variables#default-environment-variables) and [filesystem](https://help.github.com/en/actions/reference/virtual-environments-for-github-hosted-runners#filesystems-on-github-hosted-runners) are all configured to match what GitHub provides.\r\n* **Local Task Runner** - I love [make](<https://en.wikipedia.org/wiki/Make_(software)>). However, I also hate repeating myself. With `act`, you can use the GitHub Actions defined in your `.github/workflows/` to replace your `Makefile`!\r\n\r\n\r\nWhen you run act it reads in your GitHub Actions from .github/workflows/ and determines the set of actions that need to be run. It uses the Docker API to either pull or build the necessary images, as defined in your workflow files and finally determines the execution path based on the dependencies that were defined. Once it has the execution path, it then uses the Docker API to run containers for each action based on the images prepared earlier. The environment variables and filesystem are all configured to match what GitHub provides.\r\n\r\n![](https://github.com/nektos/act/wiki/quickstart/act-quickstart-2.gif)","links":[{"article_link":"","code_link":"https://github.com/nektos/act","research_link":"","media_link":"","dataset_link":"","demo_link":"https://github.com/cplee/github-actions-demo","other_link":""}]},{"id":2034,"title":"Finding Similar Documents with Transformers","description":"How transformers can help us distill text documents into points in N-dimensional vector spaces.","tags":["code","notebook","tutorial","transformers","natural-language-processing","similarity-search","semantic-search","elastic-search","document-similarity"],"details":"In this blogpost we've learned how transformers, the current state of the art in Natural Language Processing, can help us distill text documents into points in N-dimensional vector spaces.\r\n\r\nBy searching by distance to points in that space, we can discover documents similar to each other, as well as similar to user-crafted queries, creating a semantic search engine in a few lines of Python.\r\n\r\nAs a next step, I encourage you to try different models and languages (you can find them all in HuggingFace's Model Hub) and also, try using ElasticSearch dense_vectors to index your documents there and take advantage of multi-faceted, production-ready search in vector space.","links":[{"article_link":"","code_link":"https://colab.research.google.com/drive/1DfJtwWBmgB2dbTHxzBA4NqnjDP6ux4BF","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2033,"title":"FARM: Framework for Adapting Representation Models","description":"\ud83c\udfe1 Fast & easy transfer learning for NLP. Harvesting language models for the industry.","tags":["article","code","video","huggingface","transformers","library","language-modeling","natural-language-processing","transfer-learning","demo"],"details":"FARM makes Transfer Learning with BERT & Co simple, fast and enterprise-ready. It's built upon transformers and provides additional features to simplify the life of developers: Parallelized preprocessing, highly modular design, multi-task learning, experiment tracking, easy debugging and close integration with AWS SageMaker.\r\n\r\nWith FARM you can build fast proof-of-concepts for tasks like text classification, NER or question answering and transfer them easily into production.\r\n\r\n#### Core Features \r\n\r\n* Easy fine-tuning of language models to your task and domain language\r\n* Speed: AMP optimizers (~35% faster) and parallel preprocessing (16 CPU cores => ~16x faster)\r\n* Modular design of language models and prediction heads\r\n* Switch between heads or combine them for multitask learning\r\n* Full Compatibility with HuggingFace Transformers' models and model hub\r\n* Smooth upgrading to newer language models\r\n* Integration of custom datasets via Processor class\r\n* Powerful experiment tracking & execution\r\n* Checkpointing & Caching to resume training and reduce costs with spot instances\r\n* Simple deployment and visualization to showcase your model","links":[{"article_link":"https://medium.com/voice-tech-podcast/https-medium-com-deepset-ai-transfer-learning-entering-a-new-era-in-nlp-db523d9e667b","code_link":"https://github.com/deepset-ai/FARM","research_link":"","media_link":"https://www.youtube.com/watch?v=hoDgtvE-u9E","dataset_link":"","demo_link":"https://demos.deepset.ai/","other_link":"https://farm.deepset.ai/"}]},{"id":2032,"title":"Object tracking in 75 lines of code","description":"Object tracking is straightforward conceptually. And if you have a good detector, simple methods can be pretty effective.","tags":["article","code","tutorial","pytorch","computer-vision","object-tracking"],"details":"Tracking objects in video is a thoroughly studied problem in computer vision that has important applications in industries like sports, retail and security. There are several possible approaches to this problem, but a popular one that\u2019s both simple to implement and effective in practice is called tracking-by-detection.\r\n\r\nThe tracking-by-detection paradigm relies heavily on high quality object detectors. This means it can leverage advances in deep learning that have dramatically improved the performance of these models.\r\n\r\nHere\u2019s the algorithm. For each frame:\r\n\r\n* Run the detector to find the objects in the image.\r\n* Extract features for the objects you care about.\r\n* Compute the pairwise cost between each object from the previous frame and each object in the current frame.\r\n* Assign matches between the two frames in a way that minimizes the overall cost.","links":[{"article_link":"https://jbencook.com/simple-pytorch-object-tracking/","code_link":"https://github.com/jbencook/pytorch-object-tracking","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2031,"title":"NeuralQA - API and Visual Interface for Extractive QA","description":"A Usable Library for Question Answering on Large Datasets with BERT","tags":["code","attention","bert","transformers","library","natural-language-processing","question-answering","visualization"],"details":"NeuralQA provides an easy to use api and visual interface for Extractive Question Answering (QA), on large datasets. The QA process is comprised of two main stages - Passage retrieval (Retriever) is implemented using ElasticSearch and Document Reading (Reader) is implemented using pretrained BERT models via the Huggingface Transformers api.\r\n\r\n![](https://raw.githubusercontent.com/victordibia/neuralqa/master/docs/images/architecture.png)\r\n\r\n![](https://raw.githubusercontent.com/victordibia/neuralqa/master/docs/images/manual.jpg)","links":[{"article_link":"","code_link":"https://github.com/victordibia/neuralqa","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2030,"title":"A Few Favorite Recipes in Computer Vision & Deep Learning","description":"This blog post enlists a few of my favorite recipes in deep learning in the context of computer vision (as of August 2020).","tags":["article","research","deep-learning","computer-vision","representation-learning","self-supervised-learning","simclr","contrastive-learning"],"details":"In this blog post, I will expand on this tweet to convey why these are my favorite recipes among other things.\r\n\r\nThe training frameworks I mentioned can be classified into two broad categories:\r\n\r\n* **supervised learning** ([Supervised Contrastive Learning](https://arxiv.org/abs/2004.11362) and [BigTransfer](https://arxiv.org/abs/1912.11370))\r\n* **self-supervised learning** (SimCLRv2 [only the SimCLR part]).","links":[{"article_link":"https://sayak.dev/visual-representation-learning/self-supervised-learning/computer-vision/2020/08/02/favorite-recipes-vision.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2029,"title":"Self-supervised representation learning on videos","description":"Everything you need to know about video-based approaches on self-supervised learning","tags":["article","video","representation-learning","self-supervised-learning"],"details":"Nowadays, transfer learning from pretrained models on Imagenet is the ultimate standard in computer vision. Self-supervised learning dominates natural language processing, but this doesn\u2019t mean that there are no significant use-cases for computer vision that it should be considered. There are indeed a lot of cool self-supervised tasks that one can devise when she/he is dealing with images, such as jigsaw puzzles [6], image colorization, image inpainting, or even unsupervised image synthesis.\r\n\r\nBut what happens when the time dimension comes into play? How can you approach the video-based tasks that you would like to solve?\r\n\r\nSo, let\u2019s start from the beginning, one concept at a time. What is self-supervised learning? And how is it different from transfer learning? What is a pretext task?\r\n","links":[{"article_link":"https://theaisummer.com/self-supervised-learning-videos/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://theaisummer.com/"}]},{"id":2028,"title":"Which machine learning algorithm to choose?","description":"in this article, we show you structured methodology and guidelines which will help you to select the best algorithm for your use.","tags":["article","machine-learning","regression","classification"],"details":"","links":[{"article_link":"https://blog.datavalley.technology/2020/07/14/so-which-machine-learning-algorithm-to-use/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2027,"title":"Nearest Celebrity Face","description":"Implementation of FaceNet: A Unified Embedding for Face Recognition and Clustering to find the celebrity whose face matches the closest to yours. The input face","tags":["article","code","deep-learning","siamese-networks","computer-vision"],"details":"# Overview\r\n\r\n# Nearest-Celebrity-Face\r\n\r\n[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/facenet-a-unified-embedding-for-face/face-verification-on-ijb-c)](https://paperswithcode.com/sota/face-verification-on-ijb-c?p=facenet-a-unified-embedding-for-face)\r\n[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/facenet-a-unified-embedding-for-face/face-verification-on-labeled-faces-in-the)](https://paperswithcode.com/sota/face-verification-on-labeled-faces-in-the?p=facenet-a-unified-embedding-for-face)\r\n[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/facenet-a-unified-embedding-for-face/face-verification-on-megaface)](https://paperswithcode.com/sota/face-verification-on-megaface?p=facenet-a-unified-embedding-for-face)\r\n[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/facenet-a-unified-embedding-for-face/face-identification-on-megaface)](https://paperswithcode.com/sota/face-identification-on-megaface?p=facenet-a-unified-embedding-for-face)\r\n[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/facenet-a-unified-embedding-for-face/face-verification-on-youtube-faces-db)](https://paperswithcode.com/sota/face-verification-on-youtube-faces-db?p=facenet-a-unified-embedding-for-face)\r\n\r\n### Overview\r\nImplementation of [FaceNet: A Unified Embedding for Face Recognition and Clustering\r\n](https://arxiv.org/abs/1503.03832v3) to find the celebrity whose face matches the closest to yours.\r\nThe input face is encoded with a pretrained inception model into a vector and then its geometric distance is calculated with the encoded vectors of all the images present in the dataset and the image with the least distance is selected.\r\n\r\n**Article Link:** [https://soumik12345.github.io/geekyrakshit-blog/computervision/deeplearning/facenet/inception/keras/nearestcelebrityface/python/tensorflow/2019/08/07/nearest-celebrity-face.html](https://soumik12345.github.io/geekyrakshit-blog/computervision/deeplearning/facenet/inception/keras/nearestcelebrityface/python/tensorflow/2019/08/07/nearest-celebrity-face.html)\r\n\r\n### Installation\r\n1. Create a new conda environment using `conda create --name nearest_celeb_face`\r\n2. Activate the `activate nearest_celeb_face` if you are on Windows and `source activate nearest_celeb_face` if you are on Linux\r\n3. Clone the repository using `git clone https://github.com/soumik12345/Nearest-Celebrity-Face`\r\n4. Enter the root directory using `cd Nearest-Celebrity-Face`\r\n5. Install the required dependencies using `pip install -r requirements.txt`\r\n\r\n### Usage\r\nThe `TestCases` folder contains two folders `Actual` that contains full sized images of individuals and `Preprocessed` containing the faces manually cropped out of the full sized images. Any number of testcases can be added provided that one image each is present in the `Actual` and `Preprocessed` folders with the exact same filename and the preprocessed image should have the face manually cropped out for best performance. Refer to the already cropped images for further detail on how to crop. Once the tescases are setup, run `python main.py` or `python3 main.py` to run the program.\r\n\r\n### Sample Outputs\r\n![](https://raw.githubusercontent.com/soumik12345/Nearest-Celebrity-Face/master/Results/Figure_1-1.png)\r\n![](https://raw.githubusercontent.com/soumik12345/Nearest-Celebrity-Face/master/Results/Figure_1-3.png)\r\n![](https://raw.githubusercontent.com/soumik12345/Nearest-Celebrity-Face/master/Results/Figure_1-5.png)\r\n![](https://raw.githubusercontent.com/soumik12345/Nearest-Celebrity-Face/master/Results/Figure_1-8.png)\r\n![](https://raw.githubusercontent.com/soumik12345/Nearest-Celebrity-Face/master/Results/Figure_1.png)\r\n![](https://raw.githubusercontent.com/soumik12345/Nearest-Celebrity-Face/master/Results/Figure_1-10.png)\r\n\r\n### Citation\r\n```\r\n@article{1503.03832,\r\n  Author = {Florian Schroff and Dmitry Kalenichenko and James Philbin},\r\n  Title = {FaceNet: A Unified Embedding for Face Recognition and Clustering},\r\n  Year = {2015},\r\n  Eprint = {arXiv:1503.03832},\r\n  Doi = {10.1109/CVPR.2015.7298682},\r\n}\r\n```","links":[{"article_link":"https://soumik12345.github.io/geekyrakshit-blog/computervision/deeplearning/facenet/inception/keras/nearestcelebrityface/python/tensorflow/2019/08/07/nearest-celebrity-face.html","code_link":"https://github.com/soumik12345/Nearest-Celebrity-Face","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2026,"title":"Efficient Serverless Deployment of PyTorch Models on Azure","description":"A tutorial for serving models cost-effectively at scale using Azure Functions and ONNX Runtime.","tags":["article","tutorial","azure","onnx","pytorch","production","serving"],"details":"We will walk through the steps to take a PyTorch model and deploy it into the Azure Functions serverless infrastructure, running the model prediction in the highly efficient ONNX Runtime execution environment. While the steps illustrated below are specific to a model that was built using the popular fast.ai (a convenience library built on PyTorch), the pattern itself is quite generic and can be applied to deploying any PyTorch model.\r\nThe main steps to get your models into production on Azure serverless infrastructure using the ONNX Runtime execution engine (after you have trained your model are):\r\n\r\n1. Export model\r\n1. Test model deployment locally\r\n1. Deploy model to the Azure Functions","links":[{"article_link":"https://medium.com/pytorch/efficient-serverless-deployment-of-pytorch-models-on-azure-dc9c2b6bfee7","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2025,"title":"Haystack \u2014 Neural Question Answering At Scale","description":"\ud83d\udd0d Transformers at scale for question answering & search\r\n\r\n","tags":["article","code","huggingface","transformers","library","natural-language-processing","question-answering","search","elastic-search","scale","haystack"],"details":"### Introduction\r\n\r\nThe performance of **modern Question Answering Models** (BERT, ALBERT ...) has seen drastic improvements within the last year enabling many new opportunities for accessing information more efficiently. However, those models are designed to find answers within rather small text passages. **Haystack lets you scale QA models** to large collections of documents! While QA is the focussed use case for Haystack, we will address further options around neural search in the future (re-ranking, most-similar search ...).\r\n\r\nHaystack is designed in a modular way and lets you use any models trained with [FARM](https://github.com/deepset-ai/FARM) or [Transformers](https://github.com/huggingface/transformers).\r\n\r\n### Core Features\r\n\r\n-   **Powerful ML models**: Utilize all latest transformer based models (BERT, ALBERT, RoBERTa ...)\r\n-   **Modular & future-proof**: Easily switch to newer models once they get published.\r\n-   **Developer friendly**: Easy to debug, extend and modify.\r\n-   **Scalable**: Production-ready deployments via Elasticsearch backend & REST API\r\n-   **Customizable**: Fine-tune models to your own domain & improve them continuously via user feedback\r\n\r\n### Components\r\n\r\n![image](https://raw.githubusercontent.com/deepset-ai/haystack/master/docs/img/sketched_concepts_white.png)\r\n\r\n1.  **DocumentStore**: Database storing the documents for our search. We recommend Elasticsearch, but have also more light-weight options for fast prototyping (SQL or In-Memory).\r\n2.  **Retriever**: Fast, simple algorithm that identifies candidate passages from a large collection of documents. Algorithms include TF-IDF or BM25, custom Elasticsearch queries, and embedding-based approaches. The Retriever helps to narrow down the scope for Reader to smaller units of text where a given question could be answered.\r\n3.  **Reader**: Powerful neural model that reads through texts in detail to find an answer. Use diverse models like BERT, RoBERTa or XLNet trained via [FARM](https://github.com/deepset-ai/FARM) or [Transformers](https://github.com/huggingface/transformers) on SQuAD like tasks. The Reader takes multiple passages of text as input and returns top-n answers with corresponding confidence scores. You can just load a pretrained model from [Hugging Face's model hub](https://huggingface.co/models) or fine-tune it to your own domain data.\r\n4.  **Finder**: Glues together a Reader and a Retriever as a pipeline to provide an easy-to-use question answering interface.\r\n5.  **REST API**: Exposes a simple API for running QA search, collecting feedback and monitoring requests\r\n6.  **Haystack Annotate**: Create custom QA labels, [Hosted version](https://annotate.deepset.ai/login) (Beta), Docker images (coming soon)\r\n\r\n### Resources\r\n\r\n-   Tutorial 1 - Basic QA Pipeline: [Jupyter notebook](https://github.com/deepset-ai/haystack/blob/master/tutorials/Tutorial1_Basic_QA_Pipeline.ipynb) or [Colab](https://colab.research.google.com/github/deepset-ai/haystack/blob/master/tutorials/Tutorial1_Basic_QA_Pipeline.ipynb)\r\n-   Tutorial 2 - Fine-tuning a model on own data: [Jupyter notebook](https://github.com/deepset-ai/haystack/blob/master/tutorials/Tutorial2_Finetune_a_model_on_your_data.ipynb) or [Colab](https://colab.research.google.com/github/deepset-ai/haystack/blob/master/tutorials/Tutorial2_Finetune_a_model_on_your_data.ipynb)\r\n-   Tutorial 3 - Basic QA Pipeline without Elasticsearch: [Jupyter notebook](https://github.com/deepset-ai/haystack/blob/master/tutorials/Tutorial3_Basic_QA_Pipeline_without_Elasticsearch.ipynb) or [Colab](https://colab.research.google.com/github/deepset-ai/haystack/blob/master/tutorials/Tutorial3_Basic_QA_Pipeline_without_Elasticsearch.ipynb)\r\n-   Tutorial 4 - FAQ-style QA: [Jupyter notebook](https://github.com/deepset-ai/haystack/blob/master/tutorials/Tutorial4_FAQ_style_QA.ipynb) or [Colab](https://colab.research.google.com/github/deepset-ai/haystack/blob/master/tutorials/Tutorial4_FAQ_style_QA.ipynb)\r\n-   Tutorial 5 - Evaluation of the whole QA-Pipeline: [Jupyter noteboook](https://github.com/deepset-ai/haystack/blob/master/tutorials/Tutorial5_Evaluation.ipynb) or [Colab](https://colab.research.google.com/github/deepset-ai/haystack/blob/master/tutorials/Tutorial5_Evaluation.ipynb)\r\n-   Tutorial 6 - Better Retrievers via \"Dense Passage Retrieval\": [Jupyter noteboook](https://github.com/deepset-ai/haystack/blob/master/tutorials/Tutorial6_Better_Retrieval_via_DPR.ipynb) or [Colab](https://colab.research.google.com/github/deepset-ai/haystack/blob/master/tutorials/Tutorial6_Better_Retrieval_via_DPR.ipynb)","links":[{"article_link":"https://medium.com/deepset-ai/haystack-question-answering-at-scale-c2c980e7c657","code_link":"https://github.com/deepset-ai/haystack","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2024,"title":"DeText: A Deep Neural Text Understanding Framework","description":"DeText: A Deep Neural Text Understanding Framework for Ranking and Classification Tasks.","tags":["code","library","natural-language-processing","natural-language-understanding","detext"],"details":"### What is it\r\n**DeText** is a **De**ep **Text** understanding framework for NLP related ranking, classification, and language generation tasks.  It leverages semantic matching using deep neural networks to \r\nunderstand member intents in search and recommender systems. \r\nAs a general NLP framework, currently DeText can be applied to many tasks, \r\nincluding search & recommendation ranking, multi-class classification and query understanding tasks.\r\n\r\n### Highlight\r\nDesign principles for DeText framework:\r\n* Natural language understanding powered by state-of-the-art deep neural networks\r\n  * Automatic feature extraction with deep models\r\n  * End-to-end training\r\n  * Interaction modeling between ranking sources and targets\r\n* A general framework with great flexibility to meet requirement of different production applications.\r\n  * Flexible deep model types\r\n  * Multiple loss function choices\r\n  * User defined source/target fields\r\n  * Configurable network structure (layer sizes and #layers)\r\n  * Tunable hyperparameters\r\n...\r\n  \r\n* Reaching a good balance between effectiveness and efficiency to meet the industry requirements.\r\n\r\n## The framework\r\nThe DeText framework contains multiple components:\r\n\r\n**Word embedding layer**.  It converts the sequence of words into a d by n matrix.\r\n\r\n**CNN/BERT/LSTM for text encoding layer**.  It takes into the word embedding matrix as input, and maps the text data into a fixed length embedding.  It is worth noting that we adopt the representation based methods over the interaction based methods.  The main reason is the computational complexity: The time complexity of interaction based methods is at least O(mnd), which is one order higher than the representation based methods max(O(md), O(nd).\r\n\r\n**Interaction layer**.  It generates deep features based on the text embeddings.  Many options are provided, such as concatenation, cosine similarity, etc.\r\n\r\n**Wide & Deep Feature Processing**.  We combine the traditional features with the interaction features (deep features) in a wide & deep fashion.\r\n\r\n**MLP layer**. The MLP layer is to combine wide features and deep features. \r\n\r\nIt is an end-to-end model where all the parameters are jointly updated to optimize the click probability.\r\n\r\n![](https://github.com/linkedin/detext/raw/master/detext_model_architecture.png) \r\n\r\n### Model Flexibility\r\nDeText is a general ranking framework that offers great flexibility for clients to build customized networks for their own use cases:\r\n\r\n**LTR/classification layer**: in-house LTR loss implementation, or tf-ranking LTR loss, multi-class classification support.\r\n\r\n**MLP layer**: customizable number of layers and number of dimensions.\r\n\r\n**Interaction layer**: support Cosine Similarity, Outer Product, Hadamard Product, and Concatenation.\r\n\r\n**Text embedding layer**: support CNN, BERT, LSTM-Language-Model with customized parameters on filters, layers, dimensions, etc.\r\n\r\n**Continuous feature normalization**: element-wise scaling, value normalization.\r\n\r\n**Categorical feature processing**: modeled as entity embedding.\r\n\r\nAll these can be customized via hyper-parameters in the DeText template. Note that tf-ranking is supported in the DeText framework, i.e., users can choose the LTR loss and metrics defined in DeText.","links":[{"article_link":"","code_link":"https://github.com/linkedin/detext","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2023,"title":"Why You Should Do NLP Beyond English","description":"7000+ languages are spoken around the world but NLP research has mostly focused on English. This post outlines why you should work on languages other than Eng.","tags":["article","natural-language-processing","languages","non-english"],"details":"Natural language processing (NLP) research predominantly focuses on developing methods that work well for English despite the many positive benefits of working on other languages. These benefits range from an outsized societal impact to modelling a wealth of linguistic features to avoiding overfitting as well as interesting challenges for machine learning (ML).","links":[{"article_link":"https://ruder.io/nlp-beyond-english/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2022,"title":"Simple Transformers","description":"Transformers for Classification, NER, QA, Language Modeling, Language Generation, T5, Multi-Modal, and Conversational AI.","tags":["code","transformers","library","language-modeling","multi-modal","named-entity-recognition","natural-language-processing","question-answering","t5","conversational-ai","language-generation"],"details":"This library is based on the [Transformers](https://github.com/huggingface/transformers) library by HuggingFace. Simple Transformers lets you quickly train and evaluate Transformer models. Only 3 lines of code are needed to initialize a model, train the model, and evaluate a model.\r\n\r\nSupports\r\n\r\n- Sequence Classification\r\n- Token Classification (NER)\r\n- Question Answering\r\n- Language Model Fine-Tuning\r\n- Language Model Training\r\n- Language Generation\r\n- T5 Model\r\n- Seq2Seq Tasks\r\n- Multi-Modal Classification\r\n- Conversational AI.\r\n- Text Representation Generation.","links":[{"article_link":"","code_link":"https://github.com/ThilinaRajapakse/simpletransformers","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://simpletransformers.ai/"}]},{"id":2021,"title":"Handling the missing values in Data: The Easy Way","description":"Most of the Machine Learning Algorithms cannot work with missing values in the features.  Let's see the possible options we have to deal with it.","tags":["article","code","dataset","tutorial","scikit-learn","missing-data"],"details":"","links":[{"article_link":"https://towardsdatascience.com/handling-the-missing-values-in-data-the-easy-way-9ea5983f8ba4","code_link":"https://github.com/akashp1712/ml-akash/blob/master/Articles/imputer/imputer.py","research_link":"","media_link":"","dataset_link":"https://github.com/akashp1712/ml-akash/blob/master/Articles/imputer/melb_data.csv","demo_link":"","other_link":""}]},{"id":2020,"title":"Text Summarization using TF-IDF Algorithm","description":"This Article explains the TF-IDF algorithm and shows the implemtnation from scratch to summarize the text.","tags":["article","code","natural-language-processing","text-summarization","demo","tf-idf"],"details":"","links":[{"article_link":"https://towardsdatascience.com/text-summarization-using-tf-idf-e64a0644ace3","code_link":"https://github.com/akashp1712/nlp-akash/blob/master/text-summarization/TF_IDF_Summarization.py","research_link":"","media_link":"","dataset_link":"","demo_link":"https://share.streamlit.io/akashp1712/streamlit-apps/main/text_summarization_streamlit.py","other_link":""}]},{"id":2018,"title":"Training CNN with Mixed Precision in PyTorch 1.6","description":"Simple Example on MNIST dataset illustrating Mixed Precision Training.\r\n","tags":["code","tutorial","pytorch","convolutional-neural-networks","deep-learning"],"details":"- Simple Example on MNIST dataset illustrating Mixed Precision Training.\r\n- Demonstrates the new inbuilt Mixed Precision Training. \r\n- Shows tricks like Gradient Penalty, and combining this procedure with normal training.\r\n- Shows how to train EfficientNet with these tricks.","links":[{"article_link":"","code_link":"https://www.kaggle.com/okeaditya/mixed-precision-training-using-pytorch-1-6","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2017,"title":"AutoML clone","description":"AutoMl clone that lets you build and deploy ML models with 0 lines of code","tags":["code","fastai","keras","convolutional-neural-networks","machine-learning","automl","fastap"],"details":"**Objectives**\r\n\r\n* Build and deploy ML model without code\r\n\r\n**Features**\r\n\r\n* Scrap High quality dataset from web\r\n* Edit Datasets\r\n* Train Ml Models\r\n* Test Ml Models\r\n* Deploy ML models\r\n\r\n**Roadmap**\r\n\r\n* Deploy To GCP cloud Functions\r\n* Export to TFlite\r\n* Export to TFjs\r\n* NLP models\r\n","links":[{"article_link":"","code_link":"https://github.com/AbdulRashidReshamwala/TAP_TAP_ML","research_link":"","media_link":"https://youtu.be/jKqy1bwYJN8","dataset_link":"","demo_link":"","other_link":""}]},{"id":2016,"title":"Meme Classifier Using TFlite and flutter","description":"Meme classifier using fine tuned mobilenet. This app showcases how you can perform low latency realtime classification apps using TFlite","tags":["code","video","tensorflow","convolutional-neural-networks","computer-vision","image-classification","transfer-learning","tensorflow-lite","demo"],"details":"**Meme Classifier**\r\n\r\nTechnologies used:\r\n\r\n* TFlite\r\n* keras\r\n* flutter\r\n\r\nObjectives:\r\n\r\n* Showcase transfer learning\r\n* Converting model to tflite format\r\n* Performing On device realtime inference\r\n\r\nNext Steps:\r\n\r\n*  Building modular system to download multiple model","links":[{"article_link":"","code_link":"https://github.com/AbdulRashidReshamwala/mobilnet-realtime-detection","research_link":"","media_link":"https://www.youtube.com/watch?v=V_UyfkKM2BY","dataset_link":"","demo_link":"https://github.com/AbdulRashidReshamwala/mobilnet-realtime-detection/blob/master/app.apk","other_link":""}]},{"id":2015,"title":"How to Derive Convolution From First Principles","description":"I derive the convolution from first principles and show that it naturally emerges from translational symmetry.","tags":["article","convolutional-neural-networks"],"details":"**TL;DR**: Have you even wondered what is so special about convolution? In this post, I derive the convolution from first principles and show that it naturally emerges from translational symmetry.\r\n","links":[{"article_link":"https://medium.com/@michael.bronstein/deriving-convolution-from-first-principles-4ff124888028","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2014,"title":"Fourier Feature Mapping Networks","description":"Tensorflow 2.2 implementation of Fourier Feature Mapping Networks ","tags":["code","paper","research","tensorflow","neural-networks","multilayer-perceptrons","fourier-features","arxiv:2006.10739"],"details":"Tensorflow 2.2 implementation of Fourier Feature Mapping networks described in the paper : [Fourier Features Let Networks Learn High Frequency Functions in Low Dimensions](https://arxiv.org/abs/2006.10739). Please check the Github Repository for implementation details and Weights & Biases Reports.","links":[{"article_link":"","code_link":"https://github.com/Samyak2/fourier-dnn.git","research_link":"https://arxiv.org/abs/2006.10739","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2013,"title":"DeepClas4Bio","description":"DeepClas4Bio is a project that aims to facilitate the interoperability of bioimaging tools with deep learning frameworks.","tags":["code","paper","research","computer-vision","image-classification","interoperability","imagej","bioimage"],"details":"","links":[{"article_link":"","code_link":"https://github.com/adines/DeepClas4Bio","research_link":"https://doi.org/10.1016/j.compbiomed.2019.03.026","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2012,"title":"LabelStoma: stomata detection using YOLO","description":"LabelStoma is a graphical image tool for automatically detecting stomata in images. ","tags":["code","research","computer-vision","object-detection"],"details":"","links":[{"article_link":"","code_link":"https://github.com/ancasag/labelStoma","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2011,"title":"UFOD: A Unified Framework for Object Detection","description":"UFOD is an open-source framework that enables the training and comparison of object detection models on custom datasets using different underlying frameworks an","tags":["code","automl","computer-vision","object-detection"],"details":"","links":[{"article_link":"","code_link":"https://github.com/ManuGar/UFOD","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2010,"title":"FrImCla: A framework for image classification","description":"\r\nFrImCla is an open-source framework for Image Classification using traditional and deep learning techniques. It supports a wide variety of deep learning and c","tags":["code","paper","research","computer-vision","image-classification","transfer-learning"],"details":"","links":[{"article_link":"","code_link":"https://github.com/ManuGar/FrImCla","research_link":"https://doi.org/10.1109/ACCESS.2020.2980798","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2009,"title":"ATLASS: AutoML using Transfer and Semi-Supervised Learning","description":"This repository includes the code, application, and notebooks for the work \"AutoML using Transfer and Semi-Supervised Learning\". The tools presented here can be","tags":["code","paper","research","automl","computer-vision","image-classification","semi-supervised-learning","transfer-learning"],"details":"","links":[{"article_link":"","code_link":"https://github.com/adines/ATLASS/","research_link":"https://github.com/adines/ATLASS/blob/master/assets/draft.pdf","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2008,"title":"Extension to block NSFW content using AI","description":"NSFW Filter is an extension that blocks NSFW content from your browser.\r\nIt uses a computer vision model to detect NSFW content and hides it from the user.","tags":["code","javascript","tensorflow","tensorflow-js","convolutional-neural-networks","deep-learning","machine-learning","web-services","computer-vision","transfer-learning","demo"],"details":"[NSFW Filter](https://github.com/navendu-pottekkat/nsfw-filter) is an extension to block NSFW content from your browsers.\r\n\r\nIt uses a Computer Vision-CNN model- to detect NSFW content from web pages and hides them from the user.\r\n\r\nNSFW Filter is completely open-source and it always will be. \r\n\r\nWe are a passionate team of developers from around the World trying to find the solutions for unsolved problems.\r\n\r\nAny contributions to the project can be made through the [GitHub repo](https://github.com/navendu-pottekkat/nsfw-filter).\r\n\r\nYou can share your feedback through our [Slack channel](https://join.slack.com/t/nsfwfilter/shared_invite/zt-gfx0dewg-Hc0~3gu4jXcCDYWQxu3lZA).","links":[{"article_link":"","code_link":"https://github.com/navendu-pottekkat/nsfw-filter","research_link":"","media_link":"","dataset_link":"","demo_link":"https://github.com/navendu-pottekkat/nsfw-filter/blob/master/DEMO.md","other_link":""}]},{"id":2007,"title":"CLoDSA: A Tool for Augmentation in Computer Vision tasks","description":"CLoDSA is an open-source image augmentation library for object classification, localization, detection, semantic segmentation and instance segmentation. It supp","tags":["code","paper","research","library","computer-vision","data-augmentation","object-classification","object-detection","segmentation"],"details":"CLoDSA is an open-source image augmentation library for object classification, localization, detection, semantic segmentation and instance segmentation. It supports a wide variety of augmentation techniques and allows the user to easily combine them. It can also be applied to lists of images like videos or z-stacks. \r\n\r\n#### Notebooks (colab)\r\n\r\n* [Augmenting a dataset for instance segmentation using COCO format](https://colab.research.google.com/github/joheras/CLoDSA/blob/master/notebooks/CLODSA_Instance_Segmentation.ipynb).\r\n* [Augmenting a dataset for detection using COCO format](https://colab.research.google.com/github/joheras/CLoDSA/blob/master/notebooks/CLODSA_COCO_Detection.ipynb).\r\n* [Augmenting a dataset for instance segmentation using COCO format and ignoring some of the classes](https://colab.research.google.com/github/joheras/CLoDSA/blob/master/notebooks/CLODSA_Instance_Segmentation_Ignore_Classes.ipynb).\r\n* [Augmenting a dataset for instance segmentation](https://colab.research.google.com/github/joheras/CLoDSA/blob/master/notebooks/CLODSA_Instance_Segmentation_JSON.ipynb).\r\n* [Augmenting a dataset for semantic segmentation](https://colab.research.google.com/github/joheras/CLoDSA/blob/master/notebooks/CLODSA_Nuclei.ipynb).\r\n* [Augmenting a dataset for object detection](https://colab.research.google.com/github/joheras/CLoDSA/blob/master/notebooks/CLODSA_Plants.ipynb).\r\n* [Augmenting a dataset for object detection using YOLO format](https://colab.research.google.com/github/joheras/CLoDSA/blob/master/notebooks/CLODSA_YOLO.ipynb).\r\n* [Augmenting a dataset for image classification](https://colab.research.google.com/github/joheras/CLoDSA/blob/master/notebooks/CLODSA_Melanoma.ipynb).\r\n* [Online augmentation for image classification using Keras](https://colab.research.google.com/github/joheras/CLoDSA/blob/master/notebooks/CLODSA_Keras.ipynb).\r\n* [Augmenting a dataset for image classification modifying the class](https://colab.research.google.com/github/joheras/CLoDSA/blob/master/notebooks/CLODSA_left_right.ipynb).\r\n* [Augmenting a dataset for video classification of action recognition](https://colab.research.google.com/github/joheras/CLoDSA/blob/master/notebooks/CLODSA_Video_Classification.ipynb).\r\n* [Augmenting a dataset for video detection](https://colab.research.google.com/github/joheras/CLoDSA/blob/master/notebooks/CLODSA_Video_Detection.ipynb).\r\n* [Augmenting a dataset of stacks of images for segmentation](https://colab.research.google.com/github/joheras/CLoDSA/blob/master/notebooks/CLODSA_Stack_Segmentation.ipynb).\r\n","links":[{"article_link":"","code_link":"https://github.com/joheras/clodsa","research_link":"https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-019-2931-1","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2006,"title":"Deep Learning Techniques for NLP in Healthcare","description":"A talk discussing the recent advancements of deep learning to facilitate the adaption of NLP in the healthcare domain.","tags":["tutorial","video","deep-learning","health","natural-language-processing"],"details":"My Talk on recent advancements of Deep learning to facilitate the adaption of NLP in the healthcare domain organized by TensorFlow User Group and MUST Research Club.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=zCyAbwZk-qM","dataset_link":"","demo_link":"","other_link":"https://drive.google.com/file/d/195Fz8krHwagMNnEwOiMNNViDJ1dIdsWB/view?usp=sharing"}]},{"id":2005,"title":"Social Distance Detection","description":"If people are very close to each other, a red bounding box is displayed around them indicating that they are not maintaining social distance.","tags":["code","tutorial","video","python","computer-vision","opencv","inference","social-distancing"],"details":"1. The camera needs calibration so we can map the pixel distance correctly to the real world distance\r\n2. The code here is quite light weight and could run on an embedded device like\u00a0Jetson TX2\u00a0connected to a camera.\r\n3. If there is a social distancing violation an action can be triggered. ","links":[{"article_link":"","code_link":"https://github.com/swayam01/Social-Distance-Algorithm","research_link":"","media_link":"https://github.com/swayam01/Social-Distance-Algorithm/blob/master/presentation.pptx","dataset_link":"","demo_link":"","other_link":"https://www.youtube.com/watch?v=AiDQQ-GgEQ8&t"}]},{"id":2004,"title":"Cancer Diagnosis using ML Techniques","description":"In this project we will be discussing how to predict the effect of Genetic Variants to enable Personalized Medicine for various types of cancer using ML algos.\r\n","tags":["article","code","dataset","logistic-regression","machine-learning","random-forests","regression","support-vector-machines","k-nearest-neighbors","decision-tree","cancer"],"details":"","links":[{"article_link":"https://medium.com/analytics-vidhya/personalized-cancer-diagnosis-3d6f09a6b8c9","code_link":"https://github.com/tulasiram58827/Cancer-Diagnosis","research_link":"","media_link":"","dataset_link":"https://www.kaggle.com/c/msk-redefining-cancer-treatment/data","demo_link":"","other_link":""}]},{"id":2003,"title":"What's New in PyTorch 1.6","description":"A brief overview of new and interesting features in PyTorch 1.6\r\nIt contains byte-sized and working examples to show these features.","tags":["code","tutorial","pytorch","library"],"details":"Display of new features in PyTorch 1.6\r\n\r\nNotebook displays some of the new features of PyTorch\r\n\r\n1. Mixed Precision Training using `torch.amp`\r\n2. New Model Profiling tool.\r\n3. Graph Quantization Updates.\r\n4. Numeric Suite for Quantization ","links":[{"article_link":"","code_link":"https://www.kaggle.com/okeaditya/what-s-new-in-pytorch-1-6","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2002,"title":"Multi-target in Albumentations","description":"Many images, many masks, bounding boxes, and key points. How to transform them in sync?","tags":["article","library","computer-vision","data-augmentation","image-augmentation","albumentations","multi-target"],"details":"Albumentations work the best with the standard tasks of classification, segmentation, object, and keypoint detection. But there are situations when your samples consist of a set of different objects.\r\n\r\n* Multi-target functionality specifically designed for this situation.\r\n* Possible use cases.\r\n* Siamese networks\r\n* Sequential frames in the video.\r\n* Image2image.\r\n* Multilabel segmentation.\r\n* Instance segmentation.\r\n* Panoptic segmentation.","links":[{"article_link":"https://towardsdatascience.com/multi-target-in-albumentations-16a777e9006e?source=friends_link&sk=8c3579aa48cfea5e5c703bda6fe5451c","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://albumentations.ai/"}]},{"id":2001,"title":"Deep Learning's Most Important Ideas - A Brief Historical Review","description":"Review well-adopted deep learning ideas that have stood the test of time.","tags":["article","deep-learning","history"],"details":"The goal of this post is to review well-adopted ideas that have stood the test of time. I will present a small set of techniques that cover a lot of basic knowledge necessary to understand modern Deep Learning research. If you're new to the field, these are a great starting point.\r\n\r\n","links":[{"article_link":"https://dennybritz.com/blog/deep-learning-most-important-ideas/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":2000,"title":"The Ultimate Guide to the Pandas Library for Data Science in Pyth","description":"The fundamentals of pandas that you can use to build data-driven Python applications today.","tags":["article","tutorial","pandas"],"details":"**Table of contents**:\r\n\r\n* Introduction to Pandas\r\n* Pandas Series\r\n* Pandas DataFrames\r\n* How to Deal With Missing Data in Pandas DataFrames\r\n* The Pandas groupby Method\r\n* What is the Pandas groupby Feature?\r\n* The Pandas concat Method\r\n* The Pandas merge Method\r\n* The Pandas join Method\r\n* Other Common Operations in Pandas\r\n* Local Data Input and Output (I/O) in Pandas\r\n* Remote Data Input and Output (I/O) in Pandas\r\n* Final Thoughts & Special Offer","links":[{"article_link":"https://www.freecodecamp.org/news/the-ultimate-guide-to-the-pandas-library-for-data-science-in-python/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1999,"title":"Small differences in BLEU are meaningless","description":"Only big differences in metric scores are meaningful in MT.","tags":["article","paper","research","language-modeling","metrics","natural-language-processing","bleu","arxiv:2006.06264"],"details":"Small differences in evaluation metrics such as BLEU are probably meaningless.  Which is striking since ACL and other \u201cselective\u201d and \u201cprestigious\u201d venues are happy to accept papers on the basis of small improvements in metric scores.","links":[{"article_link":"https://ehudreiter.com/2020/07/28/small-differences-in-bleu-are-meaningless/","code_link":"","research_link":"https://arxiv.org/abs/2006.06264","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1998,"title":"Test Internet Speed using Python","description":"In this article we discuss how to test internet speed using Python as well as covered the features of the speetest-cli library.","tags":["article","tutorial","python","program-development"],"details":"","links":[{"article_link":"In this article we discussed how to test internet speed using Python as well as covered the features of the speetest-cli library and showed how some parameters can be adjusted.","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1997,"title":"Image Classification by @carrycooldude","description":"Image Classification using TFLite and ImageNet  by  @carrycooldude","tags":["code","dataset","tensorflow","convolutional-neural-networks","computer-vision","image-classification","tensorflow-lite","imagenet"],"details":"**Image Classification using TFLite and ImageNet  by @carrycooldude **","links":[{"article_link":"","code_link":"https://github.com/carrycooldude/imageClassification","research_link":"","media_link":"https://drive.google.com/file/d/1Dmuw5kUAX-AsiBWl4N1RpNECgnheKCrK/view?usp=sharing","dataset_link":"http://www.image-net.org/","demo_link":"","other_link":"http://www.image-net.org/"}]},{"id":1996,"title":"Classify Song Genres from Audio Data","description":"My first machine learning project has been uploaded on GitHub.\r\nI started simple with a supervised learning to classify Rock and HipHop songs","tags":["code","dataset","notebook","music","audio","audio-classification","exploratory-data-analysis"],"details":"Objective\r\nUsing a dataset comprised of songs of two music genres (Hip-Hop and Rock),train a classifier to distinguish between the two genres based only on track information derived from Echonest\r\nNext Steps:\r\nA recommendation system for Music\r\n","links":[{"article_link":"","code_link":"https://github.com/OmarEltouny78/SupervisedMusicPrediction/blob/master/notebook.ipynb","research_link":"","media_link":"","dataset_link":"datasets/fma-rock-vs-hiphop.csv","demo_link":"","other_link":""}]},{"id":1995,"title":"Cartoonize your world!","description":"A demo web application to showcase the capability of \"white box cartoonization\" on image and videos.","tags":["code","paper","research","deep-learning","demo","gans","cartoon"],"details":"","links":[{"article_link":"","code_link":"https://github.com/experience-ml/cartoonize","research_link":"https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Learning_to_Cartoonize_Using_White-Box_Cartoon_Representations_CVPR_2020_paper.pdf","media_link":"https://youtu.be/GqduSLcmhto","dataset_link":"","demo_link":"https://cartoonize-lkqov62dia-de.a.run.app/","other_link":""}]},{"id":1994,"title":"Understanding the Effectivity of Ensembles in Deep Learning","description":"The report explores the ideas presented in Deep Ensembles: A Loss Landscape Perspective by Stanislav Fort, Huiyi Hu, and Balaji Lakshminarayanan.","tags":["article","code","research","tutorial","deep-learning","neural-networks","computer-vision","wandb","ensembles"],"details":"The report explores the ideas presented in [Deep Ensembles: A Loss Landscape Perspective](https://arxiv.org/abs/1912.02757) by Stanislav Fort, Huiyi Hu, and Balaji Lakshminarayanan.\r\n\r\nIn the paper, the authors investigate the question - ***why deep ensembles work better than single deep neural networks?***\r\n\r\nIn their investigation, the authors figure out:\r\n\r\n- Different snapshots (i.e., model from epoch 1, model from epoch 2, and so on) of the same model exhibit functional similarity. Hence, their ensemble is less likely to explore the different modes of local minima in the optimization space.\r\n- Different solutions of the same model (i.e., trained with different random initializations each time) exhibit functional dissimilarity. Hence, their ensemble is more likely to explore the different modes of local minima in the optimization space.\r\n\r\nAlong with this fascinating finding, they present several different things that are useful to understand the dynamics of deep neural networks in general.\r\n\r\nThanks to Yannic Kilcher for [his amazing explanation video](https://www.youtube.com/watch?v=5IRlUVrEVL8) of the paper which helped us pursue our experiments.\r\n\r\nThanks to Balaji Lakshminarayanan for providing feedback on the initial draft of the report and also for rectifying our mistake on the tSNE projections.","links":[{"article_link":"https://app.wandb.ai/authors/loss-landscape/reports/Understanding-the-effectivity-of-ensembles-in-deep-learning-(tentative)--VmlldzoxODAxNjA","code_link":"https://github.com/ayulockin/LossLandscape","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1993,"title":"Real-time text detection with EAST in TFLite","description":"Demonstrates the conversion process from the original EAST model to TFLite and how to use it on static images and also on real-time video feeds. ","tags":["article","code","notebook","video","tensorflow","computer-vision","object-detection","tflite"],"details":"The real-time results (see [here](https://www.youtube.com/watch?v=CpywwaAmHPs)) are coming from my humble MacBook Air (13 inch 2017) so please excuse the latency there. ","links":[{"article_link":"https://tfhub.dev/sayakpaul/lite-model/east-text-detector/dr/1","code_link":"https://github.com/sayakpaul/Adventures-in-TensorFlow-Lite/blob/master/EAST_TFLite.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.youtube.com/watch?v=CpywwaAmHPs"}]},{"id":1992,"title":"Time series forecasting","description":"A thorough introduction to time series forecasting using TensorFlow.","tags":["article","code","notebook","tutorial","keras","tensorflow","forecasting","time-series"],"details":"This tutorial is an introduction to time series forecasting using TensorFlow. It builds a few different styles of models including Convolutional and Recurrent Neural Networks (CNNs and RNNs).\r\n\r\nThis is covered in two main parts, with subsections:\r\n\r\nForecast for a single timestep:\r\n\r\n* A single feature.\r\n* All features.\r\n\r\nForecast multiple steps:\r\n\r\n* Single-shot: Make the predictions all at once.\r\n* Autoregressive: Make one prediction at a time and feed the output back to the model.","links":[{"article_link":"https://www.tensorflow.org/tutorials/structured_data/time_series","code_link":"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1991,"title":"2020 Machine Learning Roadmap","description":"A beginner mind map (and presentation) connecting many of the most foundational concepts in machine learning.","tags":["code","tutorial","machine-learning","data-science","beginner","introduction"],"details":"![2020 machine learning roadmap overview](https://raw.githubusercontent.com/mrdbourke/machine-learning-roadmap/master/2020-ml-roadmap-overview.png?token=AD7ZOCOIG7IZXHDL63W6RZK7A3B6I)\r\n\r\nA roadmap connecting many of the most important concepts in machine learning, how to learn them and what tools to use to perform them.\r\n\r\nNamely:\r\n\r\n1. \ud83e\udd14 **Machine Learning Problems** - what does a machine learning problem look like?\r\n2. \u267b\ufe0f **Machine Learning Process** - once you\u2019ve found a problem, what steps might you take to solve it?\r\n3. \ud83d\udee0 **Machine Learning Tools** - what should you use to build your solution?\r\n4. \ud83e\uddee **Machine Learning Mathematics** - what exactly is happening under the hood of all the machine learning code you're writing?\r\n5. \ud83d\udcda **Machines Learning Resources** - okay, this is cool, how can I learn all of this?\r\n\r\nSee the [full interactive version](https://dbourke.link/mlmap).\r\n\r\n[Watch a feature-length film video walkthrough](https://youtu.be/pHiMN_gy9mk) (yes, really, it's longer than most movies).\r\n\r\nMany of the materials in this roadmap were inspired by [Daniel Formoso](https://github.com/dformoso)'s [machine learning mindmaps](https://github.com/dformoso/machine-learning-mindmap), so if you enjoyed this one, go and check out his. He also has a mindmap specifically for [deep learning](https://github.com/dformoso/deeplearning-mindmap) too.","links":[{"article_link":"","code_link":"https://github.com/mrdbourke/machine-learning-roadmap","research_link":"","media_link":"https://youtu.be/pHiMN_gy9mk","dataset_link":"","demo_link":"","other_link":"https://dbourke.link/mlmap"}]},{"id":1990,"title":"scikit-learn-lambda","description":"A cost-efficient toolkit for deploying scikit-learn models for realtime HTTP inference on AWS Lambda.","tags":["article","code","aws","scikit-learn","serverless"],"details":"# scikit-learn-lambda\r\n\r\n[![scikit-learn-lambda](https://circleci.com/gh/model-zoo/scikit-learn-lambda.svg?style=svg)](https://app.circleci.com/pipelines/github/model-zoo/scikit-learn-lambda) [![PyPI version](https://badge.fury.io/py/scikit-learn-lambda.svg)](https://badge.fury.io/py/scikit-learn-lambda) [![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\r\n\r\nscikit-learn-lambda is a toolkit for deploying scikit-learn models for realtime inference on AWS Lambda.\r\n\r\n## Why use scikit-learn-lambda?\r\n\r\n* **Get started quickly** - `scikit-learn-lambda` handles the boilerplate code for you,\r\n  simply drop in a `joblib` or `pickle` model file and deploy.\r\n* **Cost efficient** - The equivalent architecture on [AWS\r\n  SageMaker](https://aws.amazon.com/sagemaker/) will cost you ~$50 per endpoint per month.\r\n  Deploying on AWS Lambda allows you to pay-per-request and not worry about\r\n  the number of models you're deploying to production.\r\n* **Built-in autoscaling** - Deploying on [Elastic Container\r\n  Service](https://aws.amazon.com/ecs/) or [Kubernetes](https://kubernetes.io/)\r\n  requires configuring and maintaining autoscaling groups. AWS Lambda abstracts\r\n  this complexity away for you.\r\n\r\nRead more in our blogpost: [Saving 95% on infrastructure costs using AWS Lambda for scikit-learn predictions](https://modelzoo.dev/blog/lambda.html).\r\n\r\n## Overview\r\n\r\nscikit-learn-lambda provides three components:\r\n\r\n1) `scikit-learn-lambda`: A Python package that includes a handler for serving\r\n   `scikit-learn` predictions via AWS Lambda, designed for use with API Gateway.\r\n2) A repository of Lambda layers for various versions of Python (3.6 - 3.8)\r\n   and `scikit-learn` (0.22+).\r\n3) Example Serverless template configuration for deploying a model to an HTTP\r\n   endpoint.\r\n\r\n## Quickstart (Serverless)\r\n\r\nYou have two options for deploying a model with Serverless framework.\r\n\r\n* Package your model as part of the deployment package upload to AWS Lambda.\r\nThis option will require your model file to be under ~50 MB, but achieve the best\r\ncold-start latency.\r\n\r\n* Store your model into Amazon S3 and load it from there on AWS Lambda\r\ninitialization. This option has no model size constraints.\r\n\r\n#### Prerequisites\r\n\r\n* [Install Serverless](https://www.serverless.com/framework/docs/providers/aws/guide/installation/)\r\n* [Configure your AWS credentials](https://www.serverless.com/framework/docs/providers/aws/guide/credentials/)\r\n\r\n#### Package your model with the code (~50 MB limit)\r\n\r\n1) Copy your model joblib file to `scikit-learn-lambda/model.joblib`, the same\r\ndirectory that `serverless.yaml` is in.\r\n\r\n```\r\n$ cp testdata/svm.joblib scikit-learn-lambda/model.joblib\r\n```\r\n\r\n2) Deploy your model with Serverless framework.\r\n\r\n```\r\n$ serverless deploy\r\n```\r\n\r\n3) Test the your endpoint with some example data:\r\n\r\n```\r\n$ curl --header \"Content-Type: application/json\" \\\r\n  --request POST \\\r\n  --data '{\"input\":[[0, 0, 0, 0]]}' \\\r\n  https://<insert your api here>.execute-api.us-west-2.amazonaws.com/dev/predict\r\n$ {\"prediction\": [0]}\r\n```\r\n\r\n#### Customize the Python runtime version or scikit-learn version.\r\n\r\nIt is a good idea to match your Python version and scikit-learn version with\r\nthe environment that was used to train and serialize the model.\r\n\r\nThe default template is configured to use *Python 3.7* and *scikit-learn\r\n0.23.1*. To use a different version, change the layer ARN in the serverless\r\ntemplate. We have prebuilt and published a set of AWS Lambda you can get\r\nstarted with quickly. For production usage, we recommend that you use our\r\nprovided scripts to build and host your own AWS Lambda layer -- see\r\n[Layers](#layers).\r\n\r\n```\r\nfunction:\r\n  scikitLearnLambda:\r\n    ...\r\n    layers:\r\n      - \"<layer ARN including version number>\"\r\n```\r\n\r\nWhen changing the Python runtime version, make sure to also edit the `runtime`\r\nin `serverless`:\r\n\r\n```\r\nprovider:\r\n  ...\r\n  runtime: \"<python3.6, python3.7, or python3.8>\"\r\n```\r\n\r\n## Layers\r\n\r\nTo get around a the [50 MB (zipped) deployment package\r\nlimit](https://docs.aws.amazon.com/lambda/latest/dg/gettingstarted-limits.html),\r\nit is useful to create a distinct layer for the `scikit-learn` dependency. This\r\nfrees up more room in your deployment package for your model or other\r\ndependencies.\r\n\r\n`scikit-learn-lambda` comes with a pre-built set of AWS Lambda layers that include\r\n`scikit-learn` and `joblib` that you can use out of the box on `us-west-2`.\r\nThese layers are hosted on the Model Zoo AWS account  with public permissions\r\nfor any AWS account to use. We also provide a script `tools/build-layers.sh`\r\nthat allows you to build and upload layers owned by your own AWS account.\r\n\r\n#### Prebuilt Layers\r\n\r\nWe have published a set of layers for combinations of Python 3.6 - 3.8 and\r\nscikit-learn 0.22 - 0.24 to different US regions. These are published to\r\n`layers.csv`:\r\n\r\n[`layers.csv`](https://github.com/model-zoo/scikit-learn-lambda/blob/master/layers.csv)\r\n\r\n#### Build your own layers\r\n\r\n`tools/build-layers.sh` is a bash script that can be used to build one or more\r\nAWS Lambda Layers with the `scikit-learn` and `joblib` dependencies.\r\n\r\n_This script assumes you have jq, Docker, and the AWS cli installed on your machine._\r\n\r\n**Example 1**: Build layer for Python 3.7 and scikit-learn 0.23.0.\r\n\r\n    ./build-layers.sh --scikit-learn=0.23.0 --python=3.7\r\n\r\n**Example 2**: Build layer for Python 3.7 and scikit-learn 0.23.0 and\r\npublish to us-west-2.\r\n\r\n     ./build-layers.sh --python=3.7 --scikit-learn==0.23.0 --region=us-west-2\r\n\r\n    ./build-layers.sh\r\n\r\n## Expected HTTP Schema\r\n\r\n`scikit-learn-lambda` is designed to be used with [Lambda Proxy Integrations in\r\nAPI\r\nGateway](https://docs.aws.amazon.com/apigateway/latest/developerguide/set-up-lambda-proxy-integrations.html).\r\nWhen using the provided serverless template, the HTTP endpoint will expect a\r\nPOST request with a `Content-Type` of `application/json`.\r\n\r\nThe expected input fields are:\r\n\r\n* `input` (`string`): The list of array-like values to predict. The shape\r\n  should match the value that is typically fed into a `model.predict` call.\r\n* `return_prediction` (`boolean`): Will return `prediction` in output if true.\r\n  This field is optional and defaults to true.\r\n* `return_probabilities` (`boolean`): Will return `probabilities` in output if\r\n  true. This field is optional and defaults to false.\r\n\r\nOne of `return_prediction` or `return_probabilities` or both must be true.\r\n\r\nThe return response will be JSON-encoded with the following fields:\r\n\r\n* `prediction`: A list of array-like prediction from `model.predict()`, one for\r\n  every sample in the batch.  Present if `return_prediction` is true.\r\n* `probabilities`: A list of dictionaries mapping string class names to\r\n  probabilities from `model.predict_proba()`, one for every sample in the\r\nbatch. Present if `return_probabilities` is true.\r\n\r\n#### Examples\r\n\r\n```\r\n$ curl --header \"Content-Type: application/json\" \\\r\n      --request POST \\\r\n      --data '{\"input\":[[0, 0, 0, 0]]}' \\\r\n      https://<api-id>.execute-api.us-west-2.amazonaws.com/mlp-250-250-250/predict\r\n{\"prediction\": [0]}\r\n```\r\n\r\n```\r\n$ curl --header \"Content-Type: application/json\" \\\r\n      --request POST \\\r\n      --data '{\"input\":[[0, 0, 0, 0]], \"return_probabilities\": true}' \\\r\n      https://<api-id>.execute-api.us-west-2.amazonaws.com/mlp-250-250-250/predict\r\n{\"prediction\": [0], \"probabilities\": [{\"0\": 0.3722170997279803, \"1\": 0.29998954257031885, \"2\": 0.32779335770170076}]}\r\n```\r\n\r\n## Cost Benchmarks\r\n\r\n[https://modelzoo.dev/lambda-vs-sagemaker-cost/](https://modelzoo.dev/lambda-vs-sagemaker-cost/)\r\n\r\nWe've created this interactive visualization to help us understand the cost per month under various usage scenarios. It also includes a comparison to SageMaker inference endpoint costs.","links":[{"article_link":"https://modelzoo.dev/blog/lambda.html","code_link":"https://github.com/model-zoo/scikit-learn-lambda","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1989,"title":"Interpretability in ML: A Broad Overview","description":"An overview of the sub-field of machine learning interpretability, with example models and graphics.","tags":["article","code","machine-learning","interpretability","ai-safety"],"details":"This blog post is my attempt to give an overview of the sub-field of machine learning interpretability. This post isn't comprehensive, but my goal is to review conceptual frameworks, existing research, and future directions. Also features a [GitHub repo](https://github.com/owenshen24/interp-exp) with code used to produce the simple interpretability examples used in the post.","links":[{"article_link":"https://mlu.red/muse/52906366310.html","code_link":"https://github.com/owenshen24/interp-exp","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1988,"title":"Self-Supervised Learning - PyTorch Lightning","description":"This bolts module houses a collection of all self-supervised learning models.","tags":["code","pytorch","library","self-supervised-learning","pytorch-lightning","simclr","contrastive-learning","moco"],"details":"This bolts module houses a collection of all self-supervised learning models.\r\n\r\nSelf-supervised learning extracts representations of an input by solving a pretext task. In this package, we implement many of the current state-of-the-art self-supervised algorithms.\r\n\r\nSelf-supervised models are trained with unlabeled datasets","links":[{"article_link":"","code_link":"https://pytorch-lightning-bolts.readthedocs.io/en/latest/self_supervised_models.html","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1987,"title":"SimCLR in Keras","description":"Tensorflow-Keras Implementation of SimCLR","tags":["code","dataset","paper","research","keras","tensorflow","self-supervised-learning","simclr","contrastive-learning","demo","arxiv:2002.05709","keras-models","t-sne"],"details":"A Tensorflow-Keras Implementation of SimCLRv1 which allows to improve the feature representation quality of your base_model by the means of the Simple Framework for Contrastive Learning of Visual Representations (SimCLR). The provided code should allow to apply the framework to any Keras model with only minor changes.\r\n\r\n![](https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)\r\n\r\nThe given implementation allowed for an top-1 accuracy increase of 17% on the linear classifier trained, with 5% of the data. Furthermore, the t-SNE plot demonstrates a clear clustering of the features according to their class, after training with the SimCLR framework.","links":[{"article_link":"","code_link":"https://github.com/mwdhont/SimCLRv1-keras-tensorflow","research_link":"https://arxiv.org/abs/2002.05709","media_link":"","dataset_link":"https://github.com/garythung/trashnet","demo_link":"https://drive.google.com/file/d/1Npf8sE0dlyV0-SAISnsrGsJBjRDZM-EQ/view?usp=sharing","other_link":""}]},{"id":1986,"title":"Behavioral Testing of NLP models with CheckList","description":"An overview of the \u201cCheckList\u201d framework for fine-grained evaluation of NLP models","tags":["article","tutorial","natural-language-processing","nlp"],"details":"- Understand how you can evaluate NLP models beyond just performance metrics\r\n- Understand \"CheckList\" framework and how you can write blackbox tests to know exactly where your NLP model is weak and where it's strong\r\n- Be familiar with a suite of linguistic capability tests for NLP models","links":[{"article_link":"https://amitness.com/2020/07/checklist/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1985,"title":"Temporal Graph Networks","description":"In this post, we describe Temporal Graph Network, a generic framework for deep learning on dynamic graphs.","tags":["article","code","paper","research","tutorial","graph-neural-networks","graphs","temporal-graph-networks","arxiv:2006.10637"],"details":"Many real-world problems involving networks of transactions of various nature and social interactions and engagements are dynamic and can be modelled as graphs where nodes and edges appear over time. In this post, we describe Temporal Graph Network, a generic framework for deep learning on dynamic graphs.\r\n\r\nIn a nutshell, a TGN encoder acts by creating compressed representations of the nodes based on their interactions and updates them upon each event. To accomplish this, a TGN has the following main components: memory, message function, memory updater, embedding.","links":[{"article_link":"https://towardsdatascience.com/temporal-graph-networks-ab8f327f2efe","code_link":"https://github.com/twitter-research/tgn","research_link":"https://arxiv.org/abs/2006.10637","media_link":"","dataset_link":"","demo_link":"","other_link":"https://ogb.stanford.edu/docs/team/"}]},{"id":1984,"title":"How GPT3 Works - Visualizations and Animations","description":"A compilation of my threads explaining GPT3. ","tags":["article","tutorial","gpt","transformers","natural-language-processing","illustrated","gpt-3"],"details":"How GPT3 works. A visual thread.\r\n\r\nA trained language model generates text.\r\n\r\nWe can optionally pass it some text as input, which influences its output. \r\n\r\nThe output is generated from what the model \"learned\" during its training period where it scanned vast amounts of text.","links":[{"article_link":"https://jalammar.github.io/how-gpt3-works-visualizations-animations/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1983,"title":"CoreML Model Zoo","description":"Collection of unified and converted pre-trained models.","tags":["code","coreml","library","computer-vision","image-classification","object-detection","pretraining","model-hub"],"details":"This is a collection of Machine Learning models converted into the CoreML framework. These models can run on Apple devices under one of the following operating systems: iOS, macOS, tvOS, watchOS.\r\n\r\nAll the models in the repo:\r\n\r\n* have pre-trained weights\r\n* are intended mainly for inference\r\n* are optimized for mobile devices","links":[{"article_link":"","code_link":"https://github.com/vladimir-chernykh/coreml-model-zoo","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1982,"title":"AutoQP: Genetic Programming for Quantum Programing","description":"Automatically writing of quantum code using genetic programming. This code is the actual implementation of research AutoQP.","tags":["code","paper","research","genetic-algorithm","qiskit","quantum-computing","ibm-quantum-computers"],"details":"","links":[{"article_link":"","code_link":"https://github.com/usamaahsan93/AutoQP","research_link":"https://ieeexplore.ieee.org/document/9044554/","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1981,"title":"Deploying FastAPI app to Heroku","description":"A detailed walkthrough on Creating a simple FastAPI app and deploying it to Heroku.","tags":["article","code","tutorial","fastapi","python","devops","heroku","demo"],"details":"A detailed walkthrough on Creating a simple FastAPI app and deploying it to Heroku.","links":[{"article_link":"https://www.tutlinks.com/create-and-deploy-fastapi-app-to-heroku/","code_link":"https://github.com/windson/fastapi/tree/fastapi-deploy-heroku","research_link":"","media_link":"https://youtu.be/H7zAJf20Moc","dataset_link":"","demo_link":"https://youtu.be/H7zAJf20Moc","other_link":""}]},{"id":1980,"title":"Understanding & Implementing SimCLR - an ELI5 guide","description":"I explain the SimCLR and its contrastive loss function step by step, build image embeddings and then show how to use them to train image classifier on top.","tags":["article","code","dataset","notebook","tutorial","pytorch","deep-learning","computer-vision","embeddings","self-supervised-learning","unsupervised-learning","simclr"],"details":"I explore SimCLR pre-training framework proposed by Google in arXiv:2002.05709 paper. I explain the SimCLR and its contrastive loss function step by step, starting from naive implementation followed by faster, vectorized one. Then I show how to use SimCLR\u2019s pretraining routine to first build image embeddings using EfficientNet network architecture and finally how to build classifier on top of it.\r\n\r\nThis post covers:\r\n\r\n* understanding the SimCLR framework\r\n* from scratch explanation & implementation of SimCLR\u2019s loss function (NT-Xent) in PyTorch\r\n* pre-training image embeddings using EfficientNet architecture\r\n* training classifier by using transfer learning from the pre-trained embeddings","links":[{"article_link":"https://zablo.net/blog/post/understanding-implementing-simclr-guide-eli5-pytorch/","code_link":"https://github.com/marrrcin/pytorch-simclr-efficientnet","research_link":"","media_link":"","dataset_link":"https://ai.stanford.edu/~acoates/stl10/","demo_link":"","other_link":""}]},{"id":1978,"title":"How to Set Up a Python Project For Automation and Collaboration","description":"How to set up a Python repo with unit tests, code coverage, lint checking, type checking, Makefile wrapper, and automated build with GitHub Actions.","tags":["article","code","tutorial","git","python","unit-tests","testing"],"details":"As your Python project gets larger in scope, it can become difficult to manage.\r\n\r\n* How can we automate checks (e.g., unit testing, type-checking, linting)?\r\n* How can we minimise collaboration overhead (e.g., code reviews, consistency)?\r\n* How can we maximise developer experience by adding the least extra steps?\r\n\r\nIn this article, I\u2019ll share an approach that works well for me. When we\u2019re done, we\u2019ll have an automated workflow of:\r\n\r\n* Units tests\r\n* Coverage reports\r\n* Lint checks\r\n* Type checks \r\n* Run in local with a single command (make check)\r\n* Run on remote repository with each git push","links":[{"article_link":"https://eugeneyan.com/writing/setting-up-python-project-for-automation-and-collaboration/","code_link":"https://github.com/eugeneyan/python-collab-template/","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1977,"title":"LabelDetection: simplifying the use and construction of deep dete","description":"LabelDetection is a graphical tool that aims to facilitate all the steps required in the pipeline to construct and use a deep-learning base object detection mod","tags":["code","notebook","annotation","computer-vision","object-detection"],"details":"","links":[{"article_link":"","code_link":"https://github.com/ancasag/LabelDetection","research_link":"","media_link":"https://youtu.be/Lqf-IH1CaBE","dataset_link":"","demo_link":"","other_link":""}]},{"id":1976,"title":"Close-Domain fine-tuning for table detection","description":"In this project, we show the benefits of using models trained on a close domain, using the TableBank dataset, for fine-tuning table detection models. In additio","tags":["code","paper","research","computer-vision","object-detection","arxiv:1912.05846"],"details":"","links":[{"article_link":"","code_link":"https://github.com/holms-ur/fine-tuning","research_link":"https://arxiv.org/abs/1912.05846","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1975,"title":"Ensemble methods for object detection","description":"In this repository, we provide the code for ensembling the output of object detection models, and applying test-time augmentation for object detection. This lib","tags":["code","paper","research","deep-learning","library","computer-vision","object-detection"],"details":"","links":[{"article_link":"","code_link":"https://github.com/ancasag/ensembleObjectDetection","research_link":"https://drive.google.com/file/d/1ku8X8lHs6lethEa5Adhj7frzV44NTbl4/view?usp=sharing","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1974,"title":"How to Set Up a HTML App with FastAPI, Jinja, Forms & Templates","description":"I couldn\u2019t find any guides on how to serve HTML with FastAPI. Thus, I wrote this simple article to plug the hole on the internet.","tags":["article","code","tutorial","fastapi","html","jinja","templates"],"details":"I usually use Flask to build and deploy REST/web apps. Flask is simple to use and apps are easy to spin up with minimal code. Today, I decided to try FastAPI for my new web app, inspired by @tiangolo\u2019s recent talk.\r\n\r\nThe switch was easier than expected. FastAPI has great documentation and this article by @amitness was useful. Nonetheless, I couldn\u2019t find any guides on how to serve HTML with FastAPI. Thus, I wrote this simple article to plug the hole on the internet.","links":[{"article_link":"https://eugeneyan.com/writing/how-to-set-up-html-app-with-fastapi-jinja-forms-templates/","code_link":"https://github.com/eugeneyan/fastapi-html","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1973,"title":"PyGLN: Gated Linear Network implementations (NumPy, PT/TF, JAX)","description":"Gated Linear Network implementations for NumPy, PyTorch, TensorFlow and JAX.","tags":["article","code","paper","research","jax","pytorch","tensorflow","library","gated-linear-networks","arxiv:1910.01526"],"details":"This paper presents a new family of backpropagation-free neural architectures, Gated Linear Networks (GLNs). What distinguishes GLNs from contemporary neural networks is the distributed and local nature of their credit assignment mechanism; each neuron directly predicts the target, forgoing the ability to learn feature representations in favor of rapid online learning. Individual neurons can model nonlinear functions via the use of data-dependent gating in conjunction with online convex optimization. We show that this architecture gives rise to universal learning capabilities in the limit, with effective model capacity increasing as a function of network size in a manner comparable with deep ReLU networks. Furthermore, we demonstrate that the GLN learning mechanism possesses extraordinary resilience to catastrophic forgetting, performing comparably to a MLP with dropout and Elastic Weight Consolidation on standard benchmarks. These desirable theoretical and empirical properties position GLNs as a complementary technique to contemporary offline deep learning methods.","links":[{"article_link":"https://aiwabdn.github.io/pygln/","code_link":"https://github.com/aiwabdn/pygln","research_link":"https://arxiv.org/abs/1910.01526","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1972,"title":"Evolution of Representations in the Transformer","description":"The evolution of representations of individual tokens in Transformers trained with different training objectives (MT, LM, MLM - BERT-style).","tags":["article","paper","research","tutorial","attention","bert","transformers","language-modeling","natural-language-processing","representation-learning","representations","arxiv:1909.01380"],"details":"We look at the evolution of representations of individual tokens in Transformers trained with different training objectives (MT, LM, MLM - BERT-style) from the Information Bottleneck perspective and show, that:\r\n\r\n* LMs gradually forget past when forming predictions about future;\r\n* for MLMs, the evolution proceeds in two stages of context encoding and token reconstruction;\r\n* MT representations get refined with context, but less processing is happening.","links":[{"article_link":"https://lena-voita.github.io/posts/emnlp19_evolution.html","code_link":"","research_link":"https://arxiv.org/abs/1909.01380","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1971,"title":"Attention based YOLO: Object Detection","description":"An easy to follow, YOLO implementation with keras lib.  Used a attention based architecture to extract more fine grained information about object.","tags":["code","keras","tensorflow","attention","computer-vision","object-detection","yolo"],"details":"To extract the fine grained information of the object such as boundaries, background etc  this project use the spatial and channel wise attention on top of a simple pre-trained model with in the YOLO framework.","links":[{"article_link":"","code_link":"https://github.com/ankishb/MLProjects/tree/master/simple-conditional-object-detection","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://github.com/experiencor/keras-yolo2"}]},{"id":1970,"title":"Shortcuts: How Neural Networks Love to Cheat","description":"Neural Nets can often succeed on datasets, while failing to actually do the intended task. How?","tags":["article","neural-networks","memorization"],"details":"Concept of \"Shortcuts\" as a unifying way of thinking about such failures. Shortcut learning accounts for some of the most iconic differences between current ML models and human intelligence - but ironically, it is exactly this preference for \u201ccheating\u201d that can make neural networks seem almost human: Who has never cut corners by memorizing exam material, instead of investing time to truly understand? Who has never tried to find a loophole in a regulation, instead of adhering to its spirit? In the end, neural networks perhaps aren\u2019t that different from (lazy) humans after all ...","links":[{"article_link":"https://thegradient.pub/shortcuts-neural-networks-love-to-cheat/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1969,"title":"Pydeck","description":"Large-scale interactive data visualization in Python","tags":["code","library","visualization","pydeck"],"details":"The pydeck library is a set of Python bindings for making spatial visualizations with deck.gl, optimized for a Jupyter environment. \r\n\r\n![](https://user-images.githubusercontent.com/2204757/58838976-1538f400-8615-11e9-84f6-a2fe42bb300b.gif)","links":[{"article_link":"","code_link":"https://github.com/visgl/deck.gl/tree/master/bindings/pydeck","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://pydeck.gl/"}]},{"id":1968,"title":"Sentiment Analysis With Transformers","description":"Sentiment analysis neural network trained by fine-tuning BERT, ALBERT, or DistilBERT on the Stanford Sentiment Treebank.","tags":["code","tutorial","attention","bert","transformers","natural-language-processing","sentiment-analysis","stanford-sentiment-treebank"],"details":"Sentiment analysis neural network trained by fine-tuning BERT, ALBERT, or DistilBERT on the Stanford Sentiment Treebank.\r\n\r\n![](https://github.com/barissayil/SentimentAnalysis/raw/master/public/analyze.gif)","links":[{"article_link":"","code_link":"https://github.com/barissayil/SentimentAnalysis","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1967,"title":"AutoGOAL","description":"A Python framework for Automated Machine Learning (AutoML), hyperparameter tunning and program synthesis in general.","tags":["article","code","paper","research","python","deep-learning","machine-learning","regression","library","automl","computer-vision","image-classification","natural-language-processing","streamlit","demo","tabular"],"details":"AutoGOAL is a Python library for automatically finding the best way to solve a given task. It has been designed mainly for Automated Machine Learning (aka AutoML) but it can be used in any scenario where you have several possible ways to solve a given task.\r\n\r\nTechnically speaking, AutoGOAL is a framework for program synthesis, i.e., finding the best program to solve a given problem, provided that the user can describe the space of all possible programs. AutoGOAL provides a set of low-level components to define different spaces and efficiently search in them. In the specific context of machine learning, AutoGOAL also provides high-level components that can be used as a black-box in almost any type of problem and dataset format.\r\n\r\nOverall architecture of the AutoGOAL framework:\r\n\r\n![AutoGOAL architecture](https://autogoal.github.io/autogoal-library.svg)","links":[{"article_link":"https://dev.to/apiad/introduction-to-automated-machine-learning-in-python-with-autogoal-45n4","code_link":"https://github.com/autogoal/autogoal","research_link":"https://www.automl.org/wp-content/uploads/2020/07/AutoML_2020_paper_20.pdf","media_link":"","dataset_link":"","demo_link":"https://autogoal.github.io/demo","other_link":"https://autogoal.github.io"}]},{"id":1966,"title":"Experimental Exploratory Data Analysis for a Classification Task","description":"Expand the traditional EDA in a wider pipeline looking for the impact of each action into the behaviour of models. Exploratory Data & Models Analysis","tags":["article","code","tutorial","logistic-regression","machine-learning","neural-networks","random-forests","regression","classification","gradient-boosting","decision-tree","exploratory-data-analysis"],"details":"","links":[{"article_link":"https://data-service-alliance.ch/about-us/blog/blog/an-experimental-exploratory-data-analysis-for-a-classification-task-pre-conference-workshop-25-06-2020","code_link":"https://github.com/claudio1975/SDS2020","research_link":"","media_link":"https://github.com/claudio1975/SDS2020/blob/master/EEDA_Presentation.pptx","dataset_link":"","demo_link":"","other_link":""}]},{"id":1965,"title":"model-logger","description":"Model-Logger is a Python library for storing model's profile and rapid inter model comparison.","tags":["code","notebook","library","experiment-tracking","logging","model-comparison","model-logger"],"details":"model-logger is a Python library for storing model's profile and rapid inter model comparision. Powered by dash and SQLITE3, It's compact ,light weight ,interactive yet powerful tool to gain useful insights.\r\n\r\n![](https://github.com/SohamPathak/modellogger.github.io/raw/master/assets/model-store.gif)","links":[{"article_link":"","code_link":"https://github.com/SohamPathak/modellogger.github.io","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://colab.research.google.com/github/SohamPathak/modellogger.github.io/blob/master/assets/sample/model-logger.ipynb"}]},{"id":1964,"title":"MLOps Tutorial Series","description":"How to create an automatic model training & testing setup using GitHub Actions and Continuous Machine Learning (CML).","tags":["code","tutorial","video","production","github-actions","ml-ops","cml","ci-cd"],"details":"Learn how to use one of the most powerful ideas from the DevOps revolution, continuous integration, in your data science and machine learning projects. This hands-on tutorial shows you how to create an automatic model training & testing setup using GitHub Actions and Continuous Machine Learning (CML), two free and open-source tools in the Git ecosystem. Designed for total beginners!\r\n\r\n1. [Intro to Continuous Integration for ML](https://www.youtube.com/watch?v=9BgIDqAzfuA)\r\n2. [When data is too big for Git](https://www.youtube.com/watch?v=kZKAuShWF0s)\r\n3. [Track ML models with Git & GitHub Actions](https://www.youtube.com/watch?v=xPncjKH6SPk)\r\n4. [GitHub Actions with your own GPUs](https://www.youtube.com/watch?v=rVq-SCNyxVc)\r\n\r\n**Using CML with DVC**\r\n\r\nIn many ML projects, data isn't stored in a Git repository and needs to be downloaded from external sources. DVC is a common way to bring data to your CML runner. DVC also lets you visualize how metrics differ between commits to make reports like this:\r\n\r\n![](https://github.com/iterative/cml/blob/master/imgs/dvc_cml_long_report.png?raw=true)","links":[{"article_link":"","code_link":"https://github.com/andronovhopf/wine","research_link":"","media_link":"https://www.youtube.com/watch?v=9BgIDqAzfuA&list=PL7WG7YrwYcnDBDuCkFbcyjnZQrdskFsBz","dataset_link":"","demo_link":"","other_link":"https://github.com/iterative/cml"}]},{"id":1963,"title":"Modern Data Augmentation Techniques for Computer Vision","description":"A bunch of modern data augmentation techniques for computer vision covering cutout, mixup, cutmix and augmix.","tags":["article","code","research","tutorial","data-augmentation","wandb","cutout","mixup","cutmix","augmix","model-robustness"],"details":"Here is a quick outline of what you should expect from this report:\r\n\r\n1. Theoretical know-how of some modern data augmentations along with there implementations in TensorFlow 2.x.\r\n2. Some interesting ablation studies.\r\n3. Comparative study between these techniques.\r\n4. Benchmarking of models trained with the augmentations techniques on the CIFAR-10-C dataset.\r\n\r\n\r\n","links":[{"article_link":"https://app.wandb.ai/authors/tfaugmentation/reports/Modern-Data-Augmentation-Techniques-for-Computer-Vision--VmlldzoxODA3NTQ","code_link":"https://github.com/ayulockin/DataAugmentationTF","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1962,"title":"3D Image Inpainting Report","description":"In this report, I introduce some key components of the 3D Photography using Context-aware Layered Depth Inpainting paper and look at stunning 3D images.","tags":["article","code","paper","research","wandb","inpainting","3d-image-inpainting"],"details":"","links":[{"article_link":"https://app.wandb.ai/authors/3D-Inpainting/reports/3D-Image-Inpainting--VmlldzoxNzIwNTY","code_link":"https://github.com/ayulockin/3d-photo-inpainting","research_link":"https://shihmengli.github.io/3D-Photo-Inpainting/","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1961,"title":"Python Template for All Projects","description":"A template that gives the batteries required to package code, CI checks, auto build and deploy docs, easy PyPi publishing support and docker files.","tags":["code","docker","python","library","devops","mlops","ci-cd"],"details":"#### Why this project ?\r\n\r\n- Most people find it hard to package their python code and do not know how to set up the repository for it.\r\n- If the repository is setup in a wrong way, it would become hard to package and deploy the code later on as well.\r\n- This serves as a template to quickly have these things setup in your repository. \r\n- Machine Learning projects created from this template can easily be deployed and shipped. It becomes hassle free and easy to debug too.\r\n\r\n### Features: -\r\n1. Black code format check.\r\n2. CI CD tests for Python Packaging.\r\n3. PyPI release tests and release.\r\n4. Automatic Doc building and generation.\r\n\r\nBuild your code and project with confidence right from the first commit.\r\n\r\nSimplifies the tasks of taking code from project to production. Use the template and start building great stuff !!!\r\n\r\n\r\n","links":[{"article_link":"","code_link":"https://github.com/oke-aditya/template_python","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://oke-aditya.github.io/template_python/"}]},{"id":1960,"title":"Deploy Machine Learning Models with Django","description":"This web service makes Machine Learning models available with REST API. It is different from most of the tutorials available on the internet.","tags":["api","code","tutorial","django","machine-learning"],"details":"This web service makes Machine Learning models available with REST API. It is different from most of the tutorials available on the internet:\r\n\r\n- it keeps information about many ML models in the web service. There can be several ML models available at the same endpoint with different versions. What is more, there can be many endpoint addresses defined.\r\n- it stores information about requests sent to the ML models, this can be used later for model testing and audit.\r\n- it has tests for ML code and server code,\r\n- it can run A/B tests between different versions of ML models.","links":[{"article_link":"","code_link":"https://github.com/pplonski/my_ml_service","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.deploymachinelearning.com/"}]},{"id":1959,"title":"TeachEasy: Web app for Text Summarization & Q/A generation","description":"An intuitive Streamlit based web app for Text Summarization and Question Answer generation so as to reduce the work for School teachers.","tags":["code","natural-language-processing","paraphrase-identification","question-answering","question-generation","text-summarization","streamlit"],"details":"TeachEasy helps in Summarization of a given Text paragraph covering all the important data present in the text. Moreover, it also offers you to generate new Questions from the text with option of paraphrasing the questions. \r\nAnswers of the generated as well as externally asked questions are also generated. \r\n\r\n**Input**: A paragraph from which you want the Questions and Summarization.\r\n\r\n**Usage areas**: TeachEasy can be really helpful for School Teachers in preparing the Question Papers and maintaining summary notes of the Chapters in Online teaching classes.\r\n\r\n![](https://github.com/parthplc/TeachEasy/raw/master/4.jpg)","links":[{"article_link":"","code_link":"https://github.com/parthplc/TeachEasy","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1958,"title":"Automated Machine Learning","description":"\u2728 Automated Machine Learning Python package designed to save time for a data scientist \ud83d\ude0e ","tags":["code","machine-learning","library"],"details":"The  mljar-supervised is an Automated Machine Learning Python package that works with tabular data. It is designed to save time for a data scientist sunglasses. It abstracts the common way to preprocess the data, construct the machine learning models, and perform hyper-parameters tuning to find the best model trophy. It is no black-box as you can see exactly how the ML pipeline is constructed (with a detailed Markdown report for each ML model).","links":[{"article_link":"","code_link":"https://github.com/mljar/mljar-supervised","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1957,"title":"The Beginner's Guide to Dimensionality Reduction","description":"Explore the methods that data scientists use to visualize high-dimensional data.","tags":["code","tutorial","dimensionality-reduction","tsne","principal-component-analysis","interactive","umap"],"details":"This guide will teach you how to think about these embeddings, and provide a comparison of some of the most popular dimensionality reduction algorithms used today.","links":[{"article_link":"","code_link":"https://github.com/mathisonian/dimensionality-reduction","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://idyll.pub/post/dimensionality-reduction-293e465c2a3443e8941b016d/"}]},{"id":1956,"title":"Video Prediction using ConvLSTM Autoencoder (PyTorch)","description":"A simple implementation of the Convolutional-LSTM model.","tags":["article","tutorial","pytorch","autoencoders","convolutional-neural-networks","lstm","pytorch-lightning","video-prediction"],"details":"In this guide, I will show you how to code a ConvLSTM autoencoder (seq2seq) model for frame prediction using the MovingMNIST dataset. This framework can easily be extended for any other dataset as long as it complies with the standard pytorch Dataset configuration.","links":[{"article_link":"https://holmdk.github.io/2020/04/02/video_prediction.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1955,"title":"Shape and Viewpoint without Keypoints","description":"Recover the 3D shape, pose and texture from a single image, trained on an image collection without any ground truth 3D shape, multi-view, camera viewpoints.","tags":["article","code","paper","research","3d","computer-vision","unsupervised-learning","pascal-3d","arxiv:2007.10982"],"details":"We present a learning framework that learns to recover the 3D shape, pose and texture from a single image, trained on an image collection without any ground truth 3D shape, multi-view, camera viewpoints or keypoint supervision. We approach this highly under-constrained problem in a \"analysis by synthesis\" framework where the goal is to predict the likely shape, texture and camera viewpoint that could produce the image with various learned category-specific priors. Our particular contribution in this paper is a representation of the distribution over cameras, which we call \"camera-multiplex\". Instead of picking a point estimate, we maintain a set of camera hypotheses that are optimized during training to best explain the image given the current shape and texture. We call our approach Unsupervised Category-Specific Mesh Reconstruction (U-CMR), and present qualitative and quantitative results on CUB, Pascal 3D and new web-scraped datasets. We obtain state-of-the-art camera prediction results and show that we can learn to predict diverse shapes and textures across objects using an image collection without any keypoint annotations or 3D ground truth.\r\n\r\n\r\n![](https://shubham-goel.github.io/ucmr/resources/images/teaser.png)","links":[{"article_link":"https://shubham-goel.github.io/ucmr/","code_link":"https://github.com/shubham-goel/ucmr","research_link":"https://arxiv.org/abs/2007.10982","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1954,"title":"Azure ML","description":"MLOps using Azure ML.","tags":["code","azure","library","mlops","serving","ci-cd"],"details":"MLOps empowers data scientists and app developers to help bring ML models to production. MLOps enables you to track / version / audit / certify / re-use every asset in your ML lifecycle and provides orchestration services to streamline managing this lifecycle.\r\n\r\n![](https://github.com/microsoft/MLOps/raw/master/media/ml-lifecycle.png)","links":[{"article_link":"","code_link":"https://github.com/microsoft/MLOps","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1953,"title":"BentoML","description":"BentoML is an open-source framework for high-performance ML model serving.","tags":["code","library","production","serving","bentoml","ci-cd"],"details":"What does BentoML do?\r\n\r\n* Create API endpoint serving trained models with just a few lines of code\r\n* Support all major machine learning training frameworks\r\n* High-Performance online API serving with adaptive micro-batching support\r\n* Model Registry for teams, providing Web UI dashboard and CLI/API access\r\n* Flexible deployment orchestration with DevOps best practices baked-in, supporting Docker, Kubernetes, Kubeflow, Knative, AWS Lambda, SageMaker, Azure ML, GCP and more.\r\n\r\n![](https://raw.githubusercontent.com/bentoml/BentoML/master/docs/source/_static/img/bentoml-overview.png)","links":[{"article_link":"","code_link":"https://github.com/bentoml/BentoML","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://docs.bentoml.org/en/latest/"}]},{"id":1952,"title":"TensorFlow Serving","description":"A flexible, high-performance serving system for machine learning models, designed for production environments. ","tags":["code","tensorflow","library","production","serving","tensorflow-serving"],"details":"### Servables\r\n\r\nServables are the central abstraction in TensorFlow Serving. They are the underlying objects that clients use to perform computation (for example, a lookup or inference).\r\n\r\nThe size and granularity of a Servable is flexible. A single Servable might include anything from a single shard of a lookup table to a single model to a tuple of inference models. Servables can be of any type and interface, enabling flexibility and future improvements such as:\r\n\r\n* streaming results\r\n* experimental APIs\r\n* asynchronous modes of operation\r\n* Servables do not manage their own lifecycle","links":[{"article_link":"","code_link":"https://www.tensorflow.org/tfx/tutorials/serving/rest_simple","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.tensorflow.org/tfx/guide/serving"}]},{"id":1951,"title":"Audio and Speech Pre-trained Models","description":"A collection of Audio and Speech pre-trained models.\r\n\r\n","tags":["code","library","audio","speech","speech-recognition","pretraining","model-hub"],"details":"A pre-trained model is a model created by some one else to solve a similar problem. Instead of building a model from scratch to solve a similar problem, we can use the model trained on other problem as a starting point. A pre-trained model may not be 100% accurate in your application.\r\n\r\n#### TensorFlow\r\n\r\n* [**Wavenet**]( https://github.com/ibab/tensorflow-wavenet) - This is a TensorFlow implementation of the WaveNet generative neural network architecture for audio generation.\r\n* [**Lip Reading**]( https://github.com/astorfi/lip-reading-deeplearning) - Cross Audio-Visual Recognition using 3D Architectures in TensorFlow\r\n* [**MusicGenreClassification**]( https://github.com/mlachmish/MusicGenreClassification) - Academic research in the field of Deep Learning (Deep Neural Networks) and Sound Processing, Tel Aviv University.  \r\n* [**Audioset**](https://github.com/tensorflow/models/tree/master/research/audioset)  - Models and supporting code for use with AudioSet. \r\n* [**DeepSpeech**]( https://github.com/tensorflow/models/tree/master/research/deep_speech)  - Automatic speech recognition.\r\n\r\n\r\n#### Keras\r\n\r\n* [**Ultrasound nerve segmentation**]( https://github.com/jocicmarko/ultrasound-nerve-segmentation)  - This tutorial shows how to use Keras library to build deep neural network for ultrasound image nerve segmentation.\r\n\r\n#### PyTorch\r\n\r\n* [**espnet**]( https://github.com/espnet/espnet)  - End-to-End Speech Processing Toolkit espnet.github.io/espnet \r\n* [**TTS**]( https://github.com/mozilla/TTS)  - Deep learning for Text2Speech\r\n* [**Neural Sequence labeling model**]( https://github.com/jiesutd/NCRFpp)  - Sequence labeling models are quite popular in many NLP tasks, such as Named Entity Recognition (NER), part-of-speech (POS) tagging and word segmentation.\r\n* [**waveglow**]( https://github.com/NVIDIA/waveglow)  - A Flow-based Generative Network for Speech Synthesis.\r\n* [**deepvoice3_pytorch**]( https://github.com/r9y9/deepvoice3_pytorch)  - PyTorch implementation of convolutional networks-based text-to-speech synthesis models.\r\n* [**deepspeech2**]( https://github.com/SeanNaren/deepspeech.pytorch)  - Implementation of DeepSpeech2 using Baidu Warp-CTC. Creates a network based on the DeepSpeech2 architecture, trained with the CTC activation function.\r\n* [**loop**]( https://github.com/facebookarchive/loop)  - A method to generate speech across multiple speakers.\r\n* [**audio**]( https://github.com/pytorch/audio)  | Simple audio I/O for pytorch. \r\n* [**speech**]( https://github.com/awni/speech)  - PyTorch ASR Implementation.\r\n* [**samplernn-pytorch**]( https://github.com/deepsound-project/samplernn-pytorch)  - PyTorch implementation of SampleRNN: An Unconditional End-to-End Neural Audio Generation Model.\r\n* [**torch_waveglow**]( https://github.com/npuichigo/waveglow)  - A PyTorch implementation of the WaveGlow: A Flow-based Generative Network for Speech Synthesis.\r\n","links":[{"article_link":"","code_link":"https://github.com/balavenkatesh3322/audio-pretrained-model","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1950,"title":"GPT-3: A Hitchhiker's Guide","description":"Post to guide your thinking on GPT-3.","tags":["article","gpt","transformers","language-modeling","natural-language-processing","gpt-3"],"details":"* Give you a glance into how the A.I. research community is thinking about GPT-3.\r\n* Provide short summaries of the best technical write-ups on GPT-3.\r\n* Provide a list of the best video explanations of GPT-3.\r\n* Show some cool demos by people with early beta access to the GPT-3 API.","links":[{"article_link":"https://lambdalabs.com/blog/gpt-3/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1949,"title":"Phonet","description":"Keras-based python framework to compute phonological posterior probabilities from audio files.","tags":["article","code","paper","research","keras","pytorch","healthcare","speech","phoneme-recognition"],"details":"This toolkit compute posteriors probabilities of phonological classes from audio files for several groups of phonemes according to the mode and manner of articulation.","links":[{"article_link":"https://www.isca-speech.org/archive/Interspeech_2019/abstracts/1405.html","code_link":"https://github.com/jcvasquezc/phonet","research_link":"https://www.isca-speech.org/archive/Interspeech_2019/pdfs/1405.pdf","media_link":"https://jcvasquezc.github.io/publication/vasquez-2019-phonet/poster.pdf","dataset_link":"","demo_link":"","other_link":"https://phonet.readthedocs.io/en/latest/?badge=latest"}]},{"id":1948,"title":"Explore new Github README feature","description":"Simple tutorial to get a cool README on GitHub profile.","tags":["article","code","tutorial","git"],"details":"","links":[{"article_link":"https://towardsdatascience.com/explore-new-github-readme-feature-7d5cc21bf02f","code_link":"https://github.com/pr2tik1/pr2tik1","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1945,"title":"Pandera","description":"A flexible and expressive pandas data validation library.","tags":["code","library","pandas","testing","data-validation","schema","validation"],"details":"pandas data structures contain information that pandera explicitly validates at runtime. This is useful in production-critical or reproducible research settings. With pandera, you can:\r\n\r\n1. Check the types and properties of columns in a DataFrame or values in a Series.\r\n1. Perform more complex statistical validation like hypothesis testing.\r\n1. Seamlessly integrate with existing data analysis/processing pipelines via function decorators.\r\n\r\n\r\npandera provides a flexible and expressive API for performing data validation on tidy (long-form) and wide data to make data processing pipelines more readable and robust.","links":[{"article_link":"","code_link":"https://github.com/pandera-dev/pandera","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://pandera.readthedocs.io/"}]},{"id":1944,"title":"Learning Perturbation Sets for Robust Machine Learning","description":"Using generative modeling to capture real-world transformations from data for adversarial robustness.","tags":["article","code","paper","research","adversarial-robustness","enerative-modeling","perturbation-sets","arxiv:2007.08450"],"details":"In this blog post, we explain how our work in learning perturbation sets can bridge the gap between \u2113p adversarial defenses and adversarial robustness to real-world transformations.\r\n\r\nOne of the core tenents of making machine learning models that are robust to adversarial attacks is to define the threat model that contains all possible perturbations, which is critical for performing a proper robustness evaluation. However, well-defined threat models are have been largely limited to mathematically nice sets that can be described a priori, such as the Lp ball or Wasserstein metric, whereas many real-world transformations may be impossible to define mathematically. This work aims to bridge this gap, by learning perturbation sets as being generated from an Lp ball in an underlying latent space. This simple characterization of a perturbation set allows us to leverage state of the art approaches in adversarial training directly in the latent space, while at the same time capturing complex real-world perturbations.","links":[{"article_link":"https://locuslab.github.io/2020-07-20-perturbation/","code_link":"https://github.com/locuslab/perturbation_learning","research_link":"https://arxiv.org/abs/2007.08450","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1943,"title":"Do we Need Deep Graph Neural Networks?","description":"Does depth in graph neural network architectures bring any advantage?","tags":["article","tutorial","graph-neural-networks","graphs","depth"],"details":"One of the hallmarks of deep learning was the use of neural networks with tens or even hundreds of layers. In stark contrast, most of the architectures used in graph deep learning are shallow with just a handful of layers. In this post, I raise a heretical question: does depth in graph neural network architectures bring any advantage?\r\n\r\n**TL;DR**: We need to do carefully designed specific experiments in order to better understand whether or when depth is useful in deep learning on graphs.","links":[{"article_link":"https://towardsdatascience.com/do-we-need-deep-graph-neural-networks-be62d3ec5c59","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1942,"title":"Unsupervised Learning of Visual Features by Contrasting Clusters","description":"We use a swapped prediction mechanism where we predict the cluster assignment of a view from the representation of another view.","tags":["article","code","paper","research","unsupervised-learning","contrasting-cluster-assignments","swav","arxiv:2006.09882"],"details":"SwAV is an efficient and simple method for pre-training convnets without using annotations. Similarly to contrastive approaches, SwAV learns representations by comparing transformations of an image, but unlike contrastive methods, it does not require to compute feature pairwise comparisons. It makes our framework more efficient since it does not require a large memory bank or an auxiliary momentum network. Specifically, our method simultaneously clusters the data while enforcing consistency between cluster assignments produced for different augmentations (or \u201cviews\u201d) of the same image, instead of comparing features directly. Simply put, we use a \u201cswapped\u201d prediction mechanism where we predict the cluster assignment of a view from the representation of another view. Our method can be trained with large and small batches and can scale to unlimited amounts of data.\r\n![](https://camo.githubusercontent.com/a6d39dcc04416c84bd23f5e2ae87dceb40c6ef8b/68747470733a2f2f646c2e666261697075626c696366696c65732e636f6d2f64656570636c75737465722f616e696d617465642e676966)","links":[{"article_link":"https://ai.facebook.com/blog/high-performance-self-supervised-image-classification-with-contrastive-clustering/","code_link":"https://github.com/facebookresearch/swav","research_link":"https://arxiv.org/abs/2006.09882","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1941,"title":"My Artificial Intelligence Bookmarks","description":"A curated list of my reads, implementations, and core concepts of Artificial Intelligence, Deep Learning, Machine Learning by best folk in the world.","tags":["article","code","research","tutorial","python","deep-learning","machine-learning","neural-networks","library","natural-language-processing","datascience","conversational-ai","algorithms","maths","awesome-list"],"details":"A curated list of my reads, implementations, and core concepts of Artificial Intelligence, Deep Learning, Machine Learning by best folk in the world.\r\n\r\n\ud83c\udf89\ud83c\udf89\ud83c\udf89 Creating more structured view on [Notion](https://www.notion.so/neutralspaceai/5117196b7c64485cad28b10a10d591c0?v=831d7a547cca4d3fad4695549f7fe4b4)\r\n","links":[{"article_link":"https://www.notion.so/neutralspaceai/5117196b7c64485cad28b10a10d591c0?v=831d7a547cca4d3fad4695549f7fe4b4","code_link":"https://github.com/goodrahstar/my-awesome-AI-bookmarks","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1940,"title":"Change Detection using Siamese networks","description":"The blog is a primer on Siamese Networks and how they're used for observing change in satellite images over time, or observing facial changes as people age","tags":["article","pytorch","contrastive-loss","convolutional-neural-networks","deep-learning","siamese-networks","computer-vision"],"details":"The blog coverts change detection in a very simple and inclusive way, trying to explain concepts visually. It talks about what properties are desirable in a Change Detection model pipeline, how Siamese Networks fulfill them, how they're trained with the Contrastive Loss function and how they're better than the alternative Early Fusion networks.","links":[{"article_link":"https://towardsdatascience.com/change-detection-using-siamese-networks-fc2935fff82?source=friends_link&sk=076f551d50a7d979acff05c97ec12e4d","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1939,"title":"Breaking down the CTC Loss","description":"This article breaks down the inner workings of the CTC loss computation using the forward-backward algorithm.","tags":["article","tutorial","ctc-loss","ctc","connectionist-temporal-classification"],"details":"The Connectionist Temporal Classification is a type of scoring function for the output of neural networks where the input sequence may not align with the output sequence at every timestep. It was first introduced in the paper by Alex Graves et al for labelling unsegmented phoneme sequence. It has been successfully applied in other classification tasks such as speech recognition, keyword spotting, handwriting recognition, video description. These tasks require alignment between the input and output which may not be given. Therefore, it has become an ubiquitous loss for tasks requiring dynamic alignment of input to output.","links":[{"article_link":"https://ogunlao.github.io/blog/2020/07/17/breaking-down-ctc-loss.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1938,"title":"Rasa NLU Examples","description":"Experimental components for Rasa NLU pipelines. ","tags":["article","code","library","natural-language-processing","natural-language-understanding"],"details":"Contains extra features for your Rasa pipelines like FastText and BytePair Embeddings. ","links":[{"article_link":"https://rasahq.github.io/rasa-nlu-examples/","code_link":"https://github.com/RasaHQ/rasa-nlu-examples/","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1937,"title":"FairLearn","description":"Scikit-Learn compatible toolkit to assess and improve the fairness of machine learning models.","tags":["article","code","library","fairness","bias"],"details":"Fairlearn provides developers and data scientists with capabilities to assess the fairness of their machine learning models and mitigate unfairness. Assess existing models and train new models with fairness in mind. Compare models and make trade-offs between fairness and model performance.\r\n\r\nThe Fairlearn Python package has two components:\r\n\r\n* A dashboard for assessing which groups are negatively impacted by a model, and for comparing multiple models in terms of various fairness and accuracy metrics.\r\n\r\n* Algorithms for mitigating unfairness in a variety of AI tasks and along a variety of fairness definitions.","links":[{"article_link":"https://fairlearn.github.io/","code_link":"https://github.com/fairlearn/fairlearn","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://fairlearn.github.io/api_reference/fairlearn.metrics.html"}]},{"id":1936,"title":"Vanilla Gan implementation from paper","description":"This is a pytorch implementation of vanilla Gan from its research paper","tags":["article","code","notebook","paper","research","pytorch","generative-adversarial-networks","unsupervised-learning","arxiv:1406.2661"],"details":"","links":[{"article_link":"https://towardsdatascience.com/converting-deep-learning-research-papers-to-code-f-f38bbd87352f","code_link":"https://github.com/bipinKrishnan/Paper2Code_vanillaGAN/blob/master/GAN_from_scratch.ipynb","research_link":"https://arxiv.org/abs/1406.2661","media_link":"https://youtu.be/eyxmSmjmNS0","dataset_link":"","demo_link":"","other_link":""}]},{"id":1935,"title":"Integrated Gradients in TensorFlow 2","description":"In this tutorial, you will walk through an implementation of IG step-by-step in TensorFlow 2 to understand the pixel feature importances of an image classifier.","tags":["article","code","tutorial","tensorflow","computer-vision","image-classification","interpretability"],"details":"This tutorial demonstrates how to implement Integrated Gradients (IG), an Explainable AI technique introduced in the paper Axiomatic Attribution for Deep Networks. IG aims to explain the relationship between a model's predictions in terms of its features. It has many use cases including understanding feature importances, identifying data skew, and debugging model performance.\r\n\r\nIG has become a popular interpretability technique due to its broad applicability to any differentiable model (e.g. images, text, structured data), ease of implementation, theoretical justifications, and computational efficiency relative to alternative approaches that allows it to scale to large networks and feature spaces such as images.\r\n\r\nIn this tutorial, you will walk through an implementation of IG step-by-step to understand the pixel feature importances of an image classifier. As an example, consider this image of a fireboat spraying jets of water. You would classify this image as a fireboat and might highlight the pixels making up the boat and water cannons as being important to your decision. Your model will also classify this image as a fireboat later on in this tutorial; however, does it highlight the same pixels as important when explaining its decision?\r\n\r\nIn the images below titled \"IG Attribution Mask\" and \"Original + IG Mask Overlay\" you can see that your model instead highlights (in purple) the pixels comprising the boat's water cannons and jets of water as being more important than the boat itself to its decision. How will your model generalize to new fireboats? What about fireboats without water jets? Read on to learn more about how IG works and how to apply IG to your models to better understand the relationship between their predictions and underlying features.","links":[{"article_link":"https://blog.tensorflow.org/2020/06/responsible-ai-with-tensorflow.html","code_link":"https://github.com/GoogleCloudPlatform/training-data-analyst/tree/master/blogs/integrated_gradients","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.tensorflow.org/tutorials/interpretability/integrated_gradients"}]},{"id":1934,"title":"Graphein","description":"Protein Graph Library","tags":["code","paper","research","health","library","graph-neural-networks","graphs","protein","geometric-deep-learning","bioinformatics","protein-structure","protein-graph-library"],"details":"This package provides functionality for producing a number of types of graph-based representations of proteins. We provide compatibility with standard formats, as well as graph objects designed for ease of use with popular deep learning libraries.\r\n\r\n![](https://github.com/a-r-j/graphein/raw/master/imgs/graph_construction_overview.png)","links":[{"article_link":"","code_link":"https://github.com/a-r-j/graphein","research_link":"https://www.biorxiv.org/content/10.1101/2020.07.15.204701v1","media_link":"","dataset_link":"","demo_link":"","other_link":"https://graphein-graphein.readthedocs-hosted.com/en/latest/"}]},{"id":1933,"title":"TurboTransformers","description":"A fast and user-friendly runtime for transformer inference on CPU and GPU.","tags":["code","transformers","library","natural-language-processing","inference","turbotransformers"],"details":"Transformer is the most critical algorithm innovation in the NLP field in recent years. It brings higher model accuracy while introduces more calculations. The efficient deployment of online Transformer-based services faces enormous challenges. In order to make the costly Transformer online service more efficient, the WeChat AI open-sourced a Transformer inference acceleration tool called TurboTransformers, which has the following characteristics.\r\n\r\n1. Supporting both Transformers Encoder and Decoder.\r\n1. Excellent CPU / GPU performance. For Intel multi-core CPU and NVIDIA GPU hardware platforms, TurboTransformers can fully utilize all levels of computing power of the hardware. It has achieved better performance over pytorch / tensorflow and current mainstream optimization engines (such as onnxruntime-mkldnn / onnxruntime-gpu, torch JIT, NVIDIA faster transformers) on a variety of CPU and GPU hardware. See the detailed benchmark results below.\r\n1. Tailored to the characteristics of NLP inference tasks. Unlike the CV task, the input dimensions of the NLP inference task always change. The traditional approach is zero padding or truncation to a fixed length, which introduces additional zero padding computational overhead. Besides, some frameworks such as onnxruntime, tensorRT, and torchlib need to preprocess the compuatation-graph according to the input size in advance for the best performance, which is not suitable for NLP tasks with varying sizes. TurboTransformers can support variable-length input sequence processing without preprocessing.\r\n1. A simpler method of use. TurboTransformers supports python and C++ interface for calling. It can be used as an acceleration plug-in for pytorch. In the Transformer task, the end-to-end acceleration effect obtained by adding a few lines of python code.","links":[{"article_link":"","code_link":"https://github.com/Tencent/TurboTransformers","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1932,"title":"Transfer Learning using Adversarially Robust ImageNet Models","description":"We explore adversarial robustness as an avenue for training computer vision models with more transferrable features.","tags":["article","code","paper","research","transfer-learning","adversarial-learning","imagenet","arxiv:2007.08489"],"details":"","links":[{"article_link":"https://gradientscience.org/transfer-learning/","code_link":"https://github.com/microsoft/robust-models-transfer","research_link":"https://arxiv.org/abs/2007.08489","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1931,"title":"Path Explain","description":"A toolkit for explaining feature attributions and feature interactions in deep neural networks.\r\n\r\n","tags":["article","code","paper","research","library","interpretability","integrated-gradients","expected-gradients","path-explain","integrated-hessians","arxiv:2002.04138"],"details":"This repository contains tools to interpret and explain machine learning models using [Integrated Gradients](https://arxiv.org/abs/1703.01365) and [Expected Gradients](https://arxiv.org/abs/1906.10670). In addition, it contains code to explain _interactions_ in deep networks using Integrated Hessians and Expected Hessians - methods that we introduced in our most recent paper: [Explaining Explanations: Axiomatic Feature Interactions for Deep Networks](https://arxiv.org/abs/2002.04138).","links":[{"article_link":"https://jjanizek.github.io/post/integrated_hessians/","code_link":"https://github.com/suinleelab/path_explain","research_link":"https://arxiv.org/abs/2002.04138","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1930,"title":"GeoTorch","description":"A library for constrained optimization and manifold optimization for deep learning in PyTorch","tags":["code","pytorch","library","optimization","manifold-optimization","geotorch"],"details":"GeoTorch provides a simple way to perform constrained optimization and optimization on manifolds in PyTorch. It is compatible out of the box with any optimizer, layer, and model implemented in PyTorch without having to reimplement the layers or optimizers and without any kind of boilerplate in the training code.","links":[{"article_link":"","code_link":"https://github.com/Lezcano/geotorch","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://geotorch.readthedocs.io/en/latest/"}]},{"id":1929,"title":"Structured Self Attention","description":"Implementation for the paper A Structured Self-Attentive Sentence Embedding (https://arxiv.org/abs/1703.03130 ). Model interpretability / explainability.","tags":["code","paper","research","pytorch","attention","deep-learning","machine-learning","recurrent-neural-networks","self-attention","embeddings","interpretability","natural-language-processing","text-classification","arxiv:1703.03130"],"details":"Implementation for the paper A Structured Self-Attentive Sentence Embedding . Usage of 2 dimensional sentence embeddings for model interpretations.","links":[{"article_link":"","code_link":"https://github.com/kaushalshetty/Structured-Self-Attention","research_link":"https://arxiv.org/abs/1703.03130","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1928,"title":"SDEC-AD for Semantic Frame Induction","description":"Code for LREC 2020 Paper \"Semi-supervised Deep Embedded Clustering with Anomaly Detection for Semantic Frame Induction\"","tags":["code","paper","research","library","semi-supervised-learning","deep-clustering","framenet"],"details":"**Paper Abstract**\r\n\r\nAlthough FrameNet is recognized as one of the most fine-grained lexical databases, its coverage of lexical units is still limited. To tackle this issue, we propose a two-step frame induction process: for a set of lexical units not yet present in Berkeley FrameNet data release 1.7, first remove those that cannot fit into any existing semantic frame in FrameNet; then, assign the remaining lexical units to their correct frames. We also present the Semi-supervised Deep Embedded Clustering with Anomaly Detection (SDEC-AD) model\u2014an algorithm that maps high-dimensional contextualized vector representations of lexical units to a low-dimensional latent space for better frame prediction and uses reconstruction error to identify lexical units that cannot evoke frames in FrameNet. SDEC-AD outperforms the state-of-the-art methods in both steps of the frame induction process. Empirical results also show that definitions provide contextual information for representing and characterizing the frame membership of lexical units.","links":[{"article_link":"","code_link":"https://github.com/yongzx/Semi-supervised-Deep-Embedded-Clustering-with-Anomaly-Detection-for-Semantic-Frame-Induction","research_link":"https://www.aclweb.org/anthology/2020.lrec-1.431.pdf","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1927,"title":"ECG arrhythmia classification using a convolutional neural net","description":"This is an implementation of the paper on ECG arrhythmia classification https://arxiv.org/pdf/1804.06812.pdf.","tags":["article","code","keras","artificial-general-intelligence","convolutional-neural-networks","deep-learning","neural-networks","health","healthcare","computer-vision"],"details":"","links":[{"article_link":"https://medium.com/datadriveninvestor/ecg-arrhythmia-classification-using-a-2-d-convolutional-neural-network-33aa586bad67","code_link":"https://github.com/ankur219/ECG-Arrhythmia-classification","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1926,"title":"Keras Implementation of Semi-supervised Deep Embedded Clustering","description":"Keras Implementation of Semi-supervised Deep Embedded Clustering (Ren et al., 2019)","tags":["code","dataset","paper","research","semi-supervised-learning","deep-clustering"],"details":"The codes are adapted from the [DEC Implementation in Keras](https://github.com/fferroni/DEC-Keras). The dataset used is MNIST.","links":[{"article_link":"","code_link":"https://github.com/yongzx/SDEC-Keras","research_link":"https://www.sciencedirect.com/science/article/abs/pii/S0925231218312049","media_link":"","dataset_link":"https://keras.io/api/datasets/mnist/","demo_link":"","other_link":""}]},{"id":1925,"title":"PyTorch Implementation of PaletteNet","description":"PyTorch implementation of PaletteNet: Image Recolorization with Given Color Palette (Cho et al., 2017).","tags":["code","paper","research","library","computer-vision","style-transfer"],"details":"PaletteNet recolors an image according to a given target color\r\npalette that is useful to express the color concept of an image. PaletteNet takes two inputs: a source image to be recolored and a target palette. PaletteNet is then designed to change the color concept of a source image so that the palette of the output image is close to the target palette.","links":[{"article_link":"","code_link":"https://github.com/yongzx/PaletteNet-PyTorch","research_link":"https://openaccess.thecvf.com/content_cvpr_2017_workshops/w12/papers/Cho_PaletteNet_Image_Recolorization_CVPR_2017_paper.pdf","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1924,"title":"Why is it Important to Monitor Machine Learning Models?","description":"The importance of monitoring and how monitoring ML is different from application performance management (APM).","tags":["article","tutorial","production","monitoring"],"details":"- **Part 1**: [Why is it Important to Monitor Machine Learning Models?](https://mlinproduction.com/why-is-it-important-to-monitor-machine-learning-models/)\r\n- **Part 2**: [Lessons Learned from 15 Years of Monitoring Machine Learning in Production](https://mlinproduction.com/lessons-learned-from-15-years-of-monitoring-machine-learning-in-production/)\r\n","links":[{"article_link":"https://mlinproduction.com/why-is-it-important-to-monitor-machine-learning-models/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://mlinproduction.com/lessons-learned-from-15-years-of-monitoring-machine-learning-in-production/"}]},{"id":1923,"title":"PyTorch Geometric Temporal","description":"A Temporal Extension Library for PyTorch Geometric ","tags":["code","python","pytorch","torch","deep-learning","graph-convolutional-networks","library","graph-neural-networks","graphs","representation-learning"],"details":"**[Documentation](https://pytorch-geometric-temporal.readthedocs.io)** | **[External Resources](https://pytorch-geometric-temporal.readthedocs.io/en/latest/notes/resources.html)**\r\n\r\n**Methods Included**\r\n\r\nIn detail, the following temporal graph neural networks were implemented.\r\n\r\n\r\n**Stacked Discrete Temporal Graph Convolutions**\r\n\r\n* **[GConvGRU](https://pytorch-geometric-temporal.readthedocs.io/en/latest/modules/root.html#torch_geometric_temporal.nn.conv.gconv_gru.GConvGRU)** from Seo *et al.*: [Structured Sequence Modeling with Graph  Convolutional Recurrent Networks](https://arxiv.org/abs/1612.07659) (ICONIP 2018)\r\n\r\n* **[GConvLSTM](https://pytorch-geometric-temporal.readthedocs.io/en/latest/modules/root.html#torch_geometric_temporal.nn.conv.gconv_lstm.GConvLSTM)** from Seo *et al.*: [Structured Sequence Modeling with Graph  Convolutional Recurrent Networks](https://arxiv.org/abs/1612.07659) (ICONIP 2018)\r\n\r\n**Integrated Discrete Temporal Graph Convolutions**\r\n\r\n* **[GC-LSTM](https://pytorch-geometric-temporal.readthedocs.io/en/latest/modules/root.html#torch_geometric_temporal.nn.conv.gc_lstm.GCLSTM)** from Chen *et al.*: [GC-LSTM: Graph Convolution Embedded LSTM for Dynamic Link Prediction](https://arxiv.org/abs/1812.04206) (CoRR 2018)\r\n\r\n* **[LRGCN](https://pytorch-geometric-temporal.readthedocs.io/en/latest/modules/root.html#torch_geometric_temporal.nn.conv.lrgcn.LRGCN)** from Li *et al.*: [Predicting Path Failure In Time-Evolving Graphs](https://arxiv.org/abs/1905.03994) (KDD 2019)\r\n","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/pytorch_geometric_temporal","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://pytorch-geometric-temporal.readthedocs.io/"}]},{"id":1922,"title":"Optimize Ridge Regression Regularizers","description":"Use an optimizer to efficiently find the parameters that maximize ridge regression's performance on a leave-one-out or generalized cross-validation","tags":["article","code","linear-regression","regression","regularization","ridge-regression","cross-validation"],"details":"This project optimizes ridge regression's regularization parameters for a leave-one-out or generalized cross-validation by turning  parameter selection into a second-order optimization problem.\r\n\r\nUnlike grid-based searching, the project computes not just cross-validation values, but also derivatives with respect to regularizers. This enables it to quickly ascend to the best performing parameters.\r\n\r\nBy framing regularization as second-order optimization, the project is able to fit not just the common single-regularizer parameterization of ridge regression\r\n\r\n![](https://raw.githubusercontent.com/rnburn/peak-engines/master/images/rr1_eqn_1x.png)\r\n\r\nbut is also able to fit multi-regularizer parameterizations.\r\n\r\n![](https://raw.githubusercontent.com/rnburn/peak-engines/master/images/rrp_eqn_1x.png)\r\n\r\nThe math behind the approach is outlined in these blog posts\r\n\r\n* [How to Do Ridge Regression Better](https://towardsdatascience.com/how-to-do-ridge-regression-better-34ecb6ee3b12)\r\n* [What Form of Cross-Validation Should You Use](https://medium.com/p/what-form-of-cross-validation-should-you-use-76aaecc45c75?source=email-f55ad0a8217--writer.postDistributed&sk=a63ac2a04e49a12e7aa4c12a75b18502)","links":[{"article_link":"https://towardsdatascience.com/how-to-do-ridge-regression-better-34ecb6ee3b12","code_link":"https://github.com/rnburn/peak-engines","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1921,"title":"NSFW Image Moderation Admin App with ReactJS","description":"A fully-functional NSFW Admin Application for simplified image classification & moderation built with Node.js, TensorFlow.js, and React","tags":["article","code","tutorial","node-js","react","tensorflow","tensorflow-js","convolutional-neural-networks","library","adversarial-image-detection","computer-vision","image-classification","image-recognition","object-detection","pretraining","open-source","adversarial-learning","models","demo","nsfw","content-moderation","nsfw-detection","nsfw-classifier","parse-server","ready-to-use"],"details":"It's been an exciting journey building an open-source Content Moderation Service from scratch and sharing the experience with you! Today, we put the cherry on top with our final tutorial of this series, where we'll add a **[beautiful Admin Panel](https://bit.ly/39e8PiU) to complete the solution.**\r\n\r\n## [Part 3: ReactJS NSFW Image Moderation Admin App](https://bit.ly/3jkovWx)\r\nTo prove that even most boring tasks can be completed with finesse we've combined the Image Classification REST API and the Automation Engine with an [exquisite ReactJS Admin Application interface](https://bit.ly/3jotzco). Now, **Content Moderation gets as easy as swiping left and right**!\r\n\r\n## What's Next?\r\nSolving the NSFW Image Classification & Moderation challenge was only the first step towards our end goal -** bringing Machine Learning closer to single developers and teams of all sizes by making it affordable and accessible.** Next, we've planned on tackling another aspect of Content Moderation - **detecting Text Toxicity** in some of the most common use cases like product reviews, chats, comments moderation, and more. Stay tuned!\r\n\r\n## Give Us a Shout!\r\nWhether you deploy directly, integrate, or fork our solution if you liked what we did and found it useful, don't forget to give us a shout on [Twitter](https://twitter.com/sashidoio?lang=en) and share the resources. Thank you in advance for the support! \r\n\r\n## Your Feedback Matters!\r\nHelp us in our mission to break the barrier to Machine Learning by sharing your feedback and use cases at hello@sashido.io.\r\n\r\nP.S. *Feel free to take advantage of SashiDo's extended [45-day free trial](https://bit.ly/2BfuKK2), no credit card required. Valid until 1st of Sep, 2020*","links":[{"article_link":"https://bit.ly/3jkovWx","code_link":"https://bit.ly/3jotzco","research_link":"","media_link":"https://bit.ly/2ZLav09","dataset_link":"","demo_link":"https://bit.ly/39e8PiU","other_link":"https://bit.ly/2BlhQdG"}]},{"id":1920,"title":"ML-Ai community Projects","description":"ml-ai.in","tags":["code","research","machine-learning","data-science"],"details":"ML-Ai community believes in Unity is the strength. We are living in an era of Machine Learning/Artificial Intelligence revolution where world is focusing on building smart solutions to solve both solved and unsolved problems. ML-Ai community believes, we can make future bright by focusing on two things.\r\n\r\nResearch We observed the industry is far behind the academic research hence it takes a lot time to make use of academic research. Few of the times, academic research adoption takes more time because of multiple constraints like worth in the market/marker demand etc but many time we are not able to utilize the full potential because of less common platforms between industry researchers and academic researchers. ML-Ai is designed to work as bridge between academic researchers and industry.\r\nMaking People Smart ML-Ai community will have people from beginner to experts and objective will be to cross learn and lead to better future. ML-Ai Experts will act like a Professor to other people in the community. Professors will help others in their projects, doing code reviews helping them with right researcher papers.","links":[{"article_link":"","code_link":"https://github.com/ML-AI-Community/ml-ai","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1919,"title":"Dframcy","description":"DframCy is a light-weight utility module to integrate Pandas Dataframe to spaCy's linguistic annotation and training tasks.","tags":["code","spacy","library","training","natural-language-processing","data-science"],"details":"","links":[{"article_link":"","code_link":"https://github.com/yash1994/dframcy","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1918,"title":"Spacy-Go","description":"spacy-go is Golang interface for accessing linguistic annotations provided by spaCy using Google's gRPC. This module only supports basic functionalities like lo","tags":["code","go","python","spacy","natural-language-processing"],"details":"","links":[{"article_link":"","code_link":"https://github.com/yash1994/spacy-go","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1917,"title":"Python Deep Learning Projects","description":"This is the code repository for Python Deep Learning Projects book, published by Packt.","tags":["article","code","tutorial","python","deep-learning","computer-vision","natural-language-processing","reinforcement-learning"],"details":"14 projects demystifying neural network and deep learning models for building intelligent systems\r\n\r\n### Table of content \r\n\r\n**SECTION I \u2013 Python deep learning : building the foundation** \r\n\r\n* Chapter 1 : Building Deep Learning Environment\r\n* Chapter 2 : Training NN for Prediction using Regression\r\n\r\n**SECTION II \u2013 Python deep learning \u2013 NLP** \r\n\r\n* Chapter 3 : Word representation using word2vec\r\n* Chapter 4 : Build NLP pipeline for building chatbots\r\n* Chapter 5 : Sequence-to-sequence models for building chatbots\r\n* Chapter 6 : Generative Language Model for Content Creation\r\n* Chapter 7 : Building Speech Recognition with DeepSpeech2 \r\n\r\n\r\n**SECTION II \u2013 Python deep learning \u2013 Computer Vision**\r\n\r\n*  Chapter 8 : Handwritten Digits Classification Using ConvNets\r\n*  Chapter 9 : Object Detection using OpenCV and TensorFlow\r\n*  Chapter 10 : Building Face Recognition using Facenet\r\n*  Chapter 11 : Automated Image Captioning\r\n*  Chapter 12 : Pose Estimation on 3D models using ConvNets\r\n*  Chapter 13 : Image translation using GANs for style transfer\r\n\r\n\r\n** SECTION III \u2013 Python deep learning \u2013 Reinforcement Learning **\r\n\r\n*  Chapter 14 : Develop an Autonomous Agents with Deep R Learning\r\n\r\n","links":[{"article_link":"https://www.packtpub.com/big-data-and-business-intelligence/python-deep-learning-projects?utm_source=github&utm_medium=repository&utm_campaign=9781788997096","code_link":"https://github.com/goodrahstar/Python-Deep-Learning-Projects","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1916,"title":"How to Stop Worrying About Compositionality","description":"Review the tenets of compositionality, and to highlight how each theory has evolved to match particular theoretical positions about the nature of language.","tags":["article","language-modeling","natural-language-processing","compositionality"],"details":"* language is innate; \r\n* natural languages are formal languages; \r\n* language is inseparable from context.","links":[{"article_link":"https://thegradient.pub/how-to-stop-worrying-about-compositionality-2/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1915,"title":"Elegy","description":"A Keras-like Deep Learning framework based on Jax + Haiku.","tags":["article","code","jax","keras","library","haiku"],"details":"Elegy implements the Keras API but makes changes to play better with Jax & Haiku and give more flexibility around losses and metrics (more on this soon). Elegy is still in a very early stage, feel free to test it and send us your feedback!\r\n\r\n**Main Features**\r\n\r\n* Familiar: Elegy should feel very familiar to Keras users.\r\n* Flexible: Elegy improves upon the basic Keras API by letting users optionally take more control over the definition of losses and metrics.\r\n* Easy-to-use: Elegy maintains all the simplicity and ease of use that Keras brings with it.\r\n* Compatible: Elegy strives to be compatible with the rest of the Jax and Haiku ecosystem.\r\n\r\nFor more information take a look at the [Documentation](https://poets-ai.github.io/elegy).\r\n\r\n![](https://pbs.twimg.com/media/EdVn2BAWsAELEjR?format=png&name=large)","links":[{"article_link":"","code_link":"https://github.com/poets-ai/elegy","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://poets-ai.github.io/elegy/"}]},{"id":1914,"title":"TensorFlow JS- Object Detection in Browser","description":"A real-time object detection model in your browser using TensorFlow JS.","tags":["code","tensorflow","tensorflow-js","computer-vision","object-detection","demo"],"details":"A real-time object detection model in your browser using TensorFlow JS.","links":[{"article_link":"","code_link":"https://github.com/navendu-pottekkat/tfjs-object-detection","research_link":"","media_link":"","dataset_link":"","demo_link":"http://navendu.me/tfjs-object-detection/","other_link":""}]},{"id":1913,"title":"Teachable Machine (Image Classifier)","description":"A teachable image classifier that runs on any browser built using TensorFlow JS.","tags":["code","tensorflow","tensorflow-js","machine-learning","web-design","computer-vision","demo"],"details":"A teachable image classifier that runs on any browser built using TensorFlow JS.\r\n\r\nThis runs locally on your browser and no data is sent to any server.","links":[{"article_link":"","code_link":"https://github.com/navendu-pottekkat/teachable-machine","research_link":"","media_link":"","dataset_link":"","demo_link":"https://navendu.me/teachable-machine","other_link":""}]},{"id":1912,"title":"How to write an Awesome README","description":"A comprehensive guide to writing README that stands out and makes people go WOW! ","tags":["article","code","tutorial","machine-learning","program-development","web-design","data-science","documentation"],"details":"If nobody **can\u2019t** figure out how to use your software, there\u2019s something very bad going on.\r\n\r\nIf people don\u2019t know what your software does, then they **won\u2019t** use it or contribute to it and they will most likely find something more clear and concise in the sea of open-source software.\r\n\r\n**That\u2019s where the README comes in!**","links":[{"article_link":"https://towardsdatascience.com/how-to-write-an-awesome-readme-68bf4be91f8b","code_link":"https://github.com/navendu-pottekkat/awesome-readme","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1910,"title":"Azure Machine Learning Template","description":"Azure Machine Learning template for MNIST classifier","tags":["code","tutorial","azure","library","mlops"],"details":"","links":[{"article_link":"","code_link":"https://github.com/nishanthkoganti-gep/aml_experiment","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1909,"title":"Imitation Learning in Pytorch","description":"Implementation of imitation learning algorithms using Pytorch and interfaced with OpenAI Gym environments","tags":["code","tutorial","pytorch","library","imitation-learning","openai-gym"],"details":"","links":[{"article_link":"","code_link":"https://github.com/buntyke/pytorch-imitation","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1908,"title":"Kinect Baxter Calibration","description":"Project to setup absolute orientation based calibration between Kinect depth sensor and Baxter robot.","tags":["code","robotics","ros"],"details":"","links":[{"article_link":"","code_link":"https://github.com/ShibataLab/kinect_baxter_calibration","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1907,"title":"Adversarial machine learning","description":"This repository contain blogs, papers and talks related to adversarial machine learning.","tags":["code","adversarial-defense","adversarial-learning","adversarial-attacks"],"details":"","links":[{"article_link":"","code_link":"https://github.com/yenchenlin/awesome-adversarial-machine-learning","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1906,"title":"Tensorflow to PyTorch","description":"This repo contains the TensorFlow tutorials converted to PyTorch code.","tags":["code","pytorch","tensorflow","convolutional-neural-networks","data-augmentation","pretraining"],"details":"","links":[{"article_link":"","code_link":"https://github.com/bipinKrishnan/tensorflow_to_pytorch","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.tensorflow.org/tutorials"}]},{"id":1905,"title":"PyTorch CNN Trainer","description":"A simple package to fine-tune CNNs from torchvision and Pytorch Image models by Ross Wightman.","tags":["code","pytorch","convolutional-neural-networks","library","training","computer-vision","fine-tuning","torchvision","demo"],"details":"![Trainer](https://raw.githubusercontent.com/oke-aditya/pytorch_cnn_trainer/master/images/example.png)\r\n\r\nA simple package to fine tune CNNs from [torchvision](https://github.com/pytorch/vision) and [Pytorch Image models](https://github.com/rwightman/pytorch-image-models) from Ross Wightman.\r\n\r\nIt is very annoying to write training loop and training code for CNN training. Also to support all the training features it takes massive time.\r\n\r\nUsually we don't need distributed training and it is very uncomfortable to use argparse and get the job done.\r\n\r\nThis simplifies the training. It provide you a powerful `engine.py` which can do lot of training functionalities. \r\nAlso a `dataset.py` to load dataset in common scenarios.\r\n\r\nIt has documentation and examples for common to advanced training scenarios too.\r\n\r\nFeatures: -\r\n\r\n- Support PyTorch image models (timm) training and transfer learning.\r\n- Quantization Aware training example.\r\n- Early stopping with patience.\r\n- Support torchvision models trainging and transfer learning.\r\n-  Support torchvision quantized models transfer learning.\r\n-  Support for Mixed Precision Training.\r\n-  L2 Norm Gradient Penalty.\r\n-  SWA Stochastic weighted Averaging support for training.\r\n-  Keras Like fit method.\r\n-  Customizable Train Step and Validation Step Method\r\n-  Sanity Check method.\r\n\r\n\r\n\r\n","links":[{"article_link":"","code_link":"https://github.com/oke-aditya/pytorch_cnn_trainer","research_link":"","media_link":"","dataset_link":"","demo_link":"https://www.kaggle.com/okeaditya/pytorch-cnn-trainer","other_link":""}]},{"id":1904,"title":"Implementation of Face Net  in TensorFlow -  2.0","description":"This repository is a naive unofficial  implementation of Face Net paper  - 2015 .This implementation opts online mode of semi - hard triplet mining.","tags":["code","research","tutorial","dlib","tensorflow","convolutional-neural-networks","computer-vision","embeddings","face-recognition","paper-implemenataion"],"details":"How does it work \u2754\r\n\r\nThe rough idea of the workflow can be summarized as:\r\n\r\n*  At first the faces are extracted from the training data using dlib module and then a ResNet50 model is used to project these extracted faces onto a unit sphere in 128 dimensional euclidean space.\r\n* Next a triplet loss which mines for semi hard triplets is used to tweak the weights of the backbone ResNet50. The training goes on untill a minimum intercluster distance is achieved between embeddings of each identy.\r\n* When a new image is evaluated on the model the identity is assigned to the closest cluster provided it lies in the margin.","links":[{"article_link":"","code_link":"https://github.com/Ashish013/FaceNet_TF-2.0","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1903,"title":"Neural Style Transfer (Gatys et al., PyTorch)","description":"My implementation of the original neural style transfer paper by Gatys et al. (In PyTorch).","tags":["code","tutorial","video","deep-learning","machine-learning","computer-vision","style-transfer","neural-style-transfer"],"details":"","links":[{"article_link":"","code_link":"https://github.com/gordicaleksa/pytorch-neural-style-transfer","research_link":"","media_link":"https://www.youtube.com/watch?v=S78LQebx6jo&list=PLBoQnSflObcmbfshq9oNs41vODgXG-608","dataset_link":"","demo_link":"","other_link":""}]},{"id":1902,"title":"Indian Paper Currency Prediction","description":"The trained model takes an image (Indian Paper Currency) as an input and predict the class of image from 10, 20, 50, 100, 200, 500, 2000 denomination.","tags":["article","code","research","tutorial","video","aws","flask","keras","artificial-general-intelligence","deep-learning","computer-vision","image-classification","demo"],"details":"# Indian Paper Curreny Prediction :india: \r\n\r\n## Table of Content\r\n  * [Demo](#demo)\r\n  * [Overview](#overview)\r\n  * [Motivation](#motivation)\r\n  * [Technical Aspect](#technical-aspect)\r\n  * [Installation](#installation)\r\n  * [Run](#run)\r\n  * [Deployement on Heroku](#deployement-on-heroku)\r\n  * [Directory Tree](#directory-tree)\r\n  * [To Do](#to-do)\r\n  * [Bug / Feature Request](#bug---feature-request)\r\n  * [Technologies Used](#technologies-used)\r\n  * [Team](#team)\r\n  * [License](#license)\r\n  * [Credits](#credits)\r\n\r\n\r\n## Demo\r\nLink: [https://indian-currency-prediction.herokuapp.com](https://indian-currency-prediction.herokuapp.com/)\r\n\r\n[![](https://i.imgur.com/5gj4USj.png)](https://indian-currency-prediction.herokuapp.com/)\r\n\r\n## Overview\r\nThis is a simple image classification Flask app trained on the top of Keras API. The trained model (`app/model/model.h5`) takes an image (Indian Paper Currency) as an input and predict the class of image from __10, 20, 50, 100, 200, 500, 2000__ denomination.\r\n\r\n## Motivation\r\nWhat could be a perfect way to utilize unfortunate lockdown period? Like most of you, I spend my time in cooking, Netflix, coding and reading some latest research papers on weekends. The idea of classifying indian currency struck to me when I was browsing through some research papers. I couldn't find any relevant research paper (and of course dataset!) associated with it. And that led me to collect the images of Indian currency to train a deep learning model using [this](https://github.com/hardikvasa/google-images-download) amazing tool.\r\n\r\n## Technical Aspect\r\nThis project is divided into two part:\r\n1. Training a deep learning model using Keras. (_Not covered in this repo. I'll update the link here once I make it public._)\r\n2. Building and hosting a Flask web app on Heroku.\r\n    - A user can choose image from a device or capture it using a pre-built camera.\r\n    - Used __Amazon S3 Bucket__ to store the uploaded image and predictions.\r\n    - Used __CSRF Token__ to protect against CSRF attacks.\r\n    - Used __Sentry__ to catch the exception on the back-end.\r\n    - After uploading the image, the predictions are displayed on a __Bar Chart__.\r\n\r\n## Installation\r\nThe Code is written in Python 3.7. If you don't have Python installed you can find it [here](https://www.python.org/downloads/). If you are using a lower version of Python you can upgrade using the pip package, ensuring you have the latest version of pip. To install the required packages and libraries, run this command in the project directory after [cloning](https://www.howtogeek.com/451360/how-to-clone-a-github-repository/) the repository:\r\n```bash\r\npip install -r requirements.txt\r\n```\r\n\r\n## Run\r\n> STEP 1\r\n#### Linux and macOS User\r\nOpen `.bashrc` or `.zshrc` file and add the following credentials:\r\n```bash\r\nexport AWS_ACCESS_KEY=\"your_aws_access_key\"\r\nexport AWS_SECRET_KEY=\"your_aws_secret_key\"\r\nexport ICP_BUCKET='your_aws_bucket_name'\r\nexport ICP_BUCKET_REGION='bucket_region'\r\nexport ICP_UPLOAD_DIR='bucket_path_to_save_images'\r\nexport ICP_PRED_DIR='bucket_path_to_save_predictions'\r\nexport ICP_FLASK_SECRET_KEY='anything_random_but_unique'\r\nexport SENTRY_INIT='URL_given_by_sentry'\r\n```\r\nNote: __SENTRY_INIT__ is optional, only if you want to catch exceptions in the app, else comment/remove the dependencies and code associated with sentry in `app/main.py`\r\n\r\n#### Windows User\r\nSince, I don't have a system with Windows OS, here I collected some helpful resource on adding User Environment Variables in Windows.\r\n\r\n__Attention__: Please perform the steps given in these tutorials at your own risk. Please don't mess up with the System Variables. It can potentially damage your PC. __You should know what you're doing__. \r\n- https://www.tenforums.com/tutorials/121855-edit-user-system-environment-variables-windows.html\r\n- https://www.onmsft.com/how-to/how-to-set-an-environment-variable-in-windows-10\r\n\r\n> STEP 2\r\n\r\nTo run the app in a local machine, shoot this command in the project directory:\r\n```bash\r\ngunicorn wsgi:app\r\n```\r\n\r\n## Deployement on Heroku\r\nSet the environment variable on Heroku as mentioned in _STEP 1_ in the __Run__ section. [[Reference](https://devcenter.heroku.com/articles/config-vars)]\r\n\r\n![](https://i.imgur.com/TmSNhYG.png)\r\n\r\nOur next step would be to follow the instruction given on [Heroku Documentation](https://devcenter.heroku.com/articles/getting-started-with-python) to deploy a web app.\r\n\r\n## Directory Tree \r\n```\r\n\u251c\u2500\u2500 app \r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 main.py\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 model\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 static\r\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 templates\r\n\u251c\u2500\u2500 config\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\r\n\u251c\u2500\u2500 processing\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\r\n\u251c\u2500\u2500 requirements.txt\r\n\u251c\u2500\u2500 runtime.txt\r\n\u251c\u2500\u2500 LICENSE\r\n\u251c\u2500\u2500 Procfile\r\n\u251c\u2500\u2500 README.md\r\n\u2514\u2500\u2500 wsgi.py\r\n```\r\n\r\n## To Do\r\n1. Convert the app to run without any internet connection, i.e. __PWA__.\r\n2. Add a better vizualization chart to display the predictions.\r\n\r\n## Bug / Feature Request\r\nIf you find a bug (the website couldn't handle the query and / or gave undesired results), kindly open an issue [here](https://github.com/rowhitswami/Indian-Currency-Prediction/issues/new) by including your search query and the expected result.\r\n\r\nIf you'd like to request a new function, feel free to do so by opening an issue [here](https://github.com/rowhitswami/Indian-Currency-Prediction/issues/new). Please include sample queries and their corresponding results.\r\n\r\n## Technologies Used\r\n\r\n![](https://forthebadge.com/images/badges/made-with-python.svg)\r\n\r\n[<img target=\"_blank\" src=\"https://keras.io/img/logo.png\" width=200>](https://keras.io/) [<img target=\"_blank\" src=\"https://flask.palletsprojects.com/en/1.1.x/_images/flask-logo.png\" width=170>](https://flask.palletsprojects.com/en/1.1.x/) [<img target=\"_blank\" src=\"https://number1.co.za/wp-content/uploads/2017/10/gunicorn_logo-300x85.png\" width=280>](https://gunicorn.org) [<img target=\"_blank\" src=\"https://www.kindpng.com/picc/b/301/3012484.png\" width=200>](https://aws.amazon.com/s3/) \r\n\r\n[<img target=\"_blank\" src=\"https://sentry-brand.storage.googleapis.com/sentry-logo-black.png\" width=270>](https://www.sentry.io/) [<img target=\"_blank\" src=\"https://openjsf.org/wp-content/uploads/sites/84/2019/10/jquery-logo-vertical_large_square.png\" width=100>](https://jquery.com/)\r\n\r\n## Team\r\n[![Rohit Swami](https://avatars1.githubusercontent.com/u/16516296?v=3&s=144)](https://rohitswami.com/) |\r\n-|\r\n[Rohit Swami](https://rohitswami.com/) |)\r\n\r\n## License\r\n[![Apache license](https://img.shields.io/badge/license-apache-blue?style=for-the-badge&logo=appveyor)](http://www.apache.org/licenses/LICENSE-2.0e)\r\n\r\nCopyright 2020 Rohit Swami\r\n\r\nLicensed under the Apache License, Version 2.0 (the \"License\");\r\nyou may not use this file except in compliance with the License.\r\nYou may obtain a copy of the License at\r\n\r\n    http://www.apache.org/licenses/LICENSE-2.0\r\n\r\nUnless required by applicable law or agreed to in writing, software\r\ndistributed under the License is distributed on an \"AS IS\" BASIS,\r\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\nSee the License for the specific language governing permissions and\r\nlimitations under the License.\r\n\r\n## Credits\r\n- [Google Images Download](https://github.com/hardikvasa/google-images-download) - This project wouldn't have been possible without this tool. It saved my enormous amount of time while collecting the data. A huge shout-out to its creator [Hardik Vasa](https://github.com/hardikvasa).\r\n","links":[{"article_link":"https://towardsdatascience.com/how-to-secure-your-machine-learning-app-with-csrf-protection-506c3383f9e5","code_link":"https://github.com/rowhitswami/Indian-Paper-Currency-Prediction","research_link":"","media_link":"https://www.youtube.com/watch?v=PTsNDuhcOOA","dataset_link":"","demo_link":"https://indian-currency-prediction.herokuapp.com","other_link":"https://www.linkedin.com/feed/update/urn:li:activity:6680695131277987840/"}]},{"id":1901,"title":"Quora Question Pair Similarity","description":"Identify which questions asked on Quora are duplicates of questions that have already been asked. Using Text features, classifying them as duplicates or not.\r\n\r\n","tags":["code","dataset","python","machine-learning","natural-language-processing","text-classification","xgboost"],"details":"# Quora-Question-Pair-Similarity\r\nQuora is a place to gain and share knowledge\u2014about anything. It\u2019s a platform to ask questions and connect with people who contribute unique insights and quality answers. This empowers people to learn from each other and to better understand the world.\r\n\r\nOver 100 million people visit Quora every month, so it's no surprise that many people ask similarly worded questions. Multiple questions with the same intent can cause seekers to spend more time finding the best answer to their question, and make writers feel they need to answer multiple versions of the same question. Quora values canonical questions because they provide a better experience to active seekers and writers, and offer more value to both of these groups in the long term.\r\n\r\n\r\n> Credits: Kaggle\r\n\r\n## Problem Statement\r\n\r\nIdentify which questions asked on Quora are duplicates of questions that have already been asked.\r\nThis could be useful to instantly provide answers to questions that have already been answered.\r\nWe are tasked with predicting whether a pair of questions are duplicates or not.\r\n\r\n## Data Overview\r\n- Data will be in a file Train.csv \r\n- Train.csv contains 5 columns : qid1, qid2, question1, question2, is_duplicate \r\n- Size of Train.csv - 60MB \r\n- Number of rows in Train.csv = 404,290\r\n","links":[{"article_link":"","code_link":"https://github.com/s9k96/Quora-Question-Pair-Similarity","research_link":"","media_link":"","dataset_link":"https://www.kaggle.com/c/quora-question-pairs","demo_link":"","other_link":""}]},{"id":1900,"title":"WikiArt StyleGAN 2 Model","description":"A conditional StyleGAN 2 model trained on images from WikiArt","tags":["article","code","generative-adversarial-networks","computer-vision","style-transfer","stylegan","stylegan-2","wikiart"],"details":"","links":[{"article_link":"https://towardsdatascience.com/the-non-treachery-of-dataset-df1f6cbe577e","code_link":"https://github.com/pbaylies/stylegan2","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://archive.org/details/wikiart-stylegan2-conditional-model"}]},{"id":1899,"title":"StyleGAN Encoder","description":"Encodes real images into the latent space of a StyleGAN model.","tags":["code","generative-adversarial-networks","computer-vision","style-transfer","stylegan","latent-space"],"details":"","links":[{"article_link":"","code_link":"https://github.com/pbaylies/stylegan-encoder","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1898,"title":"Tempering Expectations for GPT-3 and OpenAI\u2019s API","description":"A closer look at the \"magic\" behind GPT-3 and caveats to be aware of.","tags":["article","code","paper","research","tutorial","gpt","transformers","natural-language-processing","openai","gpt-3","arxiv:2005.14165"],"details":"At minimum, anyone using the OpenAI API professionally needs to know:\r\n\r\n* Cost for generation per token/request\r\n* Rate limits and max number of concurrent requests\r\n* Average and peak latencies for generating tokens\r\n* SLA for the API\r\n* AI generated content ownership/copyright","links":[{"article_link":"https://minimaxir.com/2020/07/gpt3-expectations/","code_link":"https://github.com/minimaxir/gpt-3-experiments","research_link":"https://arxiv.org/abs/2005.14165","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1897,"title":"VAE-SNE","description":"A deep generative model for dimensionality reduction and clustering.","tags":["code","paper","research","autoencoders","variational-autoencoders","clustering","dimensionality-reduction","vae-sne"],"details":"VAE-SNE is a deep generative model for both dimensionality reduction and clustering. VAE-SNE is a variational autoencoder (VAE) regularized with the stochastic neighbor embedding (t-SNE/SNE) objective to improve local structure preservation in the compressed latent space. The model simultaneously learns a Gaussian mixture cluster distribution during optimization, and overlapping mixture components are then combined using a sparse watershed procedure, so the number of clusters does not have to be specified manually \u2014 provided the number of Gaussian mixture components is large enough. VAE-SNE produces embeddings with similar quality to existing dimensionality reduction methods; can detect outliers; scales to large, out-of-core datasets; and can easily add new data to an existing embedding/clustering.","links":[{"article_link":"","code_link":"https://github.com/jgraving/vaesne","research_link":"https://www.biorxiv.org/content/10.1101/2020.07.17.207993v1","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1896,"title":"Machine Learning Production Pipeline","description":"Project Flow and Landscape\r\n","tags":["tutorial","production","serving","pipelines"],"details":"**Table of contents:**\r\n\r\n* Research vs production\r\n* Data pipeline\r\n* Modeling & training\r\n* Serving\r\n* Landscape","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://docs.google.com/presentation/d/1mvmJ1PnCe7lWGmSoL80CjLe7N2QpEwkU8x7l62BawME/","dataset_link":"","demo_link":"","other_link":""}]},{"id":1895,"title":"Deep Dream (PyTorch) \ud83d\udcbb + \ud83c\udf0a\ud83d\udca4 = \u2764\ufe0f","description":"Clean PyTorch implementation of the Deep Dream algorithm by Mordvintsev et al.","tags":["code","tutorial","python","pytorch","deep-learning","machine-learning","deep-dream"],"details":"Learn how to create visual art using Deep Dream. I've additionally added playground.py that will help you understand the basic concepts behind the algorithm.\r\n\r\nSupport for 3 types of \"dreaming\":\r\n\r\n1. For static images\r\n2. Ouroboros (video) i.e. feeding the output back to input with some geometric transformations applied\r\n3. Video - per frame dreaming with linear blending","links":[{"article_link":"","code_link":"https://github.com/gordicaleksa/pytorch-deepdream","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1894,"title":"Arabic Font Classification","description":"Tackling the visual font recognition problem for Arabic fonts by synthesizing data and addressing domain mismatch challenges.","tags":["article","code","dataset","domain-adaptation","demo","visual-font-recognition"],"details":"This project aims to tackle a simplified version of the font recognition problem. The task is to classify images of text written using Arabic letters into two classes of Arabic fonts: Ruqaa and Nastaliq (Farsi).  \r\n\r\nA dataset of 40,516 images was created consisting of 40,000 synthesized image and 516 real image.  A data synthesization process was presented and analyized to overcome the domain mismatch problem.\r\n\r\nConvolutional neural network was trained on the mentioned dataset and its performance was analyzed as more synthesization steps were introduced.\r\n\r\nResults demonstrate the effectiveness of this synthesization process, which alleviates the domain mismatch problem by a factor of 29% allowing the model to reach 97% accuracy.","links":[{"article_link":"https://mhmoodlan.github.io/blog/arabic-font-classification","code_link":"https://github.com/mhmoodlan/arabic-font-classification","research_link":"","media_link":"","dataset_link":"https://github.com/mhmoodlan/arabic-font-classification/releases/tag/v0.1.0","demo_link":"https://mhmoodlan.github.io/blog/arabic-font-classification","other_link":""}]},{"id":1893,"title":"Universal Approximation of Neural Networks","description":"Neural Networks and their approximation capabilities.","tags":["article","code","artificial-general-intelligence","deep-learning","feed-forward-neural-networks","neural-networks"],"details":"","links":[{"article_link":"https://towardsdatascience.com/exploring-neural-networks-and-their-fascinating-effectiveness-81ebc054cb16","code_link":"https://github.com/pr2tik1/universal-approximation","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1892,"title":"Introducing Streamlit Components","description":"A new way to add and share custom functionality for Streamlit apps","tags":["article","code","paper","tutorial","machine-learning","data-science","exploratory-data-analysis","demo","dashboard"],"details":"","links":[{"article_link":"https://medium.com/streamlit/introducing-streamlit-components-d73f2092ae30?source=friends_link","code_link":"https://github.com/streamlit/component-template","research_link":"","media_link":"","dataset_link":"","demo_link":"https://www.streamlit.io/components","other_link":"https://docs.streamlit.io/en/stable/streamlit_components.html"}]},{"id":1891,"title":"PyTorch Paper Implemenations","description":"Research Paper Implementations in PyTorch","tags":["code","research","pytorch","paper-implementations"],"details":"Currently: -\r\nProvides Implementation of research papers in PyTorch.\r\nMakes the paper simple, keeps implementation crisp and to the point.\r\nIt is useful to understand the gist of the paper and implement a minimalistic but working version.\r\n\r\nFuture Scope: -\r\nReplicate the same in Tensorflow.\r\n","links":[{"article_link":"","code_link":"https://github.com/oke-aditya/pytorch_paper_implementations","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1889,"title":"NLP Pretrained Models","description":"A collection of Natural language processing pre-trained models.\r\n\r\n","tags":["code","caffe","keras","mxnet","pytorch","tensorflow","library","natural-language-processing","pretraining","model-hub","pretrained-models"],"details":"A pre-trained model is a model created by some one else to solve a similar problem. Instead of building a model from scratch to solve a similar problem, we can use the model trained on other problem as a starting point. A pre-trained model may not be 100% accurate in your application.\r\n\r\n#### TensorFlow\r\n\r\n* [**Chatbot**]( https://github.com/Conchylicultor/DeepQA) - This work tries to reproduce the results of A Neural Conversational Model (aka the Google chatbot). It uses a RNN (seq2seq model) for sentence prediction\r\n* [**Show, Attend and Tell**]( https://github.com/yunjey/show-attend-and-tell) - Attention Based Image Caption Generator.\r\n* [**Seq2seq-Chatbot**]( https://github.com/tensorlayer/seq2seq-chatbot) - Chatbot in 200 lines of code.\r\n* [**Neural Caption Generator**]( https://github.com/jazzsaxmafia/show_attend_and_tell.tensorflow) - Implementation of \"Show and Tell\".\r\n* [**TensorFlow White Paper Notes**]( https://github.com/samjabrahams/tensorflow-white-paper-notes) - Annotated notes and summaries of the TensorFlow white paper, along with SVG figures and links to documentation.\r\n* [**Neural machine translation between the writings of Shakespeare and modern English using TensorFlow**]( https://github.com/tokestermw/tensorflow-shakespeare) - This performs a monolingual translation, going from modern English to Shakespeare and vice-versa.\r\n* [**Mnemonic Descent Method**](https://github.com/trigeorgis/mdm) - Tensorflow implementation of \"Mnemonic Descent Method: A recurrent process applied for end-to-end face alignment\"\r\n* [**Improved CycleGAN**]( https://github.com/luoxier/CycleGAN_Tensorlayer) - Unpaired Image to Image Translation.\r\n* [**im2im**]( https://github.com/zsdonghao/Unsup-Im2Im) - Unsupervised Image to Image Translation with Generative Adversarial Networks.\r\n* [**DeepSpeech**]( https://github.com/tensorflow/models/tree/master/research/deep_speech) - Automatic speech recognition.\r\n* [**Im2txt**]( https://github.com/tensorflow/models/tree/master/research/im2txt) - Image-to-text neural network for image captioning.\r\n\r\n#### Keras\r\n\r\n* [**Monolingual and Multilingual Image Captioning**]( https://github.com/elliottd/GroundedTranslation) - This is the source code that accompanies Multilingual Image Description with Neural Sequence Models.\r\n* [**pix2pix**]( https://github.com/tdeboissiere/DeepLearningImplementations/tree/master/pix2pix) - Keras implementation of Image-to-Image Translation with Conditional Adversarial Networks.\r\n* [**DualGAN**]( https://github.com/eriklindernoren/Keras-GAN/blob/master/dualgan/dualgan.py) - Implementation of _DualGAN: Unsupervised Dual Learning for Image-to-Image Translation_.\r\n* [**CycleGAN**]( https://github.com/eriklindernoren/Keras-GAN/blob/master/cyclegan/cyclegan.py) - Implementation of _Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks_.\r\n\r\n#### PyTorch\r\n\r\n* [**pytorch-CycleGAN-and-pix2pix**]( https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix) - PyTorch implementation for both unpaired and paired image-to-image translation. \r\n* [**vid2vid**]( https://github.com/NVIDIA/vid2vid) - Pytorch implementation of our method for high-resolution (e.g. 2048x1024) photorealistic video-to-video translation. \r\n* [**Neural Machine Translation (NMT) System**]( https://github.com/OpenNMT/OpenNMT-py) - This is a Pytorch port of OpenNMT, an open-source (MIT) neural machine translation system. It is designed to be research friendly to try out new ideas in translation, summary, image-to-text, morphology, and many other domains. \r\n* [**UNIT**]( https://github.com/mingyuliutw/UNIT) - PyTorch Implementation of our Coupled VAE-GAN algorithm for Unsupervised Image-to-Image Translation. \r\n* [**espnet**]( https://github.com/espnet/espnet) - End-to-End Speech Processing Toolkit. - `PyTorch`\r\n* [**TTS**]( https://github.com/mozilla/TTS) - Deep learning for Text2Speech. \r\n* [**Neural Sequence labeling model**]( https://github.com/jiesutd/NCRFpp) - Sequence labeling models are quite popular in many NLP tasks, such as Named Entity Recognition (NER), part-of-speech (POS) tagging and word segmentation.\r\n* [**UnsupervisedMT**]( https://github.com/facebookresearch/UnsupervisedMT) - Phrase-Based & Neural Unsupervised Machine Translation. \r\n* [**waveglow**]( https://github.com/NVIDIA/waveglow) - A Flow-based Generative Network for Speech Synthesis. \r\n* [**deepvoice3_pytorch**]( https://github.com/r9y9/deepvoice3_pytorch) - PyTorch implementation of convolutional networks-based text-to-speech synthesis models. \r\n* [**deepspeech2**]( https://github.com/SeanNaren/deepspeech.pytorch) - Implementation of DeepSpeech2 using Baidu Warp-CTC. Creates a network based on the DeepSpeech2 architecture, trained with the CTC activation function.\r\n* [**pytorch-seq2seq**]( https://github.com/IBM/pytorch-seq2seq) - A framework for sequence-to-sequence (seq2seq) models implemented in PyTorch. \r\n* [**loop**]( https://github.com/facebookarchive/loop) - A method to generate speech across multiple speakers. \r\n* [**neuraltalk2-pytorch**]( https://github.com/ruotianluo/ImageCaptioning.pytorch) - Image captioning model in pytorch (finetunable cnn in branch with_finetune) \r\n* [**seq2seq**]( https://github.com/MaximumEntropy/Seq2Seq-PyTorch) - This repository contains implementations of Sequence to Sequence (Seq2Seq) models in PyTorch. \r\n* [**seq2seq.pytorch**]( https://github.com/eladhoffer/seq2seq.pytorch) - Sequence-to-Sequence learning using PyTorch. \r\n* [**self-critical.pytorch**]( https://github.com/ruotianluo/self-critical.pytorch) - Self-critical Sequence Training for Image Captioning. \r\n* [**Hierarchical Attention Networks for Document Classification**]( https://github.com/EdGENetworks/attention-networks-for-classification) - We know that documents have a hierarchical structure, words combine to form sentences and sentences combine to form documents. \r\n* [**nmtpytorch**]( https://github.com/lium-lst/nmtpytorch) - Neural Machine Translation Framework in PyTorch. \r\n* [**pix2pix-pytorch**]( https://github.com/mrzhu-cool/pix2pix-pytorch) - PyTorch implementation of \"Image-to-Image Translation Using Conditional Adversarial Networks\". \r\n* [**torch_waveglow**]( https://github.com/npuichigo/waveglow) - A PyTorch implementation of the WaveGlow: A Flow-based Generative Network for Speech Synthesis. \r\n* [**Open Source Chatbot with PyTorch**]( https://github.com/jinfagang/pytorch_chatbot) - Aim to build a Marvelous ChatBot. \r\n* [**nonauto-nmt**]( https://github.com/salesforce/nonauto-nmt) - PyTorch Implementation of \"Non-Autoregressive Neural Machine Translation\". \r\n* [**tacotron_pytorch**]( https://github.com/r9y9/tacotron_pytorch) - PyTorch implementation of Tacotron speech synthesis model. \r\n* [**pytorch-seq2seq-intent-parsing**]( https://github.com/spro/pytorch-seq2seq-intent-parsing) - Intent parsing and slot filling in PyTorch with seq2seq + attention.\r\n* [**captionGen**]( https://github.com/eladhoffer/captionGen) - Generate captions for an image using PyTorch. \r\n* [**bandit-nmt**]( https://github.com/khanhptnk/bandit-nmt) - This is code repo for our EMNLP 2017 paper \"Reinforcement Learning for Bandit Neural Machine Translation with Simulated Human Feedback\". \r\n* [**Pytorch Poetry Generation**]( https://github.com/jhave/pytorch-poetry-generation) - is a repurposing of http://pytorch.org/: an early release beta software (developed by a consortium led by Facebook and NVIDIA), a deep learning software that puts Python first. \r\n* [**translagent**]( https://github.com/facebookresearch/translagent) - Code for Emergent Translation in Multi-Agent Communication. \r\n","links":[{"article_link":"","code_link":"https://github.com/balavenkatesh3322/NLP-pretrained-model","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1888,"title":"Monitoring Machine Learning Models in Production","description":"Once you have deployed your machine learning model to production it rapidly becomes apparent that the work is not over.","tags":["article","tutorial","production","monitoring"],"details":"1. The ML System Lifecycle\r\n2. What makes ML System Monitoring Hard\r\n3. Why You Need Monitoring\r\n4. Key Principles For Monitoring Your ML System\r\n5. Understanding the Spectrum of ML Risk Management\r\n6. Data Science Monitoring Concerns [Start here for practical advice]\r\n7. Operations Monitoring Concerns\r\n8. Bringing Ops & DS Together - Metrics with Prometheus & Grafana\r\n9. Bringing Ops & DS Together - Logs\r\n10. The Changing Landscape","links":[{"article_link":"https://christophergs.com/machine%20learning/2020/03/14/how-to-monitor-machine-learning-models/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1887,"title":"Computer Vision Pretrained Models","description":"A collection of computer vision pre-trained models.","tags":["code","caffe","keras","mxnet","pytorch","tensorflow","library","computer-vision","object-detection","pretraining","model-hub","pretrained-models","model-zoo"],"details":"A pre-trained model is a model created by some one else to solve a similar problem. Instead of building a model from scratch to solve a similar problem, we can use the model trained on other problem as a starting point. A pre-trained model may not be 100% accurate in your application.\r\n\r\nFor example, if you want to build a self learning car. You can spend years to build a decent image recognition algorithm from scratch or you can take inception model (a pre-trained model) from Google which was built on ImageNet data to identify images in those pictures.\r\n\r\n#### TensorFlow\r\n\r\n* [**ObjectDetection**]( https://github.com/tensorflow/models/tree/master/research/object_detection)  - Localizing and identifying multiple objects in a single image.\r\n* [**Mask R-CNN**]( https://github.com/matterport/Mask_RCNN)  - The model generates bounding boxes and segmentation masks for each instance of an object in the image. It's based on Feature Pyramid Network (FPN) and a ResNet101 backbone.\r\n* [**Faster-RCNN**]( https://github.com/smallcorgi/Faster-RCNN_TF)  - This is an experimental Tensorflow implementation of Faster RCNN - a convnet for object detection with a region proposal network.\r\n* [**YOLO TensorFlow**]( https://github.com/gliese581gg/YOLO_tensorflow)  - This is tensorflow implementation of the YOLO:Real-Time Object Detection.\r\n* [**YOLO TensorFlow ++**]( https://github.com/thtrieu/darkflow)  - TensorFlow implementation of 'YOLO: Real-Time Object Detection', with training and an actual support for real-time running on mobile devices.\r\n* [**MobileNet**]( https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md)  - MobileNets trade off between latency, size and accuracy while comparing favorably with popular models from the literature.\r\n* [**DeepLab**]( https://github.com/tensorflow/models/tree/master/research/deeplab)  - Deep labeling for semantic image segmentation.\r\n* [**Colornet**]( https://github.com/pavelgonchar/colornet)  - Neural Network to colorize grayscale images. \r\n* [**SRGAN**]( https://github.com/tensorlayer/srgan)  - Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network.\r\n* [**DeepOSM**]( https://github.com/trailbehind/DeepOSM)  - Train TensorFlow neural nets with OpenStreetMap features and satellite imagery. \r\n* [**Domain Transfer Network**]( https://github.com/yunjey/domain-transfer-network)  - Implementation of Unsupervised Cross-Domain Image Generation.\r\n* [**Show, Attend and Tell**]( https://github.com/yunjey/show-attend-and-tell)  - Attention Based Image Caption Generator.\r\n* [**android-yolo**]( https://github.com/natanielruiz/android-yolo)  - Real-time object detection on Android using the YOLO network, powered by TensorFlow.\r\n* [**DCSCN Super Resolution**]( https://github.com/jiny2001/dcscn-super-resolutiont)  - This is a tensorflow implementation of \"Fast and Accurate Image Super Resolution by Deep CNN with Skip Connection and Network in Network\", a deep learning based Single-Image Super-Resolution (SISR) model.\r\n* [**GAN-CLS**]( https://github.com/zsdonghao/text-to-image)  - This is an experimental tensorflow implementation of synthesizing images.\r\n* [**U-Net**]( https://github.com/zsdonghao/u-net-brain-tumor)  - For Brain Tumor Segmentation.\r\n* [**Improved CycleGAN**]( https://github.com/luoxier/CycleGAN_Tensorlayer)  -Unpaired Image to Image Translation.\r\n* [**Im2txt**]( https://github.com/tensorflow/models/tree/master/research/im2txt)  - Image-to-text neural network for image captioning.\r\n* [**Street**]( https://github.com/tensorflow/models/tree/master/research/street)  - Identify the name of a street (in France) from an image using a Deep RNN.\r\n* [**SLIM**]( https://github.com/tensorflow/models/tree/master/research/slim)  - Image classification models in TF-Slim.\r\n* [**DELF**]( https://github.com/tensorflow/models/tree/master/research/delf)  - Deep local features for image matching and retrieval. \r\n* [**Compression**]( https://github.com/tensorflow/models/tree/master/research/compression)  - Compressing and decompressing images using a pre-trained Residual GRU network.\r\n* [**AttentionOCR**]( https://github.com/tensorflow/models/tree/master/research/attention_ocr)  - A model for real-world image text extraction.\r\n\r\n#### Keras\r\n\r\n* [**Mask R-CNN**]( https://github.com/matterport/Mask_RCNN) - The model generates bounding boxes and segmentation masks for each instance of an object in the image. It's based on Feature Pyramid Network (FPN) and a ResNet101 backbone.`Keras`\r\n* [**VGG16**]( https://github.com/keras-team/keras-applications/blob/master/keras_applications/vgg16.py) - Very Deep Convolutional Networks for Large-Scale Image Recognition.\r\n* [**VGG19**]( https://github.com/keras-team/keras-applications/blob/master/keras_applications/vgg19.py) - Very Deep Convolutional Networks for Large-Scale Image Recognition.\r\n* [**ResNet**]( https://github.com/keras-team/keras-applications/blob/master/keras_applications/resnet_common.py) - Deep Residual Learning for Image Recognition.\r\n* [**Image analogies**]( https://github.com/awentzonline/image-analogies) - Generate image analogies using neural matching and blending.\r\n* [**Popular Image Segmentation Models**]( https://github.com/divamgupta/image-segmentation-keras) - Implementation of Segnet, FCN, UNet and other models in Keras.\r\n* [**Ultrasound nerve segmentation**]( https://github.com/jocicmarko/ultrasound-nerve-segmentation) - This tutorial shows how to use Keras library to build deep neural network for ultrasound image nerve segmentation.\r\n* [**DeepMask object segmentation**]( https://github.com/abbypa/NNProject_DeepMask) - This is a Keras-based Python implementation of DeepMask- a complex deep neural network for learning object segmentation masks.\r\n* [**Monolingual and Multilingual Image Captioning**]( https://github.com/elliottd/GroundedTranslation) - This is the source code that accompanies Multilingual Image Description with Neural Sequence Models.\r\n* [**pix2pix**]( https://github.com/tdeboissiere/DeepLearningImplementations/tree/master/pix2pix) - Keras implementation of Image-to-Image Translation with Conditional Adversarial Networks by Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, Alexei A.\r\n* [**Colorful Image colorization**]( https://github.com/tdeboissiere/DeepLearningImplementations/tree/master/Colorful) - B&W to color.\r\n* [**CycleGAN**]( https://github.com/eriklindernoren/Keras-GAN/blob/master/cyclegan/cyclegan.py) - Implementation of _Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks_.\r\n* [**DualGAN**](https://github.com/eriklindernoren/Keras-GAN/blob/master/dualgan/dualgan.py) - Implementation of _DualGAN: Unsupervised Dual Learning for Image-to-Image Translation_.\r\n* [**Super-Resolution GAN**]( https://github.com/eriklindernoren/Keras-GAN/blob/master/srgan/srgan.py) - Implementation of _Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network.\r\n\r\n#### PyTorch\r\n\r\n* [**FastPhotoStyle**]( https://github.com/NVIDIA/FastPhotoStyle) - A Closed-form Solution to Photorealistic Image Stylization.\r\n* [**pytorch-CycleGAN-and-pix2pix**]( https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix) - A Closed-form Solution to Photorealistic Image Stylization.\r\n* [**maskrcnn-benchmark**]( https://github.com/facebookresearch/maskrcnn-benchmark) - Fast, modular reference implementation of Instance Segmentation and Object Detection algorithms in PyTorch.\r\n* [**deep-image-prior**]( https://github.com/DmitryUlyanov/deep-image-prior) - Image restoration with neural networks but without learning.\r\n* [**StarGAN**]( https://github.com/yunjey/StarGAN) - StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation.\r\n* [**faster-rcnn.pytorch**]( https://github.com/jwyang/faster-rcnn.pytorch) - This project is a faster faster R-CNN implementation, aimed to accelerating the training of faster R-CNN object detection models.\r\n* [**pix2pixHD**]( https://github.com/NVIDIA/pix2pixHD) - Synthesizing and manipulating 2048x1024 images with conditional GANs. - `PyTorch`\r\n* [**Augmentor**]( https://github.com/mdbloice/Augmentor) - Image augmentation library in Python for machine learning. - `PyTorch`\r\n* [**albumentations**]( https://github.com/albumentations-team/albumentations) - Fast image augmentation library.\r\n* [**Deep Video Analytics**]( https://github.com/AKSHAYUBHAT/DeepVideoAnalytics) - Deep Video Analytics is a platform for indexing and extracting information from videos and images\r\n* [**semantic-segmentation-pytorch**]( https://github.com/CSAILVision/semantic-segmentation-pytorch) - Pytorch implementation for Semantic Segmentation/Scene Parsing on MIT ADE20K dataset.\r\n* [**An End-to-End Trainable Neural Network for Image-based Sequence Recognition**]( https://github.com/bgshih/crnn) - This software implements the Convolutional Recurrent Neural Network (CRNN), a combination of CNN, RNN and CTC loss for image-based sequence recognition tasks, such as scene text recognition and OCR.\r\n* [**UNIT**]( https://github.com/mingyuliutw/UNIT) - PyTorch Implementation of our Coupled VAE-GAN algorithm for Unsupervised Image-to-Image Translation.\r\n* [**Neural Sequence labeling model**]( https://github.com/jiesutd/NCRFpp) - Sequence labeling models are quite popular in many NLP tasks, such as Named Entity Recognition (NER), part-of-speech (POS) tagging and word segmentation.\r\n* [**faster rcnn**]( https://github.com/longcw/faster_rcnn_pytorch) - This is a PyTorch implementation of Faster RCNN. This project is mainly based on py-faster-rcnn and TFFRCNN. For details about R-CNN please refer to the paper Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks by Shaoqing Ren, Kaiming He, Ross Girshick, Jian Sun.\r\n* [**pytorch-semantic-segmentation**]( https://github.com/ZijunDeng/pytorch-semantic-segmentation) - PyTorch for Semantic Segmentation.\r\n* [**EDSR-PyTorch**]( https://github.com/thstkdgus35/EDSR-PyTorch) - PyTorch version of the paper 'Enhanced Deep Residual Networks for Single Image Super-Resolution'.\r\n* [**image-classification-mobile**]( https://github.com/osmr/imgclsmob) - Collection of classification models pretrained on the ImageNet-1K.\r\n* [**FaderNetworks**]( https://github.com/facebookresearch/FaderNetworks) - Fader Networks: Manipulating Images by Sliding Attributes - NIPS 2017.\r\n* [**neuraltalk2-pytorch**]( https://github.com/ruotianluo/ImageCaptioning.pytorch) - Image captioning model in pytorch (finetunable cnn in branch with_finetune).\r\n* [**RandWireNN**]( https://github.com/seungwonpark/RandWireNN) - Implementation of: \"Exploring Randomly Wired Neural Networks for Image Recognition\".\r\n* [**stackGAN-v2**]( https://github.com/hanzhanggit/StackGAN-v2)  |Pytorch implementation for reproducing StackGAN_v2 results in the paper StackGAN++.\r\n* [**Detectron models for Object Detection**]( https://github.com/ignacio-rocco/detectorch) - This code allows to use some of the Detectron models for object detection from Facebook AI Research with PyTorch.\r\n* [**DEXTR-PyTorch**]( https://github.com/scaelles/DEXTR-PyTorch) - This paper explores the use of extreme points in an object (left-most, right-most, top, bottom pixels) as input to obtain precise object segmentation for images and videos.\r\n* [**pointnet.pytorch**]( https://github.com/fxia22/pointnet.pytorch) - Pytorch implementation for \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation.\r\n* [**self-critical.pytorch**]( https://github.com/ruotianluo/self-critical.pytorch) | This repository includes the unofficial implementation Self-critical Sequence Training for Image Captioning and Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering.\r\n* [**vnet.pytorch**]( https://github.com/mattmacy/vnet.pytorch) - A Pytorch implementation for V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation.\r\n* [**piwise**]( https://github.com/bodokaiser/piwise) - Pixel-wise segmentation on VOC2012 dataset using pytorch.\r\n* [**pspnet-pytorch**]( https://github.com/Lextal/pspnet-pytorch) - PyTorch implementation of PSPNet segmentation network.\r\n* [**pytorch-SRResNet**]( https://github.com/twtygqyy/pytorch-SRResNet) - Pytorch implementation for Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network.\r\n* [**PNASNet.pytorch**]( https://github.com/chenxi116/PNASNet.pytorch) - PyTorch implementation of PNASNet-5 on ImageNet.\r\n* [**img_classification_pk_pytorch**]( https://github.com/felixgwu/img_classification_pk_pytorch) - Quickly comparing your image classification models with the state-of-the-art models.\r\n* [**Deep Neural Networks are Easily Fooled**]( https://github.com/utkuozbulak/pytorch-cnn-adversarial-attacks) - High Confidence Predictions for Unrecognizable Images.\r\n* [**pix2pix-pytorch**]( https://github.com/mrzhu-cool/pix2pix-pytorch) - PyTorch implementation of \"Image-to-Image Translation Using Conditional Adversarial Networks\".\r\n* [**NVIDIA/semantic-segmentation**]( https://github.com/NVIDIA/semantic-segmentation) - A PyTorch Implementation of Improving Semantic Segmentation via Video Propagation and Label Relaxation, In CVPR2019.\r\n* [**Neural-IMage-Assessment**]( https://github.com/kentsyx/Neural-IMage-Assessment) - A PyTorch Implementation of Neural IMage Assessment.\r\n* [**torchxrayvision**](https://github.com/mlmed/torchxrayvision) | Pretrained models for chest X-ray (CXR) pathology predictions. Medical, Healthcare, Radiology - `PyTorch`\r\n\r\n","links":[{"article_link":"","code_link":"https://github.com/balavenkatesh3322/CV-pretrained-model","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1886,"title":"Medical Zoo - 3D Multi-modal Medical Image Segmentation","description":"My articles on deep learning in medical imaging","tags":["article","code","tutorial","pytorch","deep-learning","health","library","3d","computer-vision","medical-imaging","segmentation","medical-zoo"],"details":"## Deep learning in medical imaging\r\n1. If you want to quickly understand the fundamental concepts, we strongly advice to check our [blog post](https://theaisummer.com/medical-image-deep-learning/ \"MedicalZooPytorch article\"), which provides a high level overview of all the aspects of medical image segmentation and deep learning. \r\n2. Another more introductory article I wrote on medical imaging concepts for deep learning can be found [here](https://theaisummer.com/medical-image-coordinates/). \r\n3. For more background in Deep Learning in MRI please advice [this](https://nemertes.lis.upatras.gr/jspui/handle/10889/12754 \"MSc thesis link\"). \r\n4. Our open source library Medical Zoo pytorch is provided in the Github link, which implements the following architectures:\r\nU-Net3D,V-net, ResNet3D-VAE, SkipDesneNet3D, HyperDense-Net,\r\n multi-stream Densenet3D,  DenseVoxelNet, MED3D, HighResNet3D\r\n","links":[{"article_link":"https://theaisummer.com/medical-image-coordinates/","code_link":"https://github.com/black0017/MedicalZooPytorch","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://theaisummer.com/medical-image-deep-learning/"}]},{"id":1885,"title":"The Thesis Review Podcast","description":"Each episode of The Thesis Review is a conversation centered around a researcher's PhD thesis.","tags":["podcast","machine-learning"],"details":"Each episode of The Thesis Review is a conversation centered around a researcher's PhD thesis, giving insight into their history, revisiting older ideas, and providing a valuable perspective on how their research has evolved (or stayed the same) since.\r\n\r\n* [Soundcloud](https://soundcloud.com/thesis-review)\r\n* [Apple Podcasts](https://podcasts.apple.com/us/podcast/the-thesis-review/id1518425004?mt=2&app=podcast)\r\n* [Spotify](https://open.spotify.com/show/0iWtGUWGbFBRixMOqYHAUQ)\r\n\r\nFollow on Twitter [@thesisreview](https://twitter.com/thesisreview)","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://cs.nyu.edu/~welleck/podcast.html"}]},{"id":1884,"title":"Deploying your ML Model with TorchServe","description":"In this talk, Brad Heintz walks through how to use TorchServe to deploy trained models at scale without writing custom code. ","tags":["tutorial","video","production","torchserve","serving"],"details":"Deploying and managing models in production is often the most difficult part of the machine learning process. TorchServe is a flexible and easy to use tool for serving PyTorch models. In this talk, Brad Heintz walks through how to use TorchServe to deploy trained models at scale without writing custom code. \r\n","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=jdE4hPf9juk","dataset_link":"","demo_link":"","other_link":"https://pytorch.org/serve/"}]},{"id":1883,"title":"Torchfunc","description":"PyTorch functions & utilities to make your deep learning life easier\r\n\r\n","tags":["code","pytorch","library","utilities","functions"],"details":"* Improve and analyse performance of your neural network (e.g. Tensor Cores compatibility)\r\n* Record/analyse internal state of torch.nn.Module as data passes through it\r\n* Do the above based on external conditions (using single Callable to specify it)\r\n* Day-to-day neural network related duties (model size, seeding, time measurements etc.)\r\n* Get information about your host operating system, torch.nn.Module device, CUDA capabilities etc.","links":[{"article_link":"","code_link":"https://github.com/szymonmaszke/torchfunc","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://szymonmaszke.github.io/torchfunc"}]},{"id":1882,"title":"Object Detection with RetinaNet","description":"Implementing RetinaNet: Focal Loss for Dense Object Detection.","tags":["article","notebook","paper","research","tutorial","keras","tensorflow","computer-vision","object-detection","retinanet","arxiv:1708.02002"],"details":"Object detection a very important problem in computer vision. Here the model is tasked with localizing the objects present in an image, and at the same time, classifying them into different categories. Object detection models can be broadly classified into \"single-stage\" and \"two-stage\" detectors. Two-stage detectors are often more accurate but at the cost of being slower. Here in this example, we will implement RetinaNet, a popular single-stage detector, which is accurate and runs fast. RetinaNet uses a feature pyramid network to efficiently detect objects at multiple scales and introduces a new loss, the Focal loss function, to alleviate the problem of the extreme foreground-background class imbalance.","links":[{"article_link":"https://keras.io/examples/vision/retinanet/","code_link":"","research_link":"https://arxiv.org/abs/1708.02002","media_link":"","dataset_link":"","demo_link":"","other_link":"https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/vision/ipynb/retinanet.ipynb"}]},{"id":1880,"title":"AdapterHub: A Framework for Adapting Transformers","description":"Huggingface Transformers + Adapters","tags":["code","paper","research","huggingface","transformers","library","natural-language-processing","adapters","arxiv:2007.07779"],"details":"adapter-transformers is an extension of Huggingface's Transformers library, integrating adapters into state-of-the-art language models by incorporating AdapterHub, a central repository for pre-trained adapter modules.\r\n\r\nThis library can be used as a drop-in replacement for Huggingface Transformers and regulary synchronizes new upstream changes.\r\n\r\nHuggingface's great documentation on getting started with Transformers can be found below. To get started with adapters, refer to these locations:\r\n\r\n[https://docs.adapterhub.ml](https://docs.adapterhub.ml), our documentation on training and using adapters\r\n[https://adapterhub.ml](https://adapterhub.ml) to explore available pre-trained adapters and share your own adapters","links":[{"article_link":"","code_link":"https://github.com/Adapter-Hub/adapter-transformers","research_link":"https://arxiv.org/abs/2007.07779","media_link":"","dataset_link":"","demo_link":"","other_link":"https://adapterhub.ml/"}]},{"id":1879,"title":"Cross-lingual Transfer Learning - Sebastian Ruder","description":"An overview of approaches that transfer knowledge across languages and enable us to scale NLP models to more of the world's 7,000 languages.","tags":["article","tutorial","video","cross-lingual","natural-language-processing","transfer-learning"],"details":"Research in natural language processing (NLP) has seen striking advances in recent years, mainly driven by large pretrained language models. However, most of these approaches still require fine-tuning on large labelled datasets, which has constrained their success to languages where such data is plentiful. In this talk, I will give an overview of approaches that transfer knowledge across languages and enable us to scale NLP models to more of the world's 7,000 languages. I will cover state-of-the-art methods, what we know about them so far, novel benchmarks in this area, and promising future research directions.","links":[{"article_link":"https://ruder.io/unsupervised-cross-lingual-learning/","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=z0WbBA5pZgI","dataset_link":"","demo_link":"","other_link":""}]},{"id":1878,"title":"PyPika - Python Query Builder","description":"A python SQL query builder that exposes the full richness of the SQL language using a syntax that reflects the resulting query.","tags":["code","sql","library","pypika"],"details":"PyPika is a Python API for building SQL queries. The motivation behind PyPika is to provide a simple interface for building SQL queries without limiting the flexibility of handwritten SQL. Designed with data analysis in mind, PyPika leverages the builder design pattern to construct queries to avoid messy string formatting and concatenation. It is also easily extended to take full advantage of specific features of SQL database vendors.","links":[{"article_link":"","code_link":"https://github.com/kayak/pypika","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"http://pypika.readthedocs.io/en/latest/"}]},{"id":1877,"title":"An Overview of Distributed Training of Deep Learning Models","description":"Overview of the different techniques that are used by contemporary distributed DL systems and discuss their influence and implications on the training process.","tags":["paper","research","training","distributed-training","overview","arxiv:2007.03970"],"details":"Distributed deep learning systems (DDLS) train deep neural network models by utilizing the distributed resources of a cluster. Developers of DDLS are required to make many decisions to process their particular workloads in their chosen environment efficiently. The advent of GPU-based deep learning, the ever-increasing size of datasets and deep neural network models, in combination with the bandwidth constraints that exist in cluster environments require developers of DDLS to be innovative in order to train high quality models quickly. Comparing DDLS side-by-side is difficult due to their extensive feature lists and architectural deviations. We aim to shine some light on the fundamental principles that are at work when training deep neural networks in a cluster of independent machines by analyzing the general properties associated with training deep learning models and how such workloads can be distributed in a cluster to achieve collaborative model training. Thereby we provide an overview of the different techniques that are used by contemporary DDLS and discuss their influence and implications on the training process. To conceptualize and compare DDLS, we group different techniques into categories, thus establishing a taxonomy of distributed deep learning systems.","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2007.03970","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1876,"title":"Predict the hourly output power of a Combined Cycle Power Plant.","description":"In this project I have explored the data collected from a Combined Cycle Power Plant over 6 years. Searched for the best machine learning algorithm to predict t","tags":["code","dataset","flask","scikit-learn","energy"],"details":"","links":[{"article_link":"","code_link":"https://github.com/sumanthegdegithub/Predict-the-hourly-output-power-of-a-Combined-Cycle-Power-Plant.","research_link":"","media_link":"","dataset_link":"http://archive.ics.uci.edu/ml/datasets/Combined Cycle Power Plant","demo_link":"","other_link":""}]},{"id":1874,"title":"Awesome TFLite","description":"An awesome list of TFLite models with sample apps, model zoo, helpful tools and learning resources from the community.","tags":["code","tutorial","keras","tensorflow","deep-learning","library","computer-vision","natural-language-processing","tensorflow-lite"],"details":"I started an awesome list of TFLite models with sample apps, model zoo, helpful tools and learning resources by the community.\r\n\r\nThe purpose of this project is to  \r\n- showcase what the community has built with TFLite  \r\n- put all the samples side-by-side for easy references  \r\n- knowledge sharing and learning for everyone  ","links":[{"article_link":"","code_link":"https://github.com/margaretmz/awesome-tflite","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1873,"title":"Pythonizr - Generates boilerplate code for scikit-learn","description":"Pythonizr is a machine learning boilerplate code generator to help you start coding right away!","tags":["code","tool","scikit-learn","machine-learning","demo","boilerplate"],"details":"","links":[{"article_link":"","code_link":"github.com/akashp1712/pythonizr2","research_link":"","media_link":"","dataset_link":"","demo_link":"https://pythonizr.com","other_link":""}]},{"id":1872,"title":"An Icon Classifier with TensorFlow Lite Model Maker","description":"An Icon Classifier with TensorFlow Lite Model Maker","tags":["article","code","tutorial","deep-learning","computer-vision","tensorflow-lite"],"details":"This is a two part end-to-end tutorial:\r\n\r\n1 - Make an icon classifier with the TensorFlow Lite Model Maker  \r\n2 - Implement the model on Android with ML Model Binding","links":[{"article_link":"https://medium.com/swlh/icon-classifier-with-tflite-model-maker-9263c0021f72","code_link":"https://github.com/margaretmz/icon-classifier","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1871,"title":"Summarize a webapge","description":"A Flask application that extracts and summarizes webpage using Natural Language Processing. Powered by nlp-akash.","tags":["api","article","code","tutorial","natural-language-processing","text-summarization"],"details":"Motivation of this project to make production ready API for Text Summarization Algorithm and leverage it for the real-world use cases. This project implements a NLP algorithm using Python and serves using flask API.","links":[{"article_link":"https://becominghuman.ai/text-summarization-in-5-steps-using-nltk-65b21e352b65","code_link":"https://github.com/akashp1712/summarize-webpage","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1870,"title":"Interpretability and Analysis of Models for NLP","description":"An in-depth look at interpretability and analysis of models for NLP (ACL 2020).","tags":["article","research","interpretability","natural-language-processing","acl-2020"],"details":"**Evaluating faithful interpretability**\r\n\r\nGuidelines we should keep in mind when working on faithful interpretations from Jacovi & Goldberg 2020 (talk\u2019s slides, number 16\u201324)\r\n1. Faithfulness is not Plausibility. A plausible but unfaithful interpretation is akin to lying, and can be dangerous.\r\n2.  A model decision process is not a human decision process. Humans cannot judge if an interpretation is faithful. Evaluating interpretation using human input is evaluating plausibility, not faithfulness.\r\n3. Claims are just claims until tested. A model which is believed to be \u201cinherently interpretable\u201d should be rigorously tested in just the same way as post-hoc methods.\r\n\r\n**Interpretability via different methods**\r\n\r\n1. Attention as interpretation\r\n1. Probing\r\n1. Rationales for Faithful Interpretations\r\n1. Explanation via Training Examples\r\n\r\nand many other techniques for interpretability in NLP!\r\n","links":[{"article_link":"https://medium.com/@lawrence.carolin/interpretability-and-analysis-of-models-for-nlp-e6b977ac1dc6","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1869,"title":"Bridging PyTorch and TVM","description":"Taking Hugging Face transformer BERT from PyTorch and running it on \r\nApacheTVM for both inference (with reasonable timings) and training.","tags":["article","code","tutorial","huggingface","pytorch","attention","bert","transformers","library","natural-language-processing","apache-tvm","tvm"],"details":"Some of the most intriguing applications of Artificial Intelligence have been in Natural Language Processing. Models like BERT or GPT-2 and their variants can seemingly grasp enough of a text to continue it in a way that needs a second look to recognize as gibberish.\r\n\r\nThese models belong to a class of neural network architectures called Transformers. One of the favourite libraries implementing them is the HuggingFace transformers library.\r\n\r\nBut, in contrast to convolutional models or LSTMs where we have heavily optimized implementations, this is not as much the case for transformers. So here we explore how TVM can fill the gap. We will do so in two steps:\r\n\r\n* First we look at BERT inference and tuning that on TVM.\r\n* Secondly, we start some more fundamental exploration of how one could use TVM for training in PyTorch. Given the experimental nature, we focus on feasibility more than on the performance in this part.","links":[{"article_link":"https://tvm.apache.org/2020/07/14/bert-pytorch-tvm","code_link":"https://github.com/t-vi/pytorch-tvmisc/tree/master/transformers-pytorch-tvm/","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://github.com/t-vi/pytorch-tvmisc"}]},{"id":1868,"title":"Selfie2Anime with TFLite","description":"An end-to-end tutorial with TensorFlow Lite for Selfie2Anime (U-GAT-IT). ","tags":["article","code","tutorial","tensorflow","deep-learning","generative-adversarial-networks","machine-learning","computer-vision","image-to-image-translation","tensorflow-lite","android"],"details":"This is a multi-part tutorial - [Part 1](http://bit.ly/selfie2anime-1) | [Part 2](http://bit.ly/selfie2anime-2) | [Part 3](http://bit.ly/selfie2anime-3)\r\n\r\nThe tutorial covers the following:\r\n\r\n- Exporting model checkpoints as `SavedModel` TF 1.x\r\n- Conversion of the `SavedModel` to TensorFlow Lite in TF 2.x with  `TFLiteConverter`\r\n- Model inference in Python\r\n- Add metadata to the TFLite model\r\n- Run TFLite Benchmarking Tool\r\n- Deploy TFLite model to Android in just a few lines of code with ML Model Binding\r\n","links":[{"article_link":"https://medium.com/@margaretmz/selfie2anime-with-tflite-part-1-overview-f97500800ffe","code_link":"https://github.com/margaretmz/selfie2anime-with-tflite","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1867,"title":"YOLOv4 With TensorFlow","description":"YOLOv4, YOLOv4-tiny, YOLOv3, YOLOv3-tiny Implemented in Tensorflow 2.0, Android. Convert YOLO v4 .weights tensorflow, tensorrt and tflite.","tags":["code","paper","research","tutorial","video","tensorflow","computer-vision","object-detection","yolo","tensorflow-lite","yolov4","arxiv:2004.10934","yolov4-tiny"],"details":"YOLOv4, YOLOv4-tiny Implemented in Tensorflow 2.0. Convert YOLO v4, YOLOv3, YOLO tiny .weights to .pb, .tflite and trt format for tensorflow, tensorflow lite, tensorRT.\r\n\r\n![](https://github.com/theAIGuysCode/tensorflow-yolov4-tflite/raw/master/data/helpers/demo.gif)","links":[{"article_link":"","code_link":"https://github.com/theAIGuysCode/tensorflow-yolov4-tflite","research_link":"https://arxiv.org/abs/2004.10934","media_link":"https://www.youtube.com/watch?v=iPwepy-SVCQ","dataset_link":"","demo_link":"","other_link":""}]},{"id":1866,"title":"PYthon Automated Term Extraction","description":"Term extraction algorithms such as C-Value, Basic, Combo Basic, Weirdness and Term Extractor using spaCy POS tagging.","tags":["article","code","spacy","library","named-entity-recognition","natural-language-processing","part-of-speech-tagging","terminology-extraction","terminology","pyate"],"details":"Python implementation of term extraction algorithms such as C-Value, Basic, Combo Basic, Weirdness and Term Extractor using spaCy POS tagging.\r\n\r\nIf you have a suggestion for another ATE algorithm you would like implemented in this package feel free to file it as an issue with the paper the algorithm is based on.","links":[{"article_link":"https://medium.com/@praveengovi.analytics/automated-term-extraction-with-pyate-spacy-60f9468fbfb3","code_link":"https://github.com/kevinlu1248/pyate","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1865,"title":"PDFTableExtract","description":"Build a parser to extract the table in PDF document with RetinaNet","tags":["article","code","library","computer-vision","optical-character-recognition","document-processing","table-extraction","retinanet","pdftableextract","table-detection"],"details":"There are two parts we will build. In the first part, I will go through how to train Keras-RetinaNet to detect tables in PDF file and save the weight. In the last part, I\u2019ll go through how to load the weight, and run the prediction to detect the table on the given PDF file and extract it into Panda data frame.","links":[{"article_link":"https://medium.com/@djajafer/pdf-table-extraction-with-keras-retinanet-173a13371e89","code_link":"https://github.com/ferrygun/PDFTableExtract","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1864,"title":"Deep Dive on PyTorch Quantization","description":"Model quantization using the familiar eager mode Python API.","tags":["article","tutorial","video","pytorch","model-compression","quantization"],"details":"It\u2019s important to make efficient use of both server-side and on-device compute resources when developing machine learning applications. To support more efficient deployment on servers and edge devices, PyTorch added a support for model quantization using the familiar eager mode Python API.\r\n\r\nQuantization leverages 8bit integer (int8) instructions to reduce the model size and run the inference faster (reduced latency) and can be the difference between a model achieving quality of service goals or even fitting into the resources available on a mobile device. Even when resources aren\u2019t quite so constrained it may enable you to deploy a larger and more accurate model. Quantization is available in PyTorch starting in version 1.3 and with the release of PyTorch 1.4 we published quantized models for ResNet, ResNext, MobileNetV2, GoogleNet, InceptionV3 and ShuffleNetV2 in the PyTorch torchvision 0.5 library.","links":[{"article_link":"https://pytorch.org/docs/stable/quantization.html","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=c3MT2qV5f9w","dataset_link":"","demo_link":"","other_link":""}]},{"id":1863,"title":"Variable Skipping for Autoregressive Range Density Estimation","description":"Naive marginalization to estimate range densities takes time exponential in the number of dimensions of the joint distribution.","tags":["article","code","paper","research","variable-skipping","autoregressive-range-density-estimation","arxiv:2007.05572"],"details":"* We propose range density estimation, a new downstream task for autoregressive models.\r\n* Inspired by ML-for-systems application: database query optimization.\r\n* Prior work uses a forward sampling-style algorithm for approximate inference.\r\n* We speed up inference by simple data augmentation: randomly mask inputs at training; invoke learned masks to skip inferring unconstrained variables at inference.\r\n* Variable skipping outperforms multi-order training alone, and can provide additional gains when used in combination.\r\n* We invite future research on this relatively under-explored task, where better performance translates to real-world impact (faster query engines).\r\n\r\nTo skip sampling unconstrained/absent variables during inference, we propose training special MASK tokens that signify a variable's absence:\r\n\r\n![](https://var-skip.github.io/assets/img/train.gif)","links":[{"article_link":"https://var-skip.github.io/","code_link":"https://github.com/var-skip/var-skip","research_link":"https://arxiv.org/abs/2007.05572","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1862,"title":"NumExpr: Fast numerical expression evaluator for NumPy","description":"Fast numerical array expression evaluator for Python, NumPy, PyTables, pandas, bcolz and more.","tags":["article","code","tutorial","library","pandas","numpy","numexpr"],"details":"NumExpr is a fast numerical expression evaluator for NumPy. With it, expressions that operate on arrays (like '3*a+4*b') are accelerated and use less memory than doing the same calculation in Python.\r\n\r\nIn addition, its multi-threaded capabilities can make use of all your cores -- which generally results in substantial performance scaling compared to NumPy.\r\n\r\nLast but not least, numexpr can make use of Intel's VML (Vector Math Library, normally integrated in its Math Kernel Library, or MKL). This allows further acceleration of transcendent expressions.","links":[{"article_link":"https://towardsdatascience.com/speed-up-your-numpy-and-pandas-with-numexpr-package-25bd1ab0836b","code_link":"https://github.com/pydata/numexpr","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://numexpr.readthedocs.io/"}]},{"id":1861,"title":"Determined: Deep Learning Training Platform","description":"Determined helps deep learning teams train models more quickly, easily share GPU resources, and effectively collaborate.","tags":["code","library","distributed-training","experiment-tracking","hyperparameter-optimization","neural-architecture-search","deeplearning","ml-infrastructure","model-registry"],"details":"","links":[{"article_link":"","code_link":"https://github.com/determined-ai/determined","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://determined.ai/"}]},{"id":1860,"title":"NSFW Image Moderation Automation Engine built with TensorFlow.JS ","description":"An open-source NSFW Image Classifier including an Automation Engine for fast deletion & moderation built with Node.js, TensorFlow, and Parse Server","tags":["article","code","tutorial","node-js","tensorflow","tensorflow-js","convolutional-neural-networks","library","computer-vision","image-classification","image-recognition","object-detection","pretraining","open-source","models","demo","nsfw","content-moderation","nsfw-detection","nsfw-classifier","parse-server","machine-learning-pipelines","adversial-image-detection","adversial-learning","ready-to-use","automation-engine"],"details":"## Builidng a NSFW Image Moderation Automation with Parse Config & Triggers\r\nDid you like our **[NSFW Image Classification REST API](https://bit.ly/2C8U4BV)**? If you did, this week we have prepared for you something really useful to build on top and get you closer to implementing a fully operational Content Moderation Service of your own! \r\n\r\n## [Part 2: NSFW Content Moderation Automation Engine](https://bit.ly/2OAD1vn)\r\nIf you are developing the next Tinder, Netflix, Google Maps, Snapchat, or any kind of app with lots of user-generated content then you must have faced head-on the challenges of Content Moderation. Or maybe you've already built a relatively medium-sized app(\u2248 5 000 daily users) and 5 000 photos are uploaded every 24 hours. That makes 35 000 per week and 150 000 per month. WOW! **Do you set aside a budget for content moderators? Or go through 150 000 pictures manually each month? There is an easier way! **([learn how](https://bit.ly/2OAD1vn))\r\n\r\n## What's Next?\r\nBy the end of the series you'll get a **simple, effective and ready-to-use Content Moderation solution** that can be easily integrated into every project even if this is your first encounter with Machine Learning. So in the final tutorial, we will put the cherry on top by adding **React** to our stack and create a **[beautiful Admin panel](https://bit.ly/39eHpJM)**. \r\n\r\n## Give Us a Shout!\r\nWhether you deploy directly, integrate, or fork our solution if you liked what we did, don't forget to give us a shout on [Twitter](https://twitter.com/sashidoio) or share the [repo](https://bit.ly/3j19xEN). Thank you in advance for the support!\r\n\r\n## Your Feedback Matters!\r\nHelp us in our mission to break the barrier to Machine Learning by sharing your feedback and use cases at hello@sashido.io.\r\n\r\nBut enough talk, I know you can't wait to get your hands dirty & start creating better apps with ML! \ud83d\ude1c\r\n\r\n\r\nP.S. *Feel free to take advantage of SashiDo's extended [45-day free trial](https://bit.ly/32gmQvd), no credit card required. Valid until 1st of Sep, 2020*","links":[{"article_link":"https://bit.ly/2OAD1vn","code_link":"https://bit.ly/3j19xEN","research_link":"","media_link":"https://bit.ly/3er35Dz","dataset_link":"","demo_link":"https://bit.ly/2WcsDOv","other_link":"https://bit.ly/2WlfMcW"}]},{"id":1859,"title":"You Trained a Machine Learning Model, Now What?","description":"Three often overlooked parts of this process occur after the model is actually built: model evaluation, deployment, and monitoring.","tags":["tutorial","video","production","monitoring","deployment"],"details":"Training a machine learning model is just one part of building ML powered products. Building products is an iterative process that starts with a question, challenge, or opportunity. From there we build hypotheses, collect data, and train models. But 3 often overlooked parts of this process occur after the model is actually built: model evaluation, deployment, and monitoring.\r\n\r\nThe very first video Luigi has created for the Made With ML incubator program, with a QA session to follow shortly!\r\n","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=Vugbn17LDPQ","dataset_link":"","demo_link":"","other_link":"https://www.slideshare.net/LuigiPatruno1/youve-trained-a-machine-learning-model-now-what"}]},{"id":1858,"title":"QSVM","description":"Quantum SVM for sentiment analysis","tags":["code","notebook","support-vector-machines","natural-language-processing","quantum-machine-learning","sentiment-analysis"],"details":"Created a Quantum Support Vector Machine model with TF IDF vectorization for Kaggle's Real or Not Tweets Competition. Used Qiskit and scikit-learn.","links":[{"article_link":"","code_link":"https://colab.research.google.com/drive/1SleDwcpV6QNEmIDXc4m3kLsSeSRiet_O","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1856,"title":"DeepDream Video Style Transfer","description":"DeepDream on Video","tags":["code","convolutional-neural-networks","computer-vision","style-transfer"],"details":"Script that breaks down a video into frames, applies a DeepDream filter on it using a CNN, then joins frames together to create a style inspired by [https://www.youtube.com/watch?v=5WqFqzeLpXg](https://www.youtube.com/watch?v=5WqFqzeLpXg)","links":[{"article_link":"","code_link":"https://github.com/boronhub/deepdream_dude","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1855,"title":"ULMFiT Airline Sentiment Analysis","description":"Transfer Learning using pretrained ULMFiT model","tags":["code","language-modeling","natural-language-processing","sentiment-analysis","transfer-learning","ulmfit"],"details":"For Fellowship.AI Membership challenge. Using pretrained ULMFiT model from fast.ai library to predict sentiment of tweets about US Airlines. ","links":[{"article_link":"","code_link":"https://www.kaggle.com/kagglebrun/twitter-us-airline-sentiment-analysis-ulmfit","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1854,"title":"Janggu - Deep learning for Genomics","description":"Deep learning infrastructure for bioinformatics.","tags":["code","paper","research","keras","tensorflow","health","library","genomics","bioinformatics","janggu","epigenetics"],"details":"1. Janggu provides special Genomics datasets that allow you to access raw data in FASTA, BAM, BIGWIG, BED and GFF file format.\r\n1. Various normalization procedures are supported for dealing with of the genomics dataset, including 'TPM', 'zscore' or custom normalizers.\r\n1. Biological features can be represented in terms of higher-order sequence features, e.g. di-nucleotide based features.\r\n1. The dataset objects are directly consumable with neural networks for example implemented using keras or using scikit-learn (see src/examples in this repository).\r\n1. Numpy format output of a keras model can be converted to represent genomic coverage tracks, which allows exporting the predictions as BIGWIG files and visualization of genome browser-like plots.\r\n1. Genomic datasets can be stored in various ways, including as numpy array, sparse dataset or in hdf5 format.\r\n1. Caching of Genomic datasets avoids time consuming preprocessing steps and facilitates fast reloading.\r\n1. Janggu provides a wrapper for keras models with built-in logging functionality and automatized result evaluation.\r\n1. Janggu supports input feature importance attribution using the integrated gradients method and variant effect prediction assessment.\r\n1. Janggu provides a utilities such as keras layer for scanning both DNA strands for motif occurrences.","links":[{"article_link":"","code_link":"https://github.com/BIMSBbioinfo/janggu","research_link":"https://www.nature.com/articles/s41467-020-17155-y","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1853,"title":"The Transformer Neural Network Architecture Explained","description":"\u2699\ufe0f It is time to explain how Transformers work. If you are looking for an easy explanation, you are exactly right!","tags":["tutorial","video","attention","self-attention","transformers","natural-language-processing","positional-encoding"],"details":"\u2699\ufe0f It is time to explain how Transformers work. If you are looking for an easy explanation, you are exactly right! ","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=FWFA4DGuzSc","dataset_link":"","demo_link":"","other_link":""}]},{"id":1852,"title":"Madam Optimiser","description":"A multiplicative version of the Adam optimizer and shows that it can train state of the art neural network architectures without learning rate tuning.","tags":["code","paper","research","learning-rates","optimizer","madam","arxiv:2006.14560"],"details":"Compositionality is a basic structural feature of both biological and artificial neural networks. Learning compositional functions via gradient descent incurs well known problems like vanishing and exploding gradients, making careful learning rate tuning essential for real-world applications. This paper proves that multiplicative weight updates satisfy a descent lemma tailored to compositional functions. Based on this lemma, we derive Madam---a multiplicative version of the Adam optimiser---and show that it can train state of the art neural network architectures without learning rate tuning. We further show that Madam is easily adapted to train natively compressed neural networks by representing their weights in a logarithmic number system. We conclude by drawing connections between multiplicative weight updates and recent findings about synapses in biology.","links":[{"article_link":"","code_link":"https://github.com/jxbz/madam","research_link":"https://arxiv.org/abs/2006.14560","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1851,"title":"StreamAlert","description":"A serverless, realtime data analysis framework which empowers you to ingest, analyze, and alert on data from any environment, using datasources and alerts.","tags":["code","aws","library","security","monitoring","lambda","serverless","streaming-data","streamalert","airbnb","kinesis","terraform"],"details":"StreamAlert is a serverless, real-time data analysis framework which empowers you to ingest, analyze, and alert on data from any environment, using data sources and alerting logic you define. Computer security teams use StreamAlert to scan terabytes of log data every day for incident detection and response.\r\n\r\n**Features**\r\n\r\n* Rules are written in Python; they can utilize any Python libraries or functions\r\n* Ingested logs and generated alerts can be retroactively searched for compliance and research\r\n* Serverless design is cheaper, easier to maintain, and scales to terabytes per day\r\n* Deployment is automated: simple, safe and repeatable for any AWS account\r\n* Secure by design: least-privilege execution, containerized analysis, and encrypted data storage\r\n* Merge similar alerts and automatically promote new rules if they are not too noisy\r\n* Built-in support for dozens of log types and schemas\r\n* Built-in collection of broadly applicable community rules\r\n* Fully open source and customizable: add your own log schemas, rules, and alert outputs","links":[{"article_link":"","code_link":"https://github.com/airbnb/streamalert","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://streamalert.io/"}]},{"id":1850,"title":"Wallaroo","description":"Distributed Stream Processing to Build and scale real-time applications.","tags":["article","code","library","streaming-data","stream-processing","wallaroo"],"details":"Wallaroo is a fast stream-processing framework. Wallaroo makes it easy to react to data in real-time. By eliminating infrastructure complexity, going from prototype to production has never been simpler.\r\n\r\nWhen we set out to build Wallaroo, we had several high-level goals in mind:\r\n\r\n* Create a dependable and resilient distributed computing framework\r\n* Take care of the complexities of distributed computing \"plumbing,\" allowing developers to focus on their business logic\r\n* Provide high-performance & low-latency data processing\r\n* Be portable and deploy easily (i.e., run on-prem or any cloud)\r\n* Manage in-memory state for the application\r\n* Allow applications to scale as needed, even when they are live and up-and-running","links":[{"article_link":"https://blog.wallaroolabs.com/2017/03/hello-wallaroo/","code_link":"https://github.com/WallarooLabs/wallaroo","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.wallaroolabs.com/"}]},{"id":1849,"title":"Faust","description":"Python Stream Processing.","tags":["code","library","streaming-data","faust","robinhood"],"details":"**Faust** is a stream processing library, porting the ideas from\r\n`Kafka Streams`_ to Python.\r\n\r\nIt is used at `Robinhood`_ to build high performance distributed systems\r\nand real-time data pipelines that process billions of events every day.\r\n\r\nFaust provides both *stream processing* and *event processing*,\r\nsharing similarity with tools such as\r\n`Kafka Streams`_, `Apache Spark`_/`Storm`_/`Samza`_/`Flink`_,\r\n\r\nIt does not use a DSL, it's just Python!\r\nThis means you can use all your favorite Python libraries\r\nwhen stream processing: NumPy, PyTorch, Pandas, NLTK, Django,\r\nFlask, SQLAlchemy, ++\r\n","links":[{"article_link":"","code_link":"https://github.com/robinhood/faust","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"http://faust.readthedocs.io/"}]},{"id":1848,"title":"Comprehensive analysis of important metrics in ML","description":"In this work, the authors present a comprehensive analysis of important metrics in practical applications.","tags":["paper","research","deep-learning","computer-vision","image-classification","metrics","arxiv:1605.07678"],"details":">Since the breakthrough in 2012 ImageNet competition (Russakovsky et al., 2015) achieved by\r\nAlexNet (Krizhevsky et al., 2012) \u2014 the first entry that used a Deep Neural Network (DNN) \u2014\r\nseveral other DNNs with increasing complexity have been submitted to the challenge in order to\r\nachieve better performance.\r\nIn the ImageNet classification challenge, the ultimate goal is to obtain the highest accuracy in a\r\nmulti-class classification problem framework, regardless of the actual inference time. We believe\r\nthat this has given rise to several problems. Firstly, it is now normal practice to run several trained\r\ninstances of a given model over multiple similar instances of each validation image. This practice,\r\nalso know as model averaging or ensemble of DNNs, dramatically increases the amount of computation required at inference time to achieve the published accuracy. Secondly, model selection is\r\nhindered by the fact that different submissions are evaluating their (ensemble of) models a different\r\nnumber of times on the validation images, and therefore the reported accuracy is biased on the specific sampling technique (and ensemble size). Thirdly, there is currently no incentive in speeding up\r\ninference time, which is a key element in practical applications of these models, and affects resource\r\nutilisation, power-consumption, and latency.\r\nThis article aims to compare state-of-the-art DNN architectures, submitted for the ImageNet challenge over the last 4 years, in terms of computational requirements and accuracy. We compare these\r\narchitectures on multiple metrics related to resource utilisation in actual deployments: accuracy,\r\nmemory footprint, parameters, operations count, inference time and power consumption. The purpose of this paper is to stress the importance of these figures, which are essential hard constraints\r\nfor the optimisation of these networks in practical deployments and applications.","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/1605.07678","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1847,"title":"Driver Identification Based on Vehicle's telematics data","description":"In this paper, we proposed a deep learning model, which can identify drivers from their driving behaviors based on vehicle telematics data.","tags":["code","paper","research","deep-learning","lstm","machine-learning","cyber-security","autonomous-vehicles","computer-vision","telematics"],"details":"Despite advancements in vehicle security systems, over the last decade, auto-theft rates have increased, and cybersecurity attacks on internet-connected and autonomous vehicles are becoming a new threat. In this paper, we proposed a deep learning model, which can identify drivers from their driving behaviors based on vehicle telematics data. Given the telematics is time-series data, the problem is formulated as a time series prediction task to exploit the embedded sequential information. The performance of the proposed approach is evaluated on three naturalistic driving datasets, which gives high accuracy prediction results. The robustness of the model on noisy and anomalous data that is usually caused by sensor defects or environmental factors is also investigated. Results show that the proposed model prediction accuracy remains satisfactory and outperforms the other approaches despite the extent of anomalies and noise-induced in the data.","links":[{"article_link":"","code_link":"https://github.com/Abeni18/Deep-LSTM-for-Driver-Identification-","research_link":"https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8995202&casa_token=FnCWyRl9S0sAAAAA:BJf0ASpjoTmdSgGQcJUVa-k-0olRVMwBObUuyNu0ddNwd2Xj8mTQO3Fh-qiwGzEXdtox8bGq3g&tag=1","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1846,"title":"scikit-multiflow","description":"A machine learning package for streaming data in Python.","tags":["code","video","scikit-learn","library","unsupervised-learning","concept-drift-detection","streaming-data","scikit-multiflow"],"details":"**Incremental Learning**\r\nStream learning models are created incrementally and are updated continuously. They are suitable for big data applications where real-time response is vital.\r\n\r\n**Adaptive learning**\r\nChanges in data distribution harm learning. Adaptive methods are specifically designed to be robust to concept drift changes in dynamic environments.\r\n\r\n**Resource-wise efficient**\r\nStreaming techniques efficiently handle resources such as memory and processing time given the unbounded nature of data streams.\r\n\r\n**Easy to use**\r\nscikit-multiflow is designed for users with any experience level. Experiments are easy to design, setup, and run. Existing methods are easy to modify and extend.\r\n\r\n**Stream learning tools**\r\nIn its current state, scikit-multiflow contains data generators, multi-output/multi-target stream learning methods, change detection methods, evaluation methods, and more.\r\n\r\n![](https://user-images.githubusercontent.com/2931080/62623486-4093d400-b921-11e9-9fcb-fb21f1a48ea4.png)","links":[{"article_link":"","code_link":"https://github.com/scikit-multiflow/scikit-multiflow","research_link":"","media_link":"https://www.youtube.com/watch?v=sw85SCv847Y","dataset_link":"","demo_link":"","other_link":"https://scikit-multiflow.github.io/"}]},{"id":1845,"title":"Face Predicting Web App","description":"Interactive Deep Learning Model that utilizes your computer webcam to predict your age and gender in seconds! ","tags":["code","aws","docker","flask","html","javascript","python","tensorflow","convolutional-neural-networks","deep-learning","machine-learning","computer-vision","image-classification","demo"],"details":"A personal project I decided to pursue to get familiar with deploying ML models on the cloud. Try it out and let me know what you think!","links":[{"article_link":"","code_link":"https://github.com/huntermitchell123/webApp","research_link":"","media_link":"","dataset_link":"","demo_link":"https://huntermitchell.net/project","other_link":""}]},{"id":1844,"title":"Semi-Supervised Learning in Computer Vision","description":"A comprehensive overview of recent semi-supervised learning methods in Computer Vision","tags":["article","tutorial","computer-vision","data-augmentation","semi-supervised-learning"],"details":"- Learn about self-training, consistency training and hybrid methods\r\n- Learn about 9 recent architectures for semi-supervised learning\r\n- Visual diagrams for each architecture explained using a simple cats-vs-dogs example","links":[{"article_link":"https://amitness.com/2020/07/semi-supervised-learning/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1843,"title":"Cortex","description":"Build machine learning APIs.","tags":["code","library","production","serving","cortex"],"details":"Cortex makes deploying, scaling, and managing machine learning systems in production simple. We believe that developers in any organization should be able to add natural language processing, computer vision, and other machine learning capabilities to their applications without having to worry about infrastructure.\r\n\r\n#### How it works:\r\nImplement your predictor in predictor.py, configure your deployment in cortex.yaml, and run cortex deploy.\r\n\r\nHere's how to deploy GPT-2 as a scalable text generation API:\r\n\r\n![demo](https://camo.githubusercontent.com/e20daf2b1b97290afe128a0767326dcc5e9138cc/68747470733a2f2f64317a7165626b6e7064683033332e636c6f756466726f6e742e6e65742f64656d6f2f6769662f76302e31382e676966)","links":[{"article_link":"","code_link":"https://github.com/cortexlabs/cortex","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.cortex.dev/"}]},{"id":1842,"title":"PyCaret","description":"An open source, low-code machine learning library in Python.","tags":["article","code","video","library","automl","preprocessing","pycaret","low-code"],"details":"PyCaret is an open source `low-code` machine learning library in Python that aims to reduce the hypothesis to insights cycle time in a ML experiment. It enables data scientists to perform end-to-end experiments quickly and efficiently. In comparison with the other open source machine learning libraries, PyCaret is an alternative low-code library that can be used to perform complex machine learning tasks with only few lines of code. PyCaret is essentially a Python wrapper around several machine learning libraries and frameworks such as `scikit-learn`, `XGBoost`, `Microsoft LightGBM`, `spaCy` and many more. \r\n\r\n![](https://github.com/pycaret/pycaret/raw/master/pycaret2-features.png)\r\n\r\nPyCaret is `simple`, `easy to use` and `deployment ready`. All the steps performed in a ML experiment can be reproduced using a pipeline that is automatically developed and orchestrated in PyCaret as you progress through the experiment. A `pipeline` can be saved in a binary file format that is transferable across environments.\r\n\r\nFor more information on PyCaret, please visit our official website https://www.pycaret.org\r\n","links":[{"article_link":"https://towardsdatascience.com/github-is-the-best-automl-you-will-ever-need-5331f671f105","code_link":"https://github.com/pycaret/pycaret","research_link":"","media_link":"https://www.youtube.com/channel/UCxA1YTYJ9BEeo50lxyI_B3g/videos","dataset_link":"","demo_link":"","other_link":"https://pycaret.org/"}]},{"id":1841,"title":"Highlights of ACL 2020","description":"Notes and trends from ACL 2020.","tags":["article","research","acl2020"],"details":"I decided to share the notes I took and discuss some overall trends. The list is not exhaustive, and is based on my research interests. I recommend also checking out the [best papers](https://acl2020.org/blog/ACL-2020-best-papers/).","links":[{"article_link":"https://medium.com/@vered1986/highlights-of-acl-2020-4ef9f27a4f0c","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1840,"title":"TensorFlow 2 meets the Object Detection API","description":"TF Object Detection API (OD API) officially supports TensorFlow 2!","tags":["article","code","notebook","tensorflow","library","computer-vision","object-detection","demo"],"details":"If you\u2019d like to get your feet wet immediately, we recommend checking out our shiny new Colab demos (for [inference](https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/inference_tf2_colab.ipynb) and [few-shot training](https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/eager_few_shot_od_training_tf2_colab.ipynb)).","links":[{"article_link":"https://blog.tensorflow.org/2020/07/tensorflow-2-meets-object-detection-api.html","code_link":"https://github.com/tensorflow/models/tree/master/research/object_detection","research_link":"","media_link":"","dataset_link":"","demo_link":"https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/eager_few_shot_od_training_tf2_colab.ipynb","other_link":"https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/inference_tf2_colab.ipynb"}]},{"id":1839,"title":"Gradio","description":"Interfaces for your ML Models.\r\n","tags":["code","library","dashboard","gradio"],"details":"Generate an easy-to-use UI for your ML model, function, or API with only a few lines of code. Integrate directly into your Python notebook, or share a link with anyone.\r\n","links":[{"article_link":"","code_link":"https://github.com/gradio-app/gradio","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.gradio.app/"}]},{"id":1838,"title":"Audio Classification using CNN MLP","description":"The objective of this project is to build a multi-class classifier to identify the sound of a bee, cricket or noise.","tags":["code","dataset","paper","research","convolutional-neural-networks","audio","audio-classification","cnn","mlp","multilayer-perceptron-network","tflearn","noise","convolutional-layers","cricket","classifier","audio-processing","audio-analysis"],"details":"","links":[{"article_link":"","code_link":"https://github.com/vishalshar/Audio-Classification-using-CNN-MLP","research_link":"https://github.com/vishalshar/Audio-Classification-using-CNN-MLP/blob/master/project report.pdf","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1837,"title":"Speaker Diarization (CNN, RNN, LSTM)","description":"Speaker Diarization is the problem of separating speakers in audio. ","tags":["code","paper","research","tensorflow","convolutional-neural-networks","lstm","recurrent-neural-networks","audio","speaker-diarization","speech","mlp","speaker-diarization-problem","speakerdiarization-rnn","cnn-model","separating-speakers","arxiv:2006.05596"],"details":"Speaker Diarization is the problem of separating speakers in an audio. There could be any number of speakers and final result should state when speaker starts and ends. In this project, we analyze given audio file with 2 channels and 2 speakers (on separate channel). We train Neural Network for learning when a person is speaking. We use different type of Neural Networks specifically, Single Layer Perceptron, Multi Layer Perceptron (MLP), Recurrent Neural Network (RNN) and Convolution Neural Network (CNN) we achieve 92% of accuracy with RNN.","links":[{"article_link":"","code_link":"https://github.com/vishalshar/SpeakerDiarization_RNN_CNN_LSTM","research_link":"https://arxiv.org/abs/2006.05596","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1836,"title":"Training a pets detector model with TFOD API (TF 2)","description":"In this notebook, we will be training a custom object detection model using the latest TensorFlow Object Detection (TFOD) API which is based on TensorFlow 2.2. ","tags":["code","notebook","tutorial","tensorflow","deep-learning","computer-vision","object-detection"],"details":"The content covers:\r\n\r\n- Set up TFOD API\r\n- Gather Pets dataset and prepare it\r\n- Set up GCP utilities\r\n\t- Configure GCP project\r\n\t- Configure GCS bucket\r\n\t- Set compute zone\r\n- Copy over the necessary files to GCS bucket\r\n\t- Data\r\n\t- Pretrained model checkpoints\r\n- Kickstart model training\r\n- Model evaluation\r\n- Monitor model with TensorBoard within Colab Notebook","links":[{"article_link":"","code_link":"https://colab.research.google.com/github/sayakpaul/TF-2.0-Hacks/blob/master/Training_a_pets_detector_model_within_minutes_with_TFOD_API.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1835,"title":"Multi Agent Diverse Generative Adversarial Network","description":"Easy to follow Pytorch tutorial Notebook for Multi-Agent Diverse Generative Adversarial Networks","tags":["code","paper","research","tutorial","video","pytorch","generative-adversarial-networks"],"details":"The proposed MAD-GAN is an intuitive generalization to the Generative Adversarial Networks (GANs) and its conditional variants to address the well known problem of mode\r\ncollapse. First, MAD-GAN is a multi-agent GAN architecture incorporating multiple generators and one discriminator. Second, to enforce that different generators capture diverse high probability modes, the discriminator of MAD-GAN is designed such that along with finding the real and fake samples, it is also required to identify the generator that generated the given fake sample","links":[{"article_link":"","code_link":"https://github.com/shyam671/Multi-Agent-Diverse-Generative-Adversarial-Networks","research_link":"http://openaccess.thecvf.com/content_cvpr_2018/papers/Ghosh_Multi-Agent_Diverse_Generative_CVPR_2018_paper.pdf","media_link":"https://www.youtube.com/watch?v=DP4j2w-x7KI","dataset_link":"","demo_link":"","other_link":""}]},{"id":1834,"title":"Laplacian Pyramid Reconstruction and Refinement for Semantic Seg.","description":" Pytorch implementation of multi-resolution reconstruction architecture based on a Laplacian pyramid that uses skip connections.","tags":["code","paper","research","pytorch","deep-learning","computer-vision","semantic-segmentation","segmentation","arxiv:1605.02264"],"details":"This paper makes two contributions: (1) We demonstrate that while the apparent spatial resolution of convolutional feature maps is low, the high-dimensional feature representation contains significant sub-pixel localization information. (2) We describe a multi-resolution reconstruction architecture based on a Laplacian pyramid that uses skip connections from higher resolution feature\r\nmaps and multiplicative gating to successively refine segment boundaries reconstructed from lower-resolution maps. This approach yields state-of-the-art semantic segmentation results on the PASCAL VOC and Cityscapes segmentation benchmarks without resorting to more complex random-field inference or instance detection driven architectures.","links":[{"article_link":"","code_link":"https://github.com/shyam671/Laplacian-Pyramid-Reconstruction-and-Refinement-for-Semantic-Segmentation","research_link":"https://arxiv.org/abs/1605.02264","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1833,"title":"jax-unirep","description":"A reimplementation of the UniRep model in JAX.","tags":["code","paper","research","jax","lstm","recurrent-neural-networks","protein-engineering"],"details":"Here, we accelerated the UniRep model by reimplementing it in JAX, and provide a clean API on top of the core model for production use in protein engineering applications.","links":[{"article_link":"","code_link":"https://github.com/ElArkk/jax-unirep","research_link":"https://www.biorxiv.org/content/10.1101/2020.05.11.088344v1","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1832,"title":"Market Basket Analysis using Data Science with R Programming","description":"Domain: Inventory Management\r\n\r\nProblem Statement: As a new manager in the company, you are assigned the task of increasing cross selling","tags":["article","research","tutorial","video","r","library","data-science"],"details":"Data Science is one of the top trending technology of the era and data science has stretched its roots deep down in the corporate industry. Due to this vast inference, new age learners and working professionals are keen to learn this technology. To curb this, various [online data science courses](https://intellipaat.com/data-scientist-course-training/) are available through which one can master data science and begin career as a data scientist.\r\nData science is a broad career path and is undergoing developments and thus promises abundant opportunities in the future. Data Science job roles are likely to get more specific, which will lead to specializations in the field. People inclined towards this\r\nstream can exploit their opportunities and pursue what suits them best through there specializations and specifications.","links":[{"article_link":"https://intellipaat.com/blog/tutorial/data-science-tutorial/","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=9l0DAYyJJhI","dataset_link":"","demo_link":"","other_link":"https://intellipaat.com/blog/tutorial/r-programming/"}]},{"id":1831,"title":"TF Sprinkles","description":"Fast and efficient sprinkles augmentation implemented in TensorFlow.","tags":["article","code","tensorflow","library","computer-vision","data-augmentation"],"details":"If you take a random grid/series of small squares, and randomly sprinkle those on the image, and slowly increase their probability and sizes, then you can force the CNN to look more completely at the entire image for classification clues, while at the same time, in most cases, avoid blocking out enough data that would block it from truly learning.","links":[{"article_link":"https://medium.com/@lessw/progressive-sprinkles-a-new-data-augmentation-for-cnns-and-helps-achieve-new-98-nih-malaria-6056965f671a","code_link":"https://github.com/Engineero/tf_sprinkles","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://forums.fast.ai/t/progressive-sprinkles-cutout-variation-my-new-data-augmentation-98-on-nih-malaria-dataset/50454"}]},{"id":1830,"title":"GPflow","description":"Gaussian processes in TensorFlow.","tags":["code","tensorflow","library","gaussian-processes"],"details":"GPflow is a package for building Gaussian process models in Python, using TensorFlow. GPflow implements modern Gaussian process inference for composable kernels and likelihoods. The online documentation (develop)/(master) contains more details.","links":[{"article_link":"","code_link":"https://github.com/GPflow/GPflow","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://gpflow.org/"}]},{"id":1829,"title":"Gaussian Process Regression on Molecules in GPflow","description":"Predict the experimentally-determined electronic transition wavelengths of molecular photoswitches.","tags":["article","code","notebook","tutorial","regression","library","chemistry","gaussian-processes","molecules","gpflow"],"details":"This post demonstrates how to train a Gaussian Process (GP) to predict molecular properties using the GPflow library by creating a custom-defined Tanimoto kernel to operate on Morgan fingerprints.","links":[{"article_link":"https://medium.com/@ryangriff123/gaussian-process-regression-on-molecules-in-gpflow-ee6fedab2130","code_link":"https://github.com/Ryan-Rhys/The-Photoswitch-Dataset/blob/master/examples/gp_regression_on_molecules.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1828,"title":"Dash","description":"Analytical Web Apps for Python, R, Julia, and Jupyter. No JavaScript Required.\r\n\r\n","tags":["code","library","visualization","plotly","demo","dash","dashboard"],"details":"Built on top of Plotly.js, React and Flask, Dash ties modern UI elements like dropdowns, sliders, and graphs directly to your analytical Python code. Read our tutorial proudly crafted \u2764\ufe0f by Dash itself.\r\n\r\n- [User Guide](https://dash.plotly.com/getting-started)\r\n- [Offline (PDF) Documentation](https://github.com/plotly/dash-docs/blob/master/pdf-docs/Dash_User_Guide_and_Documentation.pdf)\r\n- [Dash Docs on Heroku](https://dash-docs.herokuapp.com/) \r\n\r\n![](https://user-images.githubusercontent.com/1280389/30086123-97c58bde-9267-11e7-98a0-7f626de5199a.gif)\r\n\r\n","links":[{"article_link":"","code_link":"https://github.com/plotly/dash","research_link":"","media_link":"https://github.com/plotly/dash-sample-apps/tree/master/apps/dash-cuml-umap","dataset_link":"","demo_link":"https://dash-gallery.plotly.host/Portal/","other_link":"https://plotly.com/dash/"}]},{"id":1827,"title":"token2index","description":"A lightweight but powerful library to build token indices for NLP tasks, compatible with major Deep Learning frameworks like PyTorch and Tensorflow.","tags":["code","sequence-to-sequence","library","natural-language-processing","preprocessing","tokenization"],"details":"token2index is a small yet powerful library facilitating the fast and easy creation of a data structure mapping tokens to indices, primarily aimed at applications for Natural Language Processing. The library is fully tested, and does not require any additional requirements. The documentation can be found here, some feature highlights are shown below.\r\n\r\n","links":[{"article_link":"","code_link":"https://github.com/Kaleidophon/token2index","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"http://token2index.readthedocs.io/"}]},{"id":1826,"title":"Continuous Integration on TPUs with PyTorch Lightning","description":"In preparation for our upcoming V1, we have taken a major step in our support for training on TPUs.","tags":["article","tpu","pytorch-lightning","ci-cd"],"details":"As the first ML framework to implement PyTorch\u2019s xla-TPU support (PyTorch Lightnight\u2019s TPU support is built on top of pytorch/xla\u2019s support of PyTorch native API), we continue to lead the charge in getting PyTorch users closer to running full workloads on TPUs. We\u2019re proud to show you how we became the first ML framework to run CI on TPUs!","links":[{"article_link":"https://medium.com/pytorch/how-pytorch-lightning-became-the-first-ml-framework-to-runs-continuous-integration-on-tpus-a47a882b2c95","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1825,"title":"MLflow: A Machine Learning Lifecycle Platform","description":"Open source platform for the machine learning lifecycle.","tags":["code","model-management","library","mlflow","experiment-tracking","apache-spark","data-versioning"],"details":"MLflow is a platform to streamline machine learning development, including tracking experiments, packaging code\r\ninto reproducible runs, and sharing and deploying models. MLflow offers a set of lightweight APIs that can be\r\nused with any existing machine learning application or library (TensorFlow, PyTorch, XGBoost, etc), wherever you\r\ncurrently run ML code (e.g. in notebooks, standalone applications or the cloud). MLflow's current components are:\r\n\r\n* `MLflow Tracking <https://mlflow.org/docs/latest/tracking.html>`_: An API to log parameters, code, and\r\n  results in machine learning experiments and compare them using an interactive UI.\r\n* `MLflow Projects <https://mlflow.org/docs/latest/projects.html>`_: A code packaging format for reproducible\r\n  runs using Conda and Docker, so you can share your ML code with others.\r\n* `MLflow Models <https://mlflow.org/docs/latest/models.html>`_: A model packaging format and tools that let\r\n  you easily deploy the same model (from any ML library) to batch and real-time scoring on platforms such as\r\n  Docker, Apache Spark, Azure ML and AWS SageMaker.\r\n* `MLflow Model Registry <https://mlflow.org/docs/latest/model-registry.html>`_: A centralized model store, set of APIs, and UI, to collaboratively manage the full lifecycle of MLflow Models.","links":[{"article_link":"","code_link":"https://github.com/mlflow/mlflow","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://mlflow.org/"}]},{"id":1824,"title":"PyMC3","description":"Probabilistic Programming in Python: Bayesian Modeling and Probabilistic Machine Learning.","tags":["code","theano","library","demo","probabilistic=programming","bayesian-modeling"],"details":"PyMC3 is a Python package for Bayesian statistical modeling and Probabilistic Machine Learning focusing on advanced Markov chain Monte Carlo (MCMC) and variational inference (VI) algorithms. Its flexibility and extensibility make it applicable to a large suite of problems.\r\n\r\n","links":[{"article_link":"","code_link":"https://github.com/pymc-devs/pymc3","research_link":"","media_link":"","dataset_link":"","demo_link":"https://mybinder.org/v2/gh/pymc-devs/pymc3/master?filepath=%2Fdocs%2Fsource%2Fnotebooks","other_link":"https://docs.pymc.io/"}]},{"id":1823,"title":"ivis","description":"Dimensionality reduction in very large datasets using Siamese Networks\r\n\r\n","tags":["code","paper","research","tensorflow","siamese-networks","library","dimensionality-reduction"],"details":"Implementation of the ivis algorithm as described in the paper Structure-preserving visualisation of high dimensional single-cell datasets. Ivis is designed to reduce dimensionality of very large datasets using a siamese neural network trained on triplets. Both unsupervised and supervised modes are supported.\r\n\r\n","links":[{"article_link":"","code_link":"https://github.com/beringresearch/ivis","research_link":"https://www.nature.com/articles/s41598-019-45301-0","media_link":"","dataset_link":"","demo_link":"","other_link":"http://bering-ivis.readthedocs.io/"}]},{"id":1822,"title":"Label Studio","description":"Label Studio is a multi-type data labeling and annotation tool with standardized output format.","tags":["article","code","library","annotation","computer-vision","natural-language-processing","demo"],"details":"Label Studio is a swiss army knife of data labeling and annotation tools \u270c\ufe0f\r\n\r\nIts purpose is to help you label different types of data using a simple interface with a standardized output format. You're dealing with the custom dataset and thinking about creating your tool? Don't - using Label Studio, you can save time and create a custom tool and interface in minutes.\r\n\r\n","links":[{"article_link":"https://towardsdatascience.com/introducing-label-studio-a-swiss-army-knife-of-data-labeling-140c1be92881","code_link":"https://github.com/heartexlabs/label-studio","research_link":"","media_link":"","dataset_link":"","demo_link":"https://app.labelstud.io/welcome","other_link":"https://labelstud.io/"}]},{"id":1821,"title":"Vaex","description":"Out-of-Core DataFrames for Python, ML, visualize and explore big tabular data at a billion rows per second \ud83d\ude80","tags":["article","code","library","pandas","dataframes","out-of-core"],"details":"Vaex is a high performance Python library for lazy Out-of-Core DataFrames (similar to Pandas), to visualize and explore big tabular datasets. It calculates statistics such as mean, sum, count, standard deviation etc, on an N-dimensional grid for more than a billion (10^9) samples/rows per second. Visualization is done using histograms, density plots and 3d volume rendering, allowing interactive exploration of big data. Vaex uses memory mapping, zero memory copy policy and lazy computations for best performance (no memory wasted).\r\n\r\n","links":[{"article_link":"https://towardsdatascience.com/beyond-pandas-spark-dask-vaex-and-other-big-data-technologies-battling-head-to-head-a453a1f8cc13","code_link":"https://github.com/vaexio/vaex","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1820,"title":"Rasa","description":"An open source machine learning framework to automate text-and voice-based conversations. ","tags":["code","library","natural-language-processing","conversational-ai"],"details":"\ud83d\udcac Open source machine learning framework to automate text- and voice-based conversations: NLU, dialogue management, connect to Slack, Facebook, and more - Create chatbots and voice assistants.","links":[{"article_link":"","code_link":"https://github.com/RasaHQ/rasa","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1819,"title":"Neptune.ai","description":"The most lightweight experiment management tool that fits any workflow.","tags":["code","model-management","library","experiment-tracking"],"details":"**Track experiments**\r\nLog metrics, hyperparameters, data versions, hardware usage and more. Work on any infra, any language, scripts or notebooks. \r\n\r\n**Record data exploration**\r\nExperiments don\u2019t have to stop with running training scripts. Version your exploratory data analysis and share with your team.\r\n\r\n**Organize teamwork**\r\nManage your team with organizations, projects, and user roles. Organize experiments with tags and custom views. ","links":[{"article_link":"","code_link":"https://github.com/neptune-ai","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1818,"title":"DeepkitAI","description":"The Open-Source Machine Learning Devtool and Training Suite.","tags":["code","model-management","library","experiment-tracking"],"details":"The collaborative real-time open-source machine learning devtool and training suite: Experiment execution, tracking, and debugging. With server and project management tools.\r\n\r\n","links":[{"article_link":"","code_link":"https://github.com/deepkit/deepkit","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://deepkit.ai/"}]},{"id":1817,"title":"Artifacts - Weights & Biases","description":"Effortless pipeline tracking and production model management\r\n\r\n","tags":["article","code","notebook","library","production","wandb","data-versioning"],"details":"**Lightweight pipeline**\r\nWe take care of your end-to-end machine learning pipeline - data preparation, data versioning, training, and evaluation - with a simple dashboard.\r\n\r\n**Dataset versioning**\r\nUnderstand the changes associated with datasets using sophisticated checksums and diffs tracking.\r\n\r\n**Reproducible**\r\nSecurely record every version of your dataset - dependency, configuration, production - with just a line of code.","links":[{"article_link":"https://docs.wandb.com/artifacts","code_link":"https://colab.research.google.com/drive/1srUJTvI35olZRrQaW1zGd5_Q7t5vcAiU","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.wandb.com/artifacts"}]},{"id":1816,"title":"FastAPI","description":"FastAPI framework, high performance, easy to learn, fast to code, ready for production.","tags":["api","code","fastapi","library"],"details":"FastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.6+ based on standard Python type hints.\r\n\r\nThe key features are:\r\n\r\n* **Fast**: Very high performance, on par with **NodeJS** and **Go** (thanks to Starlette and Pydantic). [One of the fastest Python frameworks available](#performance).\r\n\r\n* **Fast to code**: Increase the speed to develop features by about 200% to 300%. *\r\n* **Fewer bugs**: Reduce about 40% of human (developer) induced errors. *\r\n* **Intuitive**: Great editor support. <abbr title=\"also known as auto-complete, autocompletion, IntelliSense\">Completion</abbr> everywhere. Less time debugging.\r\n* **Easy**: Designed to be easy to use and learn. Less time reading docs.\r\n* **Short**: Minimize code duplication. Multiple features from each parameter declaration. Fewer bugs.\r\n* **Robust**: Get production-ready code. With automatic interactive documentation.\r\n* **Standards-based**: Based on (and fully compatible with) the open standards for APIs: <a href=\"https://github.com/OAI/OpenAPI-Specification\" class=\"external-link\" target=\"_blank\">OpenAPI</a> (previously known as Swagger) and <a href=\"http://json-schema.org/\" class=\"external-link\" target=\"_blank\">JSON Schema</a>.","links":[{"article_link":"","code_link":"https://github.com/tiangolo/fastapi","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://fastapi.tiangolo.com/"}]},{"id":1815,"title":"Flask","description":"The Python micro framework for building web applications.","tags":["api","code","flask","library"],"details":"Flask is a lightweight [WSGI](https://wsgi.readthedocs.io/en/latest/) web application framework. It is designed to make getting started quick and easy, with the ability to scale up to complex applications. It began as a simple wrapper around Werkzeug and Jinja and has become one of the most popular Python web application frameworks.\r\n\r\nFlask offers suggestions, but doesn't enforce any dependencies or project layout. It is up to the developer to choose the tools and libraries they want to use. There are many extensions provided by the community that make adding new functionality easy.\r\n\r\nUseful Flask extensions: [https://github.com/humiaozuzu/awesome-flask](https://github.com/humiaozuzu/awesome-flask)","links":[{"article_link":"","code_link":"https://github.com/pallets/flask","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://palletsprojects.com/p/flask/"}]},{"id":1814,"title":"Best Practices for Designing a Pragmatic RESTful API","description":"What formats should you accept? How should you authenticate? Should your API be versioned?","tags":["api","article","tutorial","naming-conventions","endpoints","endpoint-design"],"details":"Your data model has started to stabilize and you're in a position to create a public API for your web app. You realize it's hard to make significant changes to your API once it's released and want to get as much right as possible up front. Now, the internet has no shortage on opinions on API design. But, since there's no one widely adopted standard that works in all cases, you're left with a bunch of choices: What formats should you accept? How should you authenticate? Should your API be versioned?","links":[{"article_link":"https://www.vinaysahni.com/best-practices-for-a-pragmatic-restful-api","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1813,"title":"Pytest","description":"The pytest framework makes it easy to write small tests, yet scales to support complex functional testing\r\n\r\n","tags":["article","code","e2e-tests","library","unit-tests","testing"],"details":"The pytest framework makes it easy to write small tests, yet scales to support complex functional testing for applications and libraries.\r\n\r\n","links":[{"article_link":"https://realpython.com/pytest-python-testing/","code_link":"https://github.com/pytest-dev/pytest","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://docs.pytest.org/en/stable/"}]},{"id":1812,"title":"PyTorch Lightning","description":"The lightweight PyTorch wrapper for ML researchers. Scale your models. Write less boilerplate.","tags":["code","video","pytorch","library","pytorch-lightning","template"],"details":"The lightweight PyTorch wrapper for ML researchers. Scale your models. Write less boilerplate\r\n\r\n","links":[{"article_link":"","code_link":"https://github.com/PyTorchLightning/pytorch-lightning","research_link":"","media_link":"https://www.youtube.com/watch?v=QHww1JH7IDU","dataset_link":"","demo_link":"","other_link":"https://pytorch-lightning.readthedocs.io/en/latest/"}]},{"id":1811,"title":"Foolbox Native","description":"A Python toolbox to create adversarial examples that fool neural networks in PyTorch, TensorFlow, and JAX\r\n\r\n","tags":["code","jax","pytorch","tensorflow","library","adversarial-learning","adversarial-attacks"],"details":"Foolbox is a Python library that let's you easily run adversarial attacks against machine learning models like deep neural networks. It is built on top of EagerPy and works natively with models in PyTorch, TensorFlow, JAX, and NumPy.","links":[{"article_link":"","code_link":"https://github.com/bethgelab/foolbox","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://foolbox.jonasrauber.de/"}]},{"id":1810,"title":"Flask-SQLAlchemy","description":"Adds SQLAlchemy support to Flask\r\n\r\n","tags":["code","databases","flask","sql","library","sqlalchemy"],"details":"Flask-SQLAlchemy is an extension for Flask that adds support for SQLAlchemy to your application. It aims to simplify using SQLAlchemy with Flask by providing useful defaults and extra helpers that make it easier to accomplish common tasks.\r\n\r\n","links":[{"article_link":"","code_link":"https://github.com/pallets/flask-sqlalchemy","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1809,"title":"Pandarallel","description":"A simple and efficient tool to parallelize Pandas operations on all available CPUs\r\n\r\n","tags":["code","library","pandas"],"details":"![](https://raw.githubusercontent.com/nalepae/pandarallel/master/docs/progress_apply.gif)\r\n\r\n![](https://raw.githubusercontent.com/nalepae/pandarallel/master/docs/progress_parallel_apply.gif)\r\n\r\nParallelization has a cost (instanciating new processes, sending data via shared memory, ...), so parallelization is efficient only if the amount of calculation to parallelize is high enough. For very little amount of data, using parallelization is not always worth it.","links":[{"article_link":"","code_link":"https://github.com/nalepae/pandarallel","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1808,"title":"whatlies","description":"Toolkit to help visualize - what lies in word embeddings.","tags":["code","video","library","embeddings","visualization","interactive"],"details":"This small library offers tools to make visualization easier of both word embeddings as well as operations on them. This should be considered an experimental project that is in preview mode.","links":[{"article_link":"","code_link":"https://github.com/RasaHQ/whatlies","research_link":"","media_link":"https://www.youtube.com/watch?v=FwkwC7IJWO0","dataset_link":"","demo_link":"","other_link":"https://rasahq.github.io/whatlies/"}]},{"id":1807,"title":"scikit-lego","description":"Extra blocks for sklearn pipelines.\r\n\r\n","tags":["code","scikit-learn","library"],"details":"We love scikit learn but very often we find ourselves writing custom transformers, metrics and models. The goal of this project is to attempt to consolidate these into a package that offers code quality/testing. This project started as a collaboration between multiple companies in the Netherlands but has since received contributions from around the globe. It was initiated by Matthijs Brouns and Vincent D. Warmerdam as a tool to teach people how to contribute to open source.","links":[{"article_link":"","code_link":"https://github.com/koaning/scikit-lego","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://scikit-lego.readthedocs.io/en/latest/index.html"}]},{"id":1806,"title":"Surprise","description":"Surprise is a Python scikit building and analyzing recommender systems that deal with explicit rating data.","tags":["code","library","recommendation-systems"],"details":"Surprise was designed with the following purposes in mind:\r\n\r\n* Give users perfect control over their experiments. To this end, a strong emphasis is laid on documentation, which we have tried to make as clear and precise as possible by pointing out every detail of the algorithms.\r\n* Alleviate the pain of Dataset handling. Users can use both built-in datasets (Movielens, Jester), and their own custom datasets.\r\n* Provide various ready-to-use prediction algorithms such as baseline algorithms, neighborhood methods, matrix factorization-based ( SVD, PMF, SVD++, NMF), and many others. Also, various similarity measures (cosine, MSD, pearson...) are built-in.\r\n* Make it easy to implement new algorithm ideas.\r\n* Provide tools to evaluate, analyse and compare the algorithms performance. Cross-validation procedures can be run very easily using powerful CV iterators (inspired by scikit-learn excellent tools), as well as exhaustive search over a set of parameters.","links":[{"article_link":"","code_link":"https://github.com/NicolasHug/Surprise","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1805,"title":"Segmentation Models","description":"Segmentation models with pretrained backbones. Keras and TensorFlow Keras.\r\n\r\n","tags":["code","keras","tensorflow","library","computer-vision","segmentation","unet","models","model-store"],"details":"The main features of this library are:\r\n\r\n* High level API (just two lines of code to create model for segmentation)\r\n* 4 models architectures for binary and multi-class image segmentation (including legendary Unet)\r\n* 25 available backbones for each architecture\r\n* All backbones have pre-trained weights for faster and better convergence\r\n* Helpful segmentation losses (Jaccard, Dice, Focal) and metrics (IoU, F-score)","links":[{"article_link":"","code_link":"https://github.com/qubvel/segmentation_models","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1804,"title":"Text Preprocessing in Python using spaCy library","description":"In this article, we have explored Text Preprocessing in Python using spaCy library in detail. This is the fundamental step to prepare data for applications.","tags":["article","tutorial","spacy","lemmatization","named-entity-recognition","natural-language-processing","part-of-speech-tagging","preprocessing","tokenization"],"details":"In this article, we have explored Text Preprocessing in Python using spaCy library in detail. This is the fundamental step to prepare data for specific applications.\r\n\r\n* Tokenization\r\n* Lemmatization\r\n* Removing Punctuations and Stopwords\r\n* Part of Speech Tagging\r\n* Entity Recognition","links":[{"article_link":"https://iq.opengenus.org/text-preprocessing-in-spacy/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1803,"title":"A Deep Dive into the Wonderful World of Preprocessing in NLP","description":"A glimpse into the surprisingly deep and interesting world of preprocessing in NLP.","tags":["article","tutorial","natural-language-processing","preprocessing","tokenization"],"details":"In this post, I'd like to give the reader a glimpse into the surprisingly deep and interesting world of preprocessing in NLP. I'll be going over important techniques including as byte-pair encoding (BPE), wordpiece tokenization, and sentencepiece tokenization, as well as things to be careful of and important decision points based on my (limited) experience working with text in the past few years. Hopefully, this will motivate the reader to take preprocessing more seriously and make preprocessing a little bit cooler.","links":[{"article_link":"https://mlexplained.com/2019/11/06/a-deep-dive-into-the-wonderful-world-of-preprocessing-in-nlp/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1802,"title":"SentencePiece","description":"Unsupervised text tokenizer for Neural Network-based text generation.\r\n\r\n","tags":["code","paper","research","library","machine-translation","natural-language-processing","tokenization","word-segmentation"],"details":"SentencePiece is an unsupervised text tokenizer and detokenizer mainly for Neural Network-based text generation systems where the vocabulary size is predetermined prior to the neural model training. SentencePiece implements subword units (e.g., byte-pair-encoding (BPE) [[Sennrich et al.](http://www.aclweb.org/anthology/P16-1162)]) and unigram language model [Kudo.]) with the extension of direct training from raw sentences. SentencePiece allows us to make a purely end-to-end system that does not depend on language-specific pre/postprocessing.\r\n\r\n","links":[{"article_link":"","code_link":"https://github.com/google/sentencepiece","research_link":"http://www.aclweb.org/anthology/P16-1162","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1801,"title":"Faiss","description":"A library for efficient similarity search and clustering of dense vectors.\r\n","tags":["code","library","clustering","embeddings","similarity-search"],"details":"Faiss is a library for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM. It also contains supporting code for evaluation and parameter tuning. Faiss is written in C++ with complete wrappers for Python/numpy. Some of the most useful algorithms are implemented on the GPU. It is developed by Facebook AI Research.","links":[{"article_link":"","code_link":"https://github.com/facebookresearch/faiss","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1800,"title":"jellyfish","description":"\ud83c\udf90 a python library for doing approximate and phonetic matching of strings.","tags":["code","library","natural-language-processing","text-matching","text-similarity","jellyfish","levenshtein","sounde","x-hamming","metaphon","e-jaro-winkler","fuzzy-search"],"details":"**String comparison:**\r\n\r\n* Levenshtein Distance\r\n* Damerau-Levenshtein Distance\r\n* Jaro Distance\r\n* Jaro-Winkler Distance\r\n* Match Rating Approach Comparison\r\n* Hamming Distance\r\n\r\n\r\n** Phonetic encoding:**\r\n\r\n* American Soundex\r\n* Metaphone\r\n* NYSIIS (New York State Identification and Intelligence System)\r\n* Match Rating Codex","links":[{"article_link":"","code_link":"https://github.com/jamesturk/jellyfish","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1799,"title":"FlashText","description":"Extract Keywords from sentence or Replace keywords in sentences.\r\n\r\n","tags":["article","code","paper","research","library","natural-language-processing","regex","text-extraction","arxiv:1711.00046"],"details":"FlashText can search or replace keywords in one pass over a document. The time complexity of this algorithm is not dependent on the number of terms being searched or replaced. For a document of size N (characters) and a dictionary of M keywords, the time complexity will be O(N). This algorithm is much faster than Regex, because regex time complexity is O(MxN). It is also different from Aho Corasick Algorithm, as it doesn't match substrings. FlashText is designed to only match complete words (words with boundary characters on both sides). For an input dictionary of {Apple}, this algorithm won't match it to 'I like Pineapple'. This algorithm is also designed to go for the longest match first. For an input dictionary {Machine, Learning, Machine learning} on a string 'I like Machine learning', it will only consider the longest match, which is Machine Learning. We have made python implementation of this algorithm available as open-source on GitHub, released under the permissive MIT License.","links":[{"article_link":"https://www.freecodecamp.org/news/regex-was-taking-5-days-flashtext-does-it-in-15-minutes-55f04411025f/","code_link":"https://github.com/vi3k6i5/flashtext","research_link":"https://arxiv.org/abs/1711.00046","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1798,"title":"Star Clustering","description":"A clustering algorithm that automatically determines the number of clusters and works without hyperparameter fine-tuning.","tags":["code","library","automl","clustering"],"details":"The Star Clustering algorithm is a clustering technique that is loosely inspired and analogous to the process of star system formation. Its purpose is as an alternative clustering algorithm that does not require knowing the number of clusters in advance or any hyperparameter tuning.\r\n\r\n","links":[{"article_link":"","code_link":"https://github.com/josephius/star-clustering","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1797,"title":"Contextualized Topic Models","description":"A python package to run contextualized topic modeling.","tags":["code","paper","research","attention","bert","transformers","library","contextualized-embeddings","embeddings","natural-language-processing","topic-modeling","arxiv:2004.07737"],"details":"Contextualized Topic Models (CTM) are a family of topic models that use pre-trained representations of language (e.g., BERT) to support topic modeling. See the papers for details:\r\n\r\nCross-lingual Contextualized Topic Models with Zero-shot Learning [https://arxiv.org/pdf/2004.07737v1.pdf](https://arxiv.org/pdf/2004.07737v1.pdf)\r\nPre-training is a Hot Topic: Contextualized Document Embeddings Improve Topic Coherence [https://arxiv.org/pdf/2004.03974.pdf](https://arxiv.org/pdf/2004.03974.pdf)","links":[{"article_link":"","code_link":"https://github.com/MilaNLProc/contextualized-topic-models","research_link":"https://arxiv.org/abs/2004.07737","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1796,"title":"Top2Vec","description":"Top2Vec learns jointly embedded topic, document and word vectors.\r\n\r\n","tags":["code","library","document-embeddings","embeddings","natural-language-processing","topic-modeling","word-embeddings"],"details":"Topic2Vector is an algorithm for topic modeling and semantic search. It automatically detects topics present in text and generates jointly embedded topic, document and word vectors. Once you train the Top2Vec model you can:\r\n\r\n* Get number of detected topics.\r\n* Get topics.\r\n* Get topic sizes.\r\n* Search topics by keywords.\r\n* Search documents by topic.\r\n* Search documents by keywords.\r\n* Find similar words.\r\n* Find similar documents.\r\n* Expose model with [RESTful-Top2Vec](https://github.com/ddangelov/RESTful-Top2Vec)","links":[{"article_link":"","code_link":"https://github.com/ddangelov/Top2Vec","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1795,"title":"Chakin ","description":"Simple downloader for pre-trained word vectors.","tags":["code","library","embeddings","natural-language-processing","word-embeddings"],"details":"","links":[{"article_link":"","code_link":"https://github.com/chakki-works/chakin","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1794,"title":"Contrastic Learner","description":"A simple to use pytorch wrapper for contrastive self-supervised learning on any neural network.\r\n\r\n","tags":["code","pytorch","contrastive-loss","library","self-supervised-learning"],"details":"It seems we have lift-off for self-supervised learning on images.\r\n\r\nThis is a simple to use Pytorch wrapper to enable contrastive self-supervised learning on any visual neural network. At the moment, it contains enough settings for one to train on either of the schemes used in SimCLR or CURL.\r\n\r\nYou can wrap any neural network that accepts a visual input, be it a resnet, policy network, or the discriminator of a GAN. The rest is taken care of.","links":[{"article_link":"","code_link":"https://github.com/lucidrains/contrastive-learner","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1793,"title":"Keras-FewShotLearning","description":"Some State-of-the-Art few shot learning algorithms in tensorflow 2.","tags":["code","keras","tensorflow","library","few-shot-learning"],"details":"Thus this repo mainly relies on two of the main high-level python packages for data science: Keras and Pandas. While Pandas may not seem very useful for researchers working with static dataset, it becomes a strong backbone in production applications when you always need to tinker with your data.","links":[{"article_link":"","code_link":"https://github.com/few-shot-learning/Keras-FewShotLearning","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1792,"title":"Anomaly Detection Toolkit (ADTK)","description":"A Python toolkit for rule-based/unsupervised anomaly detection in time series\r\n\r\n","tags":["code","library","anomaly-detection","time-series","unsupervised-learning"],"details":"Anomaly Detection Toolkit (ADTK) is a Python package for unsupervised / rule-based time series anomaly detection.\r\n\r\nAs the nature of anomaly varies over different cases, a model may not work universally for all anomaly detection problems. Choosing and combining detection algorithms (detectors), feature engineering methods (transformers), and ensemble methods (aggregators) properly is the key to build an effective anomaly detection model.\r\n\r\nThis package offers a set of common detectors, transformers and aggregators with unified APIs, as well as pipe classes that connect them together into models. It also provides some functions to process and visualize time series and anomaly events.","links":[{"article_link":"","code_link":"https://github.com/arundo/adtk","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://adtk.readthedocs.io/"}]},{"id":1791,"title":"scikit-fuzzy","description":"scikit-fuzzy is a fuzzy logic toolkit for SciPy.","tags":["code","scikit-learn","library","scipy","fuzzy-logic"],"details":"The goals of scikit-fuzzy are:\r\n\r\n* To provide the community with a robust toolkit of independently developed and implemented fuzzy logic algorithms\r\n* To increase the attractiveness of scientific Python as a valid alternative to closed-source options.","links":[{"article_link":"","code_link":"https://github.com/scikit-fuzzy/scikit-fuzzy","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://pythonhosted.org/scikit-fuzzy/overview.html"}]},{"id":1790,"title":"ThunderSVM: A Fast SVM Library on GPUs and CPUs","description":"Exploits GPUs and multi-core CPUs to achieve high efficiency with SVMs.","tags":["code","support-vector-machines","library","gpu"],"details":"The mission of ThunderSVM is to help users easily and efficiently apply SVMs to solve problems. ThunderSVM exploits GPUs and multi-core CPUs to achieve high efficiency. Key features of ThunderSVM are as follows.\r\n\r\nSupport all functionalities of LibSVM such as one-class SVMs, SVC, SVR and probabilistic SVMs.\r\nUse same command line options as LibSVM.\r\nSupport Python, R, Matlab and Ruby interfaces.\r\nSupported Operating Systems: Linux, Windows and MacOS.","links":[{"article_link":"","code_link":"https://github.com/Xtra-Computing/thundersvm","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1789,"title":"NGBoost","description":"Natural Gradient Boosting for Probabilistic Prediction\r\n\r\n","tags":["article","code","library","gradient-boosting","natural-gradients","uncertainty-estimation"],"details":"ngboost is a Python library that implements Natural Gradient Boosting, as described in \"[NGBoost: Natural Gradient Boosting for Probabilistic Prediction](https://stanfordmlgroup.github.io/projects/ngboost/)\". It is built on top of Scikit-Learn, and is designed to be scalable and modular with respect to choice of proper scoring rule, distribution, and base learner. A didactic introduction to the methodology underlying NGBoost is available in this slide deck.","links":[{"article_link":"https://dkopczyk.quantee.co.uk/ngboost-explained/","code_link":"https://github.com/stanfordmlgroup/ngboost","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://stanfordmlgroup.github.io/projects/ngboost/"}]},{"id":1788,"title":"LightGBM - Light Gradient Boosting Machine","description":"A fast, distributed, high performance gradient boosting (GBT, GBDT, GBRT, GBM or MART) framework based on decision tree algorithms.","tags":["code","decision-trees","library","gradient-boosting","lightgbm"],"details":"LightGBM is a gradient boosting framework that uses tree based learning algorithms. It is designed to be distributed and efficient with the following advantages:\r\n\r\n* Faster training speed and higher efficiency.\r\n* Lower memory usage.\r\n* Better accuracy.\r\n* Support of parallel and GPU learning.\r\n* Capable of handling large-scale data.\r\n\r\n","links":[{"article_link":"","code_link":"https://github.com/Microsoft/LightGBM","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://lightgbm.readthedocs.io/en/latest/"}]},{"id":1787,"title":"CatBoost","description":"A high-performance open source library for gradient boosting on decision trees","tags":["code","decision-trees","library","gradient-boosting","catboost"],"details":"A fast, scalable, high performance Gradient Boosting on Decision Trees library, used for ranking, classification, regression and other machine learning tasks for Python, R, Java, C++. Supports computation on CPU and GPU.","links":[{"article_link":"","code_link":"https://github.com/catboost","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://catboost.ai/"}]},{"id":1786,"title":"gplearn","description":"Genetic Programming in Python, with a scikit-learn inspired API.","tags":["code","scikit-learn","regression","library","genetic-programming","symbolic-regression"],"details":"gplearn implements Genetic Programming in Python, with a scikit-learn inspired and compatible API.\r\n\r\nWhile Genetic Programming (GP) can be used to perform a very wide variety of tasks, gplearn is purposefully constrained to solving symbolic regression problems. This is motivated by the scikit-learn ethos, of having powerful estimators that are straight-forward to implement.\r\n\r\nSymbolic regression is a machine learning technique that aims to identify an underlying mathematical expression that best describes a relationship. It begins by building a population of naive random formulas to represent a relationship between known independent variables and their dependent variable targets in order to predict new data. Each successive generation of programs is then evolved from the one that came before it by selecting the fittest individuals from the population to undergo genetic operations.","links":[{"article_link":"","code_link":"https://github.com/trevorstephens/gplearn","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"http://gplearn.readthedocs.io/"}]},{"id":1785,"title":"modAL","description":"A modular active learning framework for Python.","tags":["code","library","active-learning","semi-supervised-learning"],"details":"modAL is an active learning framework for Python3, designed with modularity, flexibility and extensibility in mind. Built on top of scikit-learn, it allows you to rapidly create active learning workflows with nearly complete freedom. What is more, you can easily replace parts with your custom built solutions, allowing you to design novel algorithms with ease.","links":[{"article_link":"","code_link":"https://github.com/modAL-python/modAL","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://modal-python.github.io/"}]},{"id":1784,"title":"Lazy Predict","description":"Lazy Predict help build a lot of basic models without much code and helps understand which models works better without any parameter tuning.","tags":["code","regression","library","automl","classification","lazypredict"],"details":"","links":[{"article_link":"","code_link":"https://github.com/shankarpandala/lazypredict","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://lazypredict.readthedocs.io/en/latest/"}]},{"id":1783,"title":"auto-sklearn","description":"Automated Machine Learning with scikit-learn.","tags":["code","paper","research","scikit-learn","library","automl"],"details":"auto-sklearn is an automated machine learning toolkit and a drop-in replacement for a scikit-learn estimator.","links":[{"article_link":"","code_link":"https://github.com/automl/auto-sklearn","research_link":"http://papers.nips.cc/paper/5872-efficient-and-robust-automated-machine-learning.pdf","media_link":"","dataset_link":"","demo_link":"","other_link":"https://automl.github.io/auto-sklearn/master/"}]},{"id":1782,"title":"TPOT: Tree-based Pipeline Optimization Tool","description":"TPOT is a Python Automated Machine Learning tool that optimizes machine learning pipelines using genetic programming.","tags":["code","random-forests","library","automl","gradient-boosting","decision-tree","hyperparameter-optimization","genetic-programming","tpot"],"details":"TPOT will automate the most tedious part of machine learning by intelligently exploring thousands of possible pipelines to find the best one for your data. Once TPOT is finished searching (or you get tired of waiting), it provides you with the Python code for the best pipeline it found so you can tinker with the pipeline from there.\r\n\r\nTPOT is built on top of scikit-learn, so all of the code it generates should look familiar... if you're familiar with scikit-learn, anyway.","links":[{"article_link":"","code_link":"https://github.com/EpistasisLab/tpot","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"http://epistasislab.github.io/tpot/"}]},{"id":1781,"title":"TensorFlow Model Garden","description":"Models and examples built with TensorFlow.","tags":["code","tensorflow","library","fine-tuning","pretraining","models","model-hub","model-store"],"details":"The TensorFlow Model Garden is a repository with a number of different implementations of state-of-the-art (SOTA) models and modeling solutions for TensorFlow users. We aim to demonstrate the best practices for modeling so that TensorFlow users can take full advantage of TensorFlow for their research and product development.","links":[{"article_link":"","code_link":"https://github.com/tensorflow/models","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1780,"title":"PyTorch Hub","description":"Discover and publish models to a pre-trained model repository designed for research exploration.","tags":["pytorch","library","fine-tuning","pretraining","models"],"details":"Pytorch Hub is a pre-trained model repository designed to facilitate research reproducibility.\r\n\r\n**Publishing models**\r\nPytorch Hub supports publishing pre-trained models(model definitions and pre-trained weights) to a github repository by adding a simple hubconf.py file;\r\n\r\nhubconf.py can have multiple entrypoints. Each entrypoint is defined as a python function (example: a pre-trained model you want to publish).","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://pytorch.org/hub/"}]},{"id":1779,"title":"All Models and checkpoints - Hugging Face","description":"Massive (and growing) collection of NLP models are nearly any NLP tasks, especially those involving the use of transformers.","tags":["huggingface","transformers","library","fine-tuning","natural-language-processing","pretraining","models"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://huggingface.co/models"}]},{"id":1778,"title":"FIt-SNE","description":"Fast Fourier Transform-accelerated Interpolation-based t-SNE (FIt-SNE).","tags":["code","library","dimensionality-reduction","tsne","fast-fourier-transform"],"details":"t-Stochastic Neighborhood Embedding (t-SNE) is a highly successful method for dimensionality reduction and visualization of high dimensional datasets. A popular implementation of t-SNE uses the Barnes-Hut algorithm to approximate the gradient at each iteration of gradient descent.","links":[{"article_link":"","code_link":"https://github.com/KlugerLab/FIt-SNE","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1777,"title":"tsfresh","description":"Automatic extraction of relevant features from time series.","tags":["code","library","feature-engineering","time-series"],"details":"Data Scientists often spend most of their time either cleaning data or building features. While we cannot change the first thing, the second can be automated. TSFRESH frees your time spent on building features by extracting them automatically. Hence, you have more time to study the newest deep learning paper, read hacker news or build better models.","links":[{"article_link":"","code_link":"https://github.com/blue-yonder/tsfresh","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://tsfresh.readthedocs.io/en/latest/"}]},{"id":1776,"title":"Imbalanced Learn","description":"A Python Package to Tackle the Curse of Imbalanced Datasets in Machine Learning.","tags":["code","library","class-imbalance","imbalanced-datasets"],"details":"Most classification algorithms will only perform optimally when the number of\r\nsamples of each class is roughly the same. Highly skewed datasets, where the\r\nminority is heavily outnumbered by one or more classes, have proven to be a\r\nchallenge while at the same time becoming more and more common.\r\n\r\nOne way of addressing this issue is by re-sampling the dataset as to offset this\r\nimbalance with the hope of arriving at a more robust and fair decision boundary\r\nthan you would otherwise.\r\n\r\nRe-sampling techniques are divided in two categories:\r\n    1. Under-sampling the majority class(es).\r\n    2. Over-sampling the minority class.\r\n    3. Combining over- and under-sampling.\r\n    4. Create ensemble balanced sets.\r\n\r\nBelow is a list of the methods currently implemented in this module.\r\n\r\n* Under-sampling\r\n    1. Random majority under-sampling with replacement\r\n    2. Extraction of majority-minority Tomek links [1]_\r\n    3. Under-sampling with Cluster Centroids\r\n    4. NearMiss-(1 & 2 & 3) [2]_\r\n    5. Condensed Nearest Neighbour [3]_\r\n    6. One-Sided Selection [4]_\r\n    7. Neighboorhood Cleaning Rule [5]_\r\n    8. Edited Nearest Neighbours [6]_\r\n    9. Instance Hardness Threshold [7]_\r\n    10. Repeated Edited Nearest Neighbours [14]_\r\n    11. AllKNN [14]_\r\n\r\n* Over-sampling\r\n    1. Random minority over-sampling with replacement\r\n    2. SMOTE - Synthetic Minority Over-sampling Technique [8]_\r\n    3. SMOTENC - SMOTE for Nominal Continuous [8]_\r\n    4. bSMOTE(1 & 2) - Borderline SMOTE of types 1 and 2 [9]_\r\n    5. SVM SMOTE - Support Vectors SMOTE [10]_\r\n    6. ADASYN - Adaptive synthetic sampling approach for imbalanced learning [15]_\r\n    7. KMeans-SMOTE [17]_\r\n\r\n* Over-sampling followed by under-sampling\r\n    1. SMOTE + Tomek links [12]_\r\n    2. SMOTE + ENN [11]_\r\n\r\n* Ensemble classifier using samplers internally\r\n    1. Easy Ensemble classifier [13]_\r\n    2. Balanced Random Forest [16]_\r\n    3. Balanced Bagging\r\n    4. RUSBoost [18]_\r\n\r\n* Mini-batch resampling for Keras and Tensorflow","links":[{"article_link":"","code_link":"https://github.com/scikit-learn-contrib/imbalanced-learn/","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://imbalanced-learn.readthedocs.io/en/stable/"}]},{"id":1775,"title":"DeltaPy\u2060\u2060 ","description":"Tabular Data Augmentation & Feature Engineering.","tags":["code","notebook","paper","research","library","data-augmentation","tabular-data","tabular","table"],"details":"Tabular augmentation is a new experimental space that makes use of novel and traditional data generation and synthesisation techniques to improve model prediction success. It is in essence a process of modular feature engineering and observation engineering while emphasising the order of augmentation to achieve the best predicted outcome from a given information set. DeltaPy was created with finance applications in mind, but it can be broadly applied to any data-rich environment.\r\n\r\nTo take full advantage of tabular augmentation for time-series you would perform the techniques in the following order: **(1) transforming, (2) interacting, (3) mapping, (4) extracting, and (5) synthesising**. What follows is a practical example of how the above methodology can be used. The purpose here is to establish a framework for table augmentation and to point and guide the user to existing packages.","links":[{"article_link":"","code_link":"https://github.com/firmai/deltapy","research_link":"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3582219","media_link":"","dataset_link":"","demo_link":"","other_link":"https://colab.research.google.com/drive/1-uJqGeKZfJegX0TmovhsO90iasyxZYiT"}]},{"id":1774,"title":"TRGD: Text Recognition Data Generator","description":"A synthetic data generator for text recognition.","tags":["code","library","computer-vision","data-augmentation","natural-language-processing","optical-character-recognition"],"details":"Generating text image samples to train an OCR software. Now supporting non-latin text!","links":[{"article_link":"","code_link":"https://github.com/Belval/TextRecognitionDataGenerator","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://textrecognitiondatagenerator.readthedocs.io/en/latest/index.html"}]},{"id":1773,"title":"Audiomentations","description":"A Python library for audio data augmentation. Inspired by albumentations. ","tags":["code","library","audio","data-augmentation"],"details":"","links":[{"article_link":"","code_link":"https://github.com/iver56/audiomentations","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1772,"title":"Augmentor","description":"Image augmentation library in Python for machine learning.","tags":["code","library","computer-vision","data-augmentation"],"details":"Augmentor is an image augmentation library in Python for machine learning. It aims to be a standalone library that is platform and framework independent, which is more convenient, allows for finer grained control over augmentation, and implements the most real-world relevant augmentation techniques. It employs a stochastic approach using building blocks that allow for operations to be pieced together in a pipeline.","links":[{"article_link":"","code_link":"https://github.com/mdbloice/Augmentor","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://augmentor.readthedocs.io/en/master/"}]},{"id":1771,"title":"Albumentations","description":"Fast image augmentation library and easy to use wrapper around other libraries.","tags":["article","code","notebook","library","computer-vision","data-augmentation","demo"],"details":"### Do more with less data\r\n\r\nAlbumentations is a computer vision tool that boosts the performance of deep convolutional neural networks.\r\n\r\nThe library is widely used in industry, deep learning research, machine learning competitions, and open source projects.\r\n\r\nAlbumentations is a Python library for fast and flexible image augmentations. Albumentations efficiently implements a rich variety of image transform operations that are optimized for performance, and does so while providing a concise, yet powerful image augmentation interface for different computer vision tasks, including object classification, segmentation, and detection.","links":[{"article_link":"https://albumentations.ai/docs/","code_link":"https://github.com/albumentations-team/albumentations","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://albumentations.ai/"}]},{"id":1770,"title":"imgaug","description":"Image augmentation for machine learning experiments.\r\n\r\n","tags":["code","library","computer-vision","cropping","data-augmentation","affine-transformations","segmentation-maps"],"details":"This python library helps you with augmenting images for your machine learning projects. ","links":[{"article_link":"","code_link":"https://github.com/aleju/imgaug/","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://imgaug.readthedocs.io/en/latest/"}]},{"id":1769,"title":"niacin","description":"A Python library for replacing the missing variation in your text data.\r\n\r\n","tags":["code","library","data-augmentation","natural-language-processing","enrichement","negative-sampling"],"details":"Data collected for model training necessarily undersamples the likely variance in the input space. This library is a collection of tools for inserting typical kinds of perturbations to better approximate population variance; and, for creating similar-but-incorrect examples to aid in reducing the total size of the hypothesis space. These are commonly known as ENRICHMENT and NEGATIVE SAMPLING, respectively.","links":[{"article_link":"","code_link":"https://github.com/deniederhut/niacin","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"http://niacin.readthedocs.io/"}]},{"id":1768,"title":"TextAugment","description":"Improving Short Text Classification through Global Augmentation Methods","tags":["code","library","data-augmentation","natural-language-processing"],"details":"TextAugment is a Python 3 library for augmenting text for natural language processing applications. TextAugment stands on the giant shoulders of [NLTK](https://www.nltk.org/), [Gensim](https://radimrehurek.com/gensim/), and [TextBlob](https://textblob.readthedocs.io/) and plays nicely with them.","links":[{"article_link":"","code_link":"https://github.com/dsfsi/textaugment","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1767,"title":"Imagenette","description":"Imagenette is a subset of 10 easily classified classes from Imagenet.","tags":["code","dataset","computer-vision","imagenet","imagenette"],"details":"'Imagenette' is pronounced just like 'Imagenet', except with a corny inauthentic French accent. If you've seen Peter Sellars in The Pink Panther, then think something like that. It's important to ham up the accent as much as possible, otherwise people might not be sure whether you're refering to \"Imagenette\" or \"Imagenet\". ","links":[{"article_link":"","code_link":"https://github.com/fastai/imagenette","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1766,"title":"fast.ai Datasets","description":"Collections of original and reduced datasets for popular data sources.","tags":["library","computer-vision","natural-language-processing","coco","datasets","imagenet"],"details":"We use these datasets in our teaching, because they provide great examples of the kind of data that students are likely to encounter, and the academic literature has many examples of model results using these datasets which students can compare their work to. In addition, we also use datasets from Kaggle Competitions, because the public leaderboards on Kaggle allow students to test their models against the best in the world (the Kaggle datasets are not listed here).","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://course.fast.ai/datasets.html"}]},{"id":1765,"title":"UCI ML Datasets","description":"We currently maintain 507 data sets as a service to the machine learning community.","tags":["library","datasets"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://archive.ics.uci.edu/ml/datasets.php"}]},{"id":1764,"title":"EchoML","description":"\ud83d\udd09 A web app to play, visualize, and annotate your audio files for machine learning.","tags":["code","azure","library","annotation","audio","audio-tagging","audio-visualizer","echoml"],"details":"","links":[{"article_link":"","code_link":"https://github.com/ritazh/EchoML","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1763,"title":"Audio Annotator","description":"Javascript web interface for annotating audio data.","tags":["code","library","annotation","audio","audio-tagging"],"details":"audio-annotator is a web interface that allows users to annotate audio recordings.\r\n\r\nIt has 3 types of audio visualizations (wavesurfer.params.visualization)\r\n\r\n1. invisible (appears as a blank rectangle that users can draw regions on)\r\n1. spectrogram (audio file is represented by a spectrogram that users can draw regions on)\r\n1. waveform (audio file is represented by a waveform that users can draw regions on)","links":[{"article_link":"","code_link":"https://github.com/CrowdCurio/audio-annotator","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1762,"title":"Superintendent","description":"Practical active learning in python.","tags":["code","library","active-learning","annotation","labeling","semi-supervised-learning","widget","ipywidget"],"details":"**`superintendent`** provides an `ipywidget`-based interactive labelling tool for your data. It allows you to flexibly label all kinds of data. It also allows you to combine your data-labelling task with a statistical or machine learning model to enable quick and practical active learning.","links":[{"article_link":"","code_link":"https://github.com/janfreyberg/superintendent","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://superintendent.readthedocs.io/en/latest/"}]},{"id":1761,"title":"Prodigy","description":"Radically efficient machine teaching. An annotation tool powered by active learning.","tags":["code","video","library","active-learning","annotation","semi-supervised-learning"],"details":"Prodigy is a modern annotation tool for creating training and evaluation data for machine learning models. You can also use Prodigy to help you inspect and clean your data, do error analysis and develop rule-based systems to use in combination with your statistical models.\r\n\r\nThe Python library includes a range of pre-built workflows and command-line commands for various tasks, and well-documented components for implementing your own workflow scripts. Your scripts can specify how the data is loaded and saved, change which questions are asked in the annotation interface, and can even define custom HTML and JavaScript to change the behavior of the front-end. The web application is optimized for fast, intuitive and efficient annotation.\r\n\r\nOur scriptable annotation tool for text, images and other data. Check out recipes here: [https://github.com/explosion/prodigy-recipes](https://github.com/explosion/prodigy-recipes)","links":[{"article_link":"","code_link":"https://github.com/explosion/prodigy-recipes","research_link":"","media_link":"https://www.youtube.com/watch?v=59BKHO_xBPA","dataset_link":"","demo_link":"","other_link":"https://prodi.gy/"}]},{"id":1760,"title":"Dataturks","description":"ML data annotations made super easy for teams, provides support for Image Annotation, Text and NER Annotation, Video Annotation.","tags":["library","annotation","computer-vision","named-entity-recognition","natural-language-processing","segmentation","bounding-box"],"details":"Just upload data, add your team and build training/evaluation dataset in hours.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://dataturks.com/"}]},{"id":1759,"title":"Emotion Recognition from Tom and Jerry videos","description":"Developed an application that classifies the emotion depicted by Tom and Jerry in each frame into one of the following : happy, angry, sad or suprised.","tags":["code","video","deep-learning","computer-vision","emotion-recognition","demo"],"details":"Developed an application that recognises the facial expressions from Tom and Jerry videos. The application takes video as input and splits it into multiple frames. For each frame the faces are detected, the facial expressions are classified into 4 categories, namely Happy, Angry, Sad and Surprised. A YOLO algorithm was used for the Object Detection module and a VGG-19 Convolutional Neural Network was used for the Emotion Detection module.\r\n\r\nA similar application can be developed for other type of videos too.","links":[{"article_link":"","code_link":"https://github.com/SurajSubramanian/EmotionDetection","research_link":"","media_link":"","dataset_link":"","demo_link":"https://www.youtube.com/watch?v=qWu9L-J4HCM","other_link":""}]},{"id":1758,"title":"Age, Gender, Race Prediction","description":"Using Fastai Library (Pytorch) and Resnet Architecure I implemnted a CNN Model to identify the stage of the Blindness based on the given image of Retina. You ca","tags":["code","dataset","fastai","flask","keras","pytorch","convolutional-neural-networks","deep-learning","library"],"details":"","links":[{"article_link":"","code_link":"https://github.com/BolluBalaji/Age_Gender_Race-Prediction","research_link":"","media_link":"","dataset_link":"https://www.kaggle.com/c/aptos2019-blindness-detection/data","demo_link":"","other_link":""}]},{"id":1757,"title":"Machine Learning Toolbox","description":"A curated list of 100+ libraries for all parts of the Machine Learning workflow","tags":["article","machine-learning","library","collection"],"details":"* Know existing open source libraries and prevent reinventing the wheel\r\n* Explore tools from data preparation to deployment known via practical experience\r\n* Improve your productivity on ML projects","links":[{"article_link":"https://amitness.com/toolbox/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1756,"title":"Linear Attention Transformer","description":"A fully featured Transformer that mixes (QK\u1d40)V local attention with Q(K\u1d40V) global attention (scales linearly with respect to sequence length).","tags":["code","paper","research","attention","transformers","natural-language-processing","linear","linear-attention","linear-attention-transformer","arxiv:2006.16236"],"details":"Transformers achieve remarkable performance in several tasks but due to their quadratic complexity, with respect to the input's length, they are prohibitively slow for very long sequences. To address this limitation, we express the self-attention as a linear dot-product of kernel feature maps and make use of the associativity property of matrix products to reduce the complexity from \ue23b(N2) to \ue23b(N), where N is the sequence length. We show that this formulation permits an iterative implementation that dramatically accelerates autoregressive transformers and reveals their relationship to recurrent neural networks. Our linear transformers achieve similar performance to vanilla transformers and they are up to 4000x faster on autoregressive prediction of very long sequences.","links":[{"article_link":"","code_link":"https://github.com/lucidrains/linear-attention-transformer","research_link":"https://arxiv.org/abs/2006.16236","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1755,"title":"Easy OCR","description":"Ready-to-use OCR with 40+ languages supported including Chinese, Japanese, Korean and Thai.\r\n\r\n","tags":["code","lstm","library","computer-vision","optical-character-recognition","resnet","demo"],"details":"This project is based on researches/codes from several papers/open-source repositories.\r\n\r\nDetection part is using CRAFT algorithm from this [official repository](https://github.com/clovaai/CRAFT-pytorch) and their [paper](https://arxiv.org/abs/1904.01941).\r\n\r\nRecognition model is CRNN ([paper](https://arxiv.org/abs/1507.05717)). It is composed of 3 main components, feature extraction (we are currently using [Resnet](https://arxiv.org/abs/1512.03385)), sequence labeling ([LSTM](https://www.bioinf.jku.at/publications/older/2604.pdf)) and decoding ([CTC](https://www.cs.toronto.edu/~graves/icml_2006.pdf)). Training pipeline for recognition part is a modified version from this [repository](https://github.com/clovaai/deep-text-recognition-benchmark).\r\n\r\nBeam search code is based on this [repository](https://github.com/githubharald/CTCDecoder) and his [blog](https://towardsdatascience.com/beam-search-decoding-in-ctc-trained-neural-networks-5a889a3d85a7).\r\n\r\nAnd good read about CTC from distill.pub [here](https://distill.pub/2017/ctc/).","links":[{"article_link":"","code_link":"https://github.com/JaidedAI/EasyOCR","research_link":"","media_link":"","dataset_link":"","demo_link":"https://master-easy-ocr-wook-2.endpoint.ainize.ai/","other_link":""}]},{"id":1754,"title":"Full Stack Deep Learning","description":"Full Stack Deep Learning helps you bridge the gap from training machine learning models to deploying AI systems in the real world.","tags":["code","course","tutorial","deep-learning","full-stack","production","mlops"],"details":"### About this course\r\nSince 2012, deep learning has lead to remarkable progress across a variety of challenging computing tasks, from image recognition to speech recognition, robotics, and audio synthesis. Deep learning has the potential to enable a new set of previously infeasible technologies like autonomous vehicles, real-time translation, and voice assistants and help reinvent existing software categories.\r\n\r\nThere are many great courses to learn how to train deep neural networks. However, training the model is just one part of shipping a deep learning project. This course teaches full-stack production deep learning:\r\n\r\n*  Formulating the problem and estimating project cost\r\n*  Finding, cleaning, labeling, and augmenting data\r\n*  Picking the right framework and compute infrastructure\r\n*  Troubleshooting training and ensuring reproducibility\r\n*  Deploying the model at scale","links":[{"article_link":"","code_link":"https://github.com/full-stack-deep-learning/fsdl-text-recognizer-project","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://course.fullstackdeeplearning.com/"}]},{"id":1753,"title":"TUDatasets","description":"A collection of benchmark datasets for graph classification and regression.","tags":["article","code","dataset","paper","research","regression","graph-classification","graph-neural-networks","graphs","graph-regression","tudatasets"],"details":"This page contains collected benchmark datasets for the evaluation of graph kernels and graph neural networks. The datasets were collected by Christopher Morris, Nils M. Kriege, Franka Bause, Kristian Kersting, Petra Mutzel, and Marion Neumann with partial support of the German Science Foundation (DFG) within the Collaborative Research Center SFB 876 \u201cProviding Information by Resource-Constrained Data Analysis\u201d, project A6 \u201cResource-efficient Graph Mining\u201d.","links":[{"article_link":"https://chrsmrrs.github.io/datasets/","code_link":"https://github.com/chrsmrrs/tudataset","research_link":"https://grlplus.github.io/papers/79.pdf","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1752,"title":"PyTorch Pruning | How it's Made by Michela Paganini","description":"In this talk, you will learn about pruning, why it's important and how to get started using PyTorch's Pruning (torch.nn.utils.prune).","tags":["video","pytorch","model-compression","pruning"],"details":"State-of-the-art deep learning techniques rely on over-parametrized models that are hard to deploy. On the contrary, biological neural networks are known to use efficient sparse connectivity. Identifying optimal techniques to compress models by reducing the number of parameters in them is important in order to reduce memory, battery, and hardware consumption without sacrificing accuracy, deploy lightweight models on device, and guarantee privacy with private on-device computation. On the research front, pruning is used to investigate the differences in learning dynamics between over-parametrized and under-parametrized networks, to study the role of lucky sparse subnetworks and initializations (\u201clottery tickets\u201d) as a destructive neural architecture search technique, and more.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=TaOwEa3m5dw","dataset_link":"","demo_link":"","other_link":""}]},{"id":1750,"title":"picTranslate: Seamless live Image Text translator","description":"Given an image with text on it, this app can give you a new image with text modified into a different language.","tags":["article","code","tutorial","aws","autoencoders","convolutional-neural-networks","translation","computer-vision","optical-character-recognition"],"details":"picTranslate is an AI based web app to translate the text on your image from one language to other while keeping the background of the image preserved. This way you can create images and presentation slides in multiple languages.\r\n\r\n**Input/Output**\r\nThe only input is the source image that you want the translation of. The app will generate the required image.\r\n![](https://miro.medium.com/max/810/1*he6uqhezWBaeIfpeVGAHxQ.pnghttp://)\r\n\r\n**Use Cases**\r\nImagine you're a professor who has just given a presentation in English and now want to present to Italian audience. You might want your presentation slides in Italian for better communication. Here, picTranslate can be used to transform those slides instantly!!\r\n\r\n\r\n\r\n\r\n","links":[{"article_link":"https://medium.com/@vaibhavtiwarifu/pictranslate-seamless-live-image-text-translator-882bf2cedc29","code_link":"https://github.com/Vaibhav-nn/picTranslate","research_link":"","media_link":"https://miro.medium.com/max/428/1*wIcx4CWVlIbNskvFR2vthg.gif","dataset_link":"","demo_link":"","other_link":""}]},{"id":1749,"title":"tune-sklearn","description":"A scikit-learn API on RayTune.","tags":["article","code","scikit-learn","library","hyperparameter-tuning","hyperparameter-optimization"],"details":"Tune-sklearn is a package that integrates Ray Tune's hyperparameter tuning and scikit-learn's models, allowing users to optimize hyerparameter searching for sklearn using Tune's schedulers (more details in the [Tune Documentation](http://tune.io/)). Tune-sklearn follows the same API as scikit-learn's GridSearchCV, but allows for more flexibility in defining hyperparameter search regions, such as distributions to sample from.","links":[{"article_link":"https://docs.ray.io/en/latest/tune.html","code_link":"https://github.com/ray-project/tune-sklearn","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://docs.ray.io/en/latest/tune.html"}]},{"id":1748,"title":"Continuous Machine Learning (CML)","description":"CML helps to organize MLOps infrastructure on top of the traditional software engineering stack instead of creating separate AI platforms.","tags":["article","code","library","production","dvc","mlops","github-actions","cml","ci-cd"],"details":"What is CML? Continuous Machine Learning (CML) is an open-source library for implementing continuous integration & delivery (CI/CD) in machine learning projects. Use it to automate parts of your development workflow, including model training and evaluation, comparing ML experiments across your project history, and monitoring changing datasets.\r\n\r\nWe built CML with these principles in mind:\r\n\r\n- **[GitFlow](https://nvie.com/posts/a-successful-git-branching-model/) for data\r\n  science.** Use GitLab or GitHub to manage ML experiments, track who trained ML\r\n  models or modified data and when. Codify data and models with\r\n  [DVC](#using-cml-with-dvc) instead of pushing to a Git repo.\r\n- **Auto reports for ML experiments.** Auto-generate reports with metrics and\r\n  plots in each Git Pull Request. Rigorous engineering practices help your team\r\n  make informed, data-driven decisions.\r\n- **No additional services.** Build your own ML platform using just GitHub or\r\n  GitLab and your favorite cloud services: AWS, Azure, GCP. No databases,\r\n  services or complex setup needed.\r\n\r\n![](https://github.com/iterative/cml/raw/master/imgs/github_cloud_case_lessshadow.png)","links":[{"article_link":"https://dvc.org/blog/cml-release","code_link":"https://github.com/iterative/cml","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://cml.dev/"}]},{"id":1747,"title":"Infinite-Width Neural Networks for Any Architecture","description":"What does an infinitely wide transformer look like?","tags":["code","notebook","paper","research","wide-networks","infinite-width","ntk4a","neural-tangent-kernel","arxiv:2006.14548"],"details":"We will calculate its [Neural Tangent Kernel](https://arxiv.org/abs/1806.07572) in this notebook, according to [our paper](https://arxiv.org/abs/2006.14548), so you can find out yourself! \r\n\r\nBackground on NTKs: [http://www.offconvex.org/2019/10/03/NTK/](http://www.offconvex.org/2019/10/03/NTK/)","links":[{"article_link":"","code_link":"https://github.com/thegregyang/NTK4A","research_link":"https://arxiv.org/abs/2006.14548","media_link":"","dataset_link":"","demo_link":"","other_link":"https://colab.research.google.com/github/thegregyang/NTK4A/blob/master/colab/Transformer-NTK.ipynb"}]},{"id":1746,"title":"Torch-Struct: Structured Prediction Library","description":"A library of tested, GPU implementations of core structured prediction algorithms for deep learning applications.","tags":["code","notebook","paper","research","video","pytorch","conditional-random-fields","hidden-markov-models","library","acl-2020","torch-struct","arxiv:2002.00876"],"details":"* HMM / LinearChain-CRF\r\n* HSMM / SemiMarkov-CRF\r\n* Dependency Tree-CRF\r\n* PCFG Binary Tree-CRF\r\n...\r\n\r\nDesigned to be used as efficient batched layers in other PyTorch code.","links":[{"article_link":"","code_link":"https://github.com/harvardnlp/pytorch-struct/","research_link":"https://arxiv.org/abs/2002.00876","media_link":"https://www.youtube.com/watch?v=687J5cgepn0","dataset_link":"","demo_link":"","other_link":"https://colab.research.google.com/drive/1qcGwT9gcr5LsarK7YdXsb1D_Awgrrc5W"}]},{"id":1745,"title":"Methods - Papers With Code","description":"Stay up-to-date with research papers on machine learning components.","tags":["machine-learning","methods","platform"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://paperswithcode.com/methods"}]},{"id":1744,"title":"AutoKeras","description":"AutoML library for deep learning.","tags":["code","keras","library","automl","autokeras"],"details":"An AutoML system based on Keras. It is developed by DATA Lab at Texas A&M University. The goal of AutoKeras is to make machine learning accessible for everyone.","links":[{"article_link":"","code_link":"https://github.com/keras-team/autokeras/","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"autokeras.com/"}]},{"id":1743,"title":"How to Benchmark Models with Transformers","description":"HuggingFace's Transformer library allows users to benchmark models for both TensorFlow 2 and PyTorch using the PyTorchBenchmark and TensorFlowBenchmark classes.","tags":["code","notebook","tutorial","huggingface","pytorch","tensorflow","transformers","natural-language-processing","benchmarking"],"details":"With ever-larger language models, it is no longer enough to just compare models on their performance on a specific task. One should always be aware of the computational cost that is attached to a specific model. For a given computation environment (e.g. type of GPU), the computational cost of training a model or deploying it in inference usually depends only on the required memory and the required time.","links":[{"article_link":"","code_link":"https://colab.research.google.com/github/huggingface/transformers/blob/master/notebooks/05-benchmark.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1742,"title":"PyTorch Implementation of Differentiable SDE Solvers","description":"Differentiable SDE solvers with GPU support and efficient sensitivity analysis.","tags":["code","pytorch","library","stochastic-differential-equation","sde"],"details":"This codebase provides [stochastic differential equation (SDE)](https://en.wikipedia.org/wiki/Stochastic_differential_equation) solvers with GPU support and efficient sensitivity analysis. Similar to [torchdiffeq](https://github.com/rtqichen/torchdiffeq), algorithms in this repository are fully supported to run on GPUs.","links":[{"article_link":"","code_link":"https://github.com/google-research/torchsde","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1741,"title":"carefree-learn","description":"A minimal Automatic Machine Learning (AutoML) solution for tabular datasets based on PyTorch.","tags":["code","video","pytorch","library","automl","tabular-data","tabular"],"details":"`carefree-learn` is a minimal Automatic Machine Learning (AutoML) solution for tabular datasets based on [PyTorch](https://pytorch.org/).\r\n\r\n#### Why carefree-learn?\r\n\r\n`carefree-learn`\r\n\r\n+ Provides a [scikit-learn](https://scikit-learn.org/stable/)-like interface with much more 'carefree' usages, including:\r\n    + Automatically deals with data pre-processing.\r\n    + Automatically handles datasets saved in files (.txt, .csv).\r\n    + Supports Distributed Training, which means hyper-parameter tuning can be very efficient in `carefree-learn`.\r\n+ Includes some brand new techniques which may boost vanilla Neural Network (NN) performances on tabular datasets, including:\r\n    + [`TreeDNN` with `Dynamic Soft Pruning`](https://arxiv.org/pdf/1911.05443.pdf), which makes NN less sensitive to hyper-parameters. \r\n    + [`Deep Distribution Regression (DDR)`](https://arxiv.org/pdf/1911.05441.pdf), which is capable of modeling the entire conditional distribution with one single NN model.\r\n+ Supports many convenient functionality in deep learning, including:\r\n    + Early stopping.\r\n    + Model persistence.\r\n    + Learning rate schedulers.\r\n    + And more...\r\n+ Full utilization of the WIP ecosystem `cf*`, such as:\r\n    + [`carefree-toolkit`](https://github.com/carefree0910/carefree-toolkit): provides a lot of utility classes & functions which are 'stand alone' and can be leveraged in your own projects.\r\n    + [`carefree-data`](https://github.com/carefree0910/carefree-data): a lightweight tool to read -> convert -> process **ANY** tabular datasets. It also utilizes [cython](https://cython.org/) to accelerate critical procedures.\r\n\r\nFrom the above, it comes out that `carefree-learn` could be treated as a minimal **Auto**matic **M**achine **L**earning (AutoML) solution for tabular datasets when it is fully utilized. However, this is not built on the sacrifice of flexibility. In fact, the functionality we've mentioned are all wrapped into individual modules in `carefree-learn` and allow users to customize them easily.","links":[{"article_link":"","code_link":"https://github.com/carefree0910/carefree-learn","research_link":"","media_link":"https://www.youtube.com/watch?v=hMzLmwmdQ_k&feature=youtu.be","dataset_link":"","demo_link":"","other_link":"https://carefree0910.me/carefree-learn-doc/"}]},{"id":1740,"title":"Machine Learning Monthly June 2020","description":"A monthly compilation of some of the most exciting things in machine learning curated by Daniel Bourke.\r\n\r\nNow with a video version!","tags":["article","podcast","video","newsletter"],"details":"New issues every month. If you think something should be included, [let me know](mailto:daniel@mrdbourke.com).\r\n\r\nThis month:\r\n\r\n1. Machine Learning Roadmap 2020\r\n2. aitextgen \u2014 Leverage OpenAI's GPT-2 architecture to generate text\r\n3. Using AI to play like Bach\r\n4. Data science: expectations vs. reality\r\n5. What the hell is MLOps anyway?\r\n6. One neural network to rule them all!\r\n7. All of the matrix calculus you need for deep learning\r\n8. All of the matrix calculus you need for deep learning (book)\r\n9. YOLOV4 \u2014 The state of the art real-time object detection model, You Only Look Once, is back (for a 4th time)\r\n10. End-to-end object detection with Transformers (DETR)\r\n11. The transformer explained by nostalgebraist","links":[{"article_link":"https://zerotomastery.io/blog/machine-learning-monthly-june-2020/","code_link":"","research_link":"","media_link":"https://youtu.be/tfrBuQl5iQI","dataset_link":"","demo_link":"","other_link":""}]},{"id":1739,"title":"NumPy Fundamentals for Data Science and Machine Learning","description":"In-depth interactive tutorial of NumPy fundamentals for data science & machine learning. From the ndarray object to applied linear algebra. Project is 70% done.","tags":["article","code","tutorial","python","numpy"],"details":"The goal is to provide an extensive in-depth review of NumPy **fundamentals** with Data Science and Machine Learning applications in mind, combining text, code, examples, and images.\r\n\r\nI also aim to deliver a curated and well organized list of all the NumPy topics and functions that any Data Scientist should now, so it can serve as **reference** along with the official documentation.\r\n\r\n","links":[{"article_link":"https://pabloinsente.github.io/intro-numpy-fundamentals","code_link":"https://github.com/pabloinsente/intro-sc-python","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1737,"title":"codeBERT - Automated code docstring review with transformers","description":"codeBERT provide a one command line to check if your code docstrings are up-to-date.\r\n","tags":["code","tutorial","video","huggingface","attention","bert","machine-learning","transformers","library","natural-language-processing","ml-on-code","machine-learning-on-code","documentation"],"details":"We are working on **automatically document source code**\r\n\r\n\u2705 Build [MLM for Python code](https://madewithml.com/projects/1540/codebert-masked-language-model-for-source-code/)\r\n\r\n\u2705 Fine tune MLM over code documentation\r\n\r\n\u2b1b Extend model to other languages\r\n\r\n\r\n\ud83d\udca1 If you have any feedbacks, feel free to open issues on the [github repo](https://github.com/autosoft-dev/code-bert/issues)\r\n\r\n\ud83d\udcf0 Stay tune here : [CodistAI](https://codist-ai.com/)","links":[{"article_link":"","code_link":"https://github.com/autosoft-dev/code-bert","research_link":"","media_link":"https://www.youtube.com/watch?v=oDqW1JHmaYY","dataset_link":"","demo_link":"","other_link":"http://codist-ai.com/"}]},{"id":1736,"title":"Matplotlib Style Configurator","description":"Ever wondered what all those matplotlib rc parameters do? Here's a interactive plot style customizer, made with Streamlit.","tags":["code","matplotlib","streamlit","demo"],"details":"Interactively explore how different parameter values can change the plots on matplotlib.","links":[{"article_link":"","code_link":"https://github.com/dhaitz/matplotlib-style-configurator","research_link":"","media_link":"","dataset_link":"","demo_link":"https://matplotlib-style-configurator.herokuapp.com/","other_link":"https://github.com/dhaitz/matplotlib-stylesheets"}]},{"id":1735,"title":"Criticker Dataset","description":"Yet another dataset about Movies, TV Shows and Games","tags":["article","code","dataset","demo"],"details":"","links":[{"article_link":"https://www.kaggle.com/sp1thas/criticker-dataset","code_link":"https://github.com/sp1thas/criticker-dataset","research_link":"","media_link":"","dataset_link":"","demo_link":"https://www.kaggle.com/sp1thas/criticker-dataset","other_link":""}]},{"id":1734,"title":"Data ANZ Virtual Internship","description":"For the given data of 100 hypothetical customers of their transaction history of 3 months, draw some unique and interesting insights with the features. Build a ","tags":["code","notebook","decision-trees","linear-regression","machine-learning","regression","exploratory-data-analysis"],"details":"Everything is documented in the notebook.","links":[{"article_link":"","code_link":"https://github.com/ashikshafi08/ANZ-Virtual-Internship/blob/master/ANZ Real.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1732,"title":"Book Depository Dataset","description":"A large collection of books, scraped from bookdepository.com","tags":["article","code","dataset","demo"],"details":"While I was trying to master scrapy framework I came up with this project. This is a large collection of books, scraped from bookdepository.com.\r\n\r\nYet another dataset of books. By now, the dataset contains more than a million samples. Multiple metadata fields are available for each sample (E.g. title, description, category and others), therefore, this dataset could be appropriate for Text Classification and other NLP tasks.\r\n\r\nThe dataset is available as kaggle dataset.\r\n","links":[{"article_link":"https://simakis.me/book-depository-dataset/","code_link":"https://github.com/sp1thas/book-depository-dataset","research_link":"","media_link":"","dataset_link":"","demo_link":"https://www.kaggle.com/sp1thas/book-depository-dataset","other_link":"https://www.kaggle.com/sp1thas/book-depository-dataset"}]},{"id":1731,"title":"Matplotlib Cheatsheets","description":"Official Matplotlib cheat sheets.","tags":["code","tutorial","matplotlib","cheatsheet"],"details":"Tips and tricks on how to create nearly any plot you want using matplotlib.","links":[{"article_link":"","code_link":"https://github.com/matplotlib/cheatsheets","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1730,"title":"TextBrewer","description":"a PyTorch-based model distillation toolkit for natural language processing.","tags":["code","paper","research","library","model-compression","natural-language-processing","distillation","model-distillation","arxiv:2002.12620"],"details":"TextBrewer is a PyTorch-based model distillation toolkit for natural language processing. It includes various distillation techniques from both NLP and CV field and provides an easy-to-use distillation framework, which allows users to quickly experiment with the state-of-the-art distillation methods to compress the model with a relatively small sacrifice in the performance, increasing the inference speed and reducing the memory usage.","links":[{"article_link":"","code_link":"https://github.com/airaria/TextBrewer","research_link":"https://arxiv.org/abs/2002.12620","media_link":"","dataset_link":"","demo_link":"","other_link":"https://textbrewer.readthedocs.io/"}]},{"id":1729,"title":"Comment Classification Using BERT (multi-language) Fine-Tuning","description":"We are going to use BERT layer in a model applying Keras.","tags":["article","code","tutorial","keras","tensorflow","attention","bert","transformers","fine-tuning","natural-language-processing","multi-language","comment-classification"],"details":"This time, we have decided to experiment with BERT as long as its popularity as well as a variety of its usage are growing at a rapid speed. We are going to use BERT layer in a model applying Keras.","links":[{"article_link":"https://www.eliftech.com/blog/127-comment-classification-using-bert-multi-language-fine-tuning-tf-20-keras-bert-layer","code_link":"https://github.com/meksikann/bert-multilabel-text-classification","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1728,"title":"Bounding Box Prediction from Scratch using PyTorch","description":"Multi-Task learning \u2014 Bounding Box Regression + Image Classification","tags":["article","code","tutorial","pytorch","computer-vision","image-classification","multi-task-learning","bounding-box-regression"],"details":"This article talks about the case when there is only one object of interest present in an image. The focus here is more on how to read an image and its bounding box, resize and perform augmentations correctly, rather than on the model itself. The goal is to have a good grasp of the fundamental ideas behind object detection, which you can extend to get a better understanding of the more complex techniques.","links":[{"article_link":"https://towardsdatascience.com/bounding-box-prediction-from-scratch-using-pytorch-a8525da51ddc","code_link":"https://jovian.ml/aakanksha-ns/road-signs-bounding-box-prediction","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1727,"title":"Training GANs - From Theory to Practice","description":"Optimizing min-max loss functions that arise in training GANs.","tags":["article","code","paper","research","generative-adversarial-networks","training","loss","loss-functions","arxiv:2006.12376"],"details":"We present a new algorithm for optimizing min-max loss functions that arise in training GANs. We prove that our algorithm converges to an equilibrium point in time polynomial in the dimension, and smoothness parameters of the loss function. The point our algorithm converges to is stable when the maximizing player can respond using any sequence of steps which increase the loss at each step, and the minimizing player is empowered to simulate the maximizing player's response for arbitrarily many steps but is restricted to move according to updates sampled from a stochastic gradient oracle. We apply our algorithm to train GANs on Gaussian mixtures, MNIST and CIFAR-10. We observe that our algorithm trains stably and avoids mode collapse, while achieving a training time per iteration and memory requirement similar to gradient descent-ascent.","links":[{"article_link":"http://www.offconvex.org/2020/07/06/GAN-min-max/","code_link":"https://github.com/mangoubi/Min-max-optimization-algorithm-for-training-GANs","research_link":"https://arxiv.org/abs/2006.12376","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1726,"title":"Photon: A Robust Cross-Domain Text-to-SQL System","description":"A robust, modular, cross-domain NLIDB that can flag natural language input to which a SQL mapping cannot be immediately determined. ","tags":["code","paper","research","video","sql","natural-language-processing","demo","salesforce","acl-2020","photon"],"details":"Natural language interfaces to databases(NLIDB) democratize end user access to relational data. Due to fundamental differences between natural language communication and programming, it is common for end users to issue questions that are ambiguous to the system or fall outside the semantic scope of its underlying query language. We present PHOTON, a robust, modular, cross-domain NLIDB that can flag natural language input to which a SQL mapping cannot be immediately determined. PHOTON consists of a strong neural semantic parser (63.2% structure accuracy on the Spider dev benchmark), a human-in-the-loop question corrector, a SQL executor and a response generator. The question corrector isa discriminative neural sequence editor which detects confusion span(s) in the input question and suggests rephrasing until a translatable input is given by the user or a maximum number of iterations are conducted. Experiments on simulated data show that the proposed method effectively improves the robustness of text-to-SQL system against untranslatable user input.","links":[{"article_link":"","code_link":"https://github.com/mozilla/moz-sql-parser","research_link":"https://www.aclweb.org/anthology/2020.acl-demos.24/","media_link":"https://www.youtube.com/watch?v=beZG1P2DfU8","dataset_link":"","demo_link":"http://www.naturalsql.com","other_link":""}]},{"id":1725,"title":"First Steps with TensorFlow.js","description":"How to create basic AI models and use more sophisticated models with TensorFlow.js.","tags":["article","tutorial","tensorflow","tensorflow-js"],"details":"I would like to do more articles explaining a little bit about all the machine learning and deep learning basics. I'm a beginner in this area, but I'd like to explain soon these concepts to create some interesting AI models. Nevertheless, we don't need a deep knowledge about machine learning to use some existing models. We can use some libraries like Keras, Tensorflow or TensorFlow.js. We are going to see here how to create basic AI models and use more sophisticated models with TensorFlow.js. Although it's not required a deep knowledge, we are going to explain few concepts.","links":[{"article_link":"https://aralroca.com/blog/first-steps-with-tensorflowjs","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1724,"title":"Image Classifier: In the Browser","description":"Using Tensorflow.js to make the prediction directly in the browser.","tags":["article","code","tutorial","tensorflow","tensorflow-js","convolutional-neural-networks","computer-vision","image-classification","demo"],"details":"I recommend reading this [other article](https://aralroca.com/blog/first-steps-with-tensorflowjs) where I introduce Tensorflow.js. However, after this, you'll be able to classify any kind of image in an easy way even without any knowledge of ML. Also, it can be replicated for any image classification problem.","links":[{"article_link":"https://aralroca.com/blog/cat-dog-classifier","code_link":"https://github.com/aralroca/cat-dog-detection-tfjs","research_link":"","media_link":"","dataset_link":"","demo_link":"https://cat-dog-detection-tfjs.vercel.app/","other_link":""}]},{"id":1723,"title":"BioSyn","description":"Biomedical Entity Representations with Synonym Marginalization","tags":["code","paper","research","health","library","named-entity-recognition","natural-language-processing","biomedical","demo","entity-normalization","synonym","biosyn","arxiv:2005.00239"],"details":"Biosyn is a deep learning-based biomedical entity normalization framework by searching for the most 'semantically' similar term from the dictionary. The following results show the top 10 predictions.","links":[{"article_link":"","code_link":"https://github.com/dmis-lab/BioSyn","research_link":"https://arxiv.org/abs/2005.00239","media_link":"","dataset_link":"","demo_link":"http://biosyn.korea.ac.kr/","other_link":""}]},{"id":1722,"title":"spaczz: Fuzzy matching and more for spaCy","description":"Fuzzy matching and more functionality for spaCy.","tags":["code","spacy","library","natural-language-processing","regex","fuzzy-matching"],"details":"Spaczz provides fuzzy matching and multi-token regex matching functionality for spaCy. Spaczz's components have similar APIs to their spaCy counterparts and spaczz pipeline components can integrate into spaCy pipelines where they can be saved/loaded as models.\r\n\r\nFuzzy matching is currently performed with matchers from fuzzywuzzy's fuzz module and regex matching currently relies on the regex library. Spaczz certainly takes additional influence from other libraries and resources. For additional details see the references section.\r\n\r\nSpaczz has been tested on Ubuntu-18.04 and macos-10.15. It has not been tested on Windows yet but it should still work there.","links":[{"article_link":"","code_link":"https://github.com/gandersen101/spaczz","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://github.com/explosion/spaCy/pull/5717"}]},{"id":1721,"title":"TensorflowTTS","description":"Real-Time State-of-the-art Speech Synthesis for Tensorflow 2.","tags":["code","tensorflow","library","natural-language-processing","speech","speech-synthesis","text-to-speech-synthesis"],"details":"\ud83e\udd2a TensorflowTTS provides real-time state-of-the-art speech synthesis architectures such as Tacotron-2, Melgan, Multiband-Melgan, FastSpeech, FastSpeech2 based-on TensorFlow 2. With Tensorflow 2, we can speed-up training/inference progress, optimizer further by using [fake-quantize aware](https://www.tensorflow.org/model_optimization/guide/quantization/training_comprehensive_guide) and [pruning](https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras), make TTS models can be run faster than real-time and be able to deploy on mobile devices or embedded systems.","links":[{"article_link":"","code_link":"https://github.com/TensorSpeech/TensorflowTTS","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1720,"title":"JAX: Accelerated Machine Learning Research","description":"This talk will introduce JAX and its core function transformations with a live demo. ","tags":["code","tutorial","video","jax","scipy-2020"],"details":"JAX is a system for high-performance machine learning research and numerical computing. It offers the familiarity of Python+NumPy together with hardware acceleration, and it enables the definition and composition of user-wielded function transformations. These transformations include automatic differentiation, automatic vectorized batching, end-to-end compilation (via XLA), parallelizing over multiple accelerators, and more.","links":[{"article_link":"","code_link":"https://github.com/google/jax","research_link":"","media_link":"https://www.youtube.com/watch?v=z-WSrQDXkuM","dataset_link":"","demo_link":"","other_link":""}]},{"id":1719,"title":"Texthero","description":"Text preprocessing, representation and visualization from zero to hero.","tags":["article","code","library","clustering","natural-language-processing","preprocessing","data-cleaning","text-processing","texthero"],"details":"Texthero is a python package to work with text data efficiently.\r\nIt empowers NLP developers with a tool to quickly understand any text-based dataset and it provides a solid pipeline to clean and represent text data, from zero to hero.","links":[{"article_link":"https://texthero.org/docs/getting-started","code_link":"https://github.com/jbesomi/texthero","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://texthero.org/docs/api-preprocessing"}]},{"id":1718,"title":"Mathematics for Machine Learning - Linear Algebra","description":"Welcome to the \u201cMathematics for Machine Learning: Linear Algebra\u201d course, offered by Imperial College London. ","tags":["tutorial","video","linear-algebra"],"details":"This course offers an introduction to the linear algebra required for common machine learning techniques. We start at the very beginning with thinking about vectors and what vectors are, and the basic mathematical operations we can do with vectors, like how to add vectors. We then move on to think about how to find the product of vectors and what the modulus or size of a vector is. In physical spaces that then lets us think about linear algebra geometrically, and therefore when vectors are perpendicular to eachother or have an angle between then.  We can think about the basis \u2013 the fundamental vectors that make up a vector space \u2013 and how to change basis and transform between vector frames.  That then lets us think about how to combine matrix transformations and how to do inverse transformations. That then takes us on to think about the eigenvectors and eigenvalues of a transformation and what these \u201ceigen-things\u201d mean. We then finish up the course by applying all this to a machine learning problem \u2013 the google pagerank algorithm.\r\n\r\nThis course was designed to help you quickly build an intuitive understanding of linear algebra, as well as the language necessary to look concepts up yourselves when you get stuck; it is not intended cover all the details. We hope you enjoy it and that it gives you the confidence to dive into one of the many other wonderful machine learning courses available online","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/playlist?list=PLiiljHvN6z1_o1ztXTKWPrShrMrBLo5P3","dataset_link":"","demo_link":"","other_link":"https://www.coursera.org/specializations/mathematics-machine-learning"}]},{"id":1717,"title":"TaBERT","description":"Pretraining for Joint Understanding of Textual and Tabular Data","tags":["article","code","paper","research","attention","bert","transformers","library","natural-language-processing","pretraining","tabular-data","acl-2020","tabert","arxiv:2005.08314"],"details":"Recent years have witnessed the burgeoning of pretrained language models (LMs) for text-based natural language (NL) understanding tasks. Such models are typically trained on free-form NL text, hence may not be suitable for tasks like semantic parsing over structured data, which require reasoning over both free-form NL questions and structured tabular data (e.g., database tables). In this paper we present TABERT, a pretrained LM that jointly learns representations for NL sentences and (semi-)structured tables. TABERT is trained on a large corpus of 26 million tables and their English contexts. In experiments, neural semantic parsers using TABERT as feature representation layers achieve new best results on the challenging weakly-supervised semantic parsing benchmark WIKITABLEQUESTIONS, while performing competitively on the text-toSQL dataset SPIDER.","links":[{"article_link":"https://research.fb.com/publications/tabert-pretraining-for-joint-understanding-of-textual-and-tabular-data/","code_link":"https://github.com/facebookresearch/TaBERT","research_link":"https://arxiv.org/abs/2005.08314","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1716,"title":"Introduction to Anomaly Detection in Python","description":"Provides an introduction to anomaly detection in the context of machine learning.","tags":["article","code","tutorial","machine-learning"],"details":"There are always some students in a classroom who either outperform the other students or failed to even pass with a bare minimum when it comes to securing marks in subjects. Most of the times, the marks of the students are generally normally distributed apart from the ones just mentioned. These marks can be termed as extreme highs and extreme lows respectively. In Statistics and other related areas like Machine Learning, these values are referred to as Anomalies or Outliers.\r\n\r\nThe very basic idea of anomalies is really centered around two values - extremely high values and extremely low values. Then why are they given importance? In this article, we will try to investigate questions like this. We will see how they are created/generated, why they are important to consider while developing machine learning models, how they can be detected. We will also do a small case study in Python to even solidify our understanding of anomalies.","links":[{"article_link":"https://blog.floydhub.com/introduction-to-anomaly-detection-in-python/","code_link":"https://github.com/sayakpaul/FloydHub-Anomaly-Detection-Blog","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1715,"title":"Image Classifier","description":"Pure JavaScript Image Classifier","tags":["article","machine-learning","computer-vision","image-categorization"],"details":"","links":[{"article_link":"https://theabbie.github.io/ai","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1714,"title":"Text Generator","description":"A Text Generator based on Markov Chain","tags":["article","code","hidden-markov-models","machine-learning"],"details":"A Text Generator based on Markov Chain","links":[{"article_link":"https://theabbie.github.io/text","code_link":"https://github.com/theabbie/theabbie.github.io/blob/master/text.html","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://theabbie.github.io"}]},{"id":1713,"title":"Core Machine Learning Implementations","description":"This repo contains mathematical derivations and python implementations in numpy for key machine learning algorithms","tags":["article","code","tutorial","decision-trees","linear-regression","logistic-regression","neural-networks","random-forests","regression","gradient-boosting","k-nearest-neighbors","decision-tree"],"details":"Key algorithms covered:\r\n\r\n- Linear regression\r\n- Logistic regression\r\n- Knn\r\n- Decision tree\r\n- Random forest\r\n- Gradient boosted decision tree\r\n- Neural network","links":[{"article_link":"https://www.simonwardjones.co.uk/posts/linear_regression/","code_link":"https://github.com/simonwardjones/machine_learning","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1711,"title":"Forecasting the weather with neural ODEs","description":"Interesting blog post applying neural ODEs to the problem of weather forecasting.","tags":["article","forecasting","neural-ode","weather"],"details":"","links":[{"article_link":"https://sebastiancallh.github.io/post/neural-ode-weather-forecast/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1710,"title":"NLP-task-visualizer-app","description":"This application designed with streamlit library will help in visualizing NLP tasks on text entered by you. ","tags":["article","code","tutorial","machine-learning","library","natural-language-processing","data-science"],"details":"","links":[{"article_link":"https://www.linkedin.com/posts/shubham-chaudhari-57286a175_datascience-streamlit-datascience-activity-6682374259014197248-Vroo","code_link":"https://github.com/Shubh28698/NLP-task-visualizer-app","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1709,"title":"Anti-Patterns in NLP (8 types of NLP idiots)","description":"A talk which discusses the recurring industrial problems in making NLP solutions. ","tags":["tutorial","video","python","attention","bert","deep-learning","transformers","natural-language-processing","search","transfer-learning"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=f2m6Mon0VE8&feature=youtu.be&t=208","dataset_link":"","demo_link":"","other_link":"http://bit.ly/nlp-idiots"}]},{"id":1708,"title":"Multithreaded Machine Learning Training & Inference in Browser","description":"How to train and test a deep neural network model in browser by complying to browser standards","tags":["article","code","tensorflow-js","machine-learning"],"details":"","links":[{"article_link":"https://medium.com/@Nithanaroy/multithreaded-machine-learning-training-inference-in-browser-using-tensorflow-js-comlink-js-d2991d31835e","code_link":"https://github.com/Nithanaroy/tfjs-experiments/tree/master/3-mnist-cnn","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1706,"title":"PokeZoo","description":"A deep learning based web-app developed using the MERN stack and Tensorflow.js. ","tags":["code","javascript","node-js","react","tensorflow","tensorflow-js","deep-learning","machine-learning","full-stack","computer-vision","image-classification","demo"],"details":"PokeZoo is webapp that enables users to create their own Pokemon collections by identifying Pokemon from images using deep learning.\r\n\r\nThis webapp is hosted on Heroku. All features are added using a CI-CD pipeline through Github.\r\n\r\n1.     Backend - Node.js, Express.js\r\n1.     Frontend - React.js, Emotion.js, TailwindCSS, Twin.macro\r\n1.     Database - MongoDB\r\n1.     Authentication - JsonWebToken\r\n1.     Pokemon Data API - pokeAPI\r\n1.     Deep learning Inference - Tensorflow.js\r\n1.     Deep learning training - Docker + Tensorflow + Python\r\n","links":[{"article_link":"","code_link":"https://github.com/theairbend3r/poke-zoo/","research_link":"","media_link":"https://raw.githubusercontent.com/theairbend3r/poke-zoo/master/screenshots/poke-zoo-ml.gif","dataset_link":"","demo_link":" poke-zoo.herokuapp.com","other_link":""}]},{"id":1705,"title":"Handwritten Japanese Character Recognition by Transfer Learning","description":"A Transfer Learning based approach to recognizing the handwritten Hiragana characters of the Kusushiji-MNIST(KMNIST) dataset. ","tags":["code","dataset","paper","research","keras","residual-networks","transfer-learning","arxiv:1512.03385"],"details":"The ResNet 50 model is incorporated using transfer learning resulting in much lower computational requirements and much better accuracy","links":[{"article_link":"","code_link":"https://github.com/AnweshaDas7/Japanese-handwriting-recognizer","research_link":"https://arxiv.org/abs/1512.03385","media_link":"","dataset_link":"https://www.kaggle.com/anokas/kuzushiji","demo_link":"","other_link":""}]},{"id":1704,"title":"LSTM Forecast Model for Stock Price Prediction using Keras","description":" Easy to understand LSTM forecast model for Stock Price Prediction. The dataset contains daywise details of the GOOGL stock from May,2019-May 2018.","tags":["code","dataset","keras","tensorflow","lstm","time-series","time-series-prediction"],"details":"","links":[{"article_link":"","code_link":"https://github.com/AnweshaDas7/simple-LSTM-forecast_model","research_link":"","media_link":"","dataset_link":"https://github.com/AnweshaDas7/simple-LSTM-forecast_model/commit/5cf8ed1b438b48972000cb2bb9bf56401da755a3","demo_link":"","other_link":""}]},{"id":1703,"title":"Awesome Deep RL","description":"This project is built for people who are learning and researching on the latest deep reinforcement learning methods.","tags":["code","deep-learning","multi-agent-reinforcement-learning","reinforcement-learning","game-theory"],"details":"","links":[{"article_link":"","code_link":"https://github.com/tigerneil/awesome-deep-rl","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1702,"title":"Face Recognition Techniques","description":"Face Detection and Recognition techniques using traditional CV and also using new deep learning method.","tags":["code","tutorial","computer-vision","face-recognition"],"details":"Here, I've demonstrated how we can use traditional Computer Vision method such as building your own HOG+SVM to perform face-recognition which can come handy on low power devices such as pi devices(or other non-gpu devices). Also for GPU based devices using face_recognition library, which gives more robust detection and recognition.\r\n\t\t\t\t\tI've tried to code simple and clean, if you have any query please reach out. Thanks.","links":[{"article_link":"","code_link":"https://github.com/Anku5hk/The_ML_Workflow/tree/master/Face Recognition","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1701,"title":"UFC predictor","description":"A UFC predictor","tags":["sports","demo","martial-arts","ufc"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"http://ufcagora.com","other_link":""}]},{"id":1699,"title":"Reinforcement Learning Tutorial","description":"Important reinforcement learning (RL) algorithms, including policy iteration, Q-Learning, and Neural Fitted Q.","tags":["code","notebook","tutorial","reinforcement-learning"],"details":"The tutorial covers a number of important reinforcement learning (RL) algorithms, including policy iteration, Q-Learning, and Neural Fitted Q. In the first part, we will guide you through the general interaction between RL agents and environments, where the agents ought to take actions in order to maximize returns (i.e. cumulative reward). Next, we will implement Policy Iteration, SARSA, and Q-Learning for a simple tabular environment. The core ideas in the latter will be scaled to more complex MDPs through the use of function approximation. Lastly, we will provide a short introduction to deep reinforcement learning and the DQN algorithm.\r\n","links":[{"article_link":"","code_link":"https://github.com/eemlcommunity/PracticalSessions2020/blob/master/rl/EEML2020_RL_Tutorial.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://colab.research.google.com/github/eemlcommunity/PracticalSessions2020/blob/master/rl/EEML2020_RL_Tutorial.ipynb"}]},{"id":1698,"title":"Learning to Cartoonize Using White-box Cartoon Representations","description":"An approach for image cartoonization using GANs.","tags":["article","code","paper","research","generative-adversarial-networks","computer-vision","style-transfer","cvpr-2020","cartoonize","cartoongan"],"details":"This paper presents an approach for image cartoonization. By observing the cartoon painting behavior and\r\nconsulting artists, we propose to separately identify three\r\nwhite-box representations from images: the surface representation that contains a smooth surface of cartoon images, the structure representation that refers to the sparse\r\ncolor-blocks and flatten global content in the celluloid style\r\nworkflow, and the texture representation that reflects highfrequency texture, contours, and details in cartoon images. A Generative Adversarial Network (GAN) framework\r\nis used to learn the extracted representations and to cartoonize images.\r\n\r\nThe learning objectives of our method are separately\r\nbased on each extracted representations, making our framework controllable and adjustable. This enables our approach to meet artists\u2019 requirements in different styles and\r\ndiverse use cases. Qualitative comparisons and quantitative analyses, as well as user studies, have been conducted to validate the effectiveness of this approach, and\r\nour method outperforms previous methods in all comparisons. Finally, the ablation study demonstrates the influence\r\nof each component in our framework","links":[{"article_link":"https://systemerrorwang.github.io/White-box-Cartoonization/","code_link":"https://github.com/SystemErrorWang/White-box-Cartoonization","research_link":"https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Learning_to_Cartoonize_Using_White-Box_Cartoon_Representations_CVPR_2020_paper.pdf","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1697,"title":"NAG - Network for Adversary Generation [Pytorch]","description":"Generative approach to model the manifold of perturbations that can cause CNN based classifiers to behave absurdly. ","tags":["article","code","paper","research","video","pytorch","convolutional-neural-networks","generative-adversarial-networks","adversarial-learning","adversarial-attacks","arxiv:1712.03390"],"details":"The core idea is to model the distribution of adversarial perturbations using a Generative approach, where in the discriminator used is a pre-trained model, In this approach the Only generators is getting updated. To Quantify the effectiveness of perturbations generated the authors have formulated two objectives.\r\n\r\n1.  Fooling Objective : Ideally a perturbation should confuse the classifier so as to flip the benign prediction into a different adversarial prediction. In order to improve the efficacy of the perturbations, the author's use the confidence of the benign(Unperturbed/clean) prediction which should be reduced and that of another category should be made higher.\r\n2.  Diversity Objective: The idea is to encourage the generator to explore the space of perturbations and generate a diverse set of perturbations. This is done By increasing the distance between feature embeddings projected by the target classifier.\r\n","links":[{"article_link":"https://gokkulnath.github.io/NAG_Pytorch/","code_link":"https://github.com/Gokkulnath/NAG_Pytorch","research_link":"https://arxiv.org/abs/1712.03390","media_link":"https://www.youtube.com/watch?v=2lojORAu8vA&feature=youtu.be","dataset_link":"","demo_link":"","other_link":""}]},{"id":1695,"title":"AI-Art","description":"PyTorch implementation of Neural Style Transfer, Pix2Pix, CycleGAN, and Deep Dream!","tags":["article","code","dataset","paper","research","tutorial","pytorch","generative-adversarial-networks","cyclegan","generative-models","pix2pix","neural-style-transfer","arxiv:1508.06576","deep-dream"],"details":"I wrote a tutorial covering four popular Deep-Learning based Generative models - Style Transfer, Pix2Pix, CycleGAN, and DeepDream. The implementation of all of them is available in PyTorch; I tried my best to keep the code clean, short, and readable.\r\n\r\nWhat can you expect from it - Apart from learning about these four topics, you will get to know some PyTorch too! Basics include how to use pre-trained models as feature extractors, save and load checkpoints, resume training from previously saved checkpoints. Advanced topics include how to stabilize the training process of GANs, debugging your network using Tensorboard.\r\n\r\nAny feedback or suggestions are highly appreciated!","links":[{"article_link":"https://github.com/Adi-iitd/AI-Art","code_link":"https://github.com/Adi-iitd/AI-Art","research_link":"https://arxiv.org/abs/1508.06576","media_link":"","dataset_link":"https://www.tensorflow.org/datasets/catalog/overview","demo_link":"","other_link":""}]},{"id":1694,"title":"Adversarial Training Improves Product Discovery","description":"Method automatically generates meaningful negative training examples for deep-learning model.","tags":["article","paper","research","adversarial-learning","adversarial-training","product-discovery"],"details":"During training, we feed our network automatically labeled positive examples. On a random basis, it chooses some of them for conversion to negative examples. The generator overwrites half of the example \u2014 the query \u2014 and changes its label from \u201cmatch\u201d to \u201cmismatch\u201d.","links":[{"article_link":"https://www.amazon.science/blog/adversarial-training-improves-product-discovery","code_link":"","research_link":"https://drive.google.com/file/d/12zc_j8T-eIA1mt6TvNepH-3VB7IdXduK/view","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1693,"title":"On the training dynamics of deep networks with L2 regularization","description":"Role of L2 regularization in deep learning, and uncover simple relations between the performance of the model, the L2 coefficient, the learning rate, etc.","tags":["paper","research","learning-rates","regularization","l2","l2-coefficient","arxiv:2006.08643"],"details":"We study the role of L2 regularization in deep learning, and uncover simple relations between the performance of the model, the L2 coefficient, the learning rate, and the number of training steps. These empirical relations hold when the network is overparameterized. They can be used to predict the optimal regularization parameter of a given model. In addition, based on these observations we propose a dynamical schedule for the regularization parameter that improves performance and speeds up training. We test these proposals in modern image classification settings. Finally, we show that these empirical relations can be understood theoretically in the context of infinitely wide networks. We derive the gradient flow dynamics of such networks, and compare the role of L2 regularization in this context with that of linear models.","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2006.08643","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1692,"title":"Low-Dimensional Hyperbolic Knowledge Graph Embeddings","description":"Low-dimensional knowledge graph embeddings that simultaneously capture hierarchical relations and logical patterns.","tags":["code","paper","research","video","embeddings","graph-embedding","graph-neural-networks","graphs","knowledge-graphs","acl-2020","arxiv:2005.00545"],"details":"We propose a family of methods to learn low-dimensional knowledge graph embeddings that simultaneously capture hierarchical relations (e.g. father of) and logical patterns (e.g. symmetry or anti-symmetry).","links":[{"article_link":"","code_link":"https://github.com/HazyResearch/KGEmb","research_link":"https://arxiv.org/abs/2005.00545","media_link":"https://www.youtube.com/watch?v=Yf03-CBYKe4","dataset_link":"","demo_link":"","other_link":"https://github.com/tensorflow/neural-structured-learning"}]},{"id":1691,"title":"The Simplest Way to Serve your NLP Model in Production w/ Python ","description":"From scikit-learn to Hugging Face Pipelines, learn the simplest way to deploy ML models using Ray Serve.","tags":["article","tutorial","huggingface","scikit-learn","production","ray"],"details":"In this post, we\u2019ll highlight Ray Serve\u2019s capabilities by building a simple sentiment classifier with scikit-learn and deploying it as a production service. Then, we\u2019ll upgrade the same service to a more advanced Hugging Face pipeline that uses PyTorch under the hood \u2014 with zero downtime. Finally, we\u2019ll conclude with some of the other baked-in capabilities such as scaling out and batching.","links":[{"article_link":"https://medium.com/distributed-computing-with-ray/the-simplest-way-to-serve-your-nlp-model-in-production-with-pure-python-d42b6a97ad55","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1690,"title":"Opening Up the Black Box: Model Understanding w/ Captum & PyTorch","description":"A look at using Captum for model interpretability with PyTorch.","tags":["video","pytorch","interpretability","captum"],"details":"PyTorch, the popular open-source ML framework, has continued to evolve rapidly since the introduction of PyTorch 1.0, which brought an accelerated workflow from research to production. We'll deep dive on some of the most important new advances, including the ability to name tensors, support for quantization-aware training and post-training quantization, improved distributed training on GPUs, and streamlined mobile deployment. We'll also cover new developer tools and domain-specific frameworks including Captum for model interpretability, Detectron2 for computer vision, and speech extensions for Fairseq.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=0QLrRyLndFI","dataset_link":"","demo_link":"","other_link":""}]},{"id":1689,"title":"Offline Reinforcement Learning","description":"Challenges, algorithms and benchmarks.","tags":["tutorial","video","reinforcement-learning","survey","offline-reinforcement-learning","overview"],"details":"Short lecture on offline reinforcement learning by [Sergey Levine](https://people.eecs.berkeley.edu/~svlevine/).\r\n\r\n* original: https://www.youtube.com/watch?v=IUAePhU0E7Y\r\n* extended version: https://www.youtube.com/watch?v=qgZPZREor5I","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=qgZPZREor5I","dataset_link":"","demo_link":"","other_link":""}]},{"id":1688,"title":"Python Implementation of Reinforcement Learning: An Introduction ","description":"Plot replications, exercise solutions and Anki flashcards for the entire book by chapters.","tags":["code","tutorial","reinforcement-learning","book"],"details":"Python replication for Sutton & Barto's book [Reinforcement Learning: An Introduction (2nd Edition)](http://incompleteideas.net/book/the-book-2nd.html)","links":[{"article_link":"","code_link":"https://github.com/ShangtongZhang/reinforcement-learning-an-introduction","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1687,"title":"Similarity Search for Efficient Active Learning","description":"We exploit this skew in large training datasets to reduce the number of unlabeled examples considered in each selection round with nearest nearest neighbors.","tags":["paper","research","active-learning","search","semi-supervised-learning","similarity-search","arxiv:2007.00077"],"details":"Many active learning and search approaches are intractable for industrial settings with billions of unlabeled examples. Existing approaches, such as uncertainty sampling or information density, search globally for the optimal examples to label, scaling linearly or even quadratically with the unlabeled data. However, in practice, data is often heavily skewed; only a small fraction of collected data will be relevant for a given learning task. For example, when identifying rare classes, detecting malicious content, or debugging model performance, the ratio of positive to negative examples can be 1 to 1,000 or more. In this work, we exploit this skew in large training datasets to reduce the number of unlabeled examples considered in each selection round by only looking at the nearest neighbors to the labeled examples. Empirically, we observe that learned representations effectively cluster unseen concepts, making active learning very effective and substantially reducing the number of viable unlabeled examples. We evaluate several active learning and search techniques in this setting on three large-scale datasets: ImageNet, Goodreads spoiler detection, and OpenImages. For rare classes, active learning methods need as little as 0.31% of the labeled data to match the average precision of full supervision. By limiting active learning methods to only consider the immediate neighbors of the labeled data as candidates for labeling, we need only process as little as 1% of the unlabeled data while achieving similar reductions in labeling costs as the traditional global approach. This process of expanding the candidate pool with the nearest neighbors of the labeled set can be done efficiently and reduces the computational complexity of selection by orders of magnitude.","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2007.00077","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1686,"title":"Causal Discovery in Physical Systems from Videos","description":"Discover the structural dependencies among environmental and object variables: inferring the type and strength of interactions that have a causal effect on the ","tags":["article","paper","research","unsupervised-learning","causal-discovery","keypoint-detection","unsupervised-keypoint-detection","multi-body-interaction","fabric-manipulation","arxiv:2007.00631"],"details":"Causal discovery is at the core of human cognition. It enables us to reason about the environment and make counterfactual predictions about unseen scenarios, that can vastly differ from our previous experiences. We consider the task of causal discovery from videos in an end-to-end fashion without supervision on the ground-truth graph structure. In particular, our goal is to discover the structural dependencies among environmental and object variables: inferring the type and strength of interactions that have a causal effect on the behavior of the dynamical system. Our model consists of (a) a perception module that extracts a semantically meaningful and temporally consistent keypoint representation from images, (b) an inference module for determining the graph distribution induced by the detected keypoints, and (c) a dynamics module that can predict the future by conditioning on the inferred graph. We assume access to different configurations and environmental conditions, i.e., data from unknown interventions on the underlying system; thus, we can hope to discover the correct underlying causal graph without explicit interventions. We evaluate our method in a planar multi-body interaction environment and scenarios involving fabrics of different shapes like shirts and pants. Experiments demonstrate that our model can correctly identify the interactions from a short sequence of images and make long-term future predictions. The causal structure assumed by the model also allows it to make counterfactual predictions and extrapolate to systems of unseen interaction graphs or graphs of various sizes.","links":[{"article_link":"https://yunzhuli.github.io/V-CDN/","code_link":"","research_link":"https://arxiv.org/abs/2007.00631","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1685,"title":"Text Data Cleanup - Dynamic Embedding Visualisation","description":"Identify noisy text in a Machine Translation dataset through dynamic text embedding visualisation.","tags":["article","tutorial","clustering","embeddings","natural-language-processing","visualization","bokeh"],"details":"In order for Machine Translation to be useful in the real world, we should should strive to train it on high quality translation data. This is doubly true for lower-resource languages such as Irish, where clean training data is relatively limited. In this article we will try and identify and remove clusters of dirty/noisey samples in our parallalel dataset. The stages we will go through are:\r\n\r\n* **Generate** embeddings from a pre-trained multi-lingual model, XLM-RoBERTa\r\n* **Visualise** these embeddings using a dimensionality technique via UMAP\r\n* **Identify** clusters in a sample of the data that seem to be of low translation quality via Bokeh\r\n* **Remove** similar samples from the main dataset via nmslib","links":[{"article_link":"https://www.ntentional.com/nlp/visualization/bokeh/clustering/2020/06/29/Text-Cleaning-With-Clustering.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1684,"title":"DrRepair: Learning to Repair Programs from Error Messages","description":"Graph-based, Self-Supervised Program Repair from Diagnostic Feedback","tags":["code","paper","research","michiyasunaga","arxiv:2005.10636"],"details":"We consider the problem of learning to repair programs from diagnostic feedback (e.g., compiler error messages). Program repair is challenging for two reasons: First, it requires reasoning and tracking symbols across source code and diagnostic feedback. Second, labeled datasets available for program repair are relatively small. In this work, we propose novel solutions to these two challenges. First, we introduce a program-feedback graph, which connects symbols relevant to program repair in source code and diagnostic feedback, and then apply a graph neural network on top to model the reasoning process. Second, we present a self-supervised learning paradigm for program repair that leverages unlabeled programs available online to create a large amount of extra program repair examples, which we use to pre-train our models. We evaluate our proposed approach on two applications: correcting introductory programming assignments (DeepFix dataset) and correcting the outputs of program synthesis (SPoC dataset). Our final system, DrRepair, significantly outperforms prior work, achieving 68.2% full repair rate on DeepFix (+22.9% over the prior best), and 48.4% synthesis success rate on SPoC (+3.7% over the prior best).","links":[{"article_link":"","code_link":"https://github.com/michiyasunaga/DrRepair","research_link":"https://arxiv.org/abs/2005.10636","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1683,"title":"Supermasks in Superposition","description":"SupSup leverages the expressive power of neural network connectivity. ","tags":["article","code","paper","research","superposition","supermasks","supsup","arxiv:2006.14769"],"details":"We present the Supermasks in Superposition (SupSup) model, capable of sequentially learning thousands of tasks without catastrophic forgetting. Our approach uses a randomly initialized, fixed base network and for each task finds a subnetwork (supermask) that achieves good performance. If task identity is given at test time, the correct subnetwork can be retrieved with minimal memory usage. If not provided, SupSup can infer the task using gradient-based optimization to find a linear superposition of learned supermasks which minimizes the output entropy. In practice we find that a single gradient step is often sufficient to identify the correct mask, even among 2500 tasks. We also showcase two promising extensions. First, SupSup models can be trained entirely without task identity information, as they may detect when they are uncertain about new data and allocate an additional supermask for the new training distribution. Finally the entire, growing set of supermasks can be stored in a constant-sized reservoir by implicitly storing them as attractors in a fixed-sized Hopfield network.","links":[{"article_link":"https://mitchellnw.github.io/blog/2020/supsup/","code_link":"https://github.com/RAIVNLab/supsup","research_link":"https://arxiv.org/abs/2006.14769","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1682,"title":"Debiased Contrastive Learning","description":"We develop a debiased contrastive objective that corrects for the sampling of same-label data points, even without knowledge of the true labels.","tags":["code","paper","research","simclr","contrastive-learning","bias","debiasing","stl10","arxiv:2007.00224"],"details":"A prominent technique for self-supervised representation learning has been to contrast semantically similar and dissimilar pairs of samples. Without access to labels, dissimilar (negative) points are typically taken to be randomly sampled datapoints, implicitly accepting that these points may, in reality, actually have the same label. Perhaps unsurprisingly, we observe that sampling negative examples from truly different labels improves performance, in a synthetic setting where labels are available. Motivated by this observation, we develop a debiased contrastive objective that corrects for the sampling of same-label datapoints, even without knowledge of the true labels.","links":[{"article_link":"","code_link":"https://github.com/chingyaoc/DCL","research_link":"https://arxiv.org/abs/2007.00224","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1681,"title":"A Survey on Deep Learning for Localization and Mapping","description":"Towards the Age of Spatial Machine Intelligence","tags":["paper","research","computer-vision","object-localization","survey","mapping","spatial","odometry","smis","arxiv:2006.12567"],"details":"Deep learning based localization and mapping has recently attracted great attentions. Instead of crating hand-designed algorithms via exploiting physical models or geometry theory, deep learning based solutions provide an alternative to solve the problem in a data-driven way. Benefited from the ever-increasing amount of data and computational power, these methods are fast evolving into a new area that offers accurate and robust systems to track motion and estimate scene structure for real-world applications. In this work, we provide a comprehensive survey, and propose a new taxonomy on the existing approaches on localization and mapping using deep learning. We also discuss the limitations of current models, and indicate possible future directions. A wide range of topics are covered, from learning odometry estimation, mapping, to global localization and simultaneous localization and mapping (SLAM). We revisit the problem of perceiving self-motion and scene with on-board sensors, and show how to solve it by integrating these modules into a prospective spatial machine intelligence system (SMIS). It is our hope that this work can connect the emerging works from robotics, computer vision and machine learning communities, and serve as a guide for future researchers to know about the possible ways that apply deep learning to tackle the localization and mapping problems.","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2006.12567","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1680,"title":"Feature engineering for Logistic Regression","description":"A dataset to focus on data cleaning and feature prep. ","tags":["article","code","dataset","notebook","video","logistic-regression","regression","feature-engineering","feature-selection"],"details":"This dataset is available at UCI Machine Learning. \"Census Income\" dataset with features such as gender, race, age, native country, etc. This dataset were choose to focus on feature engineering and data pre processing and cleaning. Question to be answered: Predict whether income exceeds $50K/yr based on census data. Check out the complete article about this Machine Learning model. Built based on April Chen's class available on YouTube. Check out the complete article about feature engineering with this dataset.","links":[{"article_link":"https://medium.com/joguei-os-dados/week-4-feature-engineering-4787fca0f809?source=collection_home---4------3-----------------------","code_link":"https://github.com/gerolaleticia/Pyrentena-a-dataset-per-week/blob/master/Semana 4- Dataset Adultos - feature engineering/Semana 4 - Feature Prep  adult dataset.ipynb","research_link":"","media_link":"","dataset_link":"http://archive.ics.uci.edu/ml/datasets/Adult","demo_link":"","other_link":"https://www.youtube.com/watch?v=V0u6bxQOUJ8"}]},{"id":1679,"title":"Avocado sales","description":"Exploratory analysis to answer the question: has the trend \u2018avocado toast\u2019 worshiped by millenials caused an increase on avocado sales?","tags":["article","code","dataset","notebook","exploratory-data-analysis"],"details":"This dataset is available here for download and also on Kaggle. It brings data of avocado sales in the USA market from 2015 to 2020. Question to be answered: The recent trend 'avocado toast' worshiped by millenials caused an increase on the total volume of avocado sales? What about the prices, have they increased since avocados are no longer the bad green smooth of childhood and are now an instagramable meal? Check out the complete article about this dataset.","links":[{"article_link":"https://medium.com/joguei-os-dados/week-2-avocado-dataset-2f52442116ae","code_link":"https://github.com/gerolaleticia/Pyrentena-a-dataset-per-week/blob/master/Semana 2 - Dataset Avocado/Pyrentena semana 2 - dataset AVOCADO (1).ipynb","research_link":"","media_link":"","dataset_link":"https://raw.githubusercontent.com/gerolaleticia/Pyrentena-a-dataset-per-week/master/Semana 2 - Dataset Avocado/Avocado.csv","demo_link":"","other_link":""}]},{"id":1678,"title":"NSFW Image Classification REST API built with TensorFlow.JS","description":"A ready-to-use & open-source NSFW Image Classification REST API built with TensorFlow.JS and NSFW.JS for effortless Content Moderation","tags":["api","article","code","tutorial","node-js","tensorflow","tensorflow-js","convolutional-neural-networks","library","adversarial-image-detection","computer-vision","image-classification","image-recognition","object-detection","pretraining","open-source","adversarial-learning","models","demo","nsfw","content-moderation","nsfw-detection","nsfw-classifier","parse-server","machine-learning-pipelines"],"details":"## Building a Content Moderation Service from Scratch\r\nOver the next weeks, we'll share our experience and give you an easy way to build your own Content Moderation Service with ML & [SashiDo](https://bit.ly/3gw923F). What's more, our solution is **open-source** and can be hosted on any other platform that supports fully featured **Node.js + MongoDB** or even cloud hosting providers such as AWS VMs and Digital Ocean.\r\n\r\n## Part 1: Not Safe for Work Image Classification Rest API\r\nWe kick off with step-by-step instructions on [How to create an NSFW Image Classification REST API built with TensorFlow.JS and NSFW.JS ](https://bit.ly/2VEBpEE)for effortless Content Moderation.\r\n\r\n## What's Next?\r\nThe end goal we've set for this project is to have a ready-to-use product, not only classification logic. In the upcoming tutorials, we will show you how we've built an [**Automation Engine**](https://bit.ly/2E5qzla) for fast deletion & moderation and as a final touch, we'll also add **React** to our stack for creating a [beautiful Admin panel](https://bit.ly/39eHpJM). \r\n\r\n## Give Us a Shout!\r\nWhether you deploy directly, integrate, or fork our solution if you liked what we did don't forget to give us a shout on [Twitter](https://twitter.com/sashidoio?lang=en) or share [the repo](https://bit.ly/3is6IMS). Thank you in advance for the support!\r\n\r\n## Your Feedback Matters!\r\nHelp us in our mission to break the barrier to Machine Learning by sharing your feedback and use cases at hello@sashido.io.","links":[{"article_link":"https://bit.ly/2VEBpEE","code_link":"https://bit.ly/3is6IMS","research_link":"","media_link":"https://bit.ly/2VGnGgv","dataset_link":"","demo_link":"https://bit.ly/31EovdA","other_link":"https://bit.ly/3gw923F"}]},{"id":1677,"title":"Building Level 3 Conversational AI Assistants","description":"Presentations, panels, and fireside chats addressing all topics related to the creation of Level 3 AI assistants.","tags":["article","research","video","chatbot","natural-language-processing","rasa","conversational-ai","playlist","level-3"],"details":" L3-AI is a free online event that brings together over 45 speakers - researchers, engineers, designers, and other AI practitioners who are making Level 3 assistants a reality. The agenda has over 9 hours of presentations, panels, and fireside chats addressing all topics related to the creation of Level 3 AI assistants.\r\n \r\n Conversational AI is still a hard problem to solve, and the teams building exceptional AI assistants don\u2019t get there with shortcuts or off the shelf solutions. They rely on tools, research, and techniques that produce AI assistants able to stand up to users\u2019 expectations and meet business goals. At L3-AI, we\u2019ll explore what goes into successfully implementing complex assistants.\r\n\r\nPut simply, Level 3 assistants are here today, and we\u2019ll hear real stories from the people who build them.","links":[{"article_link":"https://blog.rasa.com/l3-ai-virtual-conference/","code_link":"","research_link":"","media_link":"https://www.youtube.com/playlist?list=PL75e0qA87dlGP51yZ0dyNup-vwu0Rlv86","dataset_link":"","demo_link":"","other_link":"https://www.l3-ai.dev/"}]},{"id":1676,"title":"CatBoostLSS","description":"An extension of CatBoost to probabilistic forecasting.","tags":["code","paper","research","forecasting","uncertainty","catboostlss","probabilistic-forecasts","catboost","gamlss","distributional-regression","arxiv:2001.02121"],"details":"We propose a new framework of CatBoost that predicts the entire conditional distribution of a univariate response variable. In particular, CatBoostLSS models all moments of a parametric distribution, i.e., mean, location, scale and shape (LSS), instead of the conditional mean only. Choosing from a wide range of continuous, discrete and mixed discrete-continuous distributions, modelling and predicting the entire conditional distribution greatly enhances the flexibility of CatBoost, as it allows to gain additional insight into the data generating process, as well as to create probabilistic forecasts from which prediction intervals and quantiles of interest can be derived. In the following, we provide a short walk-through of the functionality of CatBoostLSS.","links":[{"article_link":"","code_link":"https://github.com/StatMixedML/CatBoostLSS","research_link":"https://arxiv.org/abs/2001.02121","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1675,"title":"Deterministic Uncertainty Quantification","description":"Method for training a deterministic deep model that can find and reject out of distribution data points at test time with a single forward pass.","tags":["code","paper","research","deep-q-networks","uncertainty","deterministic-uncertainty-quantification","arxiv:2003.02037"],"details":"We propose a method for training a deterministic deep model that can find and reject out of distribution data points at test time with a single forward pass. Our approach, deterministic uncertainty quantification (DUQ), builds upon ideas of RBF networks. We scale training in these with a novel loss function and centroid updating scheme and match the accuracy of softmax models. By enforcing detectability of changes in the input using a gradient penalty, we are able to reliably detect out of distribution data. Our uncertainty quantification scales well to large datasets, and using a single model, we improve upon or match Deep Ensembles in out of distribution detection on notable difficult dataset pairs such as FashionMNIST vs. MNIST, and CIFAR-10 vs. SVHN.","links":[{"article_link":"","code_link":"https://github.com/y0ast/deterministic-uncertainty-quantification","research_link":"https://arxiv.org/abs/2003.02037","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1674,"title":"Fiber: Distributed Computing for AI Made Simple","description":"Fiber is a Python distributed computing library for modern computer clusters.","tags":["article","code","paper","research","library","distributed-training","uber","multiprocessing","clusters","fiber","arxiv:2003.11164"],"details":"* It is easy to use. Fiber allows you to write programs that run on a computer cluster level without the need to dive into the details of computer cluster.\r\n* It is easy to learn. Fiber provides the same API as Python's standard multiprocessing library that you are familiar with. If you know how to use multiprocessing, you can program a computer cluster with Fiber.\r\n* It is fast. Fiber's communication backbone is built on top of Nanomsg which is a high-performance asynchronous messaging library to allow fast and reliable communication.\r\n* It doesn't need deployment. You run it as the same way as running a normal application on a computer cluster and Fiber handles the rest for you.\r\n* It it reliable. Fiber has built-in error handling when you are running a pool of workers. Users can focus on writing the actual application code instead of dealing with crashed workers.","links":[{"article_link":"https://uber.github.io/fiber/introduction/","code_link":"https://github.com/uber/fiber","research_link":"https://arxiv.org/abs/2003.11164","media_link":"","dataset_link":"","demo_link":"","other_link":"https://uber.github.io/fiber/"}]},{"id":1673,"title":"Involutive MCMC: a Unifying Framework","description":"iMCMC provides a unified view of many known MCMC algorithms, which facilitates the derivation of powerful extensions.","tags":["paper","research","markov-chain-monte-carlo","mcmc","involutive","arxiv:2006.16653"],"details":"Markov Chain Monte Carlo (MCMC) is a computational approach to fundamental problems such as inference, integration, optimization, and simulation. The field has developed a broad spectrum of algorithms, varying in the way they are motivated, the way they are applied and how efficiently they sample. Despite all the differences, many of them share the same core principle, which we unify as the Involutive MCMC (iMCMC) framework. Building upon this, we describe a wide range of MCMC algorithms in terms of iMCMC, and formulate a number of \"tricks\" which one can use as design principles for developing new MCMC algorithms. Thus, iMCMC provides a unified view of many known MCMC algorithms, which facilitates the derivation of powerful extensions. We demonstrate the latter with two examples where we transform known reversible MCMC algorithms into more efficient irreversible ones.\r\n","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2006.16653","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1672,"title":"Clustering Spotify Songs","description":"Clustering songs from my Spotify playlist","tags":["article","code","python","machine-learning","clustering","data-science","exploratory-data-analysis"],"details":"","links":[{"article_link":"https://medium.com/data-hackers/clustering-e-visualiza\u00e7\u00e3o-de-dados-aplica\u00e7\u00e3o-em-uma-playlist-do-spotify-usando-k-means-t-sne-e-d3b9d7233db9","code_link":"https://github.com/laaragm/Data-Science-Spotify","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1671,"title":"Churn Prediction with PyCaret","description":"Customer Churn is when customers leave a service in a given period of time, which is bad for business.","tags":["article","code","dataset","notebook","tutorial","python","machine-learning","automl","classification","exploratory-data-analysis","churn","pycaret"],"details":"This work has as objective to build a machine learning model to predict what customers will leave the service, the dataset used on this notebook is the Telco Customer Churn hosted at Kaggle. Also, an Exploratory Data Analysis is made to a better understand about the data. Another point on this work is use Deepnote as development enviroment and the PyCaret Python Module to make all the experiment pipeline.","links":[{"article_link":"https://beta.deepnote.com/article/customer-churn-prediction","code_link":"https://github.com/alfarias/customer-churn-prediction/blob/master/notebooks/customer-churn-prediction.ipynb","research_link":"","media_link":"","dataset_link":"https://www.kaggle.com/blastchar/telco-customer-churn","demo_link":"","other_link":"https://alfarias.github.io/"}]},{"id":1670,"title":"Generate QR Code using Python","description":"This article will explore how to generate QR code in Python and some useful creation features from pyqrcode library.","tags":["article","tutorial","python","program-development"],"details":"","links":[{"article_link":"https://pyshark.com/generate-qr-code-using-python/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1669,"title":"Personal Data Science Learning Plan","description":"This is my personal learning plan that I followed to transition from a software-engineer role to an Machine Learning Engineer role.","tags":["code","tutorial","machine-learning","data-science"],"details":"- Relevant courses to improve adjacent skills along with going deeper into fewer areas\r\n- Organized by goals to improve at specific area X of the data science process","links":[{"article_link":"","code_link":"https://github.com/amitness/learning","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1668,"title":"Model-based Reinforcement Learning: A Survey","description":"A survey of the integration of both fields, better known as model-based reinforcement learning.","tags":["paper","research","reinforcement-learning","survey","model-based-reinforcement-learning","markov-decision-process","arxiv:2006.16712"],"details":"Sequential decision making, commonly formalized as Markov Decision Process (MDP) optimization, is a key challenge in artificial intelligence. Two key approaches to this problem are reinforcement learning (RL) and planning. This paper presents a survey of the integration of both fields, better known as model-based reinforcement learning. Model-based RL has two main steps. First, we systematically cover approaches to dynamics model learning, including challenges like dealing with stochasticity, uncertainty, partial observability, and temporal abstraction. Second, we present a systematic categorization of planning-learning integration, including aspects like: where to start planning, what budgets to allocate to planning and real data collection, how to plan, and how to integrate planning in the learning and acting loop. After these two key sections, we also discuss the potential benefits of model-based RL, like enhanced data efficiency, targeted exploration, and improved stability. Along the survey, we also draw connections to several related RL fields, like hierarchical RL and transfer, and other research disciplines, like behavioural psychology. Altogether, the survey presents a broad conceptual overview of planning-learning combinations for MDP optimization.","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2006.16712","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1667,"title":"Using TensorRT for accelerated deep learning inference","description":"Accelerating inference of TensorFlow models using TensorRT.","tags":["article","code","notebook","tutorial","tensorflow","tensorrt"],"details":"If you see the way deep learning research has progressed over the years, it has always been guided by the need of the hour. If I were to develop a chronology out of it, it would be something like - train better model -> train them faster -> get them good at generalizing well, and so on. With a stern increase in the demand for using deep learning more as just another technology stack, there could not have been a better time to think about how do we make our models infer faster. In this post, we are going to see how to use TensorRT to perform accelerated inference with TensorFlow (2) models. After all, making predictions with deep learning models is what makes you real \ud83d\udcb0 and we would want to make sure that our bucks burned judiciously.","links":[{"article_link":"https://sayak.dev/tf.keras/tensorrt/tensorflow/2020/07/01/accelerated-inference-trt.html","code_link":"https://colab.research.google.com/github/sayakpaul/portfolio/blob/master/_notebooks/2020-07-01-accelerated-inference-trt.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1666,"title":"Serverless BERT with HuggingFace and AWS Lambda","description":"Build a serverless question-answering API with BERT, HuggingFace, the Serverless Framework, and AWS Lambda.","tags":["api","article","tutorial","aws","huggingface","attention","bert","transformers","natural-language-processing","question-answering","serverless","aws-lambda"],"details":"I will show you how to leverage the benefits of serverless architectures and deploy a BERT Question-Answering API in a serverless environment. We are going to use the [Transformers](https://github.com/huggingface/transformers library by HuggingFace, the [Serverless Framework](https://serverless.com/), and AWS Lambda.","links":[{"article_link":"https://www.philschmid.de/serverless-bert-with-huggingface-and-aws-lambda","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1665,"title":"BERTology Meets Biology","description":"Interpreting Attention in Protein Language Models.","tags":["article","code","paper","research","attention","bert","transformers","health","healthcare","interpretability","language-modeling","natural-language-processing","biology","bertology","proteins","language-models","arxiv:2006.15222"],"details":"Transformer architectures have proven to learn useful representations for protein classification and generation tasks. However, these representations present challenges in interpretability. Through the lens of attention, we analyze the inner workings of the Transformer and explore how the model discerns structural and functional properties of proteins. We show that attention (1) captures the folding structure of proteins, connecting amino acids that are far apart in the underlying sequence, but spatially close in the three-dimensional structure, (2) targets binding sites, a key functional component of proteins, and (3) focuses on progressively more complex biophysical properties with increasing layer depth. We also present a three-dimensional visualization of the interaction between attention and protein structure. Our findings align with known biological processes and provide a tool to aid discovery in protein engineering and synthetic biology.","links":[{"article_link":"https://blog.einstein.ai/provis/amp/","code_link":"https://github.com/salesforce/provis","research_link":"https://arxiv.org/abs/2006.15222","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1664,"title":"Sentiment Analysis: Key Milestones, Challenges and New Directions","description":"An overview of sentiment analysis, it's progress and what's ahead.","tags":["paper","research","tutorial","video","natural-language-processing","sentiment-analysis","survey","arxiv:2005.00357"],"details":"[Soujanya Poria](https://www.youtube.com/redirect?q=https%3A%2F%2Ftwitter.com%2Fsoujanyaporia&event=video_description&v=YAqjf7to-lU&redir_token=2S1wM0R8j4GodDASvTiPEu2bUvF8MTU5MzY3MzczM0AxNTkzNTg3MzMz) holds a Ph.D. in Computer Science. Soujanya main areas of [research interest](https://www.youtube.com/redirect?q=https%3A%2F%2Fdeclare-lab.net%2F&event=video_description&v=YAqjf7to-lU&redir_token=2S1wM0R8j4GodDASvTiPEu2bUvF8MTU5MzY3MzczM0AxNTkzNTg3MzMz) are NLP and sentiment analysis. At present, he works as an assistant professor at the Singapore University of Technology and Design (SUTD), Singapore. He is also part of the Institute of High-Performance Computing (IHPC), ASTAR as a senior scientist. Before joining SUTD, he worked at NTU where he was awarded the prestigious NTU presidential postdoctoral fellowship.","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2005.00357","media_link":"https://www.youtube.com/watch?v=YAqjf7to-lU","dataset_link":"","demo_link":"","other_link":"https://www.dropbox.com/s/po5rsekhdnjz114/invited%20talk%20dair%20%281%29.pdf?dl=0"}]},{"id":1663,"title":"Sktime","description":"A python toolbox for machine learning with time series.","tags":["article","code","library","forecasting","time-series","time-series-forecasting","time-series-regression"],"details":"We currently support:\r\n\r\n* Forecasting,\r\n* Time series classification,\r\n* Time series regression.\r\n\r\nsktime provides dedicated time series algorithms and [scikit-learn](https://github.com/scikit-learn/scikit-learn) compatible tools for building, tuning, and evaluating composite models.\r\n\r\nFor deep learning methods, see our companion package: [sktime-dl](https://github.com/sktime/sktime-dl).","links":[{"article_link":"https://towardsdatascience.com/sktime-a-unified-python-library-for-time-series-machine-learning-3c103c139a55","code_link":"https://github.com/alan-turing-institute/sktime","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"http://sktime.org/index.html"}]},{"id":1662,"title":"Image synthesis at CVPR 2020","description":"An overview of the different approaches to image synthesis at CVPR 2020.","tags":["article","research","computer-vision","image-generation","image-synthesis","survey","cvpr-2020"],"details":"During the conference, I took notes and decided to share them. No notes were taken on the papers that I had studied in great detail earlier. That is why articles like StyleGAN2 and StarGAN2 were not included in the list. For this post to be appropriate, it will only be about image generation (well, almost).","links":[{"article_link":"https://evgenykashin.github.io/2020/06/29/CVPR2020-Image-Synthesis.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1661,"title":"SpineNet: A Novel Architecture for Object Detection","description":"A meta architecture called a scale-permuted model that enables two major improvements on backbone architecture design,iscovered with neural architecture search.","tags":["article","code","paper","research","convolutional-neural-networks","computer-vision","object-detection","neural-architecture-search","cvpr-2020","spinenet","arxiv:1912.05027"],"details":"Convolutional neural networks typically encode an input image into a series of intermediate features with decreasing resolutions. While this structure is suited to classification tasks, it does not perform well for tasks requiring simultaneous recognition and localization (e.g., object detection). The encoder-decoder architectures are proposed to resolve this by applying a decoder network onto a backbone model designed for classification tasks. In this paper, we argue encoder-decoder architecture is ineffective in generating strong multi-scale features because of the scale-decreased backbone. We propose SpineNet, a backbone with scale-permuted intermediate features and cross-scale connections that is learned on an object detection task by Neural Architecture Search. Using similar building blocks, SpineNet models outperform ResNet-FPN models by ~3% AP at various scales while using 10-20% fewer FLOPs. In particular, SpineNet-190 achieves 52.5% AP with a MaskR-CNN detector and achieves 52.1% AP with a RetinaNet detector on COCO for a single model without test-time augmentation, significantly outperforms prior art of detectors. SpineNet can transfer to classification tasks, achieving 5% top-1 accuracy improvement on a challenging iNaturalist fine-grained dataset.","links":[{"article_link":"https://ai.googleblog.com/2020/06/spinenet-novel-architecture-for-object.html","code_link":"https://github.com/tensorflow/tpu/tree/master/models/official/detection","research_link":"https://arxiv.org/abs/1912.05027","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1660,"title":"Distributed model training using Horovod","description":"Distributing training jobs allows you to push past the single-GPU bottleneck, developing larger and more powerful models leveraging many GPUs simultaneously.","tags":["article","tutorial","pytorch","distributed-training","horovod"],"details":"Distributing training jobs allows you to push past the single-GPU bottleneck, developing larger and more powerful models leveraging many GPUs simultaneously. In this post we implement distributed training using Horovod.","links":[{"article_link":"https://spell.ml/blog/distributed-model-training-using-horovod-XvqEGRUAACgAa5th","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1659,"title":"Evaluation of Text Generation: A Survey","description":"Evaluation methods of natural language generation (NLG) and language modeling.","tags":["paper","research","language-modeling","natural-language-processing","text-generation","survey","natural-language-generation","arxiv:2006.14799"],"details":"The paper surveys evaluation methods of natural language generation (NLG) systems that have been developed in the last few years. We group NLG evaluation methods into three categories: (1) human-centric evaluation metrics, (2) automatic metrics that require no training, and (3) machine-learned metrics. For each category, we discuss the progress that has been made and the challenges still being faced, with a focus on the evaluation of recently proposed NLG tasks and neural NLG models. We then present two case studies of automatic text summarization and long text generation, and conclude the paper by proposing future research directions.\r\n","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2006.14799","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1658,"title":"SimCLR - Contrastive Learning of Visual Representations","description":"How to load pretrained/finetuned SimCLR models from hub modules for fine-tuning.","tags":["article","code","notebook","paper","research","library","computer-vision","fine-tuning","representation-learning","self-supervised-learning","unsupervised-learning","simclr","contrastive-learning","pretraining","arxiv:2002.05709"],"details":"We updated the code to reflect some changes in SimCLRv2. The SimCLRv2 checkpoints and accompanying colabs are also released (see below).\r\n\r\n![simclr](https://camo.githubusercontent.com/d92c0e914af70fe618cf3ea555e2da1737d84bc4/68747470733a2f2f312e62702e626c6f6773706f742e636f6d2f2d2d764834504b704539596f2f586f3461324259657276492f414141414141414146704d2f766146447750584f79416f6b4143385868383532447a4f67457332324e68625877434c63424741735948512f73313630302f696d616765342e676966)","links":[{"article_link":"https://ai.googleblog.com/2020/04/advancing-self-supervised-and-semi.html","code_link":"https://github.com/google-research/simclr","research_link":"https://arxiv.org/abs/2002.05709","media_link":"","dataset_link":"","demo_link":"","other_link":"https://colab.research.google.com/github/google-research/simclr/blob/master/colabs/finetuning.ipynb"}]},{"id":1657,"title":"Fast Api with Dockerization of your ML Models","description":"In this GitHub repo you can able to know and learn how to build a fast API for testing your ML model and can test your ML model with UI and to Dockerize your ML","tags":["article","code","docker","fastapi","flask","production"],"details":"See the detailed explanation about both creation of [FastAPI](https://vpkprasanna.blogspot.com/2020/05/fast-api.html) and [Dockerization](https://vpkprasanna.blogspot.com/2020/05/how-to-dockerize-your-fast-api-app.html).","links":[{"article_link":"https://vpkprasanna.blogspot.com/2020/05/how-to-dockerize-your-fast-api-app.html","code_link":"https://github.com/VpkPrasanna/fastapi_Demo","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1656,"title":"Insights from Stackoverflow Dataset","description":"Analysis of Stackoverflow Developers Dataset to answer some business questions","tags":["article","code","python","machine-learning","data-science","exploratory-data-analysis"],"details":"For this project, I was interestested in using Stack Overflow data from 2017 to 2019 in order to better understand:\r\n\r\n1.     What programming languages are on the rise during the previous three years?\r\n2.     How does the education level affects the salary, job and career satisfaction?\r\n3.     Does the number of people who desire to work in a particular language accurately predicts its rise in the following year?\r\n4.     What does the developers in general think of higher management?\r\n","links":[{"article_link":"https://towardsdatascience.com/insights-from-stackoverflows-data-from-the-last-three-years-ea50bba90736","code_link":"https://github.com/nouman-10/Insights-from-Stackoverflow-Dataset","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1655,"title":"Rethinking pre-training and self-training","description":"This new paper from Google Brain investigates self-training and how it compares to pre-training and self-supervised learning for the the same set of tasks.","tags":["article","paper","research","deep-learning","machine-learning","self-supervised-learning","pretraining","arxiv:2006.06882","self-training"],"details":"","links":[{"article_link":"https://medium.com/@nainaakash012/rethinking-pre-training-and-self-training-53d489b53cbc","code_link":"","research_link":"https://arxiv.org/abs/2006.06882","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1654,"title":"3D Detection and Domain Adaptation","description":"1st Place Solution for Waymo Open Dataset Challenge","tags":["dataset","paper","research","automobile","3d","autonomous-vehicles","computer-vision","domain-adaptation","object-detection","waymo","arxiv:2006.15505"],"details":"In this technical report, we introduce our winning solution \"HorizonLiDAR3D\" for the 3D detection track and the domain adaptation track in Waymo Open Dataset Challenge at CVPR 2020. Many existing 3D object detectors include prior-based anchor box design to account for different scales and aspect ratios and classes of objects, which limits its capability of generalization to a different dataset or domain and requires post-processing (e.g. Non-Maximum Suppression (NMS)). We proposed a one-stage, anchor-free and NMS-free 3D point cloud object detector AFDet, using object key-points to encode the 3D attributes, and to learn an end-to-end point cloud object detection without the need of hand-engineering or learning the anchors. AFDet serves as a strong baseline in our winning solution and significant improvements are made over this baseline during the challenges. Specifically, we design stronger networks and enhance the point cloud data using densification and point painting. To leverage camera information, we append/paint additional attributes to each point by projecting them to camera space and gathering image-based perception information. The final detection performance also benefits from model ensemble and Test-Time Augmentation (TTA) in both the 3D detection track and the domain adaptation track. Our solution achieves the 1st place with 77.11% mAPH/L2 and 69.49% mAPH/L2 respectively on the 3D detection track and the domain adaptation track.","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2006.15505","media_link":"","dataset_link":"https://waymo.com/open/challenges","demo_link":"","other_link":"https://waymo.com/open/challenges"}]},{"id":1653,"title":"MARGE: Pre-training via Paraphrasing","description":"A retrieval model maps a document to a set of related documents, which a reconstruction model paraphrases to maximize the likelihood of the original. ","tags":["paper","research","natural-language-processing","pretraining","paraphrasing","marge","arxiv:2006.15020"],"details":"We introduce MARGE, a pre-trained sequence-to-sequence model learned with an unsupervised multi-lingual multi-document paraphrasing objective. MARGE provides an alternative to the dominant masked language modeling paradigm, where we self-supervise the reconstruction of target text by retrieving a set of related texts (in many languages) and conditioning on them to maximize the likelihood of generating the original. We show it is possible to jointly learn to do retrieval and reconstruction, given only a random initialization. The objective noisily captures aspects of paraphrase, translation, multi-document summarization, and information retrieval, allowing for strong zero-shot performance on several tasks. For example, with no additional task-specific training we achieve BLEU scores of up to 35.8 for document translation. We further show that fine-tuning gives strong performance on a range of discriminative and generative tasks in many languages, making MARGE the most generally applicable pre-training method to date.","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2006.15020","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1652,"title":"Julia for Pythonistas","description":"Julia looks and feels a lot like Python, only much faster. It's dynamic, expressive, extensible, with batteries included, in particular for Data Science.","tags":["code","notebook","tutorial","julia","python"],"details":"This notebook is an introduction to Julia for Python programmers.\r\n\r\nIt will go through the most important Python features (such as functions, basic types, list comprehensions, exceptions, generators, modules, packages, and so on) and show you how to code them in Julia.","links":[{"article_link":"","code_link":"https://colab.research.google.com/github/ageron/julia_notebooks/blob/master/Julia_for_Pythonistas.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1651,"title":"High-Resolution Image Inpainting","description":"High-Resolution Image Inpainting with Iterative Confidence Feedback and Guided Upsampling.\r\n","tags":["article","paper","research","computer-vision","inpainting","demo","high-resolution","image-inpainting","arxiv:2005.11742"],"details":"Existing image inpainting methods often produce artifacts when dealing with large holes in real applications. To address this challenge, we propose an iterative inpainting method with a feedback mechanism. Specifically, we introduce a deep generative model which not only outputs an inpainting result but also a corresponding confidence map. Using this map as feedback, it progressively fills the hole by trusting only high-confidence pixels inside the hole at each iteration and focuses on the remaining pixels in the next iteration. As it reuses partial predictions from the previous iterations as known pixels, this process gradually improves the result. In addition, we propose a guided upsampling network to enable generation of high-resolution inpainting results. We achieve this by extending the Contextual Attention module [1] to borrow high-resolution feature patches in the input image. Furthermore, to mimic real object removal scenarios, we collect a large object mask dataset and synthesize more realistic training data that better simulates user inputs. Experiments show that our method significantly outperforms existing methods in both quantitative and qualitative evaluations.","links":[{"article_link":"https://zengxianyu.github.io/iic/","code_link":"","research_link":"https://arxiv.org/abs/2005.11742","media_link":"","dataset_link":"","demo_link":"http://47.57.135.203:2333/","other_link":""}]},{"id":1650,"title":"The Reformer - Pushing the Limits of Language Modeling","description":"An in-depth understanding of each of the key features of the Reformer.","tags":["article","code","notebook","paper","research","tutorial","huggingface","transformers","language-modeling","natural-language-processing","reformer","arxiv:2001.04451"],"details":"* **Main article**: [https://huggingface.co/blog/reformer](https://huggingface.co/blog/reformer)\r\n* **Part 1**: [https://colab.research.google.com/drive/15oP52_7W5dRcAnbgX3tYADsu4R3cjMIf](https://colab.research.google.com/drive/15oP52_7W5dRcAnbgX3tYADsu4R3cjMIf)\r\n* **Part 2**: [https://colab.research.google.com/drive/1xKK32Yhda-iYgtoA3eCrnCVuy_lraQR9](https://colab.research.google.com/drive/1xKK32Yhda-iYgtoA3eCrnCVuy_lraQR9)\r\n* **Part 3**: [https://colab.research.google.com/drive/1BLffcRt9LXmM7nKU2UXhtm0PqAG0UE7J](https://colab.research.google.com/drive/1BLffcRt9LXmM7nKU2UXhtm0PqAG0UE7J)\r\n* **Part 4**: [https://colab.research.google.com/drive/1MYxvC4RbKeDzY2lFfesN-CvPLKLk00CQ\r\n](https://colab.research.google.com/drive/1MYxvC4RbKeDzY2lFfesN-CvPLKLk00CQ)\r\n\r\nThe memory improvements can be attributed to 4 features which the Reformer authors introduced to the transformer world:\r\n\r\n* **Reformer Self-Attention Layer** - How to efficiently implement self-attention without being restricted to a local context?\r\n* **Chunked Feed Forward Layers** - How to get a better time-memory trade-off for large feed forward layers?\r\n* **Reversible Residual Layers** - How to drastically reduce memory consumption in training by a smart residual architecture?\r\n* **Axial Positional Encodings** - How to make positional encodings usable for extremely large input sequences?\r\n\r\nThe goal of this blog post is to give the reader an in-depth understanding of each of the four Reformer features mentioned above. While the explanations are focused on the Reformer, the reader should get a better intuition under which circumstances each of the four features can be effective for other transformer models as well. The four sections are only loosely connected, so they can very well be read individually.","links":[{"article_link":"https://huggingface.co/blog/reformer","code_link":"https://colab.research.google.com/drive/15oP52_7W5dRcAnbgX3tYADsu4R3cjMIf","research_link":"https://arxiv.org/abs/2001.04451","media_link":"","dataset_link":"","demo_link":"","other_link":"https://github.com/patrickvonplaten/notebooks"}]},{"id":1649,"title":"Model Serving using FastAPI and streamlit","description":"Simple example of usage of streamlit and FastAPI for ML model serving.","tags":["article","code","tutorial","video","fastapi","computer-vision","semantic-segmentation","streamlit","segmentation","deeplabv3"],"details":"Simple example of usage of streamlit and FastAPI for ML model serving described on [a blogpost](https://davidefiocco.github.io/2020/06/27/streamlit-fastapi-ml-serving.html) and [video](https://www.youtube.com/watch?v=IvHCxycjeR0).\r\n\r\nWhen developing simple APIs that serve machine learning models, it can be useful to have both a backend (with API documentation) for other applications to call and a frontend for users to experiment with the functionality.\r\n\r\nIn this example, we serve an [image semantic segmentation model](https://pytorch.org/hub/pytorch_vision_deeplabv3_resnet101/) using FastAPI for the backend service and streamlit for the frontend service. docker-compose orchestrates the two services and allows communication between them.","links":[{"article_link":"https://davidefiocco.github.io/2020/06/27/streamlit-fastapi-ml-serving.html","code_link":"https://github.com/davidefiocco/streamlit-fastapi-model-serving/","research_link":"","media_link":"https://www.youtube.com/watch?v=IvHCxycjeR0","dataset_link":"","demo_link":"","other_link":"https://pytorch.org/hub/pytorch_vision_deeplabv3_resnet101/"}]},{"id":1648,"title":"STUMPY: A Powerful and Scalable Python Library for Time Series","description":"STUMPY is a powerful and scalable Python library for computing a Matrix Profile, which can be used for a variety of time series data mining tasks.","tags":["article","code","video","library","anomaly-detection","time-series","numba","dask","pattern-matching","matrix-profile","pydata"],"details":"* Part 1: [The Matrix Profile](https://medium.com/@seanmylaw/the-matrix-profile-e4a679269692)\r\n* Part 2: [STUMPY Basics](https://medium.com/@seanmylaw/stumpy-basics-21844a2d2d92)\r\n* Part 3: [Time Series Chains](https://medium.com/@seanmylaw/part-3-time-series-chains-da281450abbf)\r\n* Part 4: [Semantic Segmentation](https://medium.com/@seanmylaw/part-4-semantic-segmentation-b42c3792833d)\r\n* Part 5: [Fast Approximate Matrix Profiles with STUMPY](https://medium.com/@seanmylaw/part-5-fast-approximate-matrix-profiles-with-scrump-c6d9c984c560)\r\n* Part 6: [Matrix Profiles for Streaming Time Series Data](https://medium.com/@seanmylaw/matrix-profiles-for-streaming-time-series-data-f877ff6f9eef)","links":[{"article_link":"https://towardsdatascience.com/the-matrix-profile-e4a679269692","code_link":"https://github.com/TDAmeritrade/stumpy","research_link":"","media_link":"https://www.youtube.com/watch?v=WvaBPSeA_JA","dataset_link":"","demo_link":"","other_link":"https://stumpy.readthedocs.io/en/latest/tutorials.html"}]},{"id":1647,"title":"Mixed Precision Training ","description":"Mixed precision  Investigation  in using  16-bit and 32-bit floating-point types in a model during training","tags":["article","tutorial","machine-learning","training","mixed-precision"],"details":"* High level Introduction about Mixed Precision Training .\r\n* Explain issues In Half Precision.\r\n* Main issues which prevent from training with FP16.\r\n* The Proposed Techniques for Training with Mixed Precision.\r\n* Investigate in Mixed Precision Training Steps.\r\n* Mixed Precision In Frameworks (Tensorflow - Pytorch ).\r\n","links":[{"article_link":"https://islammohamedmosaad.github.io/journal/Mixed-Precision-Training.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1646,"title":"Twitter Turing Test","description":"Can you guess whether this tweet is written by a human or generated by a neural network?","tags":["code","dataset","tutorial","huggingface","python","gpt2","transformers","natural-language-processing","text-generation","demo","twitter","modelzoo"],"details":"# Twitter Turing Test\r\n\r\nA game where you need to guess whether a tweet comes from a human, or from a\r\nneural network language model trained on a category of tweets.\r\n\r\n[![Deployed on Model Zoo](https://modelzoo-public.s3-us-west-2.amazonaws.com/model-zoo-badge-white-github.png)](https://app.modelzoo.dev/models/gpt2-twitter-vc)\r\n\r\n## [Live Demo](https://twitterturingtest.modelzoo.dev)\r\n\r\n## Overview\r\n\r\nThis project uses the following open source projects for developing our  models:\r\n\r\n* [twint](https://github.com/twintproject/twint) for scraping twitter data from a set of usernames. For some larger datasets, [scrapoxy](https://scrapoxy.readthedocs.io/en/master/quick_start/index.html) is used as a proxy pool for avoiding Twitter's IP blacklist.\r\n\r\n* [Hugging Face Transformers](https://huggingface.co/) for fine-tuning the [Open AI GPT-2](https://openai.com/blog/better-language-models/) model on additional data.\r\n\r\nModels are deployed to [Model Zoo](https://modelzoo.dev/) for a realtime HTTP endpoint.\r\n\r\nThe frontend React application is a wrapper around a dataset of static tweets and the Model Zoo HTTP endpoints. See [frontend documentation](./frontend/README.md) for more details.\r\n\r\n## How to train and deploy your own language model\r\n\r\n#### Preparing the dataset\r\n\r\nThe script `download-tweets.sh` contains our methodology for scraping a twitter dataset with [twint](https://github.com/twintproject/twint). The script accepts a single argument `$name`, and searches for a file `sources/$name.txt` which should specify a list of twitter handles to scrape from. The scraping script applies some crude heuristics to attempt to filter out tweets that (1) are replies to other tweets and (2) that have links in them. These heuristics aren't perfect, but I found they worked good enough.\r\n\r\nIn preparing several datasets with [twint](https://github.com/twintproject/twint), I found that Twitter was often blacklisting our IP a few minutes into the scraping process. To get around this, I used [scrapoxy on EC2](https://scrapoxy.readthedocs.io/en/master/standard/providers/awsec2/index.html) to scrape from five different EC2 proxy instances at once.\r\n\r\nSeveral datasets have been prepared and released publicly on AWS that you are free to use at `s3://modelzoo-datasets/text-generation`.\r\n\r\nThank you to [minimaxir/download-tweets-ai-textgen](https://github.com/minimaxir/download-tweets-ai-text-gen) for supplying a list of republican and democrat twitter handles.\r\n\r\n#### Training the model\r\n\r\nThe script `train.py` includes code to load pretrained weights and fine-tune the model, largely adapted from the [Hugging Face Language Modeling example](https://github.com/huggingface/transformers/tree/master/examples/language-modeling). Each model was trained on a single K80 GPU. All of the models were trained for\r\na single epoch except for COVID-19, which was a slightly smaller dataset and\r\ntrained for two epochs. Model training took somewhere between 6 - 16 hours for each model.\r\n\r\nThe training process could be improved further with hyperparameter optimization\r\nand additional experimentation. This is left as an exercise to the reader :)\r\n\r\n#### Deploying the model\r\n\r\nThe model is automatically deployed after training using the [Model Zoo](https://modelzoo.dev/) `transformers` support and a few lines of code:\r\n\r\n```\r\ntextgen = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\r\nmodelzoo.transformers.deploy(\r\n    textgen,\r\n    model_name=\"...\"\r\n    resources_config=modelzoo.ResourcesConfig(memory_mb=2048, cpu_units=1024),\r\n)\r\n```\r\n\r\nPlease ensure you run `$ modelzoo auth` to create or login to a Model Zoo account in your training environment. Alternatively, you can set the environment variable `MODELZOO_API_KEY` accordingly.\r\n\r\nSee [`modelzoo.transformers.deploy`](https://docs.modelzoo.dev/reference/modelzoo.transformers.html#modelzoo.transformers.deploy) for more details.","links":[{"article_link":"","code_link":"https://github.com/model-zoo/twitter-turing-test","research_link":"","media_link":"","dataset_link":"s3://modelzoo-datasets/text-generation","demo_link":"https://twitterturingtest.modelzoo.dev","other_link":"https://modelzoo.dev"}]},{"id":1645,"title":"Using Data Science Pipelines for Disaster Response","description":"Uses ETL and ML pipeline to build an NLP system for classification of messages into appropriate disaster categories","tags":["article","code","flask","machine-learning","natural-language-processing","data-science","natural-disasters","etl"],"details":"In this project, I have used analyze disaster data from Figure Eight to build a model for an API that classifies disaster messages.\r\n\r\nI have created an ETL pipeline that loads and cleans the data into a database to make it ready for modelling and analyzing\r\n\r\nThen, an ML pipeline is incorporated that tokenizes the data and builds a supervised ML pipeline for classification\r\n\r\nFinally, a web app using Flask is built to visualize the data and show the classification results.","links":[{"article_link":"https://towardsdatascience.com/using-data-science-pipelines-for-disaster-response-d1df827b9058","code_link":"https://github.com/nouman-10/Disaster-Response","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1644,"title":"A research guide for data scientists","description":"Tips on research from top data scientists","tags":["article","research","deep-learning","natural-language-processing"],"details":"","links":[{"article_link":"https://pakodas.substack.com/p/a-data-scientist-without-a-phd","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1643,"title":"FastAPI for Flask Users","description":"A comprehensive guide to FastAPI with a side-by-side code comparison with Flask ","tags":["api","article","tutorial","fastapi","flask"],"details":"- Learn to migrate an API from Flask to FastAPI\r\n- Learn about the batteries-included philosophy of FastAPI to develop APIs at a rapid pace","links":[{"article_link":"https://amitness.com/2020/06/fastapi-vs-flask/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1642,"title":"Sending Email with .docx Attachment using Python","description":"This article will explore how to send email with attachment in Python and how it can be integrated in your existing data science projects.","tags":["article","tutorial","python","program-development"],"details":"","links":[{"article_link":"https://pyshark.com/sending-email-with-docx-attachment-using-python/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1641,"title":"Hugging Captions","description":"Generate realistic instagram worthy captions using transformers given a hasthtag and a small text snippet.","tags":["article","code","huggingface","transformers","computer-vision","image-captioning","language-modeling","natural-language-processing","text-generation","instagram"],"details":"Hugging Captions fine-tunes [GPT-2](https://openai.com/blog/better-language-models/), a transformer-based language model by [OpenAI](https://openai.com/), to generate realistic photo captions. All of the transformer stuff is implemented using [Hugging Face's Transformers library](https://github.com/huggingface/transformers), hence the name Hugging Captions.","links":[{"article_link":"","code_link":"https://github.com/antoninodimaggio/Hugging-Captions","research_link":"","media_link":"https://www.instagram.com/huggingcaptions/","dataset_link":"","demo_link":"","other_link":""}]},{"id":1640,"title":"Smooth Adversarial Training","description":"ReLU activation function significantly weakens adversarial training due to its non-smooth nature. Hence we propose smooth adversarial training (SAT).","tags":["paper","research","relu","adversarial-learning","adversarial-training","sat","arxiv:2006.14536"],"details":"It is commonly believed that networks cannot be both accurate and robust, that gaining robustness means losing accuracy. It is also generally believed that, unless making networks larger, network architectural elements would otherwise matter little in improving adversarial robustness. Here we present evidence to challenge these common beliefs by a careful study about adversarial training. Our key observation is that the widely-used ReLU activation function significantly weakens adversarial training due to its non-smooth nature. Hence we propose smooth adversarial training (SAT), in which we replace ReLU with its smooth approximations to strengthen adversarial training. The purpose of smooth activation functions in SAT is to allow it to find harder adversarial examples and compute better gradient updates during adversarial training. Compared to standard adversarial training, SAT improves adversarial robustness for \"free\", i.e., no drop in accuracy and no increase in computational cost. For example, without introducing additional computations, SAT significantly enhances ResNet-50's robustness from 33.0% to 42.3%, while also improving accuracy by 0.9% on ImageNet. SAT also works well with larger networks: it helps EfficientNet-L1 to achieve 82.2% accuracy and 58.6% robustness on ImageNet, outperforming the previous state-of-the-art defense by 9.5% for accuracy and 11.6% for robustness.","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2006.14536","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1639,"title":"Computer Vision Recipes","description":"This repository provides examples and best practice guidelines for building computer vision systems.","tags":["article","code","tutorial","pytorch","computer-vision","crowd-counting","image-classification","object-detection","segmentation","action-recognition","recipe","keypoints-detection"],"details":"The goal of this repository is to build a comprehensive set of tools and examples that leverage recent advances in Computer Vision algorithms, neural architectures, and operationalizing such systems. Rather than creating implementions from scratch, we draw from existing state-of-the-art libraries and build additional utility around loading image data, optimizing and evaluating models, and scaling up to the cloud. In addition, having worked in this space for many years, we aim to answer common questions, point out frequently observed pitfalls, and show how to use the cloud for training and deployment.","links":[{"article_link":"https://medium.com/pytorch/pytorch-computer-vision-library-for-experts-and-beginners-84b9157584e5","code_link":"https://github.com/microsoft/computervision-recipes/","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://pytorch.org/tutorials/recipes/recipes_index.html"}]},{"id":1638,"title":"Dakshina Dataset","description":"A collection of text in both Latin and native scripts for 12 South Asian languages.","tags":["code","dataset","paper","research","natural-language-processing","languages","dakshina"],"details":"The Dakshina dataset is a collection of text in both Latin and native scripts for 12 South Asian languages. For each language, the dataset includes a large collection of native script Wikipedia text, a romanization lexicon which consists of words in the native script with attested romanizations, and some full sentence parallel data in both a native script of the language and the basic Latin alphabet.","links":[{"article_link":"","code_link":"https://github.com/google-research-datasets/dakshina","research_link":"https://www.aclweb.org/anthology/2020.lrec-1.294","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1637,"title":"AquVitae: The Easiest Knowledge Distillation Library","description":"AquVitae is a Python library that is the easiest to perform Knowledge Distillation through a very simple API. This library supports TensorFlow and PyTorch. Know","tags":["code","pytorch","tensorflow","deep-learning","machine-learning","library","knowledge-distillation","model-compression","light-weight"],"details":"github.com/aquvitae/aquvitae","links":[{"article_link":"","code_link":"https://github.com/aquvitae/aquvitae","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1636,"title":"Automatic translation of the SQUAD dataset to spanish","description":"Machine translation is used on the SQuAD dataset to produce an equivalent dataset in Spanish. Word alignment is applied to produce a synthetic spanisQA corpus.\r\n","tags":["code","paper","research","natural-language-processing","natural-language-understanding","question-answering","spanish","arxiv:1912.05200"],"details":"","links":[{"article_link":"","code_link":"https://github.com/ccasimiro88/TranslateAlignRetrieve","research_link":"https://arxiv.org/abs/1912.05200","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1635,"title":"A Weighted Mutual k-Nearest Neighbour for Classification Mining","description":"kNN revisited","tags":["code","paper","research","k-nearest-neighbors","arxiv:2005.08640"],"details":"kNN is a very effective Instance based learning\r\nmethod, and it is easy to implement. Due to heterogeneous nature\r\nof data, noises from different possible sources are also widespread\r\nin nature especially in case of large-scale databases. For noise\r\nelimination and effect of pseudo neighbours, in this paper, we\r\npropose a new learning algorithm which performs the task of\r\nanomaly detection and removal of pseudo neighbours from the\r\ndataset so as to provide comparative better results. This\r\nalgorithm also tries to minimize effect of those neighbours which\r\nare distant. A concept of certainty measure is also introduced for\r\nexperimental results. The advantage of using concept of mutual\r\nneighbours and distance-weighted voting is that, dataset will be\r\nrefined after removal of anomaly and weightage concept compels\r\nto take into account more consideration of those neighbours,\r\nwhich are closer.","links":[{"article_link":"","code_link":"https://github.com/x0v/A-Weighted-Mutual-k-Nearest-Neighbour-for-Classification-Mining","research_link":"https://arxiv.org/abs/2005.08640","media_link":"https://docs.google.com/presentation/d/1C00HLW8MezByDuMc4nB2r_y2FYNmWaH7x7LM-pgsTx8/embed?start=false&loop=true&delayms=3000&slide=id.p3","dataset_link":"","demo_link":"","other_link":""}]},{"id":1634,"title":"Introduction to Probabilistic Programming","description":"A brief intoduction to Probabilistic Programming, a tool for modelling tasks with uncertainty.","tags":["article","code","tutorial","deep-learning","machine-learning","uncertainty","probability"],"details":"Welcome to another tutorial about probabilistic models, after a primer on [PGMs](https://dasayan05.github.io/blog-tut/2019/11/20/inference-in-pgm.html) and [VAE](https://dasayan05.github.io/blog-tut/2020/01/01/variational-autoencoder.html). However, I am particularly excited to discuss a topic that does not get as much attention as traditional Deep Learning does. The idea of Probabilistic Programming has long been there in the ML literature and got enriched over time. Before it creates confusion, let\u2019s de-clutter it right now - it\u2019s not really writing traditional \u201cprograms\u201d, rather it\u2019s building Probabilistic Graphical Models (PGMs), but equipped with imperative programming style (i.e., iterations, branching, recursion etc). Just like Automatic Differentiation allowed us to compute derivative of arbitrary computation graphs (in PyTorch, TensorFlow), Black-box methods have been developed to \u201csolve\u201d probabilistic programs. In this post, I will provide a generic view on why such a language is indeed possible and how such black-box solvers are materialized. At the end, I will also introduce you to one such Universal Probabilistic Programming Language, [Pyro](http://pyro.ai/), that came out of Uber\u2019s AI lab and started gaining popularity.\r\n\r\n![example_loss](https://dasayan05.github.io/public/posts_res/16/example_loss.gif)\r\nThe full code is available in this gist: [https://gist.github.com/dasayan05/aca3352cd00058511e8372912ff685d8](https://gist.github.com/dasayan05/aca3352cd00058511e8372912ff685d8)","links":[{"article_link":"https://dasayan05.github.io/blog-tut/2020/05/05/probabilistic-programming.html","code_link":"https://gist.github.com/dasayan05/aca3352cd00058511e8372912ff685d8","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"http://dasayan05.github.io/"}]},{"id":1633,"title":"FACEAPP Gender Swap Fake detection","description":"In this project we used Deep Learning to detect fake images generated by FaceApp app gender swap feature.","tags":["code","fastai","deep-learning"],"details":"# FACEAPP gender swap fake detection\r\n\r\nIn this project we used Deep Learning to detect fake images generated by FaceApp app gender swap feature.\r\n\r\n#### Actual\r\n![](https://github.com/moaaztaha/Faceapp-Gender-Swap-Detection/blob/master/imgs/output_o.png?raw=true) \r\n#### Fake\r\n![](https://github.com/moaaztaha/Faceapp-Gender-Swap-Detection/raw/master/imgs/output_f.png)\r\n\r\n\r\n\r\n\r\n## Overview \r\n\r\nFACEAPP is a famous app that uses Deep Learning to generate fake pictures of people with different styles of hair, makeup and so on. But in this project we are interested in its gender swap feature which as its name indicates turns images of males into females and vice versa. \r\n\r\n![](https://github.com/moaaztaha/Faceapp-Gender-Swap-Detection/raw/master/imgs/example.jpg)\r\n\r\n\r\n\r\n## Goal\r\n\r\nThe goal is to scrap a decent amount of fake and original images, clean the images and train a deep learning model using transfer learning and FASTAI to achieve a good accuracy.\r\n\r\n## Table of content\r\n\r\n- [Requirements](#Requirements)\r\n- [Scrapping Data](#Scrapping Data)\r\n- [Cleaning Data](#Cleaning Data)\r\n- [Training the Model](#Training the Model)\r\n\r\n## Requirements\r\n\r\n- Python 3.x\r\n- Matplotlib\r\n\r\n### Scrapping & Cleaning\r\n\r\n- Tweepy: for scrapping twitter data\r\n- OpenCV: for cropping the images and creating new images\r\n- shutil: for moving files\r\n- Jupyter notebooks widgets:  for easier data cleaning\r\n\r\n### Training\r\n\r\n- [FASTAI](https://github.com/fastai/course-v3)\r\n\r\n## Scrapping Data\r\n\r\n### Tweets(Images) at `#faceapp`\r\n\r\n- Scrapped images in the tweets of this hashtag as most people that uses the application either talks about it or uses the hashtag when uploading their generated pictures.\r\n- Images were saved in a folder called `data` so that we can clean it later.\r\n\r\n### Tweets(Images) at `#new_avatar`\r\n\r\n- After cleaning the data, I found that the data was not balanced. So I downloaded some images at this hashtag as people tend to put their real images as profile pictures and attach the hashtag.\r\n- Images were saved in a folder called `more_original` and were finally added to the `original` folder before training.\r\n\r\n## Cleaning Data\r\n\r\n### Real & Fake Images \r\n\r\n[notebook]([https://github.com/moaaztaha/Faceapp-Gender-Swap-Detection/blob/master/Filter%20Data.ipynb](https://github.com/moaaztaha/Faceapp-Gender-Swap-Detection/blob/master/Filter Data.ipynb))\r\n\r\n- Used Jupyter notebook widgets to create a widget with buttons so that I can move images with a single click to their corresponding folders\r\n- **Buttons**\r\n   - **Original**: moves images of real people to the **original folder**\r\n   - **Fake**: moves images of fake people to the **fake folder**\r\n   - **Delete**: *deletes* images that doesn't have people in it or irrelevant\r\n   - **Later**: moves images that have **a collage of fake and real images** to a **later folder** to be **processed later**\r\n   - **Skip**: skips the current image and plots the next one\r\n\r\n#### Widget Layout\r\n\r\n![](https://github.com/moaaztaha/Faceapp-Gender-Swap-Detection/raw/master/imgs/widget.png)\r\n\r\n### Later Images / Collage images of both fake and real images\r\n\r\n[notebook]([https://github.com/moaaztaha/Faceapp-Gender-Swap-Detection/blob/master/Fix%20Later%20data.ipynb](https://github.com/moaaztaha/Faceapp-Gender-Swap-Detection/blob/master/Fix Later data.ipynb))\r\n\r\n- The code shows a window with the collage image\r\n- We then select the area of the image using the mouse\r\n - When we click **`o`** on the keyboard it means the selected area contains real person and it's moved to the original folder\r\n - When we click **`f`** it means the selected area contains a fake image generated by **faceapp** and moved to the fake folder\r\n - When we click **`q`** it will take us to the next image\r\n\r\n![](https://github.com/moaaztaha/Faceapp-Gender-Swap-Detection/raw/master/imgs/later.gif)\r\n\r\n\r\n\r\n## Training the Model\r\n\r\n[notebook]([https://github.com/moaaztaha/Faceapp-Gender-Swap-Detection/blob/master/Training%20a%20model.ipynb](https://github.com/moaaztaha/Faceapp-Gender-Swap-Detection/blob/master/Training a model.ipynb))\r\n\r\nI used FASTAI to train my models\r\n\r\n- I tried a resnet34 and resnet50\r\n\r\n  - Each time I started with half the size 128x128 pixels\r\n  - With the default data augmentation\r\n    - Horizontal flip, max rotation:10, max zoom: 1.1, max lighting: 0.2\r\n  - Trained for some epochs \r\n  - Unfreezed and trained for some more epochs\r\n  - Changed the dropout start and trained for more epochs\r\n  - Then moved to full size 244x244 pixels and did the same steps again with the previous model as my starting point\r\n\r\n#### RESNET 50\r\n ![](https://github.com/moaaztaha/Faceapp-Gender-Swap-Detection/raw/master/imgs/resnet50.png) \r\n#### RESNET 34\r\n![](https://github.com/moaaztaha/Faceapp-Gender-Swap-Detection/raw/master/imgs/resnet34.png)\r\n\r\n  \r\n\r\n- I found that resnet34 produced better results So,\r\n\r\n  - Increased data augmentation \r\n    - **max rotate to 30 degrees** and **max lighting to .5** as many people take **selfies in different angels and they use filters** which has a similar effect to the lighting so increasing these 2 parameters should help.\r\n  - Loaded my **best resnet34** model and followed the same steps [half size -> full size -> unfreeze]\r\n\r\n### Final Results\r\n\r\n![image-20200628133617706](https://github.com/moaaztaha/Faceapp-Gender-Swap-Detection/raw/master/imgs/final_results.png)\r\n\r\n**Accuracy: 98.1%**\r\n\r\n![image-20200628134037098](https://github.com/moaaztaha/Faceapp-Gender-Swap-Detection/raw/master/imgs/most_confused.png)\r\n\r\n- The model had only 2 mistakes on the validation set which are  the first 2 images (keep in mind that the validation set was quite small)\r\n\r\n![image-20200628134201988](https://github.com/moaaztaha/Faceapp-Gender-Swap-Detection/raw/master/imgs/confusion_matrix.png)","links":[{"article_link":"","code_link":"https://github.com/moaaztaha/Faceapp-Gender-Swap-Detection","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1630,"title":"Semantic Segmentation + Background Removal + Style Transfer","description":"Running multiple TF Lite models to perform semantic segmentation, remove background, and apply style transfer. ","tags":["code","notebook","tutorial","computer-vision","tf-lite"],"details":"The total size of all the models used is under **4 MB**. ","links":[{"article_link":"","code_link":"https://colab.research.google.com/github/sayakpaul/Adventures-in-TensorFlow-Lite/blob/master/Semantic_Segmentation_+_Background_Removal_+_Style_Transfer.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1629,"title":"TF Lite Semantic Segmentation Models","description":"Faster and lighter TF Lite models can perform semantic segmentation. ","tags":["article","code","tutorial","deep-learning","library","computer-vision","tf-lite"],"details":"All of the models are accompanied by Colab Notebooks that show the model conversion process and demonstrate how to run inference with them using the TF Lite Python Interpreter. \r\n\r\n**Note**: These models were specifically created to enable mobile developers to run fast and efficient semantic segmentation in realtime. Also, many of you had asked me if I had any examples that show how to use TF Lite for non-trivial conversions. Well, now you got one.","links":[{"article_link":"https://tfhub.dev/s?publisher=sayakpaul","code_link":"https://github.com/sayakpaul/Adventures-in-TensorFlow-Lite/blob/master/DeepLabV3","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md"}]},{"id":1628,"title":"Deep Reinforcement Learning Amidst Lifelong Non-Stationarity","description":"How can robots learn in changing, open-world environments? We introduce dynamic-parameter MDPs, to capture environments with persistent, unobserved changes. ","tags":["article","paper","research","reinforcement-learning","non-stationarity","off-policy","markov-decision-process","arxiv:2006.10701"],"details":"As humans, our goals and our environment are persistently changing throughout our lifetime based on our experiences, actions, and internal and external drives. In contrast, typical reinforcement learning problem set-ups consider decision processes that are stationary across episodes. Can we develop reinforcement learning algorithms that can cope with the persistent change in the former, more realistic problem settings? While on-policy algorithms such as policy gradients in principle can be extended to non-stationary settings, the same cannot be said for more efficient off-policy algorithms that replay past experiences when learning. In this work, we formalize this problem setting, and draw upon ideas from the online learning and probabilistic inference literature to derive an off-policy RL algorithm that can reason about and tackle such lifelong non-stationarity. Our method leverages latent variable models to learn a representation of the environment from current and past experiences, and performs off-policy RL with this representation. We further introduce several simulation environments that exhibit lifelong non-stationarity, and empirically find that our approach substantially outperforms approaches that do not reason about environment shift.","links":[{"article_link":"https://sites.google.com/stanford.edu/lilac/","code_link":"","research_link":"https://arxiv.org/abs/2006.10701","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1627,"title":"Timecraft: Synthesizing Time Lapse Videos of Paintings","description":"A learning-based method for synthesizing time lapse videos of paintings.","tags":["article","code","paper","research","video","keras","tensorflow","cvpr-2020","paintings","time-lapse","arxiv:2001.01026"],"details":"In this research project, we explore a new problem of synthesizing time lapse videos depicting the creation of paintings.","links":[{"article_link":"https://xamyzhao.github.io/timecraft/","code_link":"https://github.com/xamyzhao/timecraft","research_link":"https://arxiv.org/abs/2001.01026","media_link":"https://www.youtube.com/watch?v=iy1FCPQs4JI","dataset_link":"","demo_link":"","other_link":""}]},{"id":1626,"title":"5 Genetic Algorithm Applications Using PyGAD","description":"This tutorial introduces PyGAD, an open-source Python library for implementing the genetic algorithm and training machine learning algorithms.","tags":["article","code","library","genetic-algorithms","pygad"],"details":"This tutorial introduces [PyGAD](https://github.com/ahmedfgad/GeneticAlgorithmPython), an open-source Python library for implementing the genetic algorithm and training machine learning algorithms. PyGAD supports 19 parameters for customizing the genetic algorithm for various applications.\r\n\r\nWithin this tutorial we'll discuss 5 different applications of the genetic algorithm and build them using PyGAD.\r\n\r\nThe outline of the tutorial is as follows:\r\n\r\n* PyGAD Installation\r\n* Getting Started with PyGAD\r\n* Fitting a Linear Model\r\n* Reproducing Images\r\n* 8 Queen Puzzle\r\n* Training Neural Networks\r\n* Training Convolutional Neural Networks","links":[{"article_link":"https://blog.paperspace.com/genetic-algorithm-applications-using-pygad/","code_link":"https://github.com/ahmedfgad/GeneticAlgorithmPython","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://pygad.readthedocs.io/en/latest/"}]},{"id":1625,"title":"Beginner's Guide to Altair Visualization","description":"Getting started with Visualization using Altair on Kaggle with this simple tutorial.","tags":["code","notebook","tutorial","visualization","altair","exploratory-data-analysis"],"details":"This is a tutorial that will help you to get started with Altair. Interactive plots can be created with a few lines of code. ","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.kaggle.com/shwetagoyal4/beginner-s-guide-to-altair-visualization"}]},{"id":1624,"title":"Avatarify - Create Your Own Photorealistic Avatars","description":"Photorealistic avatars for video-conferencing apps. Democratized.","tags":["code","notebook","paper","research","generative-adversarial-networks","stylegan","avatars","avatar0fy","arxiv:2003.00196"],"details":"Photorealistic avatars for video-conferencing [apps](https://github.com/alievk/avatarify#configure-video-meeting-app). Democratized.\r\nBased on [First Order Motion Model](https://github.com/AliaksandrSiarohin/first-order-model).","links":[{"article_link":"","code_link":"https://github.com/alievk/avatarify","research_link":"https://arxiv.org/abs/2003.00196","media_link":"","dataset_link":"","demo_link":"","other_link":"https://colab.research.google.com/github/alievk/avatarify/blob/master/avatarify.ipynb"}]},{"id":1623,"title":"Introduction to NLP using Fastai","description":"Implementing and decoding the revolutionary ULMFiT approach to train a language model on any downstream NLP task.","tags":["article","notebook","tutorial","fastai","natural-language-processing","sentiment-analysis","ulmfit"],"details":"In continuation to my previous posts [1](https://harish3110.github.io/through-tinted-lenses/fastai/image%20classification/2020/03/29/Building-an-image-classifier-using-Fastai-V2.html), [2](https://harish3110.github.io/through-tinted-lenses/fastai/image%20classification/model%20fine-tuning/2020/04/10/Improving-baseline-model.html), which delved into the domain of computer vision by building and fine-tuning an image classification model using Fastai, I would like to venture into the fascinating domain of Natural Language Processing using Fastai.\r\n\r\nFor this post we'll be working on the [Real or Not? NLP with Disaster Tweets](https://www.kaggle.com/c/nlp-getting-started/overview) competition dataset on Kaggle to build a text classifier to distinguish between normal tweets and tweets sent out during a natural disaster using the ULMFiT approach and decoding this revolutionary paper that changed the NLP schenario for the better in the recent years.","links":[{"article_link":"https://harish3110.github.io/through-tinted-lenses/natural language processing/sentiment analysis/2020/06/27/Introduction-to-NLP-using-Fastai.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://colab.research.google.com/github/harish3110/through-tinted-lenses/blob/master/_notebooks/2020-06-27-Introduction%20to%20NLP%20using%20Fastai.ipynb"}]},{"id":1622,"title":"Building AI Trading Systems","description":"Lessons learned building a profitable algorithmic trading system using Reinforcement Learning techniques.","tags":["article","machine-learning","finance","reinforcement-learning","trading","algorithmic-trading"],"details":"If you come from a tech or startup background, transitioning to trading may require a change in thinking. Products and engineering are often about absolutes. If your website takes 100ms to load that's pretty good. Making it load in 99ms provides negligible benefit to the end-user. It'd be a waste of engineering resources. The same is true for startups. Paul Graham likes to say that startups are rarely killed by competitors. Rather, they commit suicide. They fail because they cannot find customers, don't have a solid business model, or because of founder issues. Being killed by competition with a slightly better product is quite rare.\r\n\r\nTrading is different. It's about relatives. It's fine if your website takes a horrible 10 seconds to load if your competitor needs 11 seconds. Having crappy data is fine if everyone else's data is even crappier. Paying high trading fees is fine if everyone is paying the same. This is pretty obvious if you look at the market as a multiplayer game. Even if you're a bad player on an absolute scale, you can win if your competition is worse. This has direct effects on how you build software to trade in the markets.","links":[{"article_link":"https://dennybritz.com/blog/ai-trading/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1621,"title":"The Lottery Ticket Hypothesis: A Survey","description":"Dive deeper into the lottery ticket hypothesis and review the literature after the original ICLR best paper award by Frankle & Carbin (2019).","tags":["article","paper","research","tutorial","deep-learning","model-compression","pruning","survey","lottery-ticket-hypothesis"],"details":"Metaphors are powerful tools to transfer ideas from one mind to another. Alan Kay introduced the alternative meaning of the term \u2018desktop\u2019 at Xerox PARC in 1970. Nowadays everyone - for a glimpse of a second - has to wonder what is actually meant when referring to a desktop. Recently, Deep Learning had the pleasure to welcome a new powerful metaphor: The Lottery Ticket Hypothesis (LTH). But what idea does the Hypothesis try to transmit? In todays post we dive deeper into the hypothesis and review the literature after the original ICLR best paper award by Frankle & Carbin (2019).","links":[{"article_link":"https://roberttlange.github.io/posts/2020/06/lottery-ticket-hypothesis/","code_link":"","research_link":"https://github.com/RobertTLange/code-and-blog/blob/master/05_lottery_tickets/lange2020_lottery_ticket_hypothesis.pdf","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1620,"title":"rlx: A modular Deep RL library for research","description":"\"rlx\" is a Deep RL library written on top of PyTorch & built for educational and research purpose.","tags":["article","code","pytorch","deep-learning","library","reinforcement-learning"],"details":"[rlx](https://github.com/dasayan05/rlx) is a Deep RL library written on top of PyTorch & built for educational and research purpose. Majority of the libraries/codebases for Deep RL are geared more towards reproduction of state-of-the-art algorithms on very specific tasks (e.g. Atari games etc.), but **rlx** is NOT. It is supposed to be more expressive and modular. Rather than making RL algorithms as black-boxes, **rlx** adopts an API that tries to expose more granular operation to the users which makes writing new algorithms easier. It is also useful for implementing task specific engineering into a known algorithm.\r\n\r\nConcisely, rlx is supposed to\r\n\r\n- Be generic (i.e., can be adopted for any task at hand)\r\n- Have modular lower-level components exposed to users\r\n- Be easy to implement new algorithms\r\n\r\nHere's a basic example of *PPO (with clipping)* implementation with **rlx**\r\n\r\n\tbase_rollout = agent(policy).episode(horizon) # sample an episode as a 'Rollout' object\r\n\tbase_rewards, base_logprobs = base_rollout.rewards, base_rollout.logprobs # 'rewards' and 'logprobs' for all timesteps\r\n\tbase_returns = base_rollout.mc_returns() # Monte-carlo estimates of 'returns'\r\n\t\r\n\tfor _ in range(k_epochs):\r\n        rollout = agent(policy).evaluate(base_rollout) # 'evaluate' an episode against a policy and get a new 'Rollout' object\r\n        logprobs, entropy = rollout.logprobs, rollout.entropy # get 'logprobs' and 'entropy' for all timesteps\r\n        values, = rollout.others # .. also 'value' estimates\r\n\r\n        ratios = (logprobs - base_logprobs.detach()).exp()\r\n        advantage = base_returns - values\r\n        policyloss = - torch.min(ratios, torch.clamp(ratios, 1 - clip, 1 + clip)) * advantage.detach()\r\n        valueloss = advantage.pow(2)\r\n        loss = policyloss.sum() + 0.5 * valueloss.sum() - entropy.sum() * 0.01\r\n        \r\n        agent.zero_grad()\r\n        loss.backward()\r\n        agent.step()\r\n\r\nVisit the [README](https://github.com/dasayan05/rlx/blob/master/README.md) for further details.","links":[{"article_link":"https://dasayan05.github.io/projs/2020/06/27/rlx-deep-rl-library.html","code_link":"https://github.com/dasayan05/rlx","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://dasayan05.github.io/"}]},{"id":1617,"title":"Expressive Power of Graph Neural Networks","description":"Graph isomorphism problem, the Weisfeiler-Lehman heuristic for graph isomorphism testing, and how it can be used to analyse the expressive power of GNNs.","tags":["article","graph-neural-networks","graphs","graph-isomorphism","weisfeiler-lehman"],"details":"Do you have a feeling that deep learning on graphs is a bunch of heuristics that work sometimes and nobody has a clue why? In this post, I discuss the graph isomorphism problem, the Weisfeiler-Lehman heuristic for graph isomorphism testing, and how it can be used to analyse the expressive power of graph neural networks. This is the first in the series of three posts on the expressivity of graph neural networks. In Part 2, I will discuss how to depart from the Weisfeiler-Lehman hierarchy and in Part 3, I will suggest why it may be a good idea to revisit the whole graph isomorphism framework.","links":[{"article_link":"https://towardsdatascience.com/expressive-power-of-graph-neural-networks-and-the-weisefeiler-lehman-test-b883db3c7c49","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1616,"title":"Leveraging Temporal Context for Object Detection","description":"Object detection architecture leveraging contextual clues across time for each camera deployment in a network, improving recognition of objects","tags":["article","paper","research","tensorflow","ecology","computer-vision","object-detection","faster-rcnn","arxiv:1912.03538"],"details":"This new object detection architecture leverages contextual clues across time for each camera deployment in a network, improving recognition of objects in novel camera deployments without relying on additional training data from a large number of cameras. Echoing the approach a person might use when faced with challenging images, Context R-CNN leverages up to a month\u2019s worth of images from the same camera for context to determine what objects might be present and identify them. Using this method, the model outperforms a single-frame Faster R-CNN baseline by significant margins across multiple domains, including wildlife camera traps. We have open sourced the code and models for this work as part of the TF Object Detection API to make it easy to train and test Context R-CNN models on new static camera datasets.","links":[{"article_link":"https://ai.googleblog.com/2020/06/leveraging-temporal-context-for-object.html","code_link":"","research_link":"https://arxiv.org/abs/1912.03538","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1615,"title":"Weight Poisoning Attacks on Pre-trained Models","description":"How Bert can be infused with nefarious behavior, even after fine-tuning.","tags":["code","notebook","paper","research","attention","bert","transformers","natural-language-processing","adversarial-learning","adversarial-attacks","arxiv:2004.06660"],"details":"Recently, NLP has seen a surge in the usage of large pre-trained models. Users download weights of models pre-trained on large datasets, then fine-tune the weights on a task of their choice. This raises the question of whether downloading untrusted pre-trained weights can pose a security threat. In this paper, we show that it is possible to construct ``weight poisoning'' attacks where pre-trained weights are injected with vulnerabilities that expose ``backdoors'' after fine-tuning, enabling the attacker to manipulate the model prediction simply by injecting an arbitrary keyword. We show that by applying a regularization method, which we call RIPPLe, and an initialization procedure, which we call Embedding Surgery, such attacks are possible even with limited knowledge of the dataset and fine-tuning procedure. Our experiments on sentiment classification, toxicity detection, and spam detection show that this attack is widely applicable and poses a serious threat. Finally, we outline practical defenses against such attacks","links":[{"article_link":"","code_link":"https://github.com/neulab/RIPPLe","research_link":"https://arxiv.org/abs/2004.06660","media_link":"","dataset_link":"","demo_link":"","other_link":"https://colab.research.google.com/drive/1BzdevUCFUSs_8z_rIP47VyKAlvfK1cCB"}]},{"id":1614,"title":"Natural Language Processing Roadmap","description":"Roadmap for learning NLP topics.","tags":["code","tutorial","natural-language-processing","guide","roadmap"],"details":"nlp-roadmap is Natural Language Processing ROADMAP (Mind Map) and KEYWORD for students those who have interest in learning Natural Language Processing. The roadmap covers the materials from basic probability/statistics to SOTA NLP models.","links":[{"article_link":"","code_link":"https://github.com/graykode/nlp-roadmap","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1613,"title":"Distributed model training in PyTorch","description":"Distributing training jobs allows you to push past the single-GPU bottleneck, developing larger and more powerful models leveraging many GPUs simultaneously.","tags":["article","pytorch","deep-learning","distributed-training"],"details":"Cutting edge deep learning models are growing at an exponential rate: where last year\u2019s GPT-2 had ~750 million parameters, this year\u2019s GPT-3 has 175 billion. GPT is a somewhat extreme example; nevertheless, the \"enbiggening\" of the SOTA is driving larger and larger models into production applications, challenging the ability of even the most powerful of GPU cards to finish model training jobs in a reasonable amount of time.\r\n\r\nTo deal with these problems, practitioners are increasingly turning to distributed training. Distributed training is the set of techniques for training a deep learning model using multiple GPUs and/or multiple machines. Distributing training jobs allow you to push past the single-GPU memory bottleneck, developing ever larger and powerful models by leveraging many GPUs simultaneously.","links":[{"article_link":"https://spell.ml/blog/pytorch-distributed-data-parallel-XvEaABIAAB8Ars0e","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1612,"title":"C++ for Pythonistas and Data Scientists","description":"An introduction to Cling to help learn C++.","tags":["article","code","c++","python","learning"],"details":"C++ is hard to learn for data scientists, we are use to Python and R. Here I introduce [Cling](https://root.cern.ch/cling), an interpreter for C++ to make the transition easier.\r\n\r\nCling is part of the ROOT framework created by CERN.","links":[{"article_link":"https://towardsdatascience.com/c-for-pythonistas-and-data-scientists-2e1a74a7b8be","code_link":"https://github.com/henriwoodcock/blog-post-codes/tree/master/cpp_for_data_scientists","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1610,"title":"Visualizing Model Comparison","description":"How we can compare the solutions learned by multiple different models.","tags":["article","tutorial","visualization","model-comparison"],"details":"When training deep neural networks, we often strive to compare the models and understand the consequences of different design choices beyond their final performance. We want to be able to explain different qualitative aspects of the solutions our models learn. To understand the solution a model converges to, we could either look into its parameter space or its representational space.\r\n\r\nSometimes, we can also gain some insights about how a model works by looking at its parameter values. For example, the weights of a linear classifier indicate which parts of input features are important for the models\u2019 decision. Or in some cases it can be useful to track the changes in the parameter values during training, for example to visualize the optimizer trajectory of a model ([Li et al., 2018](https://samiraabnar.github.io/articles/2020-05/vizualization#li2018visualizing)).","links":[{"article_link":"https://samiraabnar.github.io/articles/2020-05/vizualization","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1609,"title":"Google Colab Tips for Power Users","description":"Learn about lesser-known features in Google Colab to improve your productivity.","tags":["article","notebook","colab"],"details":"Colab is one of the best products to come from Google. It has made GPUs freely accessible to learners and practitioners like me who otherwise wouldn\u2019t be able to afford a high-end GPU.\r\n\r\nWhile the interface is very easy to use, there are many lesser-known and undocumented features in colab. In this post, I will share those features that I\u2019ve discovered from their official talks and basic usage.","links":[{"article_link":"https://amitness.com/2020/06/google-colaboratory-tips/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1608,"title":"Quantifying Attention Flow in Transformers","description":"I explain two simple but effective methods, called Attention Rollout and Attention Flow","tags":["article","tutorial","attention","self-attention","transformers","natural-language-processing","attention-flow","attention-rollout"],"details":"Here, I explain two simple but effective methods, called Attention Rollout and Attention Flow, to compute attention scores to input tokens (i.e., token attention) at each layer, by taking raw attentions (i.e., embedding attention) of that layer as well as those from the precedent layers.","links":[{"article_link":"https://samiraabnar.github.io/articles/2020-04/attention_flow","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1607,"title":"Message Passing Query Embedding","description":"MPQE is a model for answering complex queries over knowledge graphs, that learns embeddings of entities in the knowledge graph, & embeddings for variable types.","tags":["code","paper","research","graph-convolutional-networks","embeddings","graph-neural-networks","graphs","knowledge-graphs","mpqe","arxiv:2002.02406"],"details":"This repository contains the implementation of MPQE, proposed in our paper [Message Passing Query Embedding](https://arxiv.org/abs/2002.02406). MPQE is a model for answering complex queries over knowledge graphs, that learns embeddings of entities in the knowledge graph, and embeddings for variable types:\r\n\r\n![image](https://raw.githubusercontent.com/dfdazac/mpqe/master/img/qrgcn.png)","links":[{"article_link":"","code_link":"https://github.com/dfdazac/mpqe","research_link":"https://arxiv.org/abs/2002.02406","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1606,"title":"Paraphrase Generation Using T5 model","description":"Simple application using T5 base model fine tuned in Quora Question Pairs to generate paraphrased questions.","tags":["code","transformers","natural-language-processing","question-generation","t5","paraphrase-generation"],"details":"This repository is based on the work from @ramsrigouthamg wich explain very well how to fine tune the model.\r\n\r\n[https://madewithml.com/projects/1094/paraphrase-any-question-with-t5-text-to-text-transformer/](https://madewithml.com/projects/1094/paraphrase-any-question-with-t5-text-to-text-transformer/)","links":[{"article_link":"","code_link":"https://github.com/renatoviolin/T5-paraphrase-generation","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1605,"title":"NetHack Learning Environment (NLE)","description":"A procedurally-generated grid-world dungeon-crawl game that strikes a great balance between complexity and speed for single-agent RL research.","tags":["article","code","research","library","reinforcement-learning","game","nethack","gym"],"details":"The NetHack Learning Environment is a novel research environment for testing the robustness and systematic generalization of reinforcement learning (RL) agents. The environment is based on \r\nNetHack\r\n, one of the oldest and most popular procedurally generated roguelike games. Existing RL environments are either sufficiently complex or based on fast simulation, but they are rarely both. In contrast, the NetHack Learning Environment combines lightning-fast simulation with very complex game dynamics that are difficult even for humans to master. This allows our agents to experience billions of steps in the environment in a reasonable time frame while still challenging the limits of what current methods can achieve, driving long-term research on topics such as exploration, planning, skill acquisition, and language-conditioned RL.","links":[{"article_link":"https://ai.facebook.com/blog/nethack-learning-environment-to-advance-deep-reinforcement-learning","code_link":"https://github.com/facebookresearch/nle","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1604,"title":"Essence of privacy techniques","description":"Tried to give an overview of privacy techniques which can be used in ML\r\nTechniques -Federated learning, Differential privacy and Secure Multi-party computation.","tags":["article","tutorial","privacy","differential-privacy","federated-learning"],"details":"","links":[{"article_link":"https://medium.com/@pdr121096/essence-of-privacy-techniques-d520dfbcc3b5","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1603,"title":"A Million of ML Predictions at the Tip of Your Fingers","description":"Announcement - SashiDo is breaking the barrier to Machine Learning by introducing a fully open-sourced Content Moderation Service.","tags":["article","tutorial","node-js","react","tensorflow","machine-learning","adversarial-image-detection","computer-vision","image-classification","image-recognition","open-source","adversarial-learning","nsfw","content-moderation","nsfw-detection","nsfw-classifier","parse-server","machine-learning-pipilines"],"details":"**Get a million Machine Learning predictions at the tips of your fingers** with SashiDo's fully open source NSFW image classifier built with Node.js, Tensorflow, Parse Server and React!\r\n\r\nWe have created **a fully-functional Content Moderation service** designed to be easily maintained and integrated into every Node.js project even if this is your first encounter with Machine Learning. \r\n\r\nIt has always been SashiDo's mission to simplify technologies and with this demo, we take on a new challenge - to **bring Machine Learning closer to single developers and teams of all sizes by making it affordable and accessible**.\r\n\r\nWe'll be releasing a series of tutorials on how to build your own Content Moderation Solution with Machine Learning from scratch. Stay tuned!\r\n","links":[{"article_link":"https://bit.ly/2Vh06qu","code_link":"","research_link":"","media_link":"https://bit.ly/3eBbYeK","dataset_link":"","demo_link":"","other_link":"https://bit.ly/2Uaz9UT"}]},{"id":1602,"title":"Unet Model for Image Segmentation With EfficientNet Encoder","description":"Implemented using tensorflow 2.2.0 with custom train and test step.","tags":["code","notebook","tensorflow","computer-vision","segmentation","unet","efficientnet"],"details":"","links":[{"article_link":"","code_link":"https://colab.research.google.com/drive/1Tbyvr6JZCmE9a6pi5fBLhHWEna8Gk09D","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1601,"title":"Distilling Inductive Biases","description":"The power of knowledge distillation for transferring the effect of inductive biases from one model to another.","tags":["article","code","paper","research","knowledge-distillation","model-compression","inductive-bias","arxiv:2006.00555"],"details":"In this post, I went through the findings of our paper on \u201cTransferring Inductive Biases Through Knowledge Distillation\u201d, where we explore the power of knowledge distillation for transferring the effect of inductive biases from one model to another.","links":[{"article_link":"https://samiraabnar.github.io/articles/2020-05/indist","code_link":"https://github.com/samiraabnar/Reflect","research_link":"https://arxiv.org/abs/2006.00555","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1600,"title":"BERT Distillation with Catalyst","description":"How to distill BERT with Catalyst.","tags":["article","code","tutorial","pytorch","attention","bert","transformers","library","knowledge-distillation","model-compression","natural-language-processing","catalyst"],"details":"We are going to use [Catalyst](https://github.com/catalyst-team/catalyst) for implementing the network. Catalyst is a high-level framework for PyTorch deep learning research and development. It is focused on reproducibility, fast experimentation and code re-use.","links":[{"article_link":"https://medium.com/pytorch/bert-distillation-with-catalyst-c6f30c985854","code_link":"https://github.com/PUSSYMIPT/bert-distillation","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://github.com/catalyst-team/catalyst"}]},{"id":1599,"title":"High-Fidelity Generative Image Compression","description":"How to combine Generative Adversarial Networks and learned compression to obtain a state-of-the-art generative lossy compression system.","tags":["article","paper","research","generative-adversarial-networks","computer-vision","image-compression","generative-lossy-compression","bitrates","arxiv:2006.09965"],"details":"We extensively study how to combine Generative Adversarial Networks and learned compression to obtain a state-of-the-art generative lossy compression system. In particular, we investigate normalization layers, generator and discriminator architectures, training strategies, as well as perceptual losses. In contrast to previous work, i) we obtain visually pleasing reconstructions that are perceptually similar to the input, ii) we operate in a broad range of bitrates, and iii) our approach can be applied to high-resolution images. We bridge the gap between rate-distortion-perception theory and practice by evaluating our approach both quantitatively with various perceptual metrics and a user study. The study shows that our method is preferred to previous approaches even if they use more than 2x the bitrate.","links":[{"article_link":"https://hific.github.io/","code_link":"","research_link":"https://arxiv.org/abs/2006.09965","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1598,"title":"Automatic Data Augmentation for  Generalization in Deep RL","description":"We compare three approaches for automatically finding an appropriate augmentation combined with two novel regularization terms for the policy and value function","tags":["code","paper","research","pytorch","data-augmentation","reinforcement-learning","kornia","arxiv:2006.12862"],"details":"Deep reinforcement learning (RL) agents often fail to generalize to unseen scenarios, even when they are trained on many instances of semantically similar environments. Data augmentation has recently been shown to improve the sample efficiency and generalization of RL agents. However, different tasks tend to benefit from different kinds of data augmentation. In this paper, we compare three approaches for automatically finding an appropriate augmentation. These are combined with two novel regularization terms for the policy and value function, required to make the use of data augmentation theoretically sound for certain actor-critic algorithms. We evaluate our methods on the Procgen benchmark which consists of 16 procedurally-generated environments and show that it improves test performance by ~40% relative to standard RL algorithms. Our agent outperforms other baselines specifically designed to improve generalization in RL. In addition, we show that our agent learns policies and representations that are more robust to changes in the environment that do not affect the agent, such as the background.","links":[{"article_link":"","code_link":"https://github.com/rraileanu/auto-drac","research_link":"https://arxiv.org/abs/2006.12862","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1597,"title":"Maximizing Business Impact with Machine Learning","description":"how to effectively leverage machine learning to build intelligent products as efficiently as possible.","tags":["article","product-management","metrics","production","monitoring","model-validation"],"details":"I recently had the great fortune of presenting a lunch & learn session to the Capsule8 team. In this presentation I discussed how to effectively leverage machine learning to build intelligent products as efficiently as possible. Rather than focus on a single type of audience, I included information relevant to multiple levels including executive leadership, middle management, and individual contributors building machine learning solutions.","links":[{"article_link":"https://mlinproduction.com/maximizing-business-impact-with-machine-learning/","code_link":"","research_link":"","media_link":"https://www.slideshare.net/LuigiPatruno1/maximizing-business-impact-with-machine-learning","dataset_link":"","demo_link":"","other_link":""}]},{"id":1596,"title":"Lessons from the PULSE Model and Discussion","description":"Elements of the recent discussion that happened among AI researchers as a result of bias found in the model associated with the PULSE paper.","tags":["article","paper","research","fairness","bias","ethics","arxiv:2003.03808"],"details":"In this post I will attempt to summarize some elements of the recent discussion that happened among AI researchers as a result of bias found in the model associated with the paper \"PULSE: Self-Supervised Photo Upsampling via Latent Space Exploration of Generative Models\". I will also offer my personal reflection on this discussion and on what can be learned from it with regards to the technical topic of bias in machine learning, best practices for AI research, and best practices for discussing such topics. I write this because I believe they are valuable lessons that are worth noting. Some of these lessons are more subjective than others, so I hope that even if you disagree with the perspective offered here you will still consider it.","links":[{"article_link":"https://thegradient.pub/pulse-lessons/","code_link":"","research_link":"https://arxiv.org/abs/2003.03808","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1595,"title":"multi-task-NLP","description":"A utility toolkit enabling NLP developers to easily train and infer a single model for multiple tasks.","tags":["code","attention","bert","transformers","xlnet","library","natural-language-processing","albert","roberta","multi-task-learning","distil-bert","multi-task-nlp"],"details":"multi_task_NLP gives you the capability to define multiple tasks together and train a single model which simultaneously learns on all defined tasks. This means one can perform multiple tasks with latency and resource consumption equivalent to a single task.\r\n\r\nWe support various data formats for majority of NLI tasks and multiple transformer-based encoders (eg. BERT, Distil-BERT, ALBERT, RoBERTa, XLNET etc.)","links":[{"article_link":"","code_link":"https://github.com/hellohaptik/multi-task-NLP/","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://multi-task-nlp.readthedocs.io/en/latest/"}]},{"id":1592,"title":"Text Classification","description":"Re-implemented an article (link is given below) which was on Text classification with CNN, beside this I tried out some ML classification algorithm.","tags":["article","code","convolutional-neural-networks","logistic-regression","random-forests","regression","natural-language-processing","text-classification","decision-tree","xgboost"],"details":"","links":[{"article_link":"https://realpython.com/python-keras-text-classification/","code_link":"https://github.com/123pratik/Text-Classification","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1591,"title":"Basic GUI Calculator in Python","description":"This article will take you through the entire process of developing a basic GUI calculator in Python using tkinter.","tags":["article","code","tutorial","python","program-development"],"details":"","links":[{"article_link":"https://pyshark.com/basic-gui-calculator-in-python/","code_link":"https://github.com/misha-pyshark/python-calculator","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1590,"title":"Brain parcellation with TorchIO and HighRes3DNet","description":"A full brain parcellation of a 3D T1-weighted MRI using TorchIO and a pre-trained PyTorch deep learning model.","tags":["code","notebook","tutorial","pytorch","health","mri","torchio","highres3dnet","brain-parcellation"],"details":"We are going to perform a full brain parcellation of a 3D T1-weighted MRI using TorchIO and a pre-trained PyTorch deep learning model in less than 50 lines of code and less than two minutes.\r\n\r\n**TorchIO**\r\nTorchIO is a Python package to prepare 3D medical images for deep learning pipelines. Check out the documentation and a longer Colab notebook containing many examples.\r\n\r\n**HighRes3DNet**\r\nHighRes3DNet is a 3D residual network presented by Li et al. in On the Compactness, Efficiency, and Representation of 3D Convolutional Networks: Brain Parcellation as a Pretext Task. The authors shared the weights of the model they trained to perform full brain parcellation as in Geodesic Information Flows: Spatially-Variant Graphs and Their Application to Segmentation and Fusion, also known as GIF parcellation.\r\n\r\nThe weights were ported from TensorFlow as shown in my entry to the MICCAI educational challenge 2019.\r\n\r\n","links":[{"article_link":"","code_link":"https://colab.research.google.com/drive/10-JE1OOqM2LziPk7BgAOJcpal0F1_aEB","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1589,"title":"jiant","description":"A software toolkit for research on general-purpose text understanding models.","tags":["code","huggingface","pytorch","library","natural-language-processing","multi-task-learning","jiant"],"details":"`jiant` is a software toolkit for natural language processing research, designed to facilitate work on multitask learning and transfer learning for sentence understanding tasks.\r\n\r\njiant is a work-in-progress software toolkit for natural language processing research, designed to facilitate work on multitask learning and transfer learning for sentence understanding tasks.\r\n\r\nA few things you might want to know about jiant:\r\n\r\n* jiant is configuration-driven. You can run an enormous variety of experiments by simply writing configuration files. Of course, if you need to add any major new features, you can also easily edit or extend the code.\r\n* jiant contains implementations of strong baselines for the GLUE and SuperGLUE benchmarks, and it's the recommended starting point for work on these benchmarks.\r\n* jiant was developed at the 2018 JSALT Workshop by the General-Purpose Sentence Representation Learning team and is maintained by the NYU Machine Learning for Language Lab, with help from many outside collaborators (especially Google AI Language's Ian Tenney).\r\n* jiant is built on PyTorch. It also uses many components from AllenNLP and the HuggingFace PyTorch Transformers package.\r\n","links":[{"article_link":"","code_link":"https://github.com/jiant-dev/jiant","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://jiant.info/"}]},{"id":1588,"title":"Multi-task Training with Hugging Face Transformers and NLP","description":" A recipe for multi-task training with Transformers' Trainer and NLP datasets.","tags":["article","code","notebook","tutorial","huggingface","transformers","natural-language-processing","guide","multi-task-learning","recipe"],"details":"Hugging Face has been building a lot of exciting new NLP functionality lately. The newly released NLP provides a wide coverage of task data sets and metrics, as well as a simple interface for processing and caching the inputs extremely efficiently. They have also recently introduced a Trainer class to the Transformers library that handles all of the training and validation logic.\r\n\r\nHowever, one feature that is not currently supported in Hugging Face's current offerings is multi-task training. While there has been some discussion about the best way to support multi-task training (1, 2), the community has not yet settled on a convention for doing so. Multi-task training has been shown to improve task performance (1, 2) and is a common experimental setting for NLP researchers.\r\n\r\nIn this Colab notebook, we will show how to use both the new NLP library as well as the Trainer for a multi-task training scheme.","links":[{"article_link":"","code_link":"https://colab.research.google.com/github/zphang/zphang.github.io/blob/master/files/notebooks/Multi_task_Training_with_Transformers_NLP.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1587,"title":"Deep Learning Based Text Classification: A Comprehensive Review","description":"An overview of deep learning approaches to text classification.","tags":["paper","research","tutorial","natural-language-processing","text-classification","survey","arxiv:2004.03705"],"details":"Deep learning based models have surpassed classical machine learning based approaches in various text classification\r\ntasks, including sentiment analysis, news categorization, question answering, and natural language inference. In this work,\r\nwe provide a detailed review of more than 150 deep learning based models for text classification developed in recent years,\r\nand discuss their technical contributions, similarities, and strengths. We also provide a summary of more than 40 popular\r\ndatasets widely used for text classification. Finally, we provide a quantitative analysis of the performance of different deep\r\nlearning models on popular benchmarks, and discuss future research directions.","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2004.03705","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1586,"title":"Generalized Zero & Few-Shot Transfer for Facial Forgery Detection","description":"Deep Distribution Transfer (DDT), a new transfer learning approach to address the problem of zero and few-shot transfer in the context of facial forgery.","tags":["article","paper","research","anomaly-detection","few-shot-learning","fraud-detection","zero-shot-learning","facial-forgery-detection","deep-distribution-transfer","wasserstein-distance","faceforensics++","dessa","arxiv:2006.11863"],"details":"We propose Deep Distribution Transfer (DDT), a new transfer learning approach to address the problem of zero and few-shot transfer in the context of facial forgery detection. We examine how well a model (pre-)trained with one forgery creation method generalizes towards a previously unseen manipulation technique or different dataset. To facilitate this transfer, we introduce a new mixture model-based loss formulation that learns a multi-modal distribution, with modes corresponding to class categories of the underlying data of the source forgery method. Our core idea is to first pre-train an encoder neural network, which maps each mode of this distribution to the respective class labels, i.e., real or fake images in the source domain by minimizing wasserstein distance between them. In order to transfer this model to a new domain, we associate a few target samples with one of the previously trained modes. In addition, we propose a spatial mixup augmentation strategy that further helps generalization across domains. We find this learning strategy to be surprisingly effective at domain transfer compared to a traditional classification or even state-of-the-art domain adaptation/few-shot learning methods. For instance, compared to the best baseline, our method improves the classification accuracy by 4.88% for zero-shot and by 8.38% for the few-shot case transferred from the FaceForensics++ to Dessa dataset.\r\n","links":[{"article_link":"https://shivangi-aneja.github.io/ddt/","code_link":"","research_link":"https://arxiv.org/abs/2006.11863","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1585,"title":"Breaking the cycle\u2014Colleagues are all you need","description":"A novel approach to performing image-to-image translation between unpaired domains.","tags":["article","code","paper","research","generative-adversarial-networks","computer-vision","image-to-image-translation","arxiv:1911.10538"],"details":"This paper proposes a novel approach to performing image-to-image translation between unpaired domains.\r\nRather than relying on a cycle constraint, our method takes\r\nadvantage of collaboration between various GANs. This\r\nresults in a multi-modal method, in which multiple optional and diverse images are produced for a given image.\r\nOur model addresses some of the shortcomings of classical GANs: (1) It is able to remove large objects, such as\r\nglasses. (2) Since it does not need to support the cycle\r\nconstraint, no irrelevant traces of the input are left on the\r\ngenerated image. (3) It manages to translate between domains that require large shape modifications. Our results\r\nare shown to outperform those generated by state-of-the-art\r\nmethods for several challenging applications. Code Available at https://github.com/Onr/Council-GAN","links":[{"article_link":"https://onr.github.io/Council_web/","code_link":"https://github.com/Onr/Council-GAN","research_link":"https://arxiv.org/abs/1911.10538","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1584,"title":"Locally Masked Convolution for Autoregressive Models","description":"Locally Masked PixelCNN generates natural images in customizable orders like zig-zags and Hilbert Curves.","tags":["article","code","paper","research","pytorch","convolutional-neural-networks","cifar10","autoregression","masked-convolutions","pixelcnn","arxiv:2006.12486"],"details":"Our Locally Masked PixelCNN generates natural images in customizable orders like zig-zags and Hilbert Curves. We train a single PixelCNN++ to support 8 generation orders simultaneously, outperforming PixelCNN++ on distribution estimation and allowing globally coherent image completions on CIFAR10, CelebA-HQ and MNIST. We control the order with our proposed locally masked convolution operation, which is efficient and easy to implement via matrix multiplication.","links":[{"article_link":"https://ajayjain.github.io/lmconv/","code_link":"https://github.com/ajayjain/lmconv","research_link":"https://arxiv.org/abs/2006.12486","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1583,"title":"Adversarial Latent Autoencoders","description":"Harnessing the latent power of autoencoders, one disentanglement at a time.","tags":["article","paper","research","tutorial","autoencoders","generative-adversarial-networks","wandb","arxiv:2004.04467","adversarial-latent-autoencoders"],"details":"Even though the autoencoders have been extensively studied, some issues have not been fully discussed and they are:\r\n\r\nCan autoencoders have the same generative power as GAN?\r\nCan autoencoders learn disentangled representations?\r\nPoints in the latent space holds relevant information about the input data distribution. If these points are less entangled amongst themselves, we would then have more control over the generated data, as each point contributes to one relevant feature in the data domain. The authors of [Adversarial Latent Autoencoder](https://arxiv.org/abs/2004.04467) have designed an autoencoder which can address both the issues mentioned above jointly. Next, let's take a closer look at the architecture.","links":[{"article_link":"https://app.wandb.ai/authors/alae/reports/Adversarial-Latent-Autoencoders--VmlldzoxNDA2MDY","code_link":"","research_link":"https://arxiv.org/abs/2004.04467","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1582,"title":"spacy-streamlit: spaCy building blocks for Streamlit apps","description":"Utilities for visualizing spaCy models and building interactive spaCy-powered apps with Streamlit.","tags":["code","spacy","library","streamlit"],"details":"This package contains utilities for visualizing spaCy models and building interactive spaCy-powered apps with Streamlit. It includes various building blocks you can use in your own Streamlit app, like visualizers for syntactic dependencies, named entities, text classification, semantic similarity via word vectors, token attributes, and more.\r\n\r\nThe package includes building blocks that call into Streamlit and set up all the required elements for you. You can either use the individual components directly and combine them with other elements in your app, or call the visualize function to embed the whole visualizer.","links":[{"article_link":"","code_link":"https://github.com/explosion/spacy-streamlit","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1581,"title":"Discovering Symbolic Models from Deep Learning w/ Inductive Bias","description":"A general approach to distill symbolic representations of a learned deep model by introducing strong inductive biases.","tags":["article","code","notebook","paper","research","video","graph-neural-networks","graphs","representation-learning","demo","symbolic-models","inductive-bias","arxiv:2006.11287"],"details":"We develop a general approach to distill symbolic representations of a learned deep model by introducing strong inductive biases. We focus on Graph Neural Networks (GNNs). The technique works as follows: we first encourage sparse latent representations when we train a GNN in a supervised setting, then we apply symbolic regression to components of the learned model to extract explicit physical relations. We find the correct known equations, including force laws and Hamiltonians, can be extracted from the neural network. We then apply our method to a non-trivial cosmology example-a detailed dark matter simulation-and discover a new analytic formula which can predict the concentration of dark matter from the mass distribution of nearby cosmic structures. The symbolic expressions extracted from the GNN using our technique also generalized to out-of-distribution data better than the GNN itself. Our approach offers alternative directions for interpreting neural networks and discovering novel physical principles from the representations they learn.","links":[{"article_link":"https://astroautomata.com/paper/symbolic-neural-nets/","code_link":"https://github.com/MilesCranmer/symbolic_deep_learning","research_link":"https://arxiv.org/abs/2006.11287","media_link":"https://www.youtube.com/watch?v=2vwwu59RPL8","dataset_link":"","demo_link":"https://colab.research.google.com/github/MilesCranmer/symbolic_deep_learning/blob/master/GN_Demo_Colab.ipynb","other_link":""}]},{"id":1580,"title":"What I Learned From Looking at 200 Machine Learning Tools","description":"To better understand the landscape of available tools for machine learning production, I decided to look up every AI/ML tool I could find.","tags":["article","machine-learning","production","survey","mlops"],"details":"This post consists of 6 parts:\r\n\r\n1. Overview\r\n1. The landscape over time\r\n1. The landscape is under-developed\r\n1. Problems facing MLOps\r\n1. Open source and open-core\r\n1. Conclusion","links":[{"article_link":"https://huyenchip.com/2020/06/22/mlops.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1579,"title":"Self-Supervised Prototypical Transfer Learning","description":"Advancing state-of-the-art unsupervised few-shot learning up to supervised performance.","tags":["code","paper","research","few-shot-learning","self-supervised-learning","transfer-learning","arxiv:2006.11325"],"details":"## Introduction\r\nMost approaches in few-shot learning rely on costly annotated data related to the goal task domain during (pre-)training.\r\n\r\n- Recently, unsupervised meta-learning methods have exchanged the annotation requirement for a reduction in few-shot classification performance.\r\n- Simultaneously, in settings with realistic domain shift, common transfer learning has been shown to outperform supervised meta-learning.\r\n\r\n## Approach\r\nBuilding on these insights and on advances in self-supervised learning, we propose:\r\n\r\n(a) a transfer learning approach which constructs a metric embedding that clusters unlabeled prototypical samples and their augmentations closely together.\r\n\r\n(b) This pre-trained embedding is a starting point for few-shot classification by summarizing class clusters and fine-tuning.\r\n\r\n![Approach](https://raw.githubusercontent.com/indy-lab/ProtoTransfer/master/method_illustration.png)\r\n## Results\r\n1. We demonstrate that our self-supervised prototypical transfer learning approach ProtoTransfer outperforms state-of-the-art unsupervised meta-learning methods on few-shot tasks from the mini-ImageNet dataset.\r\n2. In few-shot experiments with domain shift, our approach even has comparable performance to supervised methods, but requires orders of magnitude fewer labels.\r\n\r\nCode and pre-trained models available on [GitHub.com/ProtoTransfer](https://github.com/indy-lab/ProtoTransfer)","links":[{"article_link":"","code_link":"https://github.com/indy-lab/ProtoTransfer","research_link":"https://arxiv.org/abs/2006.11325","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1578,"title":"PyBoxCar","description":"A BoxCar2D implementation in Python.","tags":["code","research","artificial-intelligence","genetic-algorithms","evolutionary-algorithms","simulation"],"details":"# PyBoxCar\r\n\r\nA BoxCar2D implementation in Python. The aim of the cars in this simulation is to start from the top left corner and reach the goal at the bottom right, as quickly as possible. The Genetic Algorithm is used to optimize the cars after every generation.\r\n\r\n## Demo\r\n\r\nYou can check out the GIFs from the simulation [here.](https://github.com/kad99kev/PyBoxCar/blob/master/GIFs.md)","links":[{"article_link":"","code_link":"https://github.com/kad99kev/PyBoxCar","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1577,"title":"Data Version Control (DVC) v1.0","description":"\ud83e\udd89Data Version Control | Git for Data & Models","tags":["article","code","video","library","dvc","version-control"],"details":"Open-source version control system for machine learning projects.\r\n\r\n* Save and reproduce your experiments.\r\n* Version control models and data.\r\n* Establish workflow for deployment & collaboration.","links":[{"article_link":"https://dvc.org/blog/dvc-1-0-release","code_link":"https://github.com/iterative/dvc","research_link":"","media_link":"https://www.youtube.com/watch?v=4h6I9_xeYA4","dataset_link":"","demo_link":"","other_link":""}]},{"id":1576,"title":"VPSNet for Video Panoptic Segmentation","description":"Video panoptic segmentation by generating consistent panoptic segmentation as well as an association of instance ids across video frames.","tags":["code","dataset","paper","research","pytorch","computer-vision","video-semantic-segmentation","segmentation","cvpr-2020","panoptic-segmentation","slides","video-segmentation","video-processing","video-panoptic-segmentation","vpsnet","arxiv:2006.11339"],"details":"Panoptic segmentation has become a new standard of vi-\r\nsual recognition task by unifying previous semantic segmen-\r\ntation and instance segmentation tasks in concert. In this paper, we propose and explore a new video extension of this\r\ntask, called video panoptic segmentation. The task requires\r\ngenerating consistent panoptic segmentation as well as an association of instance ids across video frames. To invigo-\r\nrate research on this new task, we present two types of video\r\npanoptic datasets. \r\n\r\nTo provide appropriate metrics for this task, we propose a video panoptic quality (VPQ) metric and evaluate our method and several other baselines. ","links":[{"article_link":"","code_link":"https://github.com/mcahny/vps","research_link":"https://arxiv.org/abs/2006.11339","media_link":"https://doc-0g-4g-docs.googleusercontent.com/docs/securesc/8ijl4oho8jl47lgmiqhke6okpt5dc6eu/kqvs5rimjbvhaaa8a0tl4lmtvoiv5ujl/1592879550000/07994257621310680122/00378334517810298963/1525wpf3kDy2kEsbaPo79ak713gYSfBPe?authuser=0&nonce=rt1jqhj2ma5h4&user=00378334517810298963&hash=jclg96u8ho4623ufulbg6ar7k7uleto9","dataset_link":"https://www.dropbox.com/s/ecem4kq0fdkver4/cityscapes-vps-dataset-1.0.zip?dl=0","demo_link":"","other_link":""}]},{"id":1575,"title":"Deep Learning for Computer Vision ","description":"Special topics class on deep learning for computer vision from the University of Michigan taught by Justin Johnson.","tags":["article","course","video","deep-learning","computer-vision","slides"],"details":"Computer Vision has become ubiquitous in our society, with applications in search, image understanding, apps, mapping, medicine, drones, and self-driving cars. Core to many of these applications are visual recognition tasks such as image classification and object detection. Recent developments in neural network approaches have greatly advanced the performance of these state-of-the-art visual recognition systems. This course is a deep dive into details of neural-network based deep learning methods for computer vision. During this course, students will learn to implement, train and debug their own neural networks and gain a detailed understanding of cutting-edge research in computer vision. We will cover learning algorithms, neural network architectures, and practical engineering tricks for training and fine-tuning networks for visual recognition tasks.\r\n\r\n* **Syllabus**: The [syllabus](https://web.eecs.umich.edu/~justincj/teaching/eecs498/syllabus.html) has detailed course policies\r\n* **Lecture videos**: [Recordings](http://leccap.engin.umich.edu/leccap/site/jhygcph151x25gjj1f0)\r\n* **Assignments**: [[A1]](https://web.eecs.umich.edu/~justincj/teaching/eecs498/assignment1.html) [[A2]](https://web.eecs.umich.edu/~justincj/teaching/eecs498/assignment2.html) [[A3]](https://web.eecs.umich.edu/~justincj/teaching/eecs498/assignment3.html) [[A4]](https://web.eecs.umich.edu/~justincj/teaching/eecs498/assignment4.html) [[A5]](https://web.eecs.umich.edu/~justincj/teaching/eecs498/assignment5.html) [[A6]](https://web.eecs.umich.edu/~justincj/teaching/eecs498/assignment6.html)","links":[{"article_link":"","code_link":"","research_link":"","media_link":"http://leccap.engin.umich.edu/leccap/site/jhygcph151x25gjj1f0","dataset_link":"","demo_link":"","other_link":"https://web.eecs.umich.edu/~justincj/teaching/eecs498/"}]},{"id":1574,"title":"MIT Embodied Intelligence Seminars","description":"Collection of very interesting talks around embodied intelligence.","tags":["video","embodied-intelligence","general-intelligence","emergent-intelligence","mit"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/channel/UCnXGbvgu9071i3koFooncAw","dataset_link":"","demo_link":"","other_link":""}]},{"id":1573,"title":"Fun Python","description":"Notes from a class held online between April - May 2020 with students\r\nage 10-12.","tags":["article","tutorial","python"],"details":"* Lesson 0: Setting things up. Hello world!\r\n* Lesson 1: Variables. Math with Big Numbers.\r\n* Lesson 2: If-then-else. Number games.\r\n* Lesson 3: Lists. Fun MadLibs generator.\r\n* Lesson 4: Loops. Adding all the numbers up to 1 billion and more.\r\n* Lesson 5: Loops 2. Generating lots of sentences. Rock, Paper, Scissors game.\r\n* Lesson 6: Functions. Cool drawings with the Turtle library.\r\n* Lesson 7: Read/write from files. Read from webpages. Count all the words in a book!\r\n* Lesson 8: Dictionaries. How to write a secret message.\r\n* What\u2019s Next?: Ways to continue learning.","links":[{"article_link":"https://web.eecs.umich.edu/~mihalcea/urls/FunPython.pdf","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1572,"title":"Python Data Science \u2013 A Free 12-Hour Course for Beginners","description":"Learn Pandas, NumPy, Matplotlib, and more.","tags":["code","course","tutorial","video","python"],"details":"* Coding on the iPython Shell\r\n* Variables and Operators in Python\r\n* Booleans and Comparisons in Python\r\n* Python Useful functions\r\n* Control Flow in Python\r\n* Functions in Python\r\n* Modules in Python\r\n* Strings in Python\r\n* Other important Python Data Structures: Lists, Tuples, Sets, and Dictionaries\r\n* The NumPy Data Science Python Library\r\n* The Pandas Data Science Python Library\r\n* The Matplotlib Data Science Python Library","links":[{"article_link":"","code_link":"https://github.com/datapublishings/Course-python-data-science","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.freecodecamp.org/news/python-data-science-course-matplotlib-pandas-numpy/"}]},{"id":1571,"title":"Stochastic Segmentation Networks","description":"An efficient probabilistic method for modelling aleatoric uncertainty with any image segmentation network architecture.","tags":["code","notebook","paper","research","health","computer-vision","medical-imaging","segmentation","mri","demo","arxiv:2006.06015"],"details":"In image segmentation, there is often more than one plausible solution for a given input. In medical imaging, for example, experts will often disagree about the exact location of object boundaries. Estimating this inherent uncertainty and predicting multiple plausible hypotheses is of great interest in many applications, yet this ability is lacking in most current deep learning methods. In this paper, we introduce stochastic segmentation networks (SSNs), an efficient probabilistic method for modeling aleatoric uncertainty with any image segmentation network architecture. In contrast to approaches that produce pixel-wise estimates, SSNs model joint distributions over entire label maps and thus can generate multiple spatially coherent hypotheses for a single image. By using a low-rank multivariate normal distribution over the logit space to model the probability of the label map given the image, we obtain a spatially consistent probability distribution that can be efficiently computed by a neural network without any changes to the underlying architecture. We tested our method on the segmentation of real-world medical data, including lung nodules in 2D CT and brain tumours in 3D multimodal MRI scans. SSNs outperform state-of-the-art for modeling correlated uncertainty in ambiguous images while being much simpler, more flexible, and more efficient.","links":[{"article_link":"","code_link":"https://colab.research.google.com/github/MiguelMonteiro/stochastic_segmentation_networks_demo/blob/master/ssn_demo.ipynb","research_link":"https://arxiv.org/abs/2006.06015","media_link":"","dataset_link":"","demo_link":"https://colab.research.google.com/github/MiguelMonteiro/stochastic_segmentation_networks_demo/blob/master/ssn_demo.ipynb","other_link":""}]},{"id":1569,"title":"Trackable","description":"The project deals with tracking humans in a narrow hallway under different lighting conditions.","tags":["code","research","pytorch","computer-vision","object-tracking","hallway-tracking"],"details":"## Overview\r\nTracking humans in a hallway.\r\n\r\n - The project deals with tracking humans in a narrow hallway under different lighting conditions.\r\n  - Unlike other [MOT](https://motchallenge.net/) models, we aim to\r\n   track people without any training, that means, all tracking is done online.\r\n   - There are many state-of-the-art models and architectures,\r\n   that have been a large source of our inspiration (they are all listed under references below).\r\n   - The videos were obtained from [this link.](http://www.santhoshsunderrajan.com/datasets.html#hfh_tracking)\r\n\r\n## Drawbacks\r\nThe two major problems are:\r\n\r\n1. Misidentification: This can be solved by training on the objects beforehand. However the main aim for this project was to differentiate between objects without any training.\r\n\r\n2. Mistracking: This could be helped with a better matching algorithm. DeepSort could be another alternative.","links":[{"article_link":"","code_link":"https://github.com/kad99kev/Trackable","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1568,"title":"missingno:  Missing data visualization module for Python. ","description":"missingno provides a small toolset of flexible and easy-to-use missing data visualizations.","tags":["code","notebook","python","library","visualization","exploratory-data-analysis"],"details":"Messy datasets? Missing values? missingno provides a small toolset of flexible and easy-to-use missing data visualizations and utilities that allows you to get a quick visual summary of the completeness (or lack thereof) of your dataset. Just pip install missingno to get started.","links":[{"article_link":"","code_link":"https://github.com/ResidentMario/missingno","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1567,"title":"fahr: a POC CLI for building machine learning models on the cloud","description":"fahr is a command-line tool for building machine learning models on cloud hardware with as little overhead as possible.","tags":["api","code","aws","training","kaggle"],"details":"fahr is a command-line tool for building machine learning models on cloud hardware with as little overhead as possible.\r\n\r\nfahr provides a simple unified interface to model training services like AWS SageMaker and Kaggle Kernels. By offloading model training to the cloud, fahr aims to make machine learning experimentation easy and fast.","links":[{"article_link":"","code_link":"https://github.com/ResidentMario/fahr","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1566,"title":"Aleksey's Machine Learning Repository","description":"Organized notes on machine learning.","tags":["article","code","notebook","scikit-learn","machine-learning","feature-engineering"],"details":" Machine learning is the study of teaching machines to learn using data, with and without human supervision.\r\n\r\nSome time ago I (@residentmario) decided that I needed to systematize my knowledge of the field by studying it from the ground up. I decided to use kernels to do it.\r\n\r\nKernels are a wonderful utility from the folks @Kaggle that provide an editable notebook environment that anyone else can then freely fork and run themselves. If you're familiar with notebooks, they're just like that, except on the cloud.\r\n\r\nThis microsite collects the write-ups I did into an organized, readable list. I cover material that ranges from the basic to the intermediate, starting with basic linear regression and train-test splits and ending with topics such as random forests, oversampling, and probability calibration. There are currently fifty-five notebooks in the list! ","links":[{"article_link":"https://residentmario.github.io/machine-learning-notes/index.html","code_link":"https://github.com/ResidentMario/machine-learning-notes","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1565,"title":"Designing data visualization APIs in Python","description":"In this post we'll examine some data visualization API design ideas.","tags":["article","d3","matplotlib","python","visualization","altair","exploratory-data-analysis"],"details":"In this post we'll examine some data visualization API design ideas. We'll look at some major interface design ideas that these libraries have implemented, and what they can and can't achieve for the user. If you are interested in building your own data visualization library, or in better understanding why these libraries make some of the decisions that they make, keep reading! ","links":[{"article_link":"https://www.residentmar.io/2018/05/30/dataviz-apis.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1564,"title":"Building fully custom machine learning models on AWS SageMaker","description":"AWS SageMaker is a cloud machine learning SDK designed for speed of iteration, and it\u2019s one of the fastest-growing toys in the Amazon AWS ecosystem.","tags":["article","code","tutorial","aws","product-management"],"details":"AWS SageMaker is a cloud machine learning SDK designed for speed of iteration, and it\u2019s one of the fastest-growing toys in the Amazon AWS ecosystem. Since launching in late 2017 SageMaker\u2019s growth has been remarkable \u2014 last year\u2019s AWS re:Invent stated that there are now over 10,000 companies using SageMaker to standardize their machine learning processes. SageMaker allows you to to use a Jupyter notebook interface to launch and tear down machine learning processes in handfuls of lines of Python code, something that makes data scientists happy because it abstracts away many of the messy infrastructural details to training. The thesis: standing up your own machine learning algorithm should always be this easy!","links":[{"article_link":"https://towardsdatascience.com/building-fully-custom-machine-learning-models-on-aws-sagemaker-a-practical-guide-c30df3895ef7","code_link":"https://github.com/quiltdata/quilt-sagemaker-demo","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1563,"title":"Classify photos in 600 classes using nine million Open Images","description":"If you\u2019re looking build an image classifier but need training data, look no further than Google Open Images.","tags":["article","code","dataset","tutorial","convolutional-neural-networks","computer-vision","data-augmentation","image-classification","data"],"details":"If you\u2019re looking build an image classifier but need training data, look no further than Google Open Images.\r\n\r\nThis massive image dataset contains over 30 million images and 15 million bounding boxes. That\u2019s 18 terabytes of image data!\r\n\r\nPlus, Open Images is much more open and accessible than certain other image datasets at this scale. For example, ImageNet has restrictive licensing.\r\n\r\nHowever, it\u2019s not easy for developers on single machines to sift through that much data.You need to download and process multiple metadata files, and roll their own storage space (or apply for access to a Google Cloud bucket).\r\n\r\nOn the other hand, there aren\u2019t many custom image training sets in the wild, because frankly they\u2019re a pain to create and share.\r\n\r\nIn this article, we\u2019ll build and distribute a simple end-to-end machine learning pipeline using Open Images.","links":[{"article_link":"https://medium.com/free-code-camp/how-to-classify-photos-in-600-classes-using-nine-million-open-images-65847da1a319","code_link":"https://github.com/quiltdata/open-images","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1562,"title":"Evaluating Keras neural network performance using Yellowbrick","description":"Yellowbrick is a dataviz toolkit that provides many advanced data and model evaluation plots.","tags":["article","tutorial","keras","library","visualization","yellobrick"],"details":"Since I first tried it out a year ago, Yellowbrick definitely grown to be one of the favorite tools in my data science toolbox.\r\n\r\nHowever, the library is designed to work with Scikit-Learn, and is not (yet \ud83d\ude09) compatible with Keras. Luckily we can fix this by building a simple model wrapper that fixes this problem. That\u2019s great news because it unlocks a few advanced model plots that for use in your neural network model evaluation.\r\n\r\nThis post will show you how!","links":[{"article_link":"https://towardsdatascience.com/evaluating-keras-neural-network-performance-using-yellowbrick-visualizations-ad65543f3174","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1561,"title":"Fran\u00e7ois Chollet wants you to care about developer experience","description":"Chollet cites three principles as the key to a great developer experience.","tags":["article","keras","project-management"],"details":"Good tools are how you build great products, win competitions, get papers published. [\u2026] This seems obvious but you\u2019d be shocked\u2026very few developers of data science tools or software tools care about UX. If you keep this principle in mind, it\u2019s like a superpower.\r\n\r\nChollet cites three principles as the key to a great developer experience:\r\n\r\n* Deliberately design end-to-end workflows focused on what users care about.\r\n* Reduce cognitive load for your users.\r\n* Provide helpful feedback for your users.","links":[{"article_link":"https://blog.quiltdata.com/fran\u00e7ois-chollet-wants-you-to-care-about-developer-experience-5fd049e45642","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1560,"title":"Battle-Tested Techniques for Scoping Machine Learning Projects","description":"One of the challenges of managing an ML project is project scoping. Even small changes in data or architecture can create huge differences in model outputs.","tags":["code","video","project-management","production","systems-design"],"details":"One of the challenges of managing an ML project is project scoping. Even small changes in data or architecture can create huge differences in model outputs, making predicting how long it will take to train a performant model extremely challenging.\r\n\r\nIn this webinar we present five techniques from the data science consulting world that will help you to budget time for new and ongoing ML projects with confidence.","links":[{"article_link":"","code_link":"https://github.com/ResidentMario/ml-project-scoping-talk","research_link":"","media_link":"https://www.youtube.com/watch?v=u0Z6N5fk5Vk","dataset_link":"","demo_link":"","other_link":""}]},{"id":1559,"title":"Boost your CNN performance with progressive resizing in Keras","description":"Progressive resizing is a technique for building CNNs that can be very helpful during the training and optimization phases of a machine learning project.","tags":["article","code","tutorial","keras","convolutional-neural-networks","project-management"],"details":"Progressive resizing is a technique for building CNNs that can be very helpful during the training and optimization phases of a machine learning project. The technique appears most prominently in Jeremy Howard\u2019s work, and he uses it to good effect throughout his terrific fast.ai course, \u201cDeep Learning for Coders\u201d.","links":[{"article_link":"https://towardsdatascience.com/boost-your-cnn-image-classifier-performance-with-progressive-resizing-in-keras-a7d96da06e20","code_link":"https://github.com/ResidentMario/progressive-resizing","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1558,"title":"An introduction to hyperparameter search with CIFAR-10","description":"A primer on one of the most common and useful techniques in machine learning.","tags":["article","hyperparameter-optimization"],"details":"One of the most common operations in machine learning is hyperparameter search. Hyperparameter search is the process of finding the magic model tuning values\u200a\u2014\u200athe hyperparameters \u2014which enable the highest possible model performance.\r\n\r\nIn this article I will showcase the core concepts and three most common techniques for performing hyperparameter search, and provide some tips for speeding up the search process that I have found helpful in my own projects.\r\n\r\nI will do so using the cifar10_cnn Keras demo model and the spell hyper Spell CLI command, but note that the same core ideas apply when using a different implementation or framework.","links":[{"article_link":"https://spell.run/blog/an-introduction-to-hyperparameter-search-with-cifar10-Xo8_6BMAACEAkwVs","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1557,"title":"Reduce cloud GPU model training costs using spot instances","description":"Though tricky to use, spot instances are essential to cost savings on large model training jobs.","tags":["article","aws","project-management","training","gcp"],"details":"While prices have steadily decreased over time, cloud GPUs remain one of the most expensive compute resources available. If you or your team trains deep learning models on the cloud, you can substantially reduce your monthly bill by switching from basic pay-as-you-go on-demand instances to the more complicated (but also more economical!) spot instances.","links":[{"article_link":"https://spell.run/blog/reduce-gpu-model-training-costs-using-spot-XqtgJBAAACMAR6h8","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1556,"title":"Guide to mixed precision training with PyTorch","description":"The mixed-precision training module forthcoming in PyTorch 1.6 provides speed-ups of up to 50-60% for large ML model training jobs.","tags":["article","tutorial","pytorch","training"],"details":"One of the most exciting additions expected to land in PyTorch 1.6, coming soon, is support for automatic mixed-precision training.\r\n\r\nMixed-precision training is a technique for substantially reducing neural net training time by performing as many operations as possible in half-precision floating point, fp16, instead of the (PyTorch default) single-precision floating point, fp32. Recent generations of NVIDIA GPUs come loaded with special-purpose tensor cores specially designed for fast fp16 matrix operations.\r\n\r\nHowever, up until now these tensor cores have remained difficult to use, as it has required writing reduced precision operations into your model by hand. This is where the automatic in automatic mixed-precision training comes in. The soon-to-be-released torch.cuda.amp API will allow you to implement mixed precision training into your training scripts in just five lines of code!","links":[{"article_link":"https://spell.run/blog/mixed-precision-training-with-pytorch-Xuk7YBEAACAASJam","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1555,"title":"Advertisement Classifier","description":"This project is about predicting whether a user will click on advertisement or not on a particular website and the model scores 95% accuracy on test data","tags":["code","tutorial","machine-learning","random-forests","classification","decision-tree","data-science","exploratory-data-analysis"],"details":"This project is about predicting whether a user will click on advertisement or not on a particular website. The machine learning model is made using the Random Forest Classifier and achieved **95%** as accuracy score on testing data.","links":[{"article_link":"","code_link":"https://github.com/rachit0705/Advertisement-classifier","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1554,"title":"Diabetes Classifier","description":"The machine learning model uses DecisionTree classifier to predict whether a person is diabetic or not","tags":["code","notebook","tutorial","python","decision-trees","machine-learning","classification","data-science","exploratory-data-analysis"],"details":"","links":[{"article_link":"","code_link":"https://github.com/rachit0705/Diabetes-Classifer","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1552,"title":"Workshop on Scalability in Autonomous Driving - Andrej Karpathy","description":"An overview of autonomous driving and computer vision at Tesla.","tags":["video","autonomous-vehicles","computer-vision","cvpr-2020","tesla"],"details":"Andrej is the Senior Director of AI at Tesla, where he leads the team responsible for all neural networks on the Autopilot. Previously, Andrej was a Research Scientist at OpenAI working on Deep Learning in Computer Vision, Generative Modeling and Reinforcement Learning. Andrej received his PhD from Stanford, where he worked with Fei-Fei Li on Convolutional/Recurrent Neural Network architectures and their applications in Computer Vision, Natural Language Processing and their intersection. Over the course of his PhD, Andrej squeezed in two internships at Google where he worked on large-scale feature learning over YouTube videos, and in 2015 he interned at DeepMind and worked on Deep Reinforcement Learning. Together with Fei-Fei, Andrej designed and taught a new Stanford class on Convolutional Neural Networks for Visual Recognition (CS231n). The class was the first Deep Learning course offering at Stanford and has grown from 150 enrolled in 2015 to 330 students in 2016, and 750 students in 2017.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=g2R2T631x7k","dataset_link":"","demo_link":"","other_link":""}]},{"id":1551,"title":"Pokemon Classifier","description":"I want to build a classifier that can classify 150 types of Pokemon.","tags":["code","tutorial","tensorflow","convolutional-neural-networks","computer-vision","pokemon"],"details":"","links":[{"article_link":"","code_link":"https://github.com/chandbud5/Pokemon-Classifier","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1550,"title":"Transformer Reinforcement Learning","description":"Leandro von Werra tells us about his new library which enables you to fine-tune GPT-2 towards a higher-level objective (sentiment of the generated text).","tags":["video","transformers","natural-language-processing","reinforcement-learning"],"details":"Leandro von Werra tells us about his new library which enables you to fine-tune GPT-2 towards a higher-level objective (like e.g. the sentiment of the generated text).","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=xQ5nc1CF7iQ","dataset_link":"","demo_link":"","other_link":""}]},{"id":1549,"title":"Deep Model-Based RL for Real-World Robotic Control","description":"Short talk about model-based RL by Sergey Levine.","tags":["video","meta-learning","reinforcement-learning","meta-reinforcement-learning","model-based-reinforcement-learning"],"details":"Short talk about model-based RL by Sergey Levine, prepared for the ICRA 2020 Workshop on Machine Learning for Planning and Controls, covering recent and older research on model-based RL, especially model-based RL in robotics. Topics include: basic deep model-based RL algorithms, model-based meta-RL, and model-based RL with image observations.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=ZQZcBSSeUu4","dataset_link":"","demo_link":"","other_link":""}]},{"id":1548,"title":"A Tutorial on VAEs: From Bayes' Rule to Lossless Compression","description":"an overview of the VAE and a tour through various derivations and interpretations of the VAE objective.","tags":["code","notebook","paper","research","tutorial","autoencoders","variational-autoencoders","bayes-rule","loseless-compression","arxiv:2006.10273"],"details":"The Variational Auto-Encoder (VAE) is a simple, efficient, and popular deep maximum likelihood model. Though usage of VAEs is widespread, the derivation of the VAE is not as widely understood. In this tutorial, we will provide an overview of the VAE and a tour through various derivations and interpretations of the VAE objective. From a probabilistic standpoint, we will examine the VAE through the lens of Bayes' Rule, importance sampling, and the change-of-variables formula. From an information theoretic standpoint, we will examine the VAE through the lens of lossless compression and transmission through a noisy channel. We will then identify two common misconceptions over the VAE formulation and their practical consequences. Finally, we will visualize the capabilities and limitations of VAEs using a code example (with an accompanying Jupyter notebook) on toy 2D data.","links":[{"article_link":"","code_link":"https://github.com/ronaldiscool/VAETutorial","research_link":"https://arxiv.org/abs/2006.10273","media_link":"","dataset_link":"","demo_link":"","other_link":"https://github.com/ronaldiscool/VAETutorial/blob/master/VAEtoy2d.ipynb"}]},{"id":1547,"title":"RoBERTa meets TPUs","description":"Understanding and applying the RoBERTa model to the current challenge.","tags":["code","tutorial","huggingface","pytorch","attention","bert","transformers","natural-language-processing","tpu","pytorch-lightning","roberta"],"details":"This is only the training part. For [inference](https://www.kaggle.com/yassinealouini/model-inference-only), you can check this notebook. You only need to save the model as a dataset and load it. One more thing to notice is that the inference part uses GPU and not TPU since it wasn't allowed. Some people have reported some discrepancy between training on TPU vs training on GPU then predicting on GPU. If you know why, please share your insights in the comments below.","links":[{"article_link":"","code_link":"https://www.kaggle.com/yassinealouini/roberta-meets-tpus","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1546,"title":"DeepSNAP","description":"Python library assists deep learning on graphs.","tags":["code","pytorch","library","graph-neural-networks","graphs","deepsnap"],"details":"DeepSNAP is a Python library to assist efficient deep learning on graphs. DeepSNAP features in its support for flexible graph manipulation, standard pipeline, heterogeneous graphs and simple API.","links":[{"article_link":"","code_link":"https://github.com/snap-stanford/deepsnap","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://snap.stanford.edu/deepsnap/"}]},{"id":1545,"title":"Tensorflow Fourier Feature Mapping Networks","description":"Tensorflow 2.0 implementation of fourier feature mapping networks.","tags":["code","paper","research","tensorflow","fourier-transformations","arxiv:2006.10739"],"details":"Tensorflow 2.0 implementation of Fourier Feature Mapping networks from the paper [Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains](https://arxiv.org/abs/2006.10739).","links":[{"article_link":"","code_link":"https://github.com/titu1994/tf_fourier_features","research_link":"https://arxiv.org/abs/2006.10739","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1544,"title":"Implicit Neural Representations with Periodic Activation Function","description":"Leverage periodic activation functions for implicit neural representations & demonstrate that these networks, dubbed sinusoidal representation networks or SIREN","tags":["article","code","notebook","paper","research","video","relu","siren","activation-functions","tanh","softplus","arxiv:2006.09661"],"details":"We propose to leverage periodic activation functions for implicit neural representations and demonstrate that these networks, dubbed sinusoidal representation networks or SIREN, are ideally suited for representing complex natural signals and their derivatives. We analyze SIREN activation statistics to propose a principled initialization scheme and demonstrate the representation of images, wavefields, video, sound, and their derivatives. Further, we show how SIREN s can be leveraged to solve challenging boundary value problems, such as particular Eikonal equations (yielding signed distance functions), the Poisson equation, and the Helmholtz and wave equations. Lastly, we combine SIREN with hypernetworks to learn priors over the space of SIREN functions.","links":[{"article_link":"https://vsitzmann.github.io/siren/","code_link":"https://github.com/vsitzmann/siren","research_link":"https://arxiv.org/abs/2006.09661","media_link":"https://www.youtube.com/watch?v=Q2fLWGBeaiI","dataset_link":"","demo_link":"","other_link":"https://colab.research.google.com/github/vsitzmann/siren/blob/master/explore_siren.ipynb"}]},{"id":1542,"title":"Autocoder - Finetuning GPT-2 for Auto Code Completion","description":"A basic and simple tool for code auto completion, built upon GPT-2","tags":["article","code","gpt2","transformers","code-generation","natural-language-processing"],"details":"This article first gives an introduction to the Autocoder\u2019s background, and then reveals the details of how the dataset is prepared and the fine-tuning process with GPT-2 is conducted in programming with Python. I will also give some of my personal reflections on the generated codes by Autocoder. Finally, a list of future pointers to Autocoder will be presented. Although this article looks like a technical introduction to Autocoder, I also by the way talk about a lot of relevant stuff, such as nice work, status quo, and future directions in NLP.\r\n\r\nIn analogy, the pre-training of GPT-2 is like our language learning in school in the past. The fine-tuning of GPT-2 for Autocoder is like we step into university and select a programming module for learning how to code. Autocoder at inference time is like we sit in the exam room for testing how well we learn from the past and the programming module. I\u2019d like to say humans will achieve a better score than Autocoder at 100% percent (maybe not sometimes\ud83d\ude02) if they go through all materials of the programming module (like Autocoder is trained through epochs of iterations of the training set). Then what is the problem?","links":[{"article_link":"https://wangcongcong123.github.io/AutoCoder/","code_link":"https://github.com/wangcongcong123/auto_coding","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1541,"title":"Data Science FAQ Search Engine","description":"A search engine to help budding data scientists find resources","tags":["similarity-search","streamlit","semantic-search","demo"],"details":"A search engine made with hybrid search using TF-IDF and USE model.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"http://ask.pratik.ai/","other_link":""}]},{"id":1540,"title":"codeBERT - Masked Language Model for source code ","description":"Tutorial to use codeBERT a MLM for Python code. Model trained from scratch using roBERTa","tags":["code","notebook","tutorial","huggingface","attention","bert","machine-learning","transformers","language-modeling","natural-language-processing","ml-on-code","machine-learning-on-code"],"details":"\ud83c\udfaf We are working  on automatically document source code \r\n\r\n1 ) Build MLM for Python code \r\n\r\n2 ) Fine tune MLM over code documentation\r\n\r\n3 ) Extend model to other languages\r\n\r\n\ud83c\udfc6  codeBERT is the first step. A **Masked Language Model for Python  source** built code using roBERTa.\r\n\r\n\ud83d\udcbb Model is hosted on  [hugging face platform](https://huggingface.co/codistai/codeBERT-small-v2)\r\n\r\n\ud83d\udcf0  Stay tune here : [CodistAI](http://codist-ai.com/)","links":[{"article_link":"","code_link":"https://colab.research.google.com/drive/11gA69kXW2MfD0zOm3TeyqXnaHV9C_Frb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1539,"title":"A Visual Guide to FastText Word Embeddings","description":"A deep-dive into how FastText enriches word vectors with sub-word information  ","tags":["article","tutorial","fasttext","embeddings","natural-language-processing","word-embeddings"],"details":"- Get a basic intuition on word representations\r\n- Understand pitfalls of previous methods such as word2vec\r\n- Understand how FastText algorithm solves these challenges","links":[{"article_link":"https://amitness.com/2020/06/fasttext-embeddings/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1536,"title":"Simple Pytorch Implementation of BYOL in Google Colab","description":"BYOL: Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning (https://arxiv.org/abs/2006.07733)","tags":["code","notebook","paper","research","tutorial","pytorch","self-supervised-learning","demo","byol","latent-representations","arxiv:2006.07733"],"details":"The major simplicity is bought in with the repository having both notebook version and a simple single python file. Readily Executable in Google Colab.\r\nLink -[ https://colab.research.google.com/drive/1T6UJ-hU1d3qZ7ActBubn5tEOihLErhGA#scrollTo=Ioq4CAvRHjgY]( https://colab.research.google.com/drive/1T6UJ-hU1d3qZ7ActBubn5tEOihLErhGA#scrollTo=Ioq4CAvRHjgY)","links":[{"article_link":"","code_link":"https://github.com/ReshinthAdith/BYOL-Pytorch","research_link":"https://arxiv.org/abs/2006.07733","media_link":"","dataset_link":"","demo_link":"https://colab.research.google.com/drive/1T6UJ-hU1d3qZ7ActBubn5tEOihLErhGA","other_link":""}]},{"id":1534,"title":"SimCLR with PyTorch Lightning","description":"A lightweight implementation of SimCLR with PyTorch Lightning. Will be used as the start point for modifications on top of SimCLR to experiment.","tags":["code","paper","research","pytorch","self-supervised-learning","unsupervised-learning","pytorch-lightning","simclr","arxiv:2002.05709"],"details":"A lightweight implementation of SimCLR with PyTorch Lightning that I'm using to explore the utility of PyTorch Lightning, as well as to experiment with SimCLR for traditional image data, while also experimenting with various regularization techniques, such as mixup (data and manifold), different types of normalization (BN, group-norm, weight standardization, etc.).","links":[{"article_link":"","code_link":"https://github.com/dthiagarajan/simclr_pytorch","research_link":"https://arxiv.org/abs/2002.05709","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1533,"title":"Caliban","description":"A CLI tool that transparently dockerizes your research workflows then helps you develop interactively in the container, locally or submit batch jobs to GCP.","tags":["code","research","docker","library","experiments","cloud","caliban","reproducibility"],"details":"Caliban is a tool that helps researchers launch and track their numerical experiments in an isolated, reproducible computing environment. It was developed by machine learning researchers and engineers, and makes it easy to go from a simple prototype running on a workstation to thousands of experimental jobs running on Cloud.","links":[{"article_link":"","code_link":"https://github.com/google/caliban","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://caliban.readthedocs.io/en/latest/"}]},{"id":1532,"title":"How Trigo Built a Scalable AI Pipeline for Frictionless Retail","description":"Using PyTorch development and deployment pipelines to create checkout-free systems.","tags":["article","pytorch","retail","deployment","trigo"],"details":"In order to build checkout-free systems we employ multiple AI & PyTorch models and techniques, with an application logic layered on top that combines all these inferences into one coherent decision. This is very similar to an autonomous vehicle, where one would have different systems, like lane detection, object avoidance, GPS location, path find etc, with a unified logic layer on top combining all the different sensors and models into a single decision for the vehicle to take at any given moment.","links":[{"article_link":"https://medium.com/pytorch/how-trigo-built-a-scalable-ai-development-deployment-pipeline-for-frictionless-retail-b583d25d0dd","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.trigo.tech/"}]},{"id":1531,"title":"Fourier Features Let Networks Learn High Frequency Functions","description":"We show that passing input points through a simple Fourier feature mapping enables an MLP to learn high-frequency functions in low-dimensional problem domains.","tags":["article","code","notebook","research","multilayer-perceptrons","fourier-features"],"details":"These results shed light on recent advances in computer vision and graphics that achieve state-of-the-art results by using MLPs to represent complex 3D objects and scenes. Using tools from the neural tangent kernel (NTK) literature, we show that a standard MLP fails to learn high frequencies both in theory and in practice. To overcome this spectral bias, we use a Fourier feature mapping to transform the effective NTK into a stationary kernel with a tunable bandwidth. We suggest an approach for selecting problem-specific Fourier features that greatly improves the performance of MLPs for low-dimensional regression tasks relevant to the computer vision and graphics communities.","links":[{"article_link":"http://people.eecs.berkeley.edu/~bmild/fourfeat/","code_link":"https://github.com/tancik/fourier-feature-networks","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://colab.research.google.com/github/tancik/fourier-feature-networks/blob/master/Demo.ipynb"}]},{"id":1530,"title":"Neural Manifold Ordinary Differential Equations","description":"A manifold generalization of Neural ODEs, and construct Manifold Continuous Normalizing Flows (MCNFs)","tags":["code","paper","research","ordinary-differential-equations","manifold","ode","manifold-continuous-normalizing-flows","mcnf","arxiv:2006.10254"],"details":"We introduce Neural Manifold Ordinary Differential Equations, a manifold generalization of Neural ODEs, and construct Manifold Continuous Normalizing Flows (MCNFs). MCNFs require only local geometry (therefore generalizing to arbitrary manifolds) and compute probabilities with continuous change of variables (allowing for a simple and expressive flow construction). We find that leveraging continuous manifold dynamics produces a marked improvement for both density estimation and downstream tasks.","links":[{"article_link":"","code_link":"https://github.com/CUVL/Neural-Manifold-Ordinary-Differential-Equations","research_link":"https://arxiv.org/abs/2006.10254","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1529,"title":"Using Selective Attention in Reinforcement Learning Agents","description":"In this work, we establish that self-attention can be viewed as a form of indirect encoding, which enables us to construct highly parameter-efficient agents.","tags":["article","code","paper","research","attention","self-attention","interpretability","reinforcement-learning","neuroevolution","selective-attention","self-interpretable-agents","arxiv:2003.08165"],"details":"In our recent GECCO 2020 paper, \u201cNeuroevolution of Self-Interpretable Agents\u201d (AttentionAgent), we investigate the properties of such agents that employ a self-attention bottleneck. We show that not only are they able to solve challenging vision-based tasks from pixel inputs with 1000x fewer learnable parameters compared to conventional methods, they are also better at generalization to unseen modifications of their tasks, simply due to its ability to \u201cnot see details\u201d that can confuse it.","links":[{"article_link":"https://ai.googleblog.com/2020/06/using-selective-attention-in.html","code_link":"https://github.com/google/brain-tokyo-workshop/tree/master/CarRacingExtension","research_link":"https://arxiv.org/abs/2003.08165","media_link":"","dataset_link":"","demo_link":"","other_link":"https://attentionagent.github.io/"}]},{"id":1528,"title":"The Future of Computer Vision is Self-Supervised Learning","description":"Talk by Yann Lecun on the applications of self-supervised learning on computer vision during CVPR 2020.","tags":["tutorial","video","deep-learning","computer-vision","cvpr-2020"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.facebook.com/wdeepvision2020/videos/2301388736824154","dataset_link":"","demo_link":"","other_link":""}]},{"id":1527,"title":"Face detection","description":"https://github.com/garimasingh128/Face-detection","tags":["code","artificial-general-intelligence","machine-learning","support-vector-machines","done"],"details":"","links":[{"article_link":"","code_link":"https://github.com/garimasingh128/Face-detection","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1525,"title":"Huggingtweets","description":"This is a streamlit app built around the huggingtweets project. I fine-tune a pre-trained gpt2 model to tweet like a user given twitter handle.  ","tags":["code","tutorial","transformers","natural-language-processing","streamlit"],"details":"","links":[{"article_link":"","code_link":"https://github.com/Pradhy729/huggingtweets","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1524,"title":"Machine Learning Projects ","description":"This Repo contains projects done by me while learning the basics. All the familiar types of regression, classification, and clustering methods have been used.","tags":["code","machine-learning","regression","classification","clustering","natural-language-processing"],"details":"","links":[{"article_link":"","code_link":"https://github.com/vedantpople4/ML_Projects","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1522,"title":"Plotting top loss images while training models","description":"The report shows why and how one should investigate the images that cause the top losses during training.","tags":["article","code","tutorial","tensorflow","deep-learning","wandb","model-debugging"],"details":"Data is a noteworthy piece of Machine Learning models. Subsequently, this is the reason it is urgent to ensure that our models are exposed to quality data while they are training. Like in our lives, lessons that are too confusing to grasp make learning a corresponding topic incredibly difficult for us. The same drill applies to machine learning models too.\r\n\r\nIn this report, we are going to show you how to investigate the data points from a training set that makes a model incur very high losses.","links":[{"article_link":"https://app.wandb.ai/tulasi1729/plot-top-losses/reports/Plotting-top-loss-images-while-training-models--VmlldzoxMTI0NDk","code_link":"https://github.com/tulasiram58827/plot_top_losses_keras","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1521,"title":"Scooping into Model Pruning in Deep Learning","description":"This report discusses pruning techniques in the context of deep learning.","tags":["article","code","notebook","tutorial","tensorflow","model-compression","pruning","wandb"],"details":"This report is the successor of [my part report on Quantization](https://app.wandb.ai/sayakpaul/tale-of-quantization/reports/A-Tale-of-Model-Quantization-in-TF-Lite--Vmlldzo5MzQwMA). In this report, we're going to go over the mechanics of model pruning in the context of deep learning. Model pruning is the art of discarding those weights that do not signify a model's performance. Carefully pruned networks lead to their better-compressed versions and they often become suitable for on-device deployment scenarios.\r\n\r\nThe content of the report is structured into the following sections:\r\n\r\n* The notion of \"Non-Significance\" in Functions and Neural Networks\r\n* Pruning a Trained Neural Network\r\n* Code Snippets and Performance Comparisons between Different Models\r\n* Modern Pruning Techniques\r\n* Final Thoughts and Conclusion","links":[{"article_link":"https://app.wandb.ai/authors/pruning/reports/Scooping-into-Model-Pruning-in-Deep-Learning--VmlldzoxMzcyMDg","code_link":"https://colab.research.google.com/github/sayakpaul/Adventures-in-TensorFlow-Lite/blob/master/Model_Pruning_in_Deep_Learning_with_tfmot.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1520,"title":"Generating cooking recipes using TensorFlow and LSTM RNN","description":"This article contains details of how the recipes generation LSTM model was trained on Python using TensorFlow 2 with Keras API.","tags":["article","code","tutorial","keras","python","tensorflow","recurrent-neural-networks","cooking","demo"],"details":"I've trained a character-level LSTM _(Long short-term memory)_ RNN _(Recurrent Neural Network)_ on _~100k_ recipes dataset using TensorFlow, and it suggested me to cook _\"Cream Soda with Onions\"_, _\"Puff Pastry Strawberry Soup\"_, _\"Zucchini flavor Tea\"_ and _\"Salmon Mousse of Beef and Stilton Salad with Jalapenos\"_ .\r\n\r\nHere you may find more examples of what I ended up with:\r\n\r\n- \ud83c\udfa8 [**Cooking recipes generator demo**](https://trekhleb.github.io/machine-learning-experiments/#/experiments/RecipeGenerationRNN) - to try the model interactively right in your browser.\r\n- \ud83c\udfcb [**LSTM model training process**](https://github.com/trekhleb/machine-learning-experiments/blob/master/experiments/recipe_generation_rnn/recipe_generation_rnn.ipynb) - to see how the model was trained.\r\n- [**\ud83e\udd16 Interactive Machine Learning Experiments**](https://github.com/trekhleb/machine-learning-experiments) repository - to see more experiments with \"Objects detection\", \"Sketch Recognition\", \"Image Classification\" etc.\r\n\r\nThis article contains details of how the LSTM model was actually trained on Python using [TensorFlow 2](https://www.tensorflow.org/) with [Keras API](https://www.tensorflow.org/guide/keras).\r\n\r\n![Cooking recipes generator demo](https://raw.githubusercontent.com/trekhleb/machine-learning-experiments/master/assets/images/recipes_generation/00-demo.gif)\r\n\r\n","links":[{"article_link":"https://github.com/trekhleb/machine-learning-experiments/blob/master/assets/recipes_generation.en.md","code_link":"https://github.com/trekhleb/machine-learning-experiments/blob/master/assets/recipes_generation.en.md","research_link":"","media_link":"","dataset_link":"","demo_link":"https://trekhleb.github.io/machine-learning-experiments/#/experiments/RecipeGenerationRNN","other_link":""}]},{"id":1519,"title":"Image and Bounding Box Annotation Slicer","description":"This easy-to-use library slices (also resizes) images and its bounding box annotations into tiles of specific sizes or any arbitrary number of equal parts. \u2702\ufe0f","tags":["code","library","utilities","computer-vision","object-detection","preprocessing"],"details":"This easy-to-use library is a data transformer maybe useful in Object Detection tasks. It splits images and their bounding box annotations into tiles, both into specific sizes and into any arbitrary number of equal parts. It can also resize them, both by specific sizes and by a resizing/scaling factor. Currently only supports PASCAL VOC format. COCO format support will be added soon.","links":[{"article_link":"","code_link":"https://github.com/acl21/image_bbox_slicer","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://image-bbox-slicer.readthedocs.io/en/latest/"}]},{"id":1518,"title":"Introduction to Neural Network Models of Cognition - Online Book","description":"On-line interactive book introducing the history, theory, and math of Neural Network Models with Python, from a Cog Science perspective.","tags":["article","code","tutorial","convolutional-neural-networks","deep-learning","neural-networks","recurrent-neural-networks"],"details":"This project is complete. It may serve as a one semester course material for advance undergraduates or early-stage graduate students, which are interested in neural networks and deep learning from a cognitive science perspective.\r\n\r\nThe goal of this project is to introduce a selection of canonical neural network models of cognition. Each section covers the following contents:\r\n\r\n* Historical and theoretical background\r\n* Mathematical formaliation\r\n* Code implementation in Python\r\n* Example application\r\n* Model limitations\r\n* Models are implemented in Python as Jupyter Notebooks tutorials. Although is recommended to follow the tutorials in a linear fashion, they can be used as stand-alone learning material.\r\n\r\nThe tutorials are intended to be used by beginner to intermediate level students and/or researchers in cognitive science or related fields, for instance, advance undergraduates or early-stage graduate students. Knowledge of Python is not required, but it is advised to have previous exposure/experience working with some dynamically typed programming language like R, Julia, Scala, or Matlab.","links":[{"article_link":"https://com-cog-book.github.io/com-cog-book/intro.html","code_link":"https://github.com/pabloinsente/nn-mod-cog","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://com-cog-book.github.io/com-cog-book/intro.html"}]},{"id":1517,"title":"NeuralPy: A Keras like DL libary that works on top of PyTorch","description":"NeuralPy is a High-Level Keras like deep learning library that works on top of PyTorch written in pure Python. ","tags":["article","code","keras","pytorch","deep-learning","machine-learning","library"],"details":"NeuralPy is a High-Level Keras like deep learning library that works on top of PyTorch written in pure Python. NeuralPy can be used to develop state-of-the-art deep learning models in a few lines of code. It provides a Keras like simple yet powerful interface to build and train models.\r\n\r\nHere are some highlights of NeuralPy:\r\n\r\n* Provides an easy interface that is suitable for fast prototyping, learning, and research\r\n* Can run on both CPU and GPU\r\n* Works on top of PyTorch\r\n* Cross-Compatible with PyTorch models\r\n","links":[{"article_link":"https://medium.com/@imdeepmind/introduction-to-neuralpy-a-keras-like-deep-learning-library-works-on-top-of-pytorch-3bbf1b887561?source=---------2------------------","code_link":"https://github.com/imdeepmind/NeuralPy","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://neuralpy.imdeepmind.com/"}]},{"id":1515,"title":"Cut, Paste and Learn: Surprisingly Easy Synthesis for Detection","description":"Generate synthetic scenes and bounding box annotations for object detection.","tags":["code","paper","research","computer-vision","data-augmentation","object-detection","segmentation","instance-segmentation","arxiv:1708.01642"],"details":"A major impediment in rapidly deploying object detection models for instance detection is the lack of large annotated datasets. For example, finding a large labeled dataset containing instances in a particular kitchen is unlikely. Each new environment with new instances requires expensive data collection and annotation. In this paper, we propose a simple approach to generate large annotated instance datasets with minimal effort. Our key insight is that ensuring only patch-level realism provides enough training signal for current object detector models. We automatically `cut' object instances and `paste' them on random backgrounds. A naive way to do this results in pixel artifacts which result in poor performance for trained models. We show how to make detectors ignore these artifacts during training and generate data that gives competitive performance on real data. Our method outperforms existing synthesis approaches and when combined with real images improves relative performance by more than 21% on benchmark datasets. In a cross-domain setting, our synthetic data combined with just 10% real data outperforms models trained on all real data.","links":[{"article_link":"","code_link":"https://github.com/debidatta/syndata-generation","research_link":"https://arxiv.org/abs/1708.01642","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1512,"title":"G5: A Universal GRAPH-BERT for Graph-to-Graph Transfer","description":"Further investigate the graph-to-graph transfer of a universal GRAPH-BERT for graph representation learning across different graph datasets","tags":["paper","research","attention","bert","transformers","graph-neural-networks","graphs","natural-language-processing","representation-learning","g5","graph-bert","arxiv:2006.06183"],"details":"GRAPH-BERT provides an opportunity for transferring pre-trained models and learned graph representations across different tasks within the same graph dataset. In this paper, we will further investigate the graph-to-graph transfer of a universal GRAPH-BERT for graph representation learning across different graph datasets, and our proposed model is also referred to as the G5 for simplicity. ","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2006.06183","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1511,"title":"RepNet - Class Agnostic Video Repetition Counting in the Wild","description":"Counting Out Time: Class Agnostic Video Repetition Counting in the Wild","tags":["code","paper","research","video","computer-vision","action-recognition","cvpr-2020","deepmind","repnet","repition-counting"],"details":"We present an approach for estimating the period with which an action is repeated in a video. The crux of the approach lies in constraining the period prediction module to use temporal self-similarity as an intermediate representation bottleneck that allows generalization to unseen repetitions in videos in the wild. We train this model, called RepNet, with a synthetic dataset that is generated from a large unlabeled video collection by sampling short clips of varying lengths and repeating them with different periods and counts. This combination of synthetic data and a powerful yet constrained model, allows us to predict periods in a class-agnostic fashion. Our model substantially exceeds the state of the art performance on existing periodicity (PERTUBE) and repetition counting (QUVA) benchmarks. We also collect a new challenging dataset called Countix (~90 times larger than existing datasets) which captures the challenges of repetition counting in real-world videos.\r\n\r\n**Architecture**:\r\n\r\n![Detailed architecture of RepNet. The Temporal Self-similarity Matrix plays a key role in RepNet. The following animation shows how we construct it. ](https://lh6.googleusercontent.com/cVdMxm7mMFEGJzixiT4Ngcj2YXFoG7yky-9pYwrwF8H84bVZ-TlckJ6nmBr8NOogGgn_4_BpycjUs6cGxXgfdTVaNDBtwjzCYT9Dk38tjotqZNHvRg=w1280)\r\n\r\n**Applications**:\r\n\r\n![One model that works across many domains can enable many applications.](https://lh3.googleusercontent.com/YrV9M-g8zDwxdnOrcwxix5Kn-A0ImXLKv_-gI6_FnCclFifwLqBqFj3DJnkJKCdMTcvcY6btqltQi1Wtdp-UZ2ipLLOK0Oh2sOIXAVKtIe7q37itcm4U=w1280)\r\n","links":[{"article_link":"","code_link":"","research_link":"http://openaccess.thecvf.com/content_CVPR_2020/papers/Dwibedi_Counting_Out_Time_Class_Agnostic_Video_Repetition_Counting_in_the_CVPR_2020_paper.pdf","media_link":"https://www.youtube.com/watch?v=bvqg-ngu54g","dataset_link":"","demo_link":"","other_link":"https://sites.google.com/view/repnet"}]},{"id":1510,"title":"Personalized Cancer Diagnosis(Gene/Mutation)","description":"Problem statement :\r\nClassify the given genetic variations/mutations based on evidence from text-based clinical literature.","tags":["code","dataset","there-are-nine-different-classes-a-genetic-mutation-can-be-classified-into-=>-multi-class-classification-problem"],"details":"We have two data files: one contains the information about the genetic mutations and the other contains the clinical evidence (text) that human experts/pathologists use to classify the genetic mutations.\r\n\r\nBoth these data files are have a common column called ID\r\n\r\nData file's information: training_variants (ID , Gene, Variations, Class) training_text (ID, Text)\r\n\r\n Real-world/Business objectives and constraints.\r\n\r\nNo low-latency requirement.\r\n\r\nInterpretability is important.\r\n\r\nErrors can be very costly.\r\n\r\nProbability of a data-point belonging to each class is needed.","links":[{"article_link":"","code_link":"https://github.com/balaramkolluru/Personalized-Cancer-Diagnosis","research_link":"","media_link":"","dataset_link":"2.1.1. Data Overview Source: https://www.kaggle.com/c/msk-redefining-cancer-treatment/data","demo_link":"","other_link":""}]},{"id":1509,"title":"Visual Grounding in Video for Unsupervised Word Translation","description":"Use visual grounding to improve unsupervised word mapping between languages.","tags":["article","paper","research","video","unsupervised-learning","visual-grounding","language-mapping","arxiv:2003.05078"],"details":"There are thousands of actively spoken languages on Earth, but a single visual world. Grounding in this visual world has the potential to bridge the gap between all these languages. Our goal is to use visual grounding to improve unsupervised word mapping between languages. The key idea is to establish a common visual representation between two languages by learning embeddings from unpaired instructional videos narrated in the native language. Given this shared embedding we demonstrate that (i) we can map words between the languages, particularly the 'visual' words; (ii) that the shared embedding provides a good initialization for existing unsupervised text-based word translation techniques, forming the basis for our proposed hybrid visual-text mapping algorithm, MUVE; and (iii) our approach achieves superior performance by addressing the shortcomings of text-based methods -- it is more robust, handles datasets with less commonality, and is applicable to low-resource languages. ","links":[{"article_link":"https://deepmind.com/research/publications/Visual-Grounding-in-Video-for-Unsupervised-Word-Translation","code_link":"","research_link":"https://arxiv.org/abs/2003.05078","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1508,"title":"Long Form Question Answering with ELI5","description":"A model for open domain long form question answering.","tags":["article","tutorial","huggingface","transformers","natural-language-processing","question-answering","streamlit","eli5","demo","long-form-question-answering"],"details":"In this notebook, we show how we can take advantage of these recent advances to train a long form question answering system which takes in a question, fetches 10 relevant passages from a [Wikipedia snapshot](https://www.aclweb.org/anthology/2020.lrec-1.297/), and writes a multi-sentence answer based on the question and retrieved passages. In particular, training embedding-based retrieval models to gather supporting evidence for open-domain questions is relatively new research area: the last few months have seen some significant progress in cases where direct supervision is available, or with extensive task-specific pretraining. Here, we show how the ELI5 dataset allows us to train a dense retrieval system without access to either, making dense retrieval models more accessible. See this [presentation](https://docs.google.com/presentation/d/1A5wJEzFYGdNem7egJ-BTm6EMI3jGNe1lalyChYL54gw/edit) from the [Hugging Face reading group](https://github.com/huggingface/awesome-papers) for a non-exhaustive overview of recent work in the field.","links":[{"article_link":"https://yjernite.github.io/lfqa.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"https://huggingface.co/qa/","other_link":""}]},{"id":1507,"title":"Amazon Fine Food Reviews(Review, Text Classification)","description":"Objective: Given a review, determine whether the review is positive (Rating of 4 or 5) or negative (rating of 1 or 2).","tags":["article","code","dataset","implemenation-of-all-supervised-learning-and-un-supervised-learning-algorithms-"],"details":"Objective: Given a review, determine whether the review is positive (Rating of 4 or 5) or negative (rating of 1 or 2).\r\n\r\nWe will Apply various Models as shown below.\r\n\r\nT-SNE\r\nK-NN\r\nNaive Bayes\r\nLogistic Regression\r\nTruncated SVD\r\nSVM\r\nDecision Trees\r\nK-means clustering\r\nLSTM","links":[{"article_link":"https://nycdatascience.com/blog/student-works/amazon-fine-foods-visualization/","code_link":"https://github.com/balaramkolluru/Balaram","research_link":"","media_link":"","dataset_link":"Data Source: https://www.kaggle.com/snap/amazon-fine-food-reviews","demo_link":"","other_link":""}]},{"id":1506,"title":"Using GitHub Actions for MLOps & Data Science","description":"A collection of resources on how to facilitate Machine Learning Ops with GitHub.","tags":["article","code","github","tutorial","production","github-actions","ml-ops","ci-cd"],"details":"Machine Learning Operations (or MLOps) enables Data Scientists to work in a more collaborative fashion, by providing testing, lineage, versioning, and historical information in an automated way.  Because the landscape of MLOps is nascent, data scientists are often forced to implement these tools from scratch. The closely related discipline of DevOps offers some help, however many DevOps tools are generic and require the implementation of \u201cML awareness\u201d through custom code. Furthermore, these platforms often require disparate tools that are decoupled from your code leading to poor debugging and reproducibility.\r\n\r\nTo mitigate these concerns, we have created a series of GitHub Actions that integrate parts of the data science and machine learning workflow with a software development workflow. Furthermore, we provide components and examples that automate common tasks.\r\n\r\n![](https://github.blog/wp-content/uploads/2020/06/update-train-py.png?resize=1024%2C1125?w=1506)","links":[{"article_link":"https://github.blog/2020-06-17-using-github-actions-for-mlops-data-science/","code_link":"https://mlops-github.com/","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1505,"title":"Diverse Image Generation via Self-Conditioned GANs","description":"A simple but effective unsupervised method for generating realistic & diverse images using a class-conditional GAN model without using manually annotated class.","tags":["article","code","paper","research","generative-adversarial-networks","computer-vision","data-augmentation","image-generation","unsupervised-learning","cvpr-2020","self-conditioned-gans","arxiv:2006.10728"],"details":"Despite the remarkable progress in Generative Adversarial Networks (GANs), unsupervised models fail to generalize to diverse datasets, such as ImageNet or Places365. To tackle such datasets, we rely on class-conditional GANs, which require class labels to train. These labels are often not available or are expensive to obtain.\r\n\r\nWe propose to increase unsupervised GAN quality by inferring class labels in a fully unsupervised manner. By periodically clustering already present discriminator features, we improve generation quality on large-scale datasets such as ImageNet and Places365. Besides increasing generation quality, we also automatically infer semantically meaningful clusters.","links":[{"article_link":"http://selfcondgan.csail.mit.edu/","code_link":"https://github.com/stevliu/self-conditioned-gan","research_link":"https://arxiv.org/abs/2006.10728","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1504,"title":"Fast Neural Style Transfer (feed-forward method) \u26a1\ud83d\udcbb + \ud83c\udfa8 = \u2764\ufe0f","description":"This repo contains a concise PyTorch implementation of the original feed-forward NST paper.","tags":["code","paper","research","tutorial","video","computer-vision","style-transfer","neural-style-transfer","arxiv:1603.08155"],"details":"This repo contains a concise PyTorch implementation of the original feed-forward NST paper (:link: [Johnson et al.](https://arxiv.org/pdf/1603.08155.pdf)).\r\n\r\nCheckout my implementation of the original NST (optimization method) paper ([Gatys et al.](https://github.com/gordicaleksa/pytorch-neural-style-transfer)).\r\n\r\nIt's an accompanying repo for [this video series on YouTube](https://www.youtube.com/watch?v=S78LQebx6jo&list=PLBoQnSflObcmbfshq9oNs41vODgXG-608).","links":[{"article_link":"","code_link":"https://github.com/gordicaleksa/pytorch-naive-video-nst","research_link":"https://arxiv.org/abs/1603.08155","media_link":"https://www.youtube.com/watch?v=S78LQebx6jo&list=PLBoQnSflObcmbfshq9oNs41vODgXG-608","dataset_link":"","demo_link":"","other_link":""}]},{"id":1503,"title":"Fastbook: Deep learning basics with fastai","description":"These notebooks cover an introduction to deep learning, fastai, and PyTorch. fastai is a layered API for deep learning","tags":["code","fastai","deep-learning"],"details":"","links":[{"article_link":"","code_link":"https://github.com/fastai/fastbook","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1502,"title":"Generate Boolean (Yes/No) Questions From Any Content ","description":"Question generation algorithm trained on the BoolQ dataset using T5 text-to-text transformer model.","tags":["article","code","research","tutorial","huggingface","pytorch","transformers","natural-language-processing","question-generation","t5"],"details":"**Generate boolean (yes/no) questions from any content using T5 text-to-text transformer model and BoolQ dataset**\r\n\r\nPre-trained model and training script are provided\r\n## Input\r\n\r\nThe input to our program will be any **content/paragraph** -\r\n\r\n> Months earlier, Coca-Cola had begun \u201cProject Kansas.\u201d It sounds like a nuclear experiment but it was just a testing project for the new flavor. In individual surveys, they\u2019d found that more than 75% of respondents loved the taste, 15% were indifferent, and 10% had a strong aversion to the taste to the point that they were angry.\r\n\r\n## Ouput\r\n\r\nThe output will be **boolean (yes/no)** questions generated from the above input. \r\n\r\n**Boolean (yes/no) questions generated from the T5 Model :**\r\n\r\n> \r\n> 1: Does coca cola have a kansas flavor?\r\n> \r\n> 2: Is project kansas a new coca cola flavor?\r\n> \r\n> 3: Is project kansas the same as coca cola?\r\n\r\n\r\n\r\n\r\n","links":[{"article_link":"https://medium.com/@ramsrigouthamg/generating-boolean-yes-no-questions-from-any-content-using-t5-text-to-text-transformer-model-69f2744aff44?source=friends_link","code_link":"https://github.com/ramsrigouthamg/generate_boolean_questions_using_T5_transformer","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1501,"title":"Traffic-Sign-Recognition-Using-Deep-Learning","description":"The training dataset contains around 39,000 images while test dataset contains around 12,000 images containing 43 different classes. We will be using Convolutio","tags":["code","dataset","deep-learning","computer-vision"],"details":"","links":[{"article_link":"","code_link":"https://github.com/vivekpandian08/Traffic-Sign-Recognition-Using-Deep-Learning","research_link":"","media_link":"","dataset_link":"http://benchmark.ini.rub.de/?section=gtsrb&subsection=news","demo_link":"","other_link":""}]},{"id":1500,"title":"Bootstrap Your Own Latent (BYOL) in Pytorch","description":"Practical implementation of a new state of the art (surpassing SimCLR) without contrast learning and having to designate negative pairs.","tags":["code","paper","research","pytorch","library","self-supervised-learning","simclr","byol","arxiv:2006.07733"],"details":"This repository offers a module that one can easily wrap any neural network that accepts an image to immediately start benefitting from unlabelled data.","links":[{"article_link":"","code_link":"https://github.com/lucidrains/byol-pytorch","research_link":"https://arxiv.org/abs/2006.07733","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1499,"title":"History of Language Models - Alec Radford","description":"A quick history of language models","tags":["tutorial","video","transformers","language-modeling","natural-language-processing","transfer-learning"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=BnpB3GrpsfM","dataset_link":"","demo_link":"","other_link":""}]},{"id":1498,"title":"Breast cancer detection","description":"By Using KNN algorithm the model achieved 98% accuracy on testing data.","tags":["code","notebook","tutorial","scikit-learn","machine-learning","k-nearest-neighbors","exploratory-data-analysis"],"details":"In this machine learning model I have built the model using two algorithms named KNN and SVM and found that KNN works far better than SVM as SVM achieves only 68% accuracy whereas KNN secured 98% accuracy on testing data.","links":[{"article_link":"","code_link":"https://github.com/rachit0705/Breast-cancer-detection/blob/master/Breast Cancer Detection with KNN.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1497,"title":"SQLZOO","description":"SQLZoo is a free, \"learn-by-doing\" SQL course that immediately starts you on practising  queries in different use cases","tags":["code","tutorial","sql"],"details":"","links":[{"article_link":"","code_link":"https://github.com/jisaw/sqlzoo-solutions","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://sqlzoo.net/"}]},{"id":1494,"title":"Object Goal Navigation using Goal-oriented Semantic Exploration","description":"Embodied interactive learning for object detection by using semantic curiosity to learn an exploration policy on set of the training environments.","tags":["article","paper","research","video","computer-vision","object-detection","object-goal-navigation","semantic-exploration","mapping","exploration-policy"],"details":"Given a set of environments (and some labeling budget), our goal is to learn an object detector by having an agent select what data to obtain labels for. How should an exploration policy decide which trajectory should be labeled? One possibility is to use a trained object detector's failure cases as an external reward. However, training RL policies requires millions of labelled samples, hence making any supervision infeasible. Instead, we explore a self-supervised approach for training our exploration policy by introducing a notion of semantic curiosity. Our semantic curiosity policy is based on a simple observation -- the detection outputs should be consistent. Therefore, our semantic curiosity rewards trajectories with inconsistent labeling behavior and encourages the exploration policy to explore such areas. The exploration policy trained via semantic curiosity generalizes to novel scenes and helps train an object detector that outperforms baselines trained with other possible alternatives such as random exploration, prediction-error curiosity and coverage-maximizing exploration.","links":[{"article_link":"https://www.cs.cmu.edu/~dchaplot/projects/SemanticCuriosity.html","code_link":"","research_link":"http://www.cs.cmu.edu/~dchaplot/papers/semantic_curiosity.pdf","media_link":"https://www.youtube.com/watch?v=QNTs6cdxOoU","dataset_link":"","demo_link":"","other_link":"https://www.cs.cmu.edu/~dchaplot/talks/CVPR20_Semantic_Exploration.pdf"}]},{"id":1493,"title":"A U-Net Based Discriminator for Generative Adversarial Networks","description":"U-Net based architecture allows to provide detailed per-pixel feedback to the generator while maintaining the global coherence of synthesized images.","tags":["paper","research","generative-adversarial-networks","unet","cvpr-2020","discriminator","arxiv:2002.12655"],"details":"Among the major remaining challenges for generative adversarial networks (GANs) is the capacity to synthesize globally and locally coherent images with object shapes and textures indistinguishable from real images. To target this issue we propose an alternative U-Net based discriminator architecture, borrowing the insights from the segmentation literature. The proposed U-Net based architecture allows to provide detailed per-pixel feedback to the generator while maintaining the global coherence of synthesized images, by providing the global image feedback as well. Empowered by the per-pixel response of the discriminator, we further propose a per-pixel consistency regularization technique based on the CutMix data augmentation, encouraging the U-Net discriminator to focus more on semantic and structural changes between real and fake images. This improves the U-Net discriminator training, further enhancing the quality of generated samples. The novel discriminator improves over the state of the art in terms of the standard distribution and image quality metrics, enabling the generator to synthesize images with varying structure, appearance and levels of detail, maintaining global and local realism. Compared to the BigGAN baseline, we achieve an average improvement of 2.7 FID points across FFHQ, CelebA, and the newly introduced COCO-Animals dataset.\r\n","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2002.12655","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1492,"title":"Q*BERT","description":"Agents that build knowledge graphs and explore textual worlds by asking questions.","tags":["code","paper","research","attention","bert","transformers","graphs","knowledge-base-question-answering","knowledge-graphs","natural-language-processing","question-generation","qa","a2c","arxiv:2006.07409"],"details":"Structured exploration using knowledge graph A2C agents. Overall and architecture one-step knowledge graph extraction is seen below: in the Jericho-QA format architecture at time step t. At each step the ALBERT-QA model extracts a relevant highlighted entity set V_t by answering questions based on the observation, which is used to update the knowledge graph.\r\n\r\nCode accompanying paper [How to Avoid Being Eaten by a Grue: Structured Exploration Strategies for Textual Worlds](https://arxiv.org/abs/2006.07409) by Prithviraj Ammanabrolu, Ethan Tien, Matthew Hausknecht, and Mark O. Riedl","links":[{"article_link":"","code_link":"https://github.com/rajammanabrolu/Q-BERT","research_link":"https://arxiv.org/abs/2006.07409","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1491,"title":"Image GPT: Generative Pretraining from Pixels","description":" Transformers trained on pixel sequences can generate coherent image completions and samples.","tags":["article","code","paper","research","tutorial","convolutional-neural-networks","transformers","computer-vision","natural-language-processing","unsupervised-learning","openai","image-completion","image-gpt"],"details":"We find that, just as a large transformer model trained on language can generate coherent text, the same exact model trained on pixel sequences can generate coherent image [completions](https://openai.com/blog/image-gpt/#completions) and [samples](https://openai.com/blog/image-gpt/#samples). By establishing a correlation between sample quality and image classification accuracy, we show that our best generative model also contains features competitive with top convolutional nets in the unsupervised setting.\r\n\r\n","links":[{"article_link":"https://openai.com/blog/image-gpt/","code_link":"https://github.com/openai/image-gpt","research_link":"https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1488,"title":"Smart Picture Editor","description":"Tool to automatically remove unwanted objects from photos","tags":["code","computer-vision","object-detection","face-recognitioni"],"details":"","links":[{"article_link":"","code_link":"https://github.com/sjakka27/smartPicEditor","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1486,"title":"Bootstrap Your Own Latent: Approach to Self-Supervised Learning","description":"A new approach to self-supervised image representation learning.","tags":["code","paper","research","representation-learning","self-supervised-learning","simclr","byol","arxiv:2006.07733"],"details":"We introduce Bootstrap Your Own Latent (BYOL), a new approach to self-supervised image representation learning. BYOL relies on two neural networks, referred to as online and target networks, that interact and learn from each other. From an augmented view of an image, we train the online network to predict the target network representation of the same image under a different augmented view. At the same time, we update the target network with a slow-moving average of the online network. While state-of-the art methods intrinsically rely on negative pairs, BYOL achieves a new state of the art without them. BYOL reaches 74.3% top-1 classification accuracy on ImageNet using the standard linear evaluation protocol with a ResNet-50 architecture and 79.6% with a larger ResNet. We show that BYOL performs on par or better than the current state of the art on both transfer and semi-supervised benchmarks.","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2006.07733","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1485,"title":"Sudoku-Game-Solver","description":"This is a Computer Vision Application that solves a 9x9 sudoku board game using Deep Learning and Backtracking algorithm.","tags":["code","tutorial","convolutional-neural-networks","deep-learning","computer-vision"],"details":"This is a Computer Vision Application that solves a 9x9 Sudoku Puzzle.This application can solve the 3 major difficulties of the puzzle, which include Easy, Medium & Hard. The puzzle is solved by using a Deep Learning Neural Network model to predict the digits in the image. The digits are extracted and solved using Backtracking Algorithm, which is a popular method of solving a sudoku puzzle. The newly found digits are then placed in the empty cells of the puzzle. An extra feature included in this application is the ability to solve the puzzle by reading in live video of the puzzle through the Computer's webcam. Enjoy!","links":[{"article_link":"","code_link":"https://github.com/Pydare/Sudoku-Game-Solver","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://levelup.gitconnected.com/solving-a-sudoku-puzzle-using-deep-learning-and-backtracking-algorithm-c6cef475ae3"}]},{"id":1483,"title":"Short Notes on Model-Based Offline Reinforcement Learning (MOReL)","description":"Blog article on Model-Based Offline Reinforcement Learning (MOReL) paper by Rahul Kidambi & Aravind Rajeswaran et al.","tags":["article","code","paper","research","tutorial","reinforcement-learning","model-based","offline-rl","arxiv:2005.05951"],"details":"This paper deals about the question of how to effectively use model-based RL techniques in the offline RL setting.","links":[{"article_link":"https://medium.com/@f20170720/model-based-offline-reinforcement-learning-morel-f5cd991d9fd5?sk=78a21646513832261c13c5a91c53e08a","code_link":"https://github.com/aravindr93/mjrl","research_link":"https://arxiv.org/abs/2005.05951","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1482,"title":"Real Time Object Detection using CNN YOLO","description":"This project is done on real time object detection using a deep learning object detection algorithm i.e., YOLO.","tags":["code","convolutional-neural-networks","deep-learning","computer-vision","object-detection","yolov3"],"details":"This project is based on real-time detection of objects using Convolutional Neural Network (CNN) . It performs real-time detection of objects in CPU using a deep learning object detection algorithm, YOLO with the help of OpenCV library in Python.","links":[{"article_link":"","code_link":"https://github.com/vaibhavsingh918/Real-Time-Object-Detection-using-CNNs-YOLO","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1480,"title":"A Guide to Natural Language Processing With AllenNLP","description":"basics of using AllenNLP","tags":["course","natural-language-processing","allenai"],"details":"We walk through the basics of using AllenNLP, describing all of the main abstractions used and why we chose them, how to use specific functionality like configuration files or pre-trained representations, and how to build various kinds of models, from simple to complex.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://guide.allennlp.org/"}]},{"id":1479,"title":"Neural Data Server (NDS): Find Best Data to Pre-Train Your Models","description":"A large-scale search engine for finding the most useful transfer learning data to the target domain.","tags":["paper","research","video","fine-tuning","search","transfer-learning","data","demo","neural-data-server","data-search","arxiv:2001.02799"],"details":"Transfer learning has proven to be a successful technique to train deep learning models in the domains where little training data is available. The dominant approach is to pretrain a model on a large generic dataset such as ImageNet and finetune its weights on the target domain. However, in the new era of an ever increasing number of massive datasets, selecting the relevant data for pretraining is a critical issue. We introduce Neural Data Server (NDS), a large-scale search engine for finding the most useful transfer learning data to the target domain. Our NDS consists of a dataserver which indexes several large popular image datasets, and aims to recommend data to a client, an end-user with a target application with its own small labeled dataset. As in any search engine that serves information to possibly numerous users, we want the online computation performed by the dataserver to be minimal. The dataserver represents large datasets with a much more compact mixture-of-experts model, and employs it to perform data search in a series of dataserver-client transactions at a low computational cost. We show the effectiveness of NDS in various transfer learning scenarios, demonstrating state-of-the-art performance on several target datasets and tasks such as image classification, object detection and instance segmentation. We obtain significant improvements over ImageNet pre-training by downloading only 26 Gb of server's data in cases when training on the entire dataserver (538 Gb) would take weeks. ","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2001.02799","media_link":"https://www.youtube.com/watch?v=I308xDHVgU4","dataset_link":"","demo_link":"http://aidemos.cs.toronto.edu/nds/index.html","other_link":"http://aidemos.cs.toronto.edu/nds/paper.html"}]},{"id":1478,"title":"Unsupervised Learning of Probably Symmetric Deformable 3D Objects","description":"A method to learn 3D deformable object categories from raw single-view images, without external supervision.","tags":["article","code","paper","research","video","pytorch","3d","computer-vision","unsupervised-learning","cvpr-2020","demo","3d-objects","3d-reconstruction","arxiv:1911.11130"],"details":"We propose a method to learn 3D deformable object categories from raw single-view images, without external supervision. The method is based on an autoencoder that factors each input image into depth, albedo, viewpoint and illumination. In order to disentangle these components without supervision, we use the fact that many object categories have, at least in principle, a symmetric structure. We show that reasoning about illumination allows us to exploit the underlying object symmetry even if the appearance is not symmetric due to shading. Furthermore, we model objects that are probably, but not certainly, symmetric by predicting a symmetry probability map, learned end-to-end with the other components of the model. Our experiments show that this method can recover very accurately the 3D shape of human faces, cat faces and cars from single-view images, without any supervision or a prior shape model. On benchmarks, we demonstrate superior accuracy compared to another method that uses supervision at the level of 2D image correspondences.","links":[{"article_link":"http://openaccess.thecvf.com/content_CVPR_2020/html/Wu_Unsupervised_Learning_of_Probably_Symmetric_Deformable_3D_Objects_From_Images_CVPR_2020_paper.html","code_link":"https://github.com/elliottwu/unsup3d","research_link":"https://arxiv.org/abs/1911.11130","media_link":"https://www.youtube.com/watch?v=5rPJyrU-WE4","dataset_link":"","demo_link":"http://www.robots.ox.ac.uk/~vgg/blog/unsupervised-learning-of-probably-symmetric-deformable-3d-objects-from-images-in-the-wild.html","other_link":""}]},{"id":1477,"title":"Deep Declarative Networks (CVPR 2020)","description":"Workshop and talks on deep declarative networks from CVPR 2020.","tags":["article","video","cvpr-2020","playlist","deep-declarative-networks"],"details":"Conventional deep learning architectures involve composition of simple feedforward processing functions that are explicitly defined. Recently, researchers have been exploring deep learning models with implicitly defined components. To distinguish these from conventional deep learning models we call them deep declarative networks, borrowing nomenclature from the programming languages community (Gould et al., 2019).","links":[{"article_link":"https://anucvml.github.io/ddn-cvprw2020/","code_link":"","research_link":"","media_link":"https://www.youtube.com/playlist?list=PLD-7XrNHCcFJCxYrZQRYsTvv3mTogWiiI","dataset_link":"","demo_link":"","other_link":""}]},{"id":1476,"title":"Course Review - Causal Inference","description":"Types of understanding that causal inference researchers value.","tags":["article","causal-inference","reinforcement-learning"],"details":"This semester, I had the pleasure of taking a course on Causal Inference with [Professor Elias Bareinboim](https://causalai.net/), one of Judea Pearl\u2019s former students and author of some seminal results in Causal Inference. I feel like this course highlighted not only the content Causal Inference researchers consider important but also the types of understanding they value. In this review, I\u2019ll focus on the latter. I hope to write some blog posts in the future about the former but have learned from past experience not to promise future posts unless I have time during which I know I can write them.","links":[{"article_link":"https://an1lam.github.io/post/2020-05-15-ci-course-review/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1475,"title":"PyTorch3D","description":"FAIR's library of reusable components for deep learning with 3D data.","tags":["code","notebook","video","c++","pytorch","library","3d","computer-vision","cuda","heterogeneous-batching","batching","differentiable-rendering","pytorch-3d"],"details":"PyTorch3D provides efficient, reusable components for 3D Computer Vision research with [PyTorch](https://pytorch.org).\r\n\r\nKey features include:\r\n\r\n- Data structure for storing and manipulating triangle meshes\r\n- Efficient operations on triangle meshes (projective transformations, graph convolution, sampling, loss functions)\r\n- A differentiable mesh renderer\r\n\r\nPyTorch3D is designed to integrate smoothly with deep learning methods for predicting and manipulating 3D data.\r\nFor this reason, all operators in PyTorch3D:\r\n\r\n- Are implemented using PyTorch tensors\r\n- Can handle minibatches of hetereogenous data\r\n- Can be differentiated\r\n- Can utilize GPUs for acceleration\r\n\r\nWithin FAIR, PyTorch3D has been used to power research projects such as [Mesh R-CNN](https://arxiv.org/abs/1906.02739).","links":[{"article_link":"","code_link":"https://github.com/facebookresearch/pytorch3d","research_link":"","media_link":"https://www.youtube.com/watch?v=0JEb7knenps","dataset_link":"","demo_link":"","other_link":"https://pytorch3d.org/"}]},{"id":1474,"title":"OpenSelfSup: Self-Supervised Learning Toolbox and Benchmark","description":"An open source unsupervised representation learning toolbox based on PyTorch.","tags":["code","pytorch","library","representation-learning","self-supervised-learning","unsupervised-learning","simclr","imagenet","moco","deepcluster","pirl"],"details":"Below is the relations among Unsupervised Learning, Self-Supervised Learning and Representation Learning. This repo focuses on the shadow area, i.e., Unsupervised Representation Learning. Self-Supervised Representation Learning is the major branch of it. Since in many cases we do not distingush between Self-Supervised Representation Learning and Unsupervised Representation Learning strictly, we still name this repo as OpenSelfSup.\r\n\r\n![image](https://raw.githubusercontent.com/open-mmlab/OpenSelfSup/master/docs/relation.jpg)","links":[{"article_link":"","code_link":"https://github.com/open-mmlab/OpenSelfSup","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1473,"title":"tslearn","description":"A machine learning toolkit dedicated to time-series data.","tags":["code","library","time-series","time-series-classification","time-series-clustering","dynamic-time-warping"],"details":"tslearn expects a time series dataset to be formatted as a 3D numpy array. The three dimensions correspond to the number of time series, the number of measurements per time series and the number of dimensions respectively (n_ts, max_sz, d). In order to get the data in the right format, different solutions exist:","links":[{"article_link":"","code_link":"https://github.com/tslearn-team/tslearn","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://tslearn.readthedocs.io/en/stable/"}]},{"id":1472,"title":"Getting to the Bottom","description":"We focus on two deep networks with the same architecture but different synaptic weights.","tags":["article","neural-networks","weights","loss","distance"],"details":"In a recent paper written by myself, Arash Vahdat, Yisong Yue and Ming-Yu Liu, we propose a mathematical formula that measures the distance between two neural networks. In particular, we focus on two deep networks with the same architecture but different synaptic weights.","links":[{"article_link":"https://jeremybernste.in/blog/getting-to-the-bottom","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1470,"title":"Audio Tagging System","description":"Audio classification through deep learning","tags":["code","deep-learning","machine-learning","audio","audio-classification","audio-tagging"],"details":"Objective: build an audio classification system that would correctly label a .WAV file with the appropriate sound out of 41 classes\r\n\r\nHow: transform the .WAV file into a Mel-spectrogram, which will act as an image for a convolutional neural network to read and predict off of\r\n\r\nResults: 56% accuracy of prediction labels","links":[{"article_link":"","code_link":"https://github.com/nvgopal/DS3_Audio_Reg","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1467,"title":"Human Activity Recognition using WiFi sensing","description":"Using changes in the Wifi signals , we want to predict the presence of  a human inside the room, we use \r\nml for prediction.","tags":["code","lstm","support-vector-machines","data-augmentation","data-science","csi"],"details":"We limited the project to only software aspects and we will be implementing an ML model.\r\n\r\nDataset required for the project has been provided by the supervisor Dr.Sai Dhiraj.\r\n\r\n\r\nIt mainly provided us .dat files of CSI values of event where there was human movement and some are for no movement.\r\n\r\nWe are exploiting the features of CSI which is captured by OFDM carriers and is intended to provide more information than RSSI .\r\n\r\n\r\nThe Machine learning algorithm will be a  supervised learning classification algorithm and we have implemented One-class SVM algorithm which is generally used for outlier detection.\r\n\r\nMetric used in the data set is based on  Channel state information(CSI).\r\n\r\nAs of now, we were able to do activity detection with an accuracy of 98.67%, we are trying to push this accuracy.\r\n\r\nDr. Sai Dhiraj will be providing us with another dataset in the near future on which we would be trying to advanced WI-Fi based recognition techniques.\r\n\r\n","links":[{"article_link":"","code_link":"https://github.com/Surya291/WiFi_Sensing","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1462,"title":"Open Compound Domain Adaptation","description":"Pytorch implementation for \"Open Compound Domain Adaptation\"","tags":["article","code","paper","research","video","pytorch","computer-vision","domain-adaptation","cvpr-2020","open-compound-domain-adaptation","arxiv:1909.03403"],"details":"A typical domain adaptation approach is to adapt the model trained on the annotated data in a source domain (e.g. sunny weather) for the test data in a target domain (e.g. rainy weather). Whether the target contains a single or multiple domains, existing works always assume that there is a known clear distinction between domains, which is often not true in practice (e.g. mixed or varying weather). We consider the open compound domain adaptation (OCDA) problem, in which the compound target domain is a combination of multiple traditional target domains without domain labels, reflecting realistic data collection in various mixed as well as novel conditions. Our model consists of two technical insights into OCDA: 1) a curriculum domain adaptation strategy to bootstrap generalization across domain distinction in a data-driven self-organizing fashion and 2) a memory module to increase the model's agility towards novel domains. Our experiments on digit classification, facial expression recognition, semantic segmentation, and reinforcement learning demonstrate the effectiveness of our approach.","links":[{"article_link":"https://bair.berkeley.edu/blog/2020/06/14/ocda/","code_link":"https://github.com/zhmiao/OpenCompoundDomainAdaptation-OCDA","research_link":"https://arxiv.org/abs/1909.03403","media_link":"https://www.youtube.com/watch?v=YcmgCCRA1qc","dataset_link":"","demo_link":"","other_link":"https://liuziwei7.github.io/projects/CompoundDomain.html"}]},{"id":1461,"title":"Detectron2","description":"FAIR's next-generation platform for object detection and segmentation.","tags":["article","code","pytorch","library","computer-vision","object-detection","object-tracking","pose-estimation","semantic-segmentation","segmentation","detectron2","detectron"],"details":"Detectron2 is Facebook AI Research's next generation software system that implements state-of-the-art object detection algorithms. It is a ground-up rewrite of the previous version, [Detectron](https://github.com/facebookresearch/Detectron/), and it originates from [maskrcnn-benchmark](https://github.com/facebookresearch/maskrcnn-benchmark/).","links":[{"article_link":"https://ai.facebook.com/blog/-detectron2-a-pytorch-based-modular-object-detection-library-/","code_link":"https://github.com/facebookresearch/detectron2","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1460,"title":"Instance Shadow Detection","description":"Instance shadow detection aims to find shadow instances paired with object instances.","tags":["api","code","dataset","paper","research","computer-vision","object-detection","cvpr-2020","shadow-detection","instance-shadow-detection","arxiv:1911.07034"],"details":"Instance shadow detection aims to find shadow instances paired with object instances. We present a dataset, a deep framework, and an evaluation metric to approach this new task. This repo is implemented on [Detectron2](https://github.com/facebookresearch/detectron2).","links":[{"article_link":"","code_link":"https://github.com/stevewongv/InstanceShadowDetection","research_link":"https://arxiv.org/abs/1911.07034","media_link":"","dataset_link":"https://github.com/stevewongv/InstanceShadowDetection/tree/master/datasets","demo_link":"","other_link":""}]},{"id":1459,"title":"SuperGlue: Learning Feature Matching with Graph Neural Networks","description":"SuperGlue, a neural network that matches two sets of local features by jointly finding correspondences and rejecting non-matchable points.","tags":["article","code","paper","research","video","graph-neural-networks","graphs","interpretability","demo","superglue","visual-localization","image-matching","context-aggregation","arxiv:1911.11763"],"details":"Assignments are estimated by solving a differentiable optimal transport problem, whose costs are predicted by a graph neural network. We introduce a flexible context aggregation mechanism based on attention, enabling SuperGlue to reason about the underlying 3D scene and feature assignments jointly. Compared to traditional, hand-designed heuristics, our technique learns priors over geometric transformations and regularities of the 3D world through end-to-end training from image pairs. SuperGlue outperforms other learned approaches and achieves state-of-the-art results on the task of pose estimation in challenging real-world indoor and outdoor environments. The proposed method performs matching in real-time on a modern GPU and can be readily integrated into modern SfM or SLAM systems.","links":[{"article_link":"https://psarlin.com/superglue/doc/superglue_slides.pdf","code_link":"https://github.com/magicleap/SuperGluePretrainedNetwork","research_link":"https://arxiv.org/abs/1911.11763","media_link":"https://www.youtube.com/watch?v=BNaIGI4VncM","dataset_link":"","demo_link":"https://psarlin.com/superglue/doc/superglue_poster.pdf","other_link":"https://psarlin.com/superglue/"}]},{"id":1458,"title":"PIFuHD: High-Resolution 3D Human Digitization ","description":"This repository contains a pytorch implementation of \"Multi-Level Pixel-Aligned Implicit Function for High-Resolution 3D Human Digitization\".","tags":["article","code","notebook","paper","research","3d","computer-vision","cvpr-2020","human-digitization","pifudh","arxiv:2004.00452"],"details":"Recent advances in image-based 3D human shape estimation have been driven by the significant improvement in representation power afforded by deep neural networks. Although current approaches have demonstrated the potential in real world settings, they still fail to produce reconstructions with the level of detail often present in the input images. We argue that this limitation stems primarily form two conflicting requirements; accurate predictions require large context, but precise predictions require high resolution. Due to memory limitations in current hardware, previous approaches tend to take low resolution images as input to cover large spatial context, and produce less precise (or low resolution) 3D estimates as a result. We address this limitation by formulating a multi-level architecture that is end-to-end trainable. A coarse level observes the whole image at lower resolution and focuses on holistic reasoning. This provides context to an fine level which estimates highly detailed geometry by observing higher-resolution images. We demonstrate that our approach significantly outperforms existing state-of-the-art techniques on single image human shape reconstruction by fully leveraging 1k-resolution input images.","links":[{"article_link":"https://shunsukesaito.github.io/PIFuHD/","code_link":"https://github.com/facebookresearch/pifuhd","research_link":"https://arxiv.org/abs/2004.00452","media_link":"","dataset_link":"","demo_link":"","other_link":"https://colab.research.google.com/drive/11z58bl3meSzo6kFqkahMa35G5jmh2Wgt"}]},{"id":1457,"title":" Synthesizing High-Resolution Images with StyleGAN2","description":"Developed by NVIDIA Researchers, StyleGAN2 yields state-of-the-art results in data-driven unconditional generative image modeling.","tags":["code","video","generative-adversarial-networks","computer-vision","image-generation","stylegan","nvidia","cvpr-2020","stylegan2","high-resolution","high-resolution-images"],"details":"This new project called [StyleGAN2](https://developer.nvidia.com/techdemos/video/dcv20), presented at CVPR 2020, uses transfer learning to generate a seemingly infinite numbers of portraits in an infinite variety of painting styles. The work builds on the team\u2019s previously published [StyleGAN](https://github.com/NVlabs/stylegan) project. ","links":[{"article_link":"","code_link":"https://github.com/NVlabs/stylegan2","research_link":"","media_link":"https://www.youtube.com/watch?v=9QuDh3W3lOY","dataset_link":"","demo_link":"","other_link":"https://news.developer.nvidia.com/synthesizing-high-resolution-images-with-stylegan2/"}]},{"id":1456,"title":"Neural Rendering - CVPR 2020 Tutorial","description":"State of the art on neural rendering.","tags":["paper","research","video","cvpr-2020","neural-rendering"],"details":"Neural rendering is a new class of deep image and video generation approaches that enable explicit or implicit control of scene properties such as illumination, camera parameters, pose, geometry, appearance, and semantic structure. It combines generative machine learning techniques with physical knowledge from computer graphics to obtain controllable and photo-realistic outputs.","links":[{"article_link":"","code_link":"","research_link":"https://www.neuralrender.com/assets/downloads/TewariFriedThiesSitzmannEtAl_EG2020STAR.pdf","media_link":"https://www.youtube.com/watch?v=LCTYRqW-ne8","dataset_link":"","demo_link":"","other_link":"https://www.neuralrender.com/"}]},{"id":1455,"title":"Predicting Unintentional Action in Video","description":"We introduce a dataset of in-the-wild videos of unintentional action, as well as a suite of tasks for recognizing, localizing, and anticipating its onset. ","tags":["article","code","dataset","paper","research","computer-vision","action-recognition","cvpr-2020","video-analysis","arxiv:1911.11206"],"details":"From just a short glance at a video, we can often tell whether a person's action is intentional or not. Can we train a model to recognize this? We introduce a dataset of in-the-wild videos of unintentional action, as well as a suite of tasks for recognizing, localizing, and anticipating its onset. We train a supervised neural network as a baseline and analyze its performance compared to human consistency on the tasks. We also investigate self-supervised representations that leverage natural signals in our dataset, and show the effectiveness of an approach that uses the intrinsic speed of video to perform competitively with highly-supervised pretraining. However, a significant gap between machine and human performance remains.","links":[{"article_link":"https://oops.cs.columbia.edu/","code_link":"https://github.com/cvlab-columbia/oops","research_link":"https://arxiv.org/abs/1911.11206","media_link":"","dataset_link":"https://oops.cs.columbia.edu/data","demo_link":"","other_link":""}]},{"id":1454,"title":"On Differentiable Optimization for Control and Vision","description":"Slides for Bamos' talk for for differentiable continuous control.","tags":["presentation","cvpr-2020","convex-optimization","differentiable-convex-optimization","differentiable-cross-entropy","slides"],"details":"Differentiable continuous control:\r\n\r\n* Differentiable model predictive control\r\n* Differential cross-entropy method","links":[{"article_link":"","code_link":"","research_link":"","media_link":"differentiable continuous control","dataset_link":"","demo_link":"","other_link":""}]},{"id":1453,"title":"Interpretable Machine Learning for Computer Vision","description":"Recent progress we made on visualization, interpretation, and explanation methodologies for analyzing both the data and the models in computer vision.","tags":["article","video","computer-vision","interpretability","cvpr-2020"],"details":"Complex machine learning models such as deep convolutional neural networks and recursive neural networks have recently made great progress in a wide range of computer vision applications, such as object/scene recognition, image captioning, visual question answering. But they are often perceived as black-boxes. As the models are going deeper in search of better recognition accuracy, it becomes even harder to understand the predictions given by the models and why.\r\n\r\n**Previous Interpretable Machine Learning Tutorials**\r\n\r\n- [CVPR\u201918](https://interpretablevision.github.io/index_cvpr2018.html)\r\n- [ICCV'19](https://interpretablevision.github.io/index_iccv2019.html)","links":[{"article_link":"https://interpretablevision.github.io/","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=PF0yFXWkc7A","dataset_link":"","demo_link":"","other_link":""}]},{"id":1452,"title":"Reassessed ImageNet: Are We Done with ImageNet","description":"Labels and other data for the paper \"Are we done with ImageNet?\"","tags":["code","dataset","paper","research","imagenet","arxiv:2006.07159"],"details":"This file is a list of 50 000 lists which contain the \"Reassessed Labels\" used for evaluation in the paper.\r\n\r\nThe outer index of the list corresponds to the validation files, sorted by name. That means, the first list holds all valid labels for the file `ILSVRC2012_val_00000001.JPEG`, the second list holds all valid labels for the file `ILSVRC2012_val_00000002.JPEG`, etc.\r\n\r\nNote that lists can be empty, in which case the file should not be included in the evaluation, nor in computing mean accuracy. These are images where the raters found none of the labels to reasonably fit.","links":[{"article_link":"","code_link":"https://github.com/google-research/reassessed-imagenet","research_link":"https://arxiv.org/abs/2006.07159","media_link":"","dataset_link":"https://github.com/google-research/reassessed-imagenet/blob/master/real.json","demo_link":"","other_link":""}]},{"id":1451,"title":"EfficientDet (PyTorch)","description":"A PyTorch implementation of EfficientDet faithful to the original Google implementation with ported weights.","tags":["code","paper","research","pytorch","computer-vision","object-detection","efficientdet","coco","pyramid-network","arxiv:1911.09070"],"details":"It is based on the\r\n\r\n* Official Tensorflow implementation by [Mingxing Tan and the Google Brain team](https://github.com/google/automl)\r\n* Paper by Mingxing Tan, Ruoming Pang, Quoc V. Le [EfficientDet: Scalable and Efficient Object Detection](https://arxiv.org/abs/1911.09070)","links":[{"article_link":"","code_link":"https://github.com/rwightman/efficientdet-pytorch","research_link":"https://arxiv.org/abs/1911.09070","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1450,"title":"BERT NLP \u2014 How To Build a Question Answering Bot","description":"Understanding the intuition with hands-on PyTorch code for BERT fine-tuned on SQuAD.","tags":["article","code","huggingface","pytorch","attention","bert","transformers","fine-tuning","natural-language-processing","question-answering","squad"],"details":"This article will present key ideas about creating and coding a question answering system based on a neural network. The implementation uses Google\u2019s language model known as pre-trained BERT. Hands-on proven PyTorch code for question answering with BERT fine-tuned and SQuAD is provided at the end of the article.\r\n\r\nYou can adapt my [PyTorch code for NLU with BERT](https://towardsdatascience.com/bert-for-dummies-step-by-step-tutorial-fb90890ffe03) to solve your question-answering task.","links":[{"article_link":"https://towardsdatascience.com/bert-nlp-how-to-build-a-question-answering-bot-98b1d1594d7b","code_link":"https://towardsdatascience.com/bert-for-dummies-step-by-step-tutorial-fb90890ffe03","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1445,"title":"Image Smoothing via L0 Gradient Minimization","description":"This is a edge-aware image smoothing algorithm. This algorithm tries to smoothen the image while preserving the global structural information of the image. ","tags":["article","code","paper","research","tutorial","library","computer-vision","computation-photography"],"details":"This algorithm basically preserves the strong edges, while suppressing the weaker ones and at the same time preserving the global structural information of the image","links":[{"article_link":"https://nthere.dev/2020/06/15/Image-Smoothing-using-L0-Gradient-Minimization/","code_link":"https://github.com/nrupatunga/L0-Smoothing","research_link":"http://www.cse.cuhk.edu.hk/~leojia/papers/L0smooth_Siggraph_Asia2011.pdf","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1442,"title":"Exploratory Data Analysis of 2019 Top 50 Spotify Songs","description":"EDA on dataset that contains data about top 50 Spotify tracks: name, artist, genre, bpm, energy, danceability, loudness, liveness, length, popularity, etc. ","tags":["code","tutorial","data-science","exploratory-data-analysis"],"details":"EDA on dataset that contains data about top 50 Spotify tracks: name, artist, genre, bpm, energy, danceability, loudness, liveness, length, popularity, etc. ","links":[{"article_link":"","code_link":"https://github.com/sh-biswas/top50spotifyanalysis","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1438,"title":"Multimodal Meme Classification","description":"UNITER has given state of the art results in various image-text related problems. This project aims at finetuning UNITER to solve Hateful memes challenge","tags":["article","code","paper","research","attention","bert","transformers","computer-vision","image-classification","natural-language-processing","arxiv:2005.04790"],"details":"","links":[{"article_link":"https://ai.facebook.com/blog/hateful-memes-challenge-and-data-set/","code_link":"","research_link":"https://arxiv.org/abs/2005.04790","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1437,"title":"COVID 19 Data Analysis","description":"Data Analysis based  on no. of COVID 19 cases in country , per day cases.","tags":["code","matplotlib","pandas"],"details":"","links":[{"article_link":"","code_link":"https://github.com/kritikashah20/COVID-19-Data-Analyisis.git","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1434,"title":"Universal Sentence Encoder Visually Explained","description":"A deep-dive into how Universal Sentence Encoder learns to generate fixed-length sentence embeddings","tags":["article","tutorial","tensorflow","embeddings","natural-language-processing","sentence-embeddings"],"details":"","links":[{"article_link":"https://amitness.com/2020/06/universal-sentence-encoder/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1431,"title":"RecommendMe","description":"RecommendMe\r\nDeveloped a recommendation engine for the posts\r\n\r\nTwo methods used:-\r\n1) content-based Filtering\r\n2) Collaberative-based Filtering","tags":["code","tutorial","recommendation-systems","k-nearest-neighbors"],"details":"","links":[{"article_link":"","code_link":"https://github.com/DB11051998/RecommendMe","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1430,"title":"Melanoma Classification","description":"This was Shubhamai 3-week project for working a new kaggle competition and deploying a web application to predicting benign or malignant based on images.","tags":["article","code","machine-learning","computer-vision","image-classification"],"details":"Many weeks ago, a kaggle competitions started SIIM-ISIC Melanoma Classification, and the favorite part for me... it was a image classification project related to computer vision, which i absolutely love to make projects on. So i started!\r\n\r\nAnd wait, What is  Melanoma ?\r\n\r\nMelanoma is a skin cancer which is responsible for the 75% of skin cancer deaths, despite being the least common skin cancer.\r\n\r\nAnd if this disease can be detected very early, the chance of death is very low.\r\n\r\nTaking the image samples, send them to doctors, doctors will analyse the samples and give you the report if it is a cancer. That's a time taking process, and remember, there are hunderds of images a single doctor will analyse. This is a tedious process.\r\n\r\nAnd that's where AI comes, image we will input a image to a web app and a Machine learning model will predict the image in seconds if it is a cancer or not. It can save days as compared to tradition process.","links":[{"article_link":"https://shubhamai.ghost.io/siim-isic-melanoma-classification/","code_link":"https://github.com/Shubhamai/melanoma-classification","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.notion.so/shubhamai/SIIM-ISIC-Melanoma-Classification-Kaggle-Competition-cd11fc8ec6f2434e9e51220467c8deb8"}]},{"id":1428,"title":"Learning Representations via Graph-structured Networks","description":"Introduce a series of effective graph-structured networks, including non-local neural networks, spatial generalized propagation networks, etc.","tags":["article","research","tutorial","3d","computer-vision","graph-neural-networks","graphs","representation-learning","graph-structured-networks","non-local-neural-networks","spatial-generalized-propagation-networks"],"details":"In this tutorial, we will introduce a series of effective graph-structured networks, including non-local neural networks, spatial generalized propagation networks, relation networks for objects and multi-agent behavior modeling, graph networks for videos and data of 3D domain. We will also discuss how to utilize graph-structured neural architectures to study the network connectivity patterns. Lastly, we will discuss related open challenges that still exist in many vision problems.","links":[{"article_link":"https://xiaolonw.github.io/graphnnv2/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1427,"title":"101 Ways to Solve Search - Dair AI ft. Pratik Bhavsar","description":"A comprehensive overview of explaining how NLP is used for search.","tags":["tutorial","video","attention","bert","transformers","natural-language-processing","search","semantic-search","elastic-search","hybrid-search","query-augmentation"],"details":"Search is one of the most used applications of NLP and has evolved tremendously with time. Search can be solved in many ways - supervised Vs unsupervised, classical Vs deep learning. Search engines are easy to start with but difficult to improve.\r\n\r\nThis talk throws light on various ways to make a **text search engine** and their practical considerations.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=VHm6_uC4vxM","dataset_link":"","demo_link":"","other_link":"https://docs.google.com/presentation/d/e/2PACX-1vTM3zlfZft8QlQqImvMz1MRa-WS0IaRzi7a1kwOm74uHN3SNmLubFxah52eHgz3keDTTAPQbCLXNI6n/pub?start=false&loop=false&delayms=3000&slide=id.p"}]},{"id":1426,"title":"From GRU to Transformer","description":"How recurrent units and self-attention are related to each other.","tags":["article","tutorial","attention","gated-recurrent-units","recurrent-neural-networks","self-attention","transformers","natural-language-processing"],"details":"To understand how the self-attention mechanism is applied in Transformers, it might be intuitive from a mathematical perspective to build-up step-by-step from what is known, i.e. Recurrent Neural Networks such as LSTMs or GRUs to a self-attention network such as Transformers. Blog posts such as Jalammar, The Annotated Transformer, Vandergoten have attacked the explanation of Transformers from different perspectives but I believe this article will give another perspective and help engineers and researchers understand Self-Attention better, as I did.","links":[{"article_link":"https://ogunlao.github.io/blog/2020/06/12/from_gru_to_transformer.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1425,"title":"Building a Captcha OCR in TF2.0","description":"A Kaggle notebook showcasing the use of an Endpoint layer for CTC loss function used for building a Captcha Reader in TensorFlow.","tags":["code","tutorial","keras","tensorflow","computer-vision","optical-character-recognition","kaggle","captcha"],"details":"Dataset: [https://www.kaggle.com/fournierp/captcha-version-2-images](https://www.kaggle.com/fournierp/captcha-version-2-images)","links":[{"article_link":"","code_link":"https://www.kaggle.com/aakashnain/building-a-captcha-ocr-in-tf2-0","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1424,"title":"Why We Switched from Flask to FastAPI for Production ML","description":"The most popular tool isn\u2019t always the best.","tags":["api","article","tutorial","fastapi","flask","machine-learning","production"],"details":"Advantages of FastAPI over Flask: \r\n\r\n1. ML inference benefits from native async support.\r\n2. Improved latency is a huge deal for inference.\r\n3. FastAPI is easy to switch to\u2014by design.","links":[{"article_link":"https://towardsdatascience.com/why-we-switched-from-flask-to-fastapi-for-production-machine-learning-765aab9b3679","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1423,"title":"Entity Embedding with LSTM for Time-Series","description":"Demonstration of using LSTM for forecasting with structured time-series data, containing categorical and numerical features.","tags":["code","tutorial","lstm","time-series","structured-data","entity-embedding"],"details":"","links":[{"article_link":"","code_link":"https://github.com/aqibsaeed/Entity-Embedding-with-LSTM-for-Time-Series","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1418,"title":"Short Notes on Behavior Regularized Offline RL","description":"Blog Article on Behavior Regularized Offline Reinforcement Learning by Yifan Wu et al. (2019)","tags":["article","code","paper","research","tutorial","q-learning","reinforcement-learning","actor-critic","arxiv:1911.11361"],"details":"The authors introduce their framework, Behavior Regularized Actor Critic, to empirically evaluate recently proposed methods as well as a number of simple baselines across a variety of offline continuous control tasks. Surprisingly, they find that many of the technical complexities introduced in recent methods are unnecessary to achieve strong performance.","links":[{"article_link":"https://medium.com/@f20170720/behavior-regularized-offline-reinforcement-learning-brac-42355d49af5d?sk=ee9a3ef000d1355305847dfea71d3294","code_link":"https://github.com/google-research/google-research/tree/master/behavior_regularized_offline_rl","research_link":"https://arxiv.org/abs/1911.11361","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1407,"title":"Hand-Written Digit Recognition using Neural Networks","description":"Using MNIST dataset","tags":["tutorial","tensorflow","convolutional-neural-networks","mnist"],"details":"In this tutorial, I have broken down the process into 6 easy steps:\r\n\r\n1. Loading libraries and MNIST Dataset\r\n1. Dividing training and Testing Data\r\n1. Normalizing and Flattening the data.\r\n1. Adding layers and compiling the model\r\n1. Evaluating the model\r\n1. Validation of the model.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.kaggle.com/ojaswininimbalkar/hand-written-digit-recognition-using-keras"}]},{"id":1404,"title":"Customer Churn Prediction Case Study","description":"Customer Churn Prediction done by using techniques of Machine Learning and Predictive Modelling .","tags":["code","paper","research","logistic-regression","machine-learning","regression","customer-churn","predictive-modelling"],"details":"Customer Retention is a very important aspect of any business-like tele-communication, retail, e-commerce, etc. Customer retention rate has a direct effect on the customer's acquisition cost, and understanding the exact value of a potential customer churn would allow the business to develop a good customer relationship. Predictive Modeling can use used to predict the customer churn of any company and help them to make better strategies for serving their customer and retain their loyal customers, The objective of the case study is to implement logistic regression methods to predict customer churn and also to analyze churning and non-churning consumers by using telco customer churn dataset from Kaggle.","links":[{"article_link":"","code_link":"https://github.com/pbisaria007/Customer-Churn-Prediction","research_link":"https://drive.google.com/file/d/1FQbg-3goOixzEIXPOBXYnRhGmD8n_Ulh/preview","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1402,"title":"My Guide","description":"It is a mobile application for school students. This will help them to make their career choices more efficiently.","tags":["code","tutorial","java","machine-learning","library"],"details":"I am currently working on training a model for text classification, which will help a student to identify if he/she is suited for a particular stream professionally.","links":[{"article_link":"","code_link":"https://github.com/anjalikaushik20/My-Guide","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1401,"title":"Linear-Regression From Scratch","description":"In this project i have implemented  the basic linear regression model without using the sci-kit library.","tags":["code","notebook","tutorial","linear-regression","machine-learning","regression"],"details":"Implementing linear regression is very easy by importing a few libraries and  its also one of the ways to implement it quickly and effectively but i wanted to explore the more behind the scenes thing and hence in this project i only make use of Numpy and Pandas to implement it. I went through all of the maths used to implement it from scratch.","links":[{"article_link":"","code_link":"https://github.com/AM1CODES/ML-Algs-From-Scratch/blob/master/Linear_Reg(Real-Life%20example).ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1400,"title":"Cancer Classification Model","description":"SVM model to classify breast cancer as benign or malignant based on it's size, radius and area.","tags":["code","scikit-learn","support-vector-machines","classification","cancer"],"details":"","links":[{"article_link":"","code_link":"https://github.com/architg1/Breast-Cancer-Classification","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1399,"title":"Video object grounding","description":"Video object grounding using semantic roles in language description. ","tags":["code","paper","research","tutorial","video","pytorch","computer-vision","image-captioning","cvpr-2020","grounding","visual-grounding","video-object-grounding","object-grounding","arxiv:2003.10606"],"details":"Video Object Grounding (VOG) is the task of localizing objects in a video referred in a query sentence description. We elevate the role of object relations via spatial and temporal concatenation of contrastive examples sampled from a newly contributed dataset called ActivityNet-SRL (ASRL).","links":[{"article_link":"","code_link":"https://github.com/TheShadow29/vognet-pytorch","research_link":"https://arxiv.org/abs/2003.10606","media_link":"https://twitter.com/ArkaSadhu29/status/1271898967396122625?s=20","dataset_link":"","demo_link":"","other_link":""}]},{"id":1398,"title":"Super-resolution Variational Auto-Encoders","description":"VAE with RealNVP prior and Super-Resolution VAE in PyTorch.","tags":["code","paper","research","tutorial","pytorch","autoencoders","variational-autoencoders","computer-vision","super-resolution","unsupervised-learning","respresentation-learning","generative-model","cifar10","arxiv:2006.05218"],"details":"The framework of Variational Auto-Encoders (VAEs) provides a principled manner of reasoning in latent-variable models using variational inference. However, the main drawback of this approach is blurriness of generated images. Some studies link this effect to the objective function, namely, the (negative) log-likelihood function. Here, we propose to enhance VAEs by adding a random variable that is a downscaled version of the original image and still use the log-likelihood function as the learning objective. Further, we provide the downscaled image as an input to the decoder and use it in a manner similar to the super-resolution. We present empirically that the proposed approach performs comparably to VAEs in terms of the negative log-likelihood function, but it obtains a better FID score.","links":[{"article_link":"","code_link":"https://github.com/ioangatop/srVAE","research_link":"https://arxiv.org/abs/2006.05218","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1393,"title":"RESTAURANT RECOMMENDATION USING YELP DATASET","description":"Built a personalized recommender web app using Yelp dataset of restaurants using Hybrid Matrix factorization model. ","tags":["code","research","angular","flask","python","recommendation-systems"],"details":"This was my academic project for CSP-571 \"Data Preparation And Analysis\". In this project I built a personalized recommender web app using Yelp dataset of restaurants. Various models were tested like Pure Collaborative, Approximate Nearest Neighbour, K-NN, Naive Bayes and Hybrid Maxtrix Factorization on various hyperparameters which were tuned using the library \"scikit optimizer\". AUC was chosen as an evaluation metric for the models which is a decision-support metric that checks whether customers like the item or not. In this case, figuring out customer preference in general is more important and practical. And for deployment, I used Angular8 and Flask frameworks.","links":[{"article_link":"","code_link":"https://github.com/rahulmnair1997/Restaurant-Recommendation-System-using-Yelp-Dataset","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1392,"title":"StackOver Flow Data Analysis","description":"Analysing certain aspects of the stack overflow data and creating \"Tag Predictor\" which predicts tag based on the post posted. ","tags":["code","research","natural-language-processing","big-data","pyspark","hive","pig"],"details":"This was my academic project for CSP-554 \"Big Data Technologies\". In this project I developed a tag predictor using pyspark which predicts tag based on the post. NLP techniques were implemented to achieve that. Apart from that, certain analysis were also performed on the StackOverflow Data using HIVE and PIG.","links":[{"article_link":"","code_link":"https://github.com/rahulmnair1997/StackOverflow-Data-Analysis","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1382,"title":"Detecting phishing website using Machine Learning","description":"The project is based on a dataset that has 30 labels and 1 target. The purpose of this project is to detect Phishing websites through Machine learning algorithm","tags":["code","research","scikit-learn","decision-trees","machine-learning","library","phishing"],"details":"","links":[{"article_link":"","code_link":"https://github.com/SmartPracticeschool/llSPS-INT-2470-Detecting-Phishing-Website-Using-Machine-Learning","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1376,"title":"VirTex: Learning Visual Representations from Textual Annotations","description":"We train CNN+Transformer from scratch from COCO, transfer the CNN to 6 downstream vision tasks, and exceed ImageNet features despite using 10x fewer images.","tags":["article","code","paper","research","tutorial","pytorch","convolutional-neural-networks","transformers","computer-vision","image-captioning","natural-language-processing","object-detection","transfer-learning","pretraining","coco","visual-representations","arxiv:2006.06666","virtex"],"details":"VirTex is a pretraining approach which uses semantically dense captions to learn visual representations. We train CNN + Transformers from scratch on COCO Captions, and transfer the CNN to downstream vision tasks including image classification, object detection, and instance segmentation. VirTex matches or outperforms models which use ImageNet for pretraining -- both supervised or unsupervised -- despite using up to 10x fewer images.","links":[{"article_link":"https://kdexd.github.io/virtex/","code_link":"https://github.com/kdexd/virtex","research_link":"https://arxiv.org/abs/2006.06666","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1374,"title":"Extracting Structured Data from Templatic Documents","description":"Automatically extract data from structured documents\u2014invoices, receipts, etc.\u2014with the potential to streamline many business workflows.","tags":["article","paper","research","computer-vision","representation-learning","structured-data","tables","templatic-documents","ocr","documents"],"details":"","links":[{"article_link":"https://ai.googleblog.com/2020/06/extracting-structured-data-from.html","code_link":"","research_link":"https://research.google/pubs/pub49122/","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1373,"title":"COVID-19 Data analysis & visualization","description":"The aim of this project is to understand the impact of COVID-19 epidemic all over the world through the visualization techniques made possible by python program","tags":["article","code","paper","research","covid-19-data-analysis-&-visualization"],"details":"*The aim of this project is to understand the impact of COVID-19 epidemic all over the world through the visualization techniques made possible by python programming language and some visualisation libraries. In this project I have analysed the data\u2019s collected from different sources over the web after doing some data pre-processing steps. *\r\n**I have done the following data visualisations:\t**\r\n\r\n\u2022\tThe current trend of COVID-19 which includes the total confirmed cases in the most affected countries.\r\n\u2022\tThe cumulative growth of confirmed, active, recovered and death cases over the world.\r\n\u2022\tThe daily count of new confirmed, recovered and death cases.\r\n\u2022\tThe rolling difference of new cases on daily basis.\r\n\u2022\tCompared all the affected countries on the basis of cumulative growth of confirmed, active, recovered and death cases.\r\n\u2022\tMaps depicting the same data as mentioned above.\r\n\u2022\tComparisons between the most affected countries on the basis of no of confirmed, active, recovered and death cases.\r\n\u2022\tComparison of the world population with the total no of cases.\r\n\u2022\tPopulation of most affected countries v/s confirmed, active, recovered and death cases.\r\n\u2022\tCompared the most affected countries on the basis of maximum confirmed, recovered, active and death cases in a day.\r\n\u2022\tCompared all the affected countries based on the frequency of new cases confirmed.\r\n\u2022\tCompared most affected countries based on percentage of positive cases (tests v/s confirmed cases), percentage of tests (tests v/s population) and tests per 1 million people.\r\n\u2022\tCompared India, China, USA and Italy on the basis of total confirmed, active, recovered and death cases.\r\n\u2022\tCompared the age wise share of death.\r\n\u2022\tCompared the share of death based on gender.\r\n\u2022\tThe fatality rate of COVID-19.\r\n\u2022\tCompared COVID-19 with similar viruses based on death rate and incubation period.\r\n\u2022\tCompared the different symptoms of COVID-19.\r\n","links":[{"article_link":"https://drive.google.com/file/d/1aHkhWzA0tvV9AWFxpGRkRQcv5t2v5jN9/view?usp=sharing","code_link":"https://drive.google.com/file/d/1lmMrVmbrVeH2PLgyKYcgQwFM3vlytpDI/view?usp=sharing","research_link":"https://drive.google.com/file/d/1IU1BCLZxszqaWmL5-C0SIG7ANFaS9mYe/view?usp=sharing","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1372,"title":"How to Evaluate Longformer on TriviaQA using NLP","description":"We will evaluate a pretrained LongformerForQuestionAnswering model on the validation dataset of TriviaQA.","tags":["code","notebook","tutorial","huggingface","transformers","natural-language-processing","question-answering","longformer","triviaqa"],"details":"- The [`nlp`](https://github.com/huggingface/nlp) library allows simple and intuitive access to nlp datasets and metrics.\r\n\r\n- **Longformer** is transformer-based model for long-range sequence modeling introduced by *Iz Beltagy, Matthew E. Peters, Arman Cohan* (see paper [here](https://arxiv.org/abs/2004.05150)) and can now be accessed via Transformers via the [docs](https://huggingface.co/transformers/model_doc/longformer.html).\r\n\r\n- **TriviaQA** is a reading comprehension dataset containing question-answer-evidence triplets (see paper here [here](https://homes.cs.washington.edu/~eunsol/papers/acl17jcwz.pdf)).","links":[{"article_link":"","code_link":"https://colab.research.google.com/drive/1m7eTGlPmLRgoPkkA7rkhQdZ9ydpmsdLE","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1371,"title":"Baymax - ChatBot","description":"Baymax Chatbot is a part of my summer training program @AdHoc Networks, Jaipur.\r\n\r\nA chatbot that allows user to signup and login to maintain their record. When c","tags":["code","databases","html","python","machine-learning","natural-language-processing","sentiment-analysis","conversational-ai"],"details":"","links":[{"article_link":"","code_link":"https://github.com/sani-Alpha/Baymax-ChatBot","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1368,"title":"Financial Risk Prediction","description":"Financial Risk Prediction","tags":["code","finance","financial-risk"],"details":"Financial Risk Prediction","links":[{"article_link":"","code_link":"https://github.com/blkjack/https-www.machinehack.com-course-financial-risk-prediction-weekend-hackathon-5","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1363,"title":"Short Notes on Batch Constrained Deep Reinforcement Learning","description":"Blog article on Off-Policy Deep Reinforcement Learning without Exploration paper by Fujimoto et al. (ICML 2019)","tags":["article","code","paper","research","tutorial","q-learning","reinforcement-learning","batch-rl","arxiv:1812.02900"],"details":"The paper introduces a novel class of off-policy algorithms, batch constrained reinforcement learning, which restricts the action space in order to force the agent towards behaving close to on-policy with respect to a subset of the given data.","links":[{"article_link":"https://medium.com/@f20170720/short-notes-on-batch-constrained-deep-reinforcement-learning-bcq-6fd69feca521?source=friends_link&sk=e64992a638fc684cfc5c437da16834e6","code_link":"https://github.com/sfujim/BCQ","research_link":"https://arxiv.org/abs/1812.02900","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1353,"title":"Combining Sketch and Tone for Pencil Drawing Production","description":"This is the C++  implementation of the paper  \"Combining Sketch and Tone for Pencil Drawing Production\" ","tags":["code","paper","research","library","color-pencil-sketch"],"details":"Idea that interested me in this paper is that, they try to imitate the actual way human draw the sketch, which is composed of short lines. ","links":[{"article_link":"","code_link":"https://github.com/nrupatunga/Color-Pencil-Sketch","research_link":"http://www.cse.cuhk.edu.hk/leojia/projects/pencilsketch/npar12_pencil.pdf","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1342,"title":"library for LVQ-II neural algorithm","description":"aims to predict certain crime types using lvq-II neural nets","tags":["code","library","lvq","learning-vector-quantization"],"details":"","links":[{"article_link":"","code_link":"https://github.com/juanpransisko/LVQNets","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1341,"title":"Intro to Jupyter Notebooks & JupyterLab with Python","description":"Introduction to Jupyter Notebooks & JupyterLab: set-up, user-guide, and best practices with Python. This is a beginner level intro. ","tags":["article","code","notebook","tutorial","video","python","jupyter-notebook","ide"],"details":"","links":[{"article_link":"https://pabloinsente.github.io/intro-jupyter-ide","code_link":"https://github.com/pabloinsente/intro-sc-python/blob/master/notebooks/intro-jupyter-ide.ipynb","research_link":"","media_link":"https://www.youtube.com/playlist?list=PL_FxwzD1C2iHVNhGBqvfuqwzV9OWAw0SW","dataset_link":"","demo_link":"","other_link":""}]},{"id":1337,"title":"Sending Simple Email Using Python","description":"Introduction to creating email senders with Python with complete code examples and explanations.","tags":["article","tutorial","python","program-development"],"details":"","links":[{"article_link":"https://pyshark.com/sending-email-using-python/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1334,"title":"Training Generative Adversarial Networks with Limited Data","description":"An adaptive discriminator augmentation mechanism that significantly stabilizes training in limited data regimes.","tags":["article","paper","research","generative-adversarial-networks","data-augmentation","limited-data"],"details":"Training generative adversarial networks (GAN) using too little data typically leads to discriminator overfitting, causing training to diverge. We propose an adaptive discriminator augmentation mechanism that significantly stabilizes training in limited data regimes. The approach does not require changes to loss functions or network architectures, and is applicable both when training from scratch and when fine-tuning an existing GAN on another dataset. We demonstrate, on several datasets, that good results are now possible using only a few thousand training images, often matching StyleGAN2 results with an order of magnitude fewer images. We expect this to open up new application domains for GANs. We also find that the widely used CIFAR-10 is, in fact, a limited data benchmark, and improve the record FID from 5.59 to 2.67.","links":[{"article_link":"https://research.nvidia.com/publication/2020-06_Training-Generative-Adversarial","code_link":"","research_link":"https://research.nvidia.com/sites/default/files/pubs/2020-06_Training-Generative-Adversarial/karras2020-limited-data.pdf","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1329,"title":"Training game agents with supervised learning","description":"This is a continuing research project trying find ways to learn complex tasks such as games without using Reinforcement Learning.","tags":["article","research","pytorch","video-games","reinforcement-learning"],"details":"Reinforcement Learning provides a framework for solving complex games such as Go, Dota and StarCraft. It however suffers from serious problems such as sample inefficiency and instability when training. You need thousands of computers to train a starcraft bot that is at the level of professional human players. Even for simple problems RL models are hard to tune and its problems, difficult to diagnose. There is a need to find a new deep learning paradigm to solve these problems. The goal of this newsletter is to investigate ways in which reinforcement learning can be replaced by a more robust deep learning paradigm. Victory conditions are that the resulting framework will enable training of agents that solve simple, complex, single and multi agent problems in a robust, sample efficient and more diagnostic manner. Every week we post my research findings about experimental methods to train agents without using reinforcement learning. Our hope is that over the course of this research  subscribers will get to see weekly progress and suggest solutions for training robust, efficient and versatile AI agents. We aim to devise one algorithm to play games such as cartpole & Lunar lander, then on to more complex games in the atari environment and then on to even more complex games such as Dota, Fifa and starcraft. [Subscribers](https://gumroad.com/l/bxJfF) will get first hand knowledge on a new frontier, cool ideas to apply to their own research, in depth analysis of experiments and code solutions for experiments adapt to their own problems.\r\n\r\n[Subscribe](https://gumroad.com/l/bxJfF) to get weekly reports on this ambitious research project.","links":[{"article_link":"https://syntheticmindai.github.io/supervisedagents/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1327,"title":"Implementing Autoencoders in the Fastai Library","description":"Step by step guide to implementing an autoencoder in fastai.","tags":["article","code","fastai","pytorch","autoencoders"],"details":"### Objective:\r\n* Implement autoencoders with PyTorch and the fastai library.\r\n\r\n### Summary:\r\n* Implementation of fastai Databunch ready for use in autoencoder\r\n* Creation of PyTorch module for autoencoder\r\n* Creating fastai learner and training of an autoencoder\r\n* Code for *general* array autoencoder as well as *image* data.","links":[{"article_link":"https://towardsdatascience.com/autoencoders-in-the-fastai-library-fa288e1f899a","code_link":"https://github.com/henriwoodcock/blog-post-codes/tree/master/autoencoders-in-fastai","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://henriwoodcock.github.io/2020/05/18/autoencoders-in-fastai/"}]},{"id":1325,"title":"Author Identification using Doc2Vec","description":"Web app of an author identification model trained on PAN 2012 dataset and Kaggle's Spooky Authorship Dataset","tags":["code","tutorial","natural-language-processing","kaggle","doc2vec","author-identification"],"details":"","links":[{"article_link":"","code_link":"https://github.com/cedricconol/author-identification","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1320,"title":"Implementation of a Contextual Chatbot in PyTorch","description":"Simple chatbot implementation with PyTorch.","tags":["code","tutorial","video","pytorch","chatbot","natural-language-processing","conversational-ai","contextual-chatbot"],"details":"Simple chatbot implementation with PyTorch.\r\n\r\n* The implementation should be easy to follow for beginners and provide a basic understanding of chatbots.\r\n* The implementation is straightforward with a Feed Forward Neural net with 2 hidden layers.\r\n* Customization for your own use case is super easy. Just modify intents.json with possible patterns and responses and re-run the training (see below for more info).","links":[{"article_link":"","code_link":"https://github.com/python-engineer/pytorch-chatbot","research_link":"","media_link":"https://www.youtube.com/watch?v=RpWeNzfSUHw&list=PLqnslRFeH2UrFW4AUgn-eY37qOAWQpJyg","dataset_link":"","demo_link":"","other_link":""}]},{"id":1319,"title":"Diagram of Distribution Relationships","description":"Overview of relationships between distributions.","tags":["article","tutorial","probability-distributions"],"details":"Probability distributions have a surprising number inter-connections. A dashed line in the chart below indicates an approximate (limit) relationship between two distribution families. A solid line indicates an exact relationship: special case, sum, or transformation.","links":[{"article_link":"https://www.johndcook.com/blog/distribution_chart/#beta_binomial","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1318,"title":"Audino","description":"Open source audio annotation tool for humans\u2122.","tags":["code","paper","research","library","annotation","audio","arxiv:2006.05236"],"details":"audino is an open source audio annotation tool. It provides features such as transcription and labeling which enables annotation for Voice Activity Detection (VAD), Diarization, Speaker Identification, Automated Speech Recognition, Emotion Recognition tasks and more.\r\n\r\n#### Features\r\n\r\nCurrent features of the tool include:\r\n\r\n1. Multi-language support\r\n2. Collaborative annotation\r\n3. JWT based authentication\r\n4. User-level project, role and data assignment\r\n5. Project-level API Key based datapoint creation\r\n6. Emoji support\r\n7. Flexibility in label creation","links":[{"article_link":"","code_link":"https://github.com/midas-research/audino","research_link":"https://arxiv.org/abs/2006.05236","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1317,"title":"Peak Engines","description":"Build warped linear regression models in Python when your model has a non-normal error distribution.","tags":["article","code","linear-regression","regression","library","non-normal","warped-linear-regression","peak-engines","non-linear-regresssion","non-linear"],"details":"Warped Linear Regression is like Ordinary Least Squares but with an extra transformation step where target values are remapped using a parameterized monotonic function and adjusted so as to maximize likelihood on a linear model. The transformation makes Warped Linear Regression more general purpose than Ordinary Least Squares and able to fit models with non-normal error distributions.\r\n\r\n**Articles**\r\n\r\n* [What to Do When Your Model Has a Non-Normal Error Distribution](https://towardsdatascience.com/what-to-do-when-your-model-has-a-non-normal-error-distribution-f7c3862e475f)\r\n* [How to Build a Warped Linear Regression Model](https://towardsdatascience.com/how-to-build-a-warped-linear-regression-model-3e778e30a201)\r\n\r\n**Examples**\r\n\r\n* [example/boston_housing.ipynb](example/boston_housing.ipynb):\r\n  Build a model to predict housing values.\r\n* [example/fish.ipynb](example/fish.ipynb): \r\n  Predict the weight of fish.\r\n* [example/abalone.ipynb](example/abalone.ipynb): \r\n  Predict the age of sea snails.\r\n","links":[{"article_link":"https://towardsdatascience.com/what-to-do-when-your-model-has-a-non-normal-error-distribution-f7c3862e475f","code_link":"https://github.com/rnburn/peak-engines","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://github.com/rnburn/peak-engines/blob/master/doc/Reference.pdf"}]},{"id":1314,"title":"Sparkify","description":"Use Spark to process user activity logs of a 2-month duration and build classification models to predict churned users with Spark\u2019s MLlib.","tags":["article","code","tutorial","spark","classification"],"details":"This project will serve as an exploration of how to make a churn-prediction model using Spark, with the following steps included:\r\n\r\n* explore and manipulate our dataset\r\n* engineer relevant features for our problem\r\n* split data into train and test sets by sampling churn\r\n* build binary classifier models with Spark\u2019s DataFrame-based MLlib\r\n* select and fine-tune the final model with Spark\u2019s ML Pipelines and a StratifiedCrossValidator","links":[{"article_link":"https://towardsdatascience.com/using-spark-to-predict-churn-c69e675272bf","code_link":"https://github.com/silviaclaire/sparkify","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1312,"title":"OpenAI API","description":"API for accessing new AI models developed by OpenAI.","tags":["api","article","library","language-modeling","natural-language-processing","openai"],"details":"Unlike most AI systems which are designed for one use-case, the API today provides a general-purpose \u201ctext in, text out\u201d interface, allowing users to try it on virtually any English language task. You can now [request access](https://forms.office.com/Pages/ResponsePage.aspx?id=VsqMpNrmTkioFJyEllK8sx3ELsv0PEhHphhNz30FttVUNkYwTlNPMVI1V0lXNjExMlExUlc4SE5YSS4u) in order to integrate the API into your product, develop an entirely new application, or help us explore the strengths and limits of this technology.","links":[{"article_link":"https://openai.com/blog/openai-api/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"http://beta.openai.com"}]},{"id":1311,"title":"Artifacts - Weights and Biases","description":"Versioned data, models and results across your pipelines","tags":["article","tutorial","wandb","dvc","versioning","data-versioning","artifacts","model-versioning"],"details":"Artifacts is available in version 0.9.0 of our wandb Python library. You can use it to store and version your datasets, models, and results. We automatically keep track of all the relationships between artifacts & runs in your projects, so you can dig in and understand exactly how a model was produced.","links":[{"article_link":"https://medium.com/@shawnup/announcing-artifacts-a7f680b6afd6","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://docs.wandb.com/artifacts"}]},{"id":1310,"title":"GPT-3 Language Model: A Technical Overview","description":"Technical details of the GPT-3 model, training, inference and what to expect next. ","tags":["article","tutorial","language-modeling","natural-language-processing","gpt-3"],"details":"If GPT-2 was \"too dangerous to release,\" and GPT-3 almost passed the Turing test for writing short articles. What can a trillion parameter model do? For years the research community has been searching for chatbots that \"just works,\" could GPT-3 be the breakthrough? Is it really possible to have a massive pre-trained model, so any downstream tasks become a matter of providing a few examples or descriptions in the prompt? At a broader scale, can this \"data compilation + reprogram\" paradigm ultimately lead us to AGI? AI safety needs to go a long way to prevent techniques like these from being misused, but it seems the day of having truly intelligent conversations with robots is just at the horizon.","links":[{"article_link":"https://lambdalabs.com/blog/demystifying-gpt-3/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1309,"title":"Sentiment Analysis on News Article","description":"Used Twitter API to extract news-related tweets. Did some preprocessing and then calculated the tweets' polarity.","tags":["code","natural-language-processing","sentiment-analysis"],"details":"Sentiment analysis is the interpretation and classification of emotions (positive, negative and neutral) within text data using text analysis techniques. Sentiment analysis allows businesses to identify customer sentiment toward products, brands or services in conversations and feedback.\r\n","links":[{"article_link":"","code_link":"https://github.com/Shadaab17/Sentiment-Analysis/tree/master/Sentiment%20Analysis%20on%20News%20Article","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1301,"title":"Big GANs Are Watching You","description":" We demonstrate that object saliency masks for GAN-produced images can be obtained automatically with BigBiGAN.","tags":["code","paper","research","tutorial","generative-adversarial-networks","computer-vision","object-detection","segmentation","unet","object-saliency","big-gan","bigbigan","arxiv:2006.04988"],"details":"First, we explore the latent space of the BigBiGAN -- the state-of-the-art unsupervised GAN, which parameters are publicly available. We demonstrate that object saliency masks for GAN-produced images can be obtained automatically with BigBiGAN. These masks then are used to train a discriminative segmentation model. Being very simple and easy-to-reproduce, our approach provides competitive performance on common benchmarks in the unsupervised scenario.","links":[{"article_link":"","code_link":"https://github.com/anvoynov/BigGANsAreWatching","research_link":"https://arxiv.org/abs/2006.04988","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1300,"title":"Structured Data Classification from Scratch","description":"Binary classification of structured data including numerical and categorical features.","tags":["code","notebook","tutorial","keras","tensorflow","classification","features"],"details":"This example demonstrates how to do structured data classification, starting from a raw CSV file. Our data includes both numerical and categorical features. We will use Keras preprocessing layers to normalize the numerical features and vectorize the categorical ones.","links":[{"article_link":"","code_link":"https://github.com/keras-team/keras-io/blob/master/examples/structured_data/structured_data_classification_from_scratch.py","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/structured_data/ipynb/structured_data_classification_from_scratch.ipynb"}]},{"id":1299,"title":"RFEst ","description":"A Python 3 toolbox for neural receptive field estimation using splines and Gaussian priors.","tags":["code","library","matrix-factorization","gaussian-priors","splines","spline-based-methods","ridge-regression"],"details":"### Supported Methods\r\n\r\n**Spline-based Methods** [1]\r\n\r\n`splineLG`, `splineLNP` and `splineLNLN` use *natural cubic regression splines* to approximate spatio-temporal RFs. \r\n\r\nGiven a stimulus design matrix (X) and the corresponding response (y), an optimized RF is calculated with respect to the dimension of the RF `dims=(nT, nY, nX)` :\r\n\r\n```\r\nfrom rfest import splineLG\r\n\r\nspl = splineLG(X, y, dims=(5, 20, 15), df=9, smooth='cr') \r\nspl.fit(num_iters=500, alpha=1, lambd=0.025, verbal=100)\r\n```\r\n\r\n**Evidence Optimization**\r\n\r\n* Ridge Regression \r\n* Automatic Relevance Determination (ARD) [2]\r\n* Automatic Smoothness Determination (ASD) [3]\r\n* Automatic Locality Determination (ALD) [4]\r\n\r\n```\r\nfrom rfest import ASD\r\n\r\nasd = ASD(X, y, dims=(5, 20, 15)) # nt, ny, dx\r\np0 = [1., 1., 2., 2., 2.] # sig, rho, \ud835\udefft, \ud835\udeffy, \ud835\udeffx\r\nasd.fit(p0=p0, num_iters=300)\r\n```\r\n\r\n**Matrix Factorization**\r\n\r\nA few matrix factorization methods have been implemented as a submodule (`MF`). \r\n\r\n```\r\nfrom rfest.MF import KMeans, semiNMF\r\n```\r\n\r\nFor more information, see [here](https://github.com/berenslab/RFEst/blob/master/rfest/MF/README.md). ","links":[{"article_link":"","code_link":"https://github.com/berenslab/RFEst","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1298,"title":"PEGASUS: a SOTA model for Abstractive Text Summarization","description":"A State-of-the-Art Model for Abstractive Text Summarization.","tags":["article","research","transformers","natural-language-processing","text-summarization","pegasus"],"details":"[Abstractive text summarization](https://ai.googleblog.com/2016/08/text-summarization-with-tensorflow.html) is one of the most challenging tasks in natural language processing, involving understanding of long passages, information compression, and language generation.","links":[{"article_link":"https://ai.googleblog.com/2020/06/pegasus-state-of-art-model-for.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1297,"title":"Machine Learning Street Talk","description":"Machine Learning Street Talk with Tim Scarfe, Yannic Kilcher, and Connor Shorten! New Episodes every Week, Please Subscribe!","tags":["podcast","research","tutorial","video","machine-learning","youtube","talk"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/channel/UCMLtBahI5DMrt0NPvDSoIRQthttps://www.youtube.com/channel/UCMLtBahI5DMrt0NPvDSoIRQ","dataset_link":"","demo_link":"","other_link":""}]},{"id":1296,"title":"Deep Learning Research Papers","description":"An illustrative look at trending deep learning research papers.","tags":["video","deep-learning","youtube","papers"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/playlist?list=PLTl9hO2Oobd8UboKp8CyxomVqXyOfOjXe","dataset_link":"","demo_link":"","other_link":""}]},{"id":1295,"title":"Two Minute Papers","description":"Awesome research for everyone - two new science videos every week.","tags":["podcast","research","tutorial","video","papers"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/playlist?list=PLujxSBD-JXgnqDD1n-V30pKtp6Q886x7e","dataset_link":"","demo_link":"","other_link":""}]},{"id":1294,"title":"TWIML AI Podcast","description":"Keep up with the most interesting & important stories from the world of machine learning, deep learning & artificial intelligence.","tags":["podcast","machine-learning","twiml-ai"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://twimlai.com/"}]},{"id":1293,"title":"Henry AI Labs - Deep Learning Research Videos","description":"Overview of trending machine learning research topics.","tags":["tutorial","video","machine-learning","videos","papers","henry-ai"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/channel/UCHB9VepY6kYvZjj0Bgxnpbw/videos","dataset_link":"","demo_link":"","other_link":"https://www.henryailabs.com/"}]},{"id":1292,"title":"Talks - Abhishek Thakur","description":"Talks series with interseting ML experts. ","tags":["podcast","video","machine-learning","youtube","talks"],"details":"If you want to be a speaker, fill out this form: [https://bit.ly/AbhishekTalks](https://bit.ly/AbhishekTalks)","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/playlist?list=PL98nY_tJQXZl79DdyMQDvGDgv6A3zsMIf","dataset_link":"","demo_link":"","other_link":""}]},{"id":1291,"title":"Chai Time Data Science","description":"Interviews with popular data science individuals.","tags":["podcast","video","machine-learning","data-science","kaggle"],"details":"Interviews with Researchers, Kagglers and Practitioners, released every Thursday and Sunday.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/playlist?list=PLLvvXm0q8zUbiNdoIazGzlENMXvZ9bd3x","dataset_link":"","demo_link":"","other_link":"http://ctds.show"}]},{"id":1290,"title":"Papers Explained - Yannic Kilcher","description":"Detailed paper explanations usually released the day after a popular paper is released. ","tags":["tutorial","video","videos","papers-explained","youtube"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/playlist?list=PL1v8zpldgH3pR7LPuidEZK68kS6AaU1y7","dataset_link":"","demo_link":"","other_link":""}]},{"id":1289,"title":"Artificial Intelligence Podcast","description":"Podcast hosts accessible, big-picture conversations at MIT and beyond about the nature of intelligence.","tags":["podcast","video","artificial-intelligence","lex-fridman"],"details":"The Artificial Intelligence (AI) podcast hosts accessible, big-picture conversations at MIT and beyond about the nature of intelligence with some of the most interesting people in the world thinking about AI from the perspective of deep learning, robotics, AGI, neuroscience, philosophy, psychology, cognitive science, economics, physics, mathematics, and more.\r\n\r\nSubscribe to this YouTube channel or connect on:\r\n- Twitter:[ https://twitter.com/lexfridman]( https://twitter.com/lexfridman)\r\n- LinkedIn: [https://www.linkedin.com/in/lexfridman](https://www.linkedin.com/in/lexfridman)\r\n- Facebook: [https://www.facebook.com/lexfridman](https://www.facebook.com/lexfridman)\r\n- Instagram: [https://www.instagram.com/lexfridman](https://www.instagram.com/lexfridman)\r\n- Medium: [https://medium.com/@lexfridman](https://medium.com/@lexfridman)\r\n- Support on Patreon: [https://www.patreon.com/lexfridman](https://www.patreon.com/lexfridman)","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/playlist?list=PLrAXtmErZgOdP_8GztsuKi9nrraNbKKp4","dataset_link":"","demo_link":"","other_link":"https://lexfridman.com/ai/"}]},{"id":1288,"title":"ENEM","description":"Predicting ENEM Grades","tags":["code","research","python","scikit-learn","linear-regression","regression","inference","data-science","enem","ensemble"],"details":"AceleraDev's 2020 Challenge to create a Predicting Model for ENEM's Math  Grades","links":[{"article_link":"","code_link":"https://github.com/ecsantana76/ENEM","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1287,"title":"BERT Loses Patience: Fast and Robust Inference with Early Exit","description":"Patience-based Early Exit, a inference method that can be used as a plug-and-play technique to simultaneously improve the efficiency of a pretrained LM.","tags":["code","paper","research","attention","bert","transformers","language-modeling","natural-language-processing","optimization","inference","patience-based-early-exit","arxiv:2006.04152"],"details":"In this paper, we propose Patience-based Early Exit, a straightforward yet effective inference method that can be used as a plug-and-play technique to simultaneously improve the efficiency and robustness of a pretrained language model (PLM). To achieve this, our approach couples an internal-classifier with each layer of a PLM and dynamically stops inference when the intermediate predictions of the internal classifiers do not change for a pre-defined number of steps. Our approach improves inference efficiency as it allows the model to make a prediction with fewer layers. Meanwhile, experimental results with an ALBERT model show that our method can improve the accuracy and robustness of the model by preventing it from overthinking and exploiting multiple classifiers for prediction, yielding a better accuracy-speed trade-off compared to existing early exit methods.","links":[{"article_link":"","code_link":"https://github.com/JetRunner/PABEE","research_link":"https://arxiv.org/abs/2006.04152","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1286,"title":"Exploring Knowledge Captured in Probability of Strings","description":"An exploration of simple knowledge captured by language models with code examples","tags":["article","gpt2","transformers","language-modeling","natural-language-processing","zero-shot-learning"],"details":"Explore what language models can learn by just observing a bunch of strings over the internet.","links":[{"article_link":"https://amitness.com/2020/06/knowledge-in-language-model/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1285,"title":"Organize pandas notebook with a cool hack","description":"An article on a cool hack for making Pandas Jupyter notebooks readable, clean, organized, and almost production-ready, without any additional library.","tags":["article","python","pandas","data-analysis","data-science","jupyter-notebook","plotly","pipeline"],"details":"**Objectives: **\r\n\r\n1. Solving the problem of messy and unorganized pandas Jupyter notebook which greatly affects our productivity.\r\n\r\n2. Making the notebook readable, clean and organized without any additional library.\r\n\r\n3. Making it easier for converting the notebook code to production.\r\n\r\n4. Making the jupyter notebook code maintainable, shareable, adaptable, readable, reusable and easy to debug.\r\n\r\n**Highlights**\r\n\r\n1. Importance of Workflow\r\n\r\n2. The Usual coding style\r\n \r\n3. Problems in the usual coding style\r\n\r\n4. Coding Implementation (df.pipe)\r\n\r\n5. Advantages of the approach\r\n\r\n**Bonus**\r\n\r\n- Demonstration of COVID-19 Data analysis using interactive plots with plotly library.\r\n\r\n","links":[{"article_link":"https://shahayush.com/2020/06/pandas-pipe-plotly/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1283,"title":"https://artificialneural.expert/","description":"In this website we will share and review with you the best AI Learning resources we have come across so far. We will keep updating it on an almost daily basis\r\n\r\n","tags":["article","tutorial","deep-learning","machine-learning"],"details":"1. Books , \r\n1. Online Courses\r\n1.  Research Review Papers","links":[{"article_link":"https://artificialneural.expert/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://artificialneural.expert/"}]},{"id":1281,"title":"AI Automated dubbing","description":"Build an end-to-end Youtube audio translation platform using AWS serverless architecture","tags":["article","code","tutorial","aws","audio","dubbing"],"details":"**Input :**\r\n\r\nYoutube video in any language (Eg: English)\r\n\r\n**Ouput** :\r\n\r\nNew video with audio in a different language (Eg: Spanish) or different accent (Eg: Indian English)\r\n\r\n**Demo playlist:**\r\n\r\n[Playlist](https://www.youtube.com/playlist?list=PLeIs-OgljgIwCJwJUFqWTRZVzM0VTyT4D)","links":[{"article_link":"https://medium.com/swlh/ai-automated-dubbing-building-and-end-to-end-youtube-audio-translation-platform-using-aws-ebe5b0f153dd?source=friends_link&sk=83fb00c13529e5ff013622c2fdae79c7","code_link":"https://github.com/ramsrigouthamg/End-to-end-Youtube-audio-translation-aws-serverless","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1279,"title":"Perceptron to Deep-Neural-Network: The Road Less Traveled","description":"A journey from Perceptron to Deep Neural Networks in a sequential fashion.","tags":["article","code","notebook","tutorial","neural-networks","multilayer-perceptrons","perceptron"],"details":"A journey from Perceptron to Deep Neural Networks in a sequential fashion.\r\n\r\nObjectives:   \r\n1. Learn sequentially: Perceptron,  Logistic Regression, Single Layer Neural Network, Multilayer Perceptron (1 hidden layer) and finally Deep Neural Network.   \r\n2. Understand the algorithms along with Visualization and Math.\r\n\r\n*Many people jump directly into Deep Learning and face a problem understanding what exactly the algorithm is doing. It is useful to ignore the details by calling it a black box that just works. It is more useful to understand the details of its working for research and tinkering purpose.*","links":[{"article_link":"https://tsumansapkota.github.io/algorithm/2020/06/06/Perceptron-to-DeepNeuralNets/","code_link":"https://colab.research.google.com/github/tsumansapkota/Blog_Post/blob/master/04_Regression_MLP/00_Modifying_Perceptron-Animation.ipynb","research_link":"","media_link":"https://github.com/tsumansapkota/Blog_Post/tree/master/04_Regression_MLP","dataset_link":"","demo_link":"","other_link":""}]},{"id":1278,"title":"Automatically Generate Multiple Choice Questions (MCQs) ","description":"Automatically Generate Multiple Choice Questions (MCQs) from any content with BERT Summarizer, Wordnet, and Conceptnet","tags":["article","code","tutorial","attention","bert","transformers","natural-language-processing","question-generation","wordnet","conceptnet"],"details":"**Input ** **: (Any content or text)**\r\n> The Greek historian knew what he was talking about. The Nile River fed Egyptian civilization for hundreds of years. The Longest River the Nile is 4,160 miles long \u2014 the world\u2019s longest river. It begins near the equator in Africa and flows north to the Mediterranean Sea ..\r\n\r\n**Output (Generated MCQs)**\r\n> **1) **The Nile provided so well for  _____  that sometimes they had surpluses, or more goods than they needed.\r\n> \r\n> \t a )   Angolan\r\n> \t \r\n> \t b )   Algerian\r\n> \t \r\n> **\t c )   Egyptians**\r\n> \r\n> \t d )   Bantu\r\n> \r\n> More options:  ['Basotho', 'Beninese', 'Berber', 'Black African', 'Burundian', 'Cameroonian', 'Carthaginian', 'Chadian', 'Chewa', 'Congolese', 'Djiboutian', 'Egyptian', 'Ethiopian', 'Eurafrican', 'Ewe', 'Fulani'] \r\n> \r\n> \r\n> **2) **The  _____  provided so well for Egyptians that sometimes they had surpluses, or more goods than they needed.\r\n> \r\n> \t a )   Nyala\r\n> \t \r\n> \t b )   Omdurman\r\n> \t \r\n> **\t c )   Nile**\r\n> \r\n> \t d )   Port Sudan\r\n> \r\n> More options:  ['Khartoum', 'Nubian Desert', 'Darfur', 'Libyan Desert', 'Kordofan', 'Gulu', 'Buganda', 'Entebbe', 'Jinja', 'Lake Edward', 'entebbe', 'gulu', 'kayunga', 'Upper Egypt', 'Suez Canal', 'Aswan High Dam']","links":[{"article_link":"https://towardsdatascience.com/practical-ai-automatically-generate-multiple-choice-questions-mcqs-from-any-content-with-bert-2140d53a9bf5?source=friends_link&sk=d0ceb25b7a435b5f530ce7d34003588c","code_link":"https://github.com/ramsrigouthamg/Generate_MCQ_BERT_Wordnet_Conceptnet","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1275,"title":"Exploration Strategies in Deep Reinforcement Learning","description":"Exploitation versus exploration is a critical topic in reinforcement learning. This post introduces several common approaches for better exploration in Deep RL.","tags":["article","tutorial","reinforcement-learning","exploration-strategies"],"details":"[Exploitation versus exploration](https://lilianweng.github.io/lil-log/2018/01/23/the-multi-armed-bandit-problem-and-its-solutions.html) is a critical topic in Reinforcement Learning. I would like to discuss several common exploration strategies in Deep RL here. As this is a very big topic, my post by no means can cover all the important subtopics. I plan to update it periodically and keep further enriching the content gradually in time.","links":[{"article_link":"https://lilianweng.github.io/lil-log/2020/06/07/exploration-strategies-in-deep-reinforcement-learning.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1274,"title":"Getting Machine Learning to Production","description":"Machine learning is hard and there are a lot, a lot of moving pieces.","tags":["article","tutorial","machine-learning","production"],"details":"A fun proof-of-concept ML project to really explain all the things that need to happen for machine learning to work in the wild.","links":[{"article_link":"http://veekaybee.github.io/2020/06/09/ml-in-prod/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1273,"title":"Hummingbird","description":"Hummingbird is a library for compiling trained traditional ML models into tensor computations.","tags":["code","pytorch","scikit-learn","machine-learning","neural-networks","library","tensor-computation","hummingbird","micorsoft"],"details":"Hummingbird allows users to seamlessly leverage neural network frameworks (such as PyTorch) to accelerate traditional ML models. Thanks to Hummingbird, users can benefit from: \r\n\r\n1. all the current and future optimizations implemented in neural network frameworks; \r\n1. native hardware acceleration; \r\n1. having a unique platform to support for both traditional and neural network models; and have all of this\r\n1. without having to re-engineer their models.","links":[{"article_link":"","code_link":"https://github.com/microsoft/hummingbird","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1272,"title":"Linformer: Self-Attention with Linear Complexity","description":"We demonstrate that the self-attention mechanism can be approximated by a low-rank matrix.","tags":["paper","research","attention","self-attention","transformers","natural-language-processing","linear-complexity","complexity","linformer","arxiv:2006.04768"],"details":"Standard self-attention mechanism of the Transformer uses O(n^2) time and space with respect to sequence length. In this paper, we demonstrate that the self-attention mechanism can be approximated by a low-rank matrix. We further exploit this finding to propose a new self-attention mechanism, which reduces the overall self-attention complexity from O(n^2) to O(n) in both time and space. The resulting linear transformer, the Linformer, performs on par with standard Transformer models, while being much more memory- and time-efficient.","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2006.04768","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1271,"title":"WExDA - Web-based Data Exploration Tool","description":"WExDA is a web-based data exploration tool made with streamlit. It can be used for Exploratory Data Analysis.","tags":["article","code","library","visualization","streamlit","data-science","exploratory-data-analysis"],"details":"**WExDA** is a web based data exploration tool primarily useful for data preparation/ data analysis stage. This automates the EDA via web UI and is built using streamlit. Go to [https://wexda.herokuapp.com/](https://wexda.herokuapp.com/) and start using ;)\r\n\r\n**Features**\r\n\r\n*     upload csv files upto 200MB\r\n*     describe data set\r\n*     find missing values\r\n*     find unique values and its count\r\n*     plot data via scatter, bar and pair plots\r\n*     plot correlation matrix in heatmap style\r\n","links":[{"article_link":"https://wexda.herokuapp.com/","code_link":"https://github.com/rahulrajpl/wexda","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://wexda.herokuapp.com/"}]},{"id":1270,"title":"Movie Recommendation System","description":"Collaborative Based Filtering System Recommendation System using ratings given and genres liked by other users.","tags":["code","tutorial","recommendation-systems"],"details":"","links":[{"article_link":"","code_link":"https://github.com/harsh7502/Movie-Recommendation-system","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1269,"title":"Coursera Course Dataset","description":"The project aims to scrap through data from website of Coursera and generate a csv file for its analysis.\r\n\r\n","tags":["article","code","tutorial","scrapping","analysis","courser"],"details":"Project name : Coursera-Course-Dataset\r\n\r\nPublication: https://medium.com/analytics-vidhya/web-scraping-and-coursera-8db6af45d83f\r\n\r\nDescription : The project aims to scrap through data from website of Coursera and generate a csv file for its analysis.\r\n\r\nIn this url: https://github.com/Siddharth1698/Coursera-Course-Dataset\r\n\r\nTable of Contents :\r\n\r\n    scrapping_coursera.py : Used for scrapping\r\n\r\n    UCoursera_Courses.csv : The final scrapped CSV file.\r\n\r\nLibraries used :\r\n\r\nhttps://pypi.org/project/beautifulsoup4/\r\n\r\nUsage : Csv can be used for data analysis and to bring out insights about courses.\r\n\r\nContributing : Feel free to fork and add more code to scrap more data for better csv.\r\n","links":[{"article_link":"https://medium.com/analytics-vidhya/web-scraping-and-coursera-8db6af45d83f","code_link":"https://github.com/Siddharth1698/Coursera-Course-Dataset","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.kaggle.com/siddharthm1698/coursera-course-dataset"}]},{"id":1266,"title":"Text Classification using Bert from Tensorflow-Hub","description":"This Tutorial helps to learn about Bert Models for Classification  task on a #Tweet dataset.","tags":["article","tutorial","tensorflow","attention","bert","transformers","classification","natural-language-processing","text-classification"],"details":"you will Learn to build a simple text classification model using #bert with the help of Tensorflow Hub","links":[{"article_link":"https://vpkprasanna.blogspot.com/2020/05/bert-for-classification-with-tensorflow.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1265,"title":"Dota 2 International 10 Traveller's Guide","description":"Its a project that uses the data from Foursquare API to generate travel recommendations for the International Attendees using clustering algorithm(K-Means)","tags":["code","clustering","data-science","exploratory-data-analysis"],"details":"","links":[{"article_link":"","code_link":"https://github.com/sphinxkid/Coursera_Capstone","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://ibm.co/2z75Awd"}]},{"id":1260,"title":"Advanced Deep Learning for Computer Vision (ADL4CV)","description":"The Visual Computing Group offers a variety of lectures and seminars on a regular basis, covering hot areas in computer graphics, vision, and machine learning.","tags":["course","tutorial","video","deep-learning","computer-vision"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/playlist?list=PLog3nOPCjKBnjhuHMIXu4ISE4Z4f2jm39","dataset_link":"","demo_link":"","other_link":"https://dvl.in.tum.de/teaching/adl4cv-ws18/"}]},{"id":1259,"title":"Network Fusion for Content Creation With Conditional Inns","description":"We present a method to repurpose powerful, existing models for new tasks, even though they have never been designed for them.","tags":["article","paper","research","computer-vision","image-generation","conditioned-generation","network-fusion","content-creation","arxiv:2005.13580"],"details":"Artificial Intelligence for Content Creation has the potential to reduce the amount of manual content creation work significantly. While automation of laborious work is welcome, it is only useful if it allows users to control aspects of the creative process when desired. Furthermore, widespread adoption of semi-automatic content creation depends on low barriers regarding the expertise, computational budget and time required to obtain results and experiment with new techniques.","links":[{"article_link":"https://compvis.github.io/network-fusion/","code_link":"","research_link":"https://arxiv.org/abs/2005.13580","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1258,"title":"MSeg: A Composite Dataset for Multi-domain Semantic Segmentation","description":"A composite dataset that unifies semantic segmentation datasets from different domains.","tags":["api","code","dataset","paper","research","tutorial","video","library","computer-vision","labeling","segmentation","instance-segmentation","panoptic-segmentation","multi-domain","mechanical-turk"],"details":"* [mseg-api](https://github.com/mseg-dataset/mseg-api): utilities to download the MSeg dataset, prepare the data on disk in a unified taxonomy, on-the-fly mapping to a unified taxonomy during training.\r\n* [mseg-semantic](https://github.com/mseg-dataset/mseg-semantic): utilities to train semantic segmentation models, using a HRNet-W48 or PSPNet backbone, sufficient to train a winning entry on the [WildDash](https://wilddash.cc/benchmark/summary_tbl) benchmark).\r\n* [mseg-panoptic](https://github.com/mseg-dataset/mseg-panoptic): provides Panoptic-FPN and Mask-RCNN training, based on Detectron2\r\n* [mseg-mturk](https://github.com/mseg-dataset/mseg-panoptic): provides utilities to perform large-scale Mechanical Turk re-labeling","links":[{"article_link":"","code_link":"https://github.com/mseg-dataset/mseg-semantic","research_link":"http://vladlen.info/papers/MSeg.pdf","media_link":"https://www.youtube.com/watch?v=PzBK6K5gyyo","dataset_link":"","demo_link":"","other_link":""}]},{"id":1257,"title":"How Big Should My Language Model Be?","description":"Tool to explore language model training and optimize the compute costs.","tags":["huggingface","transformers","library","language-modeling","natural-language-processing","compute","calculator"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://huggingface.co/calculator/"}]},{"id":1256,"title":"AlphaZero using DeepMind OpenSpiel","description":"Implementation of AlphaZero for the DeepMind OpenSpiel repository.","tags":["article","code","paper","research","tutorial","rl","deepmind","alphazero","openspiel"],"details":"The philosophy of this implementation is to follow the pseudocode of the AlphaZero Science paper as closely as possible, and also fit it into the current [OpenSpiel](https://github.com/deepmind/open_spiel) framework with minimal framework changes.","links":[{"article_link":"https://sebastianbodenstein.net/post/alphazero/","code_link":"https://gist.github.com/sbodenstein/e4027feb52d1da5e90f23828d77774d1","research_link":"https://science.sciencemag.org/content/362/6419/1140","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1255,"title":"TransformerTTS","description":"\ud83e\udd16\ud83d\udcac Transformer TTS: Implementation of a non-autoregressive Transformer based neural network for text to speech.","tags":["code","tutorial","tensorflow","transformers","natural-language-processing","speech","speech-synthesis","text-to-speech","demo","wavernn","melgan"],"details":"Implementation of a non-autoregressive Transformer based neural network for Text-to-Speech (TTS). <br>\r\nThis repo is based on the following papers:\r\n- [Neural Speech Synthesis with Transformer Network](https://arxiv.org/abs/1809.08895)\r\n- [FastSpeech: Fast, Robust and Controllable Text to Speech](https://arxiv.org/abs/1905.09263)\r\n\r\nOur pre-trained LJSpeech models are compatible with the pre-trained vocoders from:\r\n- [WaveRNN](https://github.com/fatchord/WaveRNN)\r\n- [MelGAN](https://github.com/seungwonpark/melgan)\r\n\r\n#### Non-Autoregressive\r\nBeing non-autoregressive, this Transformer model is:\r\n- Robust: No repeats and failed attention modes for challenging sentences.\r\n- Fast: With no autoregression, predictions take a fraction of the time.\r\n- Controllable: It is possible to control the speed of the generated utterance.","links":[{"article_link":"","code_link":"https://github.com/as-ideas/TransformerTTS","research_link":"","media_link":"https://as-ideas.github.io/TransformerTTS/","dataset_link":"","demo_link":"https://as-ideas.github.io/TransformerTTS/","other_link":""}]},{"id":1254,"title":"Unsupervised Translation of Programming Languages","description":"We train our model on source code from open source GitHub projects, and show that it can translate functions between C++, Java, and Python with high accuracy.","tags":["code","paper","research","translation","code-generation","unsupervised-learning","code-translation","programming-languages","arxiv:2006.03511"],"details":"Our method relies exclusively on monolingual source code, requires no expertise in the source or target languages, and can easily be generalized to other programming languages. We also build and release a test set composed of 852 parallel functions, along with unit tests to check the correctness of translations. We show that our model outperforms rule-based commercial baselines by a significant margin.","links":[{"article_link":"","code_link":"https://github.com/facebookresearch/TransCoder/","research_link":"https://arxiv.org/abs/2006.03511","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1253,"title":"Perceptrons Explained","description":"Play with several perceptron variants in browser, including noise-tolerant variants.","tags":["article","code","tutorial","perceptrons","noise-tolerance","deep-dive","voted-perceptron"],"details":"Visualize how perceptrons update in real-time, as well as their proof of convergence. Explore two additional variants--the Voted Perceptron and the Maxover Perceptron--which extend the perceptron's performance and convergence to the linearly unseparable cases.","links":[{"article_link":"https://owenshen24.github.io/perceptron/","code_link":"https://github.com/owenshen24/perceptron","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1252,"title":"torchlambda","description":"Lightweight tool to deploy PyTorch models to AWS Lambda","tags":["code","aws","c++","pytorch","deep-learning","library","deployment","lambda","lightweight","yaml"],"details":"[__torchlambda__](https://github.com/szymonmaszke/torchlambda/wiki) is a tool to deploy [PyTorch](https://pytorch.org/) models\r\non [Amazon's AWS Lambda](https://aws.amazon.com/lambda/) using [AWS SDK for C++](https://aws.amazon.com/sdk-for-cpp/)\r\nand [custom C++ runtime](https://github.com/awslabs/aws-lambda-cpp).\r\n\r\nUsing statically compiled dependencies __whole package is shrunk to only `30MB`__.\r\n\r\nDue to small size of compiled source code users can pass their models as [AWS Lambda layers](https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html).\r\n__Services like [Amazon S3](https://aws.amazon.com/s3/) are no longer necessary to load your model__.\r\n\r\n[__torchlambda__](https://github.com/szymonmaszke/torchlambda/wiki) has it's PyTorch & AWS dependencies always tested & up to date because of daily [continuous deployment](https://en.wikipedia.org/wiki/Continuous_deployment) runs.\r\n\r\n## Why should I use `torchlambda`?\r\n\r\n- __Lightweight & latest dependencies__ - compiled source code weights only `30MB`. Previous approach to PyTorch network deployment on AWS Lambda ([fastai](https://course.fast.ai/deployment_aws_lambda.html)) uses outdated PyTorch (`1.1.0`) as dependency layer and requires AWS S3 to host your model. Now you can only use AWS Lambda and host your model as layer and PyTorch `master` and latest stable release are supported on a daily basis.\r\n- __Cheaper and less resource hungry__ - available solutions run server hosting incoming requests all the time. AWS Lambda (and torchlambda) runs only when the request comes.\r\n- __Easy automated scaling__  usually autoscaling is done with [Kubernetes](https://kubernetes.io/) or similar tools (see [KubeFlow](https://www.kubeflow.org/docs/gke/deploy/)). This approach requires knowledge of another tool, setting up appropriate services (e.g. [Amazon EKS](https://aws.amazon.com/eks/)). In AWS Lambda case you just push your neural network inference code and you are done.\r\n- __Easy to use__ - no need to learn new tool. `torchlambda` has at most\r\n`4` commands and deployment is done via [YAML](https://yaml.org/) settings. No need to modify your PyTorch code.\r\n- __Do one thing and do it well__ - most deployment tools are complex solutions\r\nincluding multiple frameworks and multiple services. `torchlambda` focuses\r\nsolely on inference of PyTorch models on AWS Lambda.\r\n- __Write programs to work together__ - This tool does not repeat PyTorch & AWS's functionalities (like `aws-cli`). You can also use your favorite third party tools (say [saws](https://github.com/donnemartin/saws), [Terraform](https://www.terraform.io/) with AWS and [MLFlow](https://www.mlflow.org/docs/latest/index.html), [PyTorch-Lightning](https://github.com/PyTorchLightning/pytorch-lightning) to train your model).\r\n- __Test locally, run in the cloud__ - `torchlambda` uses [Amazon Linux 2](https://aws.amazon.com/amazon-linux-2/) Docker [images](https://hub.docker.com/_/amazonlinux) under the hood & allows you to use [lambci/docker-lambda](https://github.com/lambci/docker-lambda) to test your deployment on `localhost` before pushing deployment to the cloud (see [Test Lambda deployment locally](https://github.com/szymonmaszke/torchlambda/wiki/Test-Lambda-deployment-locally) tutorial).\r\n- __Extensible when you need it__ - All you usually need are a few lines of YAML settings, but if you wish to fine-tune your deployment you can use `torchlambda build` `--flags` (changing various properties of PyTorch and AWS dependencies themselves). You can also write your own C++ deployment code (generate template via `torchlambda template` command).\r\n- __Small is beautiful__ - `3000` LOC (most being convenience wrapper creating this tool)\r\nmake it easy to jump into source code and check what's going on under the hood.\r\n\r\n\r\n## Table Of Contents\r\n\r\n- [Installation](https://github.com/szymonmaszke/torchlambda/wiki/Installation)\r\n- [Tutorials](https://github.com/szymonmaszke/torchlambda/wiki/Tutorials)\r\n\t- [ResNet18 deployment on AWS Lambda](https://github.com/szymonmaszke/torchlambda/wiki/ResNet18-deployment-on-AWS-Lambda)\r\n\t- [Test Lambda deployment locally](https://github.com/szymonmaszke/torchlambda/wiki/Test-Lambda-deployment-locally)\r\n\t- [`base64` image encoding](https://github.com/szymonmaszke/torchlambda/wiki/base64-image-encoding)\r\n- [Commands](https://github.com/szymonmaszke/torchlambda/wiki/Commands)\r\n\t- [settings](https://github.com/szymonmaszke/torchlambda/wiki/Commands#torchlambda-settings)\r\n\t- [template](https://github.com/szymonmaszke/torchlambda/wiki/Commands#torchlambda-template)\r\n\t- [build](https://github.com/szymonmaszke/torchlambda/wiki/Commands#torchlambda-build)\r\n\t- [layer](https://github.com/szymonmaszke/torchlambda/wiki/Commands#torchlambda-layer)\r\n- [YAML settings file reference](https://github.com/szymonmaszke/torchlambda/wiki/YAML-settings-file-reference)\r\n- [C++ code](https://github.com/szymonmaszke/torchlambda/wiki/CPP---code)\r\n\r\n## Benchmarks\r\n\r\nBenchmarks can be seen in [`BENCHMARKS.md`](https://github.com/szymonmaszke/torchlambda/blob/master/BENCHMARKS.md) file and are comprised of around ~30000 test cases.","links":[{"article_link":"","code_link":"https://github.com/szymonmaszke/torchlambda","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://github.com/szymonmaszke/torchlambda/wiki"}]},{"id":1251,"title":"Automatic Asset Classification","description":"This project aims to automate the task of labelling images of flood defence assets as well as clustering images to find possibly better groupings.","tags":["article","code","research","computer-vision","image-classification","image-clustering","transfer-learning","engineering","asset-management","water","flood-defence"],"details":"This project aims to automate the task of labelling images of flood defence assets as well as clustering images to find possibly better groupings.\r\n\r\n\r\nObjectives:\r\n\r\n\r\n* Semi-Automatic Asset Classification: classify assets by already used labels\r\n\r\n\r\n* Automatic Asset Classification: find underlying groupings of assets from image clustering\r\n\r\n\r\nHighlights:\r\n\r\n\r\n* Creation of a flood defence image dataset.\r\n\r\nKey Takeaways:\r\n\r\n\r\n* Flood defence assets can be classified to a high accuracy of 90% with transfer learning\r\n\r\n\r\n* Neural networks can group assets by some underlying features such as material, environment and risk\r\n\r\n\r\n* A resnet autoencoder was most effective at finding the most clusters\r\n\r\n\r\n* A combination of supervised and unsupervised learning could help label images as well as label other attributes such as material without requiring time to label large datasets.","links":[{"article_link":"https://henriwoodcock.github.io/2020/06/07/Automatic-Asset-Classification/","code_link":"https://github.com/henriwoodcock/automatic-asset-classification","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1249,"title":"Know-Corona : Kaggle COVID-19 Open Research Dataset Challenge (CO","description":"NLP/state-of-the-art language model (BERT) based Question & Answering pipeline to answer all task questions after analyzing articles abstract of COVID-19, SARS-","tags":["article","code","research","tutorial","react","transformers","library","language-modeling","natural-language-processing","question-answering","biobert"],"details":"**Objectives**\r\n\r\n1. In response to the COVID-19 pandemic, the White House and a coalition of leading research groups have prepared the COVID-19 Open Research Dataset (CORD-19)\r\n2.  CORD-19 is a resource of over 52,000 scholarly articles, including over 41,000 with full text, about COVID-19, SARS-CoV-2, and related coronaviruses\r\n3.  To develop NLP based solution that can help the medical community to answer high priority scientific questions\r\n\r\n**Approach**\r\n\r\nLeveraged BM25 Rank function with Pre-trained BioBERT Q&A Model (SQuAD 2.0) from Transformers\r\n\r\n**References**\r\n\r\n1. [https://huggingface.co/models](https://huggingface.co/models)\r\n2. [https://pypi.org/project/rank-bm25/]( https://pypi.org/project/rank-bm25/)\r\n3. [https://github.com/gitname/react-gh-pages](https://github.com/gitname/react-gh-pages)\r\n4. [https://dev.to/yuribenjamin/how-to-deploy-react-app-in-github-pages-2a1f](https://dev.to/yuribenjamin/how-to-deploy-react-app-in-github-pages-2a1f)","links":[{"article_link":"https://overfitter.github.io/2020-05-01-Covid-19-Q&A-BioBert/","code_link":"https://github.com/Overfitter/Know-Corona","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1247,"title":"Tensor functions for Pytorch's Autograd","description":"A blog and notebook to understand the Pytorch's autograd.","tags":["article","code","notebook","tutorial","pytorch","autograd","tensors"],"details":"This contains the most important Pytorch tensor functions and properties to needed to understand the Autograd tool of Pytorch for automatic differentiation. ","links":[{"article_link":"https://medium.com/@namanphy/understanding-autograd-5-pytorch-tensor-functions-8f47c27dc38","code_link":"https://github.com/namanphy/pytorch-handson/blob/master/autograd_tensor_functions_pytorch.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1246,"title":"Fairseq-tagging","description":"a Fairseq fork for sequence tagging/labeling tasks\r\n","tags":["code","machine-learning","library","named-entity-recognition","natural-language-processing","part-of-speech-tagging","sequence-labeling"],"details":"Fairseq is a great library to build sequence-to-sequence models. Unfortunately, it does not support sequence labeling tasks, and you will need to treat the task as seq2seq to make use of Fairseq. This will deprive you of fine-tuning pre-trained models such as RoBERTa XLM-R and BERT and will require you to needlessly train an extra decoder network. I adapted Fairseq here for these tasks so that one is able to utilize the full power of fairseq when training on these tasks.\r\n\r\nFeatures:\r\n\r\n*  load and finetune pretrained BERT or RoBERTa\r\n*  support Byte-Pair Encoding (BPE) models\r\n*  log F1 metric on validation using Seqeva\r\n*  save best model on validation data according to F1 score not loss\r\n\r\n","links":[{"article_link":"","code_link":"https://github.com/mohammadKhalifa/fairseq-tagging","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1243,"title":"Timeseries Anomaly Detection using an Autoencoder","description":"Detect anomalies in a timeseries using an Autoencoder.","tags":["article","code","notebook","tutorial","keras","tensorflow","autoencoders","anomaly-detection","time-series"],"details":"","links":[{"article_link":"https://keras.io/examples/timeseries/timeseries_anomaly_detection/","code_link":"https://github.com/keras-team/keras-io/blob/master/examples/timeseries/timeseries_anomaly_detection.py","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/timeseries/ipynb/timeseries_anomaly_detection.ipynb"}]},{"id":1242,"title":"A Comprehensive Survey of Neural Architecture Search","description":"An overview of the characteristics of the earliest NAS algorithms, summarizing the problems in these early NAS algorithms, and then giving solutions.","tags":["paper","research","optimization","survey","neural-architecture-search","arxiv:2006.02903"],"details":"Deep learning has made major breakthroughs and progress in many fields. This is due to the powerful automatic representation capabilities of deep learning. It has been proved that the design of the network architecture is crucial to the feature representation of data and the final performance. In order to obtain a good feature representation of data, the researchers designed various complex network architectures. However, the design of the network architecture relies heavily on the researchers' prior knowledge and experience. Therefore, a natural idea is to reduce human intervention as much as possible and let the algorithm automatically design the architecture of the network. Thus going further to the strong intelligence.\r\n\r\nIn recent years, a large number of related algorithms for Neural Architecture Search (NAS) have emerged. They have made various improvements to the NAS algorithm, and the related research work is complicated and rich. In order to reduce the difficulty for beginners to conduct NAS-related research, a comprehensive and systematic survey on the NAS is essential. Previously related surveys began to classify existing work mainly from the basic components of NAS: search space, search strategy and evaluation strategy. This classification method is more intuitive, but it is difficult for readers to grasp the challenges and the landmark work in the middle. Therefore, in this survey, we provide a new perspective: starting with an overview of the characteristics of the earliest NAS algorithms, summarizing the problems in these early NAS algorithms, and then giving solutions for subsequent related research work. In addition, we conducted a detailed and comprehensive analysis, comparison and summary of these works. Finally, we give possible future research directions.","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2006.02903","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1241,"title":"Funnel-Transformer: Filtering out Sequential Redundancy","description":"Funnel-Transformer is a self-attention model that gradually compresses the sequence of hidden states to a shorter one and hence reduces the computation cost.","tags":["code","paper","research","tutorial","pytorch","tensorflow","attention","self-attention","transformers","natural-language-processing","funnel-transformer","arxiv:2006.03236"],"details":"We examine the redundancy in maintaining a full-length token-level presentation, especially for tasks that only require a single-vector presentation of the sequence.","links":[{"article_link":"","code_link":"https://github.com/laiguokun/Funnel-Transformer","research_link":"https://arxiv.org/abs/2006.03236","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1240,"title":"An Illustrated Proof of the No Free Lunch Theorem","description":"There is no universal learning algorithm that outperforms every other algorithm on every learning task.","tags":["article","tutorial","illustrated","no-free-lunch"],"details":"","links":[{"article_link":"https://mlu.red/muse/52449366310.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1239,"title":"Zero-shot Text Classification With Generative Language Models","description":"An overview of a text generation approach to zero-shot text classification with GPT-2","tags":["article","tutorial","natural-language-processing","text-classification","text-generation","zero-shot-learning"],"details":"- Learn how GPT-2 can be used to perform zero-shot text classification\r\n- Challenges and Problems with Zero-Shot Learning","links":[{"article_link":"https://amitness.com/2020/06/zero-shot-classification-via-generation/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1237,"title":"Keras notifications on Slack!","description":"Get slack notifications of your model's training progress when training with Keras (or tf.keras)","tags":["code","tutorial","keras","python","tensorflow","deep-learning","machine-learning","training","computer-vision","logging"],"details":"A simple example of how to send updates from your Keras experiments to slack\r\n\r\n![](https://github.com/ssundar6087/Keras-Slack-Logging/raw/master/assets/Slack_demo.gif)\r\n\r\n**Disclaimers:**\r\n\r\n* This is one of the ways to do this, and there are perhaps better ways to do this than what I've shown here.\r\n\r\n* The objective of this notebook is not to show some model train to SOTA, so the hyperparameters are randomly chosen just to show the model training.\r\n \r\n\r\n**What's not covered here:** I will be writing a blog post to accompany this notebook to walk through some of the things that are not covered here (as yet):\r\n\r\n* Setting up your slack workspace\r\n* Creating a bot and a slack api token\r\n* Possible Kaggle Integration","links":[{"article_link":"","code_link":"https://github.com/ssundar6087/Keras-Slack-Logging","research_link":"","media_link":"https://github.com/ssundar6087/Keras-Slack-Logging/raw/master/assets/Slack_demo.gif","dataset_link":"","demo_link":"","other_link":""}]},{"id":1236,"title":"COVID-Q: A Dataset of 1,690 Questions about COVID-19","description":"This dataset consists of COVID-19 questions which have been annotated into a broad category (e.g. Transmission, Prevention) and a more specific class such that ","tags":["code","dataset","paper","research","attention","bert","transformers","library","few-shot-learning","natural-language-processing","question-answering","covid-19","triplet-loss","covid-q","knn-classification"],"details":"We present COVID-Q, a set of 1,690 questions about COVID-19 from 13 sources, which we annotate into 15 question categories and 207 question classes. The most common questions in our dataset asked about transmission, prevention, and societal effects of COVID, and we found that many questions that appeared in multiple sources were not answered by any FAQ websites of reputable organizations such as the CDC and FDA.\r\nFor classifying questions into 15 categories, a BERT baseline scored 58.1% accuracy when trained on 20 examples per class, and for classifying questions into 89 question classes, the baseline achieved 54.6% accuracy. We hope COVID-Q can be helpful either for direct use in developing applied systems or as a domain- specific resource for model evaluation.","links":[{"article_link":"","code_link":"https://github.com/JerryWei03/COVID-Q","research_link":"https://openreview.net/pdf?id=qd51R0JNLl","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1235,"title":"NBA k-means","description":"Extraction of NBA statistics from \"basketball-reference.com\" to visualise them and detect trends and patterns. Clustering of the top players using KMeans.","tags":["code","tutorial","scikit-learn","k-means"],"details":"","links":[{"article_link":"","code_link":"https://github.com/DAndresSanchez/NBA_KMeans","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1231,"title":"NYC property price predictor","description":"Web app that predicts the price of a NYC property based on a tuned regression model.","tags":["code","flask","scikit-learn","regression","library","real-estate"],"details":"Downloaded data from NYC open data. Compared the result of various regression models. Built web application using most effective model. Web application built using flask framework and supports API calls.","links":[{"article_link":"","code_link":"https://github.com/smolgeat/NYC_property_sales","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1230,"title":"Basic Tensorflow Serving Example","description":"Basic example of serving a Tensorflow CNN model for Hand Detection using Tensorflow Serving.","tags":["code","tutorial","tensorflow","computer-vision","object-detection","production","serving"],"details":"Demo Video - [Tensorflow Serving Example](https://www.youtube.com/watch?v=yJwxuasLETQ)","links":[{"article_link":"","code_link":"https://github.com/tataganesh/TF-Serving-CNN-example","research_link":"","media_link":"https://docs.google.com/presentation/d/1-NKPK4XU8BXYBbre_GYseep4RAwPl0ebzscIgOb00bw/edit?usp=sharing","dataset_link":"","demo_link":"","other_link":"https://www.analyticsvidhya.com/datahack-summit-2019/schedule/hack-session-all-you-need-to-know-about-deploying-dl-models-using-tensorflow/"}]},{"id":1229,"title":"Pytorch-Tensor Operations","description":"Tensor-operations you can apply with PyTorch.","tags":["article","code","notebook","tutorial","pytorch","tensor-networks","operations"],"details":"","links":[{"article_link":"https://medium.com/simply-dev/pytorch-tensor-operations-210ad241f4f0","code_link":"https://colab.research.google.com/drive/1a5skL8J6hTYxdFOqVTrDhhwx8TeuPPoA","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1225,"title":"Network Traffic Classification Using Time Related Features","description":"Classification of different types of network traffic according to their types.","tags":["code","python","machine-learning","cyber-security"],"details":"In this work different types of network traffic such as: email, chat, browsing etc were classified using time related features. Main application of network traffic classification as: better quality of service, pricing etc. The main reason behind using time related features is that they are encryption independent. For classification both ensemble learning and machine learning techniques were used.","links":[{"article_link":"","code_link":"https://github.com/TanvirHimel/Netwrok-Traffic-Classification-Using-TIme-Related-Features","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1223,"title":"Leafy: Plant Leaf Classifier","description":"The sequential model trained on images from the leafsnap.com","tags":["scikit-learn","tensorflow","tensorflow-js","computer-vision","image-classification"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://sumitpaul1809.pythonanywhere.com/"}]},{"id":1222,"title":"Paragraph Summarizer","description":"Uses the extractive way of summarizing the text by finding the score and ranking it.","tags":["code","flask","python","machine-learning","natural-language-processing"],"details":"","links":[{"article_link":"","code_link":"https://github.com/Sumit189/Text-Summarizer","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1215,"title":"Pytorch Faster RCNN","description":"Fine Tune Faster RCNN in pytorch for your task.","tags":["code","pytorch","convolutional-neural-networks","computer-vision","object-detection"],"details":"Faster RCNN With simple to use train.py file.\r\nEdit the config, to set the parameters and train the model.\r\n\r\nSupports multiple backbones resnet50, resnet101, mobilent, vgg.\r\n\r\nWill support pytorch lightning for multi gpu and tpu training as well.","links":[{"article_link":"","code_link":"https://github.com/oke-aditya/pytorch_fasterrcnn","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1211,"title":"Literate Lamp: Answering Question with Common Sense","description":"We study the problem of answering questions that require common sense to be answered using Transformer-based models and the ConceptNet knowledge base.","tags":["code","transformers","common-sense-reasoning","knowledge-base-question-answering","natural-language-processing","question-answering","qa"],"details":"This work investigates the problem of Commonsense Question Answering, the task of answering multiple-choice questions that require not only understanding of the text, but also of implicit knowledge that is considered commonsense to human answerers.\r\n\r\nThis challenge is addressed by applying techniques from Deep Learning, including state-of-the-art models such as BERT and XLNet. We developed multiple models, ranging from baselines, previous state-of-the-art and recent developments from the Natural Language Processing area.\r\n\r\nWe study the impact of adding an explicit knowledge representation from the knowledge base ConceptNet. We found that our best models, a derivatives\r\nof XLNet and BERT, perform better without any extra knowledge. We explore this result, positing that teaching models via extensive pre-training can perform better than the explicit approach.\r\n\r\nWe identify that the largest obstacle for these models is not retrieving the necessary knowledge, but performing elaborate inference with the available information, an observation that could guide further work in this problem.","links":[{"article_link":"","code_link":"https://github.com/oyarsa/literate-lamp","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1210,"title":"Cat vs Dog Classifier using Fast.ai ","description":"Cat vs Dog Classifier using Fast.ai for beginners","tags":["code","notebook","fastai","deep-learning"],"details":"","links":[{"article_link":"","code_link":"https://github.com/kush1307/Deep_Learning_Projects/blob/master/Cat%20or%20Dog%20Classifier%20using%20Fast.ai/cat-vs-dogs-using-fast-ai.ipynb","research_link":"","media_link":"https://github.com/kush1307/Deep_Learning_Projects/blob/master/Cat%20or%20Dog%20Classifier%20using%20Fast.ai/cat-vs-dogs-using-fast-ai.ipynb","dataset_link":"","demo_link":"","other_link":""}]},{"id":1206,"title":"Data Understanding","description":"Identify relationship between the features in a dataset using Hypothesis testing - Chi-square, ANOVA, PearsonR","tags":["code","feature-importance","hypothesis-testing","anova","bi-variate-analysis","univariate-analysis","chi-square-test","pearsonr","inferential-statistics"],"details":"**Objective**:\r\nIdentify the most important features given a dataset with large number of features using Hypothesis testing.\r\n\r\n1. Univariate and Bi-variate analysis on different types of features\r\n1. Find relationship between  input variables - Input features should be independent of each other \r\n1. Find relationship between input and target variables - input features should depend on target and should be independent of each other\r\n1. Come up with list of important features , on which we can apply ML algorithms\r\n\r\n**Highlights** : Considered different hypothesis testing approaches for different types of variables - Categorical, quantitative. \r\n\r\n**Take away **: This application is more like a framework which can be used on any dataset. \r\n\r\n**Next steps** : Need to sample the dataset , and apply these hypothesis testing tricks on the sample . Come up with insights from the dataset","links":[{"article_link":"","code_link":"https://github.com/savitha91/DataUnderstanding_MLproject","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1205,"title":"Paper Explanation: Going deeper with Convolutions","description":"Blog post about 'Going Deeper with Convolutions' with its implementation in Tensorflow.","tags":["article","code","paper","research","tutorial","tensorflow","deep-learning","arxiv:1409.4842"],"details":"","links":[{"article_link":"https://prabinnepal.com/paper-explanation-going-deeper-with-convolutions-googlenet/","code_link":"https://github.com/nepalprabin/deeplearning-paper-implementation/tree/master/GoogLeNet","research_link":"https://arxiv.org/abs/1409.4842","media_link":"","dataset_link":"","demo_link":"","other_link":"prabinnepal.com"}]},{"id":1204,"title":"Snaked: Classifying Snake Species using Images","description":"Proof of concept that it is possible to identify snake species and whether poisonous from photographs (PyTorch code/model with Android app)","tags":["article","code","python","pytorch","convolutional-neural-networks","computer-vision"],"details":"5.4 million people are bitten by snakes every year and 81-138 million people die due to snake bites each year. Preventing snake bites is clearly a major issue, in need of preventative measures to save lives. This repository serves as a demonstration of the code required to identify snake species and whether poisonous from photographs. A sample application/proof of concept is additionally available on the Google Play Store!","links":[{"article_link":"https://www.kamwithk.com/snake-classification-report-ck6oj5dg202fwdfs10qim8fwd","code_link":"https://github.com/KamWithK/Snaked","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1203,"title":"Summary of \ud83e\udd17 Transformers Models","description":"A high-level summary of the differences between each model in HuggingFace's Transformer library.","tags":["article","tutorial","huggingface","transformers","natural-language-processing","summary"],"details":"This is a summary of the models available in the transformers library. It assumes you\u2019re familiar with the [original transformer model](https://arxiv.org/abs/1706.03762). For a gentle introduction check the [annotated transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html). Here we focus on the high-level differences between the models. You can check them more in detail in their respective documentation. Also checkout the[ pretrained model page](https://huggingface.co/transformers/pretrained_models.html) to see the checkpoints available for each type of model.","links":[{"article_link":"https://huggingface.co/transformers/summary.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://huggingface.co/transformers/pretrained_models.html"}]},{"id":1202,"title":"The NLP Pandect - All NLP resources in one place","description":"The NLP Pandect was created to help you find almost anything related to Natural Language Processing that is available online.","tags":["code","tutorial","natural-language-processing"],"details":"","links":[{"article_link":"","code_link":"https://github.com/ivan-bilan/The-NLP-Pandect","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1199,"title":"How NLP has evolved for Financial Sentiment Analysis","description":"Do we still need humans to read boring financial statements?","tags":["article","code","tutorial","finance","natural-language-processing"],"details":"* I explore the evolution of NLP in Financial Sentiment Classification, from lexicon methods to embeddings to deep learning, i.e. Transformers.","links":[{"article_link":"https://towardsdatascience.com/how-nlp-has-evolved-for-financial-sentiment-analysis-fb2990d9b3ed","code_link":"https://gist.github.com/neoyipeng2018/73b61bec5e7034a92ea0a4e393202f7d","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1198,"title":"Differential Machine Learning","description":"Extends supervised learning, with models trained on examples of not only inputs and labels, but also differentials of labels to inputs. ","tags":["code","notebook","paper","research","tutorial","finance","differential-machine-learning","risk-management","arxiv:2005.02347"],"details":"Differential ML is applicable in all situations where high quality first order derivatives wrt training inputs are available.  In the context of financial Derivatives risk management, pathwise differentials are efficiently computed with automatic adjoint differentiation (AAD). Differential ML, combined with AAD, provides extremely effective pricing and risk approximations. We can produce fast pricing analytics in models too complex for closed form solutions, extract the risk factors of complex transactions and trading books, and effectively compute risk management metrics like reports across a large number of scenarios, backtesting and simulation of hedge strategies, or capital regulations.","links":[{"article_link":"","code_link":"https://github.com/differential-machine-learning","research_link":"https://arxiv.org/abs/2005.02347","media_link":"https://colab.research.google.com/github/differential-machine-learning/notebooks/blob/master/DifferentialML.ipynb","dataset_link":"","demo_link":"","other_link":""}]},{"id":1197,"title":"Scale Invariant Feature Transform For Cirebon Mask Classification","description":"This is about my project in Image Classification focus to Pattern Recognition about Cirebon Mask Classification in MATLAB. ","tags":["code","machine-learning","random-forests","support-vector-machines","pattern-recognition","k-nearest-neighbors","decision-tree","matlab","cirebon-mask"],"details":"*The vast diversity of art in Indonesia generates many interest both domestically and internationally. One of the prominent culture is Cirebon Mask. There are five types of Cirebon masks: Panji, Samba, Rumyang, Tumenggung and Klana. In this research, Cirebon masks is classified using digital images processing techniques using Scale-Invariant Feature Transform, while K-Nearest Neighbour, Support Vector Machines and Random Forest as the classifier.*","links":[{"article_link":"","code_link":"https://github.com/fendy07/sift-mask","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1194,"title":"Divide Hugging Face Transformers Training Time By 2","description":"Reducing training time helps to iterate more in a fixed budget time and thus achieve better results.","tags":["article","code","tutorial","huggingface","transformers","natural-language-processing","optimization","mixed-precision","batch-sizing"],"details":"We have shown that both uniform sized batching and mixed precision techniques constantly provide significant time reduction without reducing accuracy.","links":[{"article_link":"https://towardsdatascience.com/divide-hugging-face-transformers-training-time-by-2-or-more-21bf7129db9q-21bf7129db9e","code_link":"https://gist.github.com/pommedeterresautee/1a334b665710bec9bb65965f662c94c8","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1193,"title":"DeepMind x UCL |  Intro to Machine Learning & AI","description":"In this lecture series, research scientists from leading AI research lab, DeepMind, deliver 12 lectures on an exciting selection of topics in Deep Learning.","tags":["course","tutorial","video","machine-learning","deepmind","ucl"],"details":"In this lecture series, research scientists from leading AI research lab, DeepMind, deliver 12 lectures on an exciting selection of topics in Deep Learning, ranging from the fundamentals of training neural networks via advanced ideas around memory, attention, and generative modelling to the important topic of responsible innovation.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=7R52wiUgxZI&list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF","dataset_link":"","demo_link":"","other_link":""}]},{"id":1192,"title":"BERT Summarization","description":"This folder contains colab notebooks that guide you through the summarization by BERT and GPT-2 to play with your data.","tags":["code","tutorial","attention","bert","transformers","natural-language-processing","summarization"],"details":"","links":[{"article_link":"","code_link":"https://github.com/VincentK1991/BERT_summarization_1","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1191,"title":"Syntactic Search by Example","description":"We present a system that allows a user to search a large linguistically annotated corpus using syntactic patterns over dependency graphs. ","tags":["paper","research","search","allenai","syntactic-patterns","spike","arxiv:2006.03010"],"details":"We demonstrate the system using queries over two corpora: the English wikipedia, and a collection of English pubmed abstracts. A demo of the wikipedia system is available at: [this https URL](https://spike.wikipedia.apps.allenai.org/search/wikipedia/#queryType=S)","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2006.03010","media_link":"https://spike.wikipedia.apps.allenai.org/search/wikipedia/#queryType=S","dataset_link":"","demo_link":"","other_link":""}]},{"id":1190,"title":"Image Augmentations for GAN Training","description":"We systematically study the effectiveness of various existing augmentation techniques for GAN training in a variety of settings. ","tags":["paper","research","generative-adversarial-networks","data-augmentation","image-augmentation","arxiv:2006.02595"],"details":"Data augmentations have been widely studied to improve the accuracy and robustness of classifiers. However, the potential of image augmentation in improving GAN models for image synthesis has not been thoroughly investigated in previous studies. In this work, we systematically study the effectiveness of various existing\r\naugmentation techniques for GAN training in a variety of settings. We provide insights and guidelines on how to augment images for both vanilla GANs and GANs with regularizations, improving the fidelity of the generated images substantially. Surprisingly, we find that vanilla GANs attain generation quality on par with recent state-of-the-art results if we use augmentations on both real and generated images.","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2006.02595","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1189,"title":"DogandCatBreed Classifier","description":"Model can to learn to differentiate between these 37 distinct categories","tags":["article","code","fastai","pytorch"],"details":"","links":[{"article_link":"https://kirankamath.netlify.app/blog/image-classification-fast-ai/","code_link":"https://github.com/kirankamatmgm/DogandCatBreed_Classifier","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1185,"title":"PyTorch Transformers Tutorials","description":"A set of annotated Jupyter notebooks, that give user a template to fine-tune transformers model to downstream NLP tasks such as classification, NER etc. ","tags":["code","tutorial","huggingface","pytorch","transformers","named-entity-recognition","natural-language-processing","question-answering","text-classification","text-summarization","wandb","multi-class","multi-label"],"details":"A set of annotated Jupyter notebooks, that give user a template to fine-tune transformers model to downstream NLP tasks.\r\n\r\nThe objective of this tutorial is to provide a step by step guide to users to fine-tune transformers model on their dataset for downstream NLP tasks with ease. Making the phase of theory to Production easy and fast. \r\n\r\nThe tutorials cover following NLP tasks:\r\n\r\n1. Classification\r\n2. Summarization\r\n3. Named Entity Recognition\r\n4. Question Answering","links":[{"article_link":"","code_link":"https://github.com/abhimishra91/transformers-tutorials","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1184,"title":"Bank Marketing Campaign","description":"Predict if the client will subscribe to a term deposit based on the analysis of the marketing campaigns the bank performed.","tags":["code","tutorial","library","#marketing#campaign#bank"],"details":"Business Use Case\r\nThere has been a revenue decline for a bank and they would like to know what actions to take. After investigation, they found out that the root cause is that their clients are not depositing as frequently as before. Knowing that term deposits allow banks to hold onto a deposit for a specific amount of time, so banks can invest in higher gain financial products to make a profit. In addition, banks also hold better chance to persuade term deposit clients into buying other products such as funds or insurance to further increase their revenues. As a result, the bank would like to identify existing clients that have higher chance to subscribe for a term deposit and focus marketing efforts on such clients.","links":[{"article_link":"","code_link":"https://github.com/anilsharma7/Bank_Marketing_Campaign","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1182,"title":"A beginner\u2019s guide to understanding the AI buzz words ","description":"A beginner\u2019s guide to understanding the buzz words -AI, ML, NLP, Deep Learning, Computer Vision, and Data Science","tags":["article","tutorial","machine-learning","starter-guide"],"details":"A beginner\u2019s guide to understanding the buzz words - AI, ML, NLP, Deep Learning, Computer Vision, and Data Science","links":[{"article_link":"https://medium.com/@ramsrigouthamg/a-beginners-guide-to-understanding-the-buzz-words-ai-ml-nlp-deep-learning-computer-vision-a877ee1c2cde?source=friends_link&sk=e8a03640a784a3230daa70149cbb00d0","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1181,"title":"TensorflowTTS: Real-Time SOTA Speech Synthesis for Tensorflow 2.0","description":"TensorflowTTS provides real-time state-of-the-art speech synthesis architectures such as Tacotron2, Melgan, FastSpeech.","tags":["code","tensorflow","natural-language-processing","speech","speech-synthesis","text-to-speech"],"details":"TensorflowTTS provides real-time state-of-the-art speech synthesis architectures such as Tacotron-2-Tensorflow, Melgan-Tensorflow, FastSpeech-Tensorflow based-on TensorFlow 2. With Tensorflow 2, we can speed-up training/inference progress, optimizer further by using fake-quantize aware and pruning, make TTS models can be run faster than real-time and be able to deploy on mobile devices or embedded systems.","links":[{"article_link":"","code_link":"https://github.com/dathudeptrai/TensorflowTTS","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://dathudeptrai.github.io/TensorflowTTS/"}]},{"id":1180,"title":"The Transformer \u2026 \u201cExplained\u201d?","description":"An intuitive explanation of the Transformer by motivating it through the lens of CNNs, RNNs, etc.","tags":["article","tutorial","convolutional-neural-networks","recurrent-neural-networks","transformers","natural-language-processing"],"details":"- I\u2019m going to take a \u201chistorical\u201d route where I go through some other, mostly older architectural patterns first, to put it in context; hopefully it\u2019ll be useful to people who are new to this stuff, while also not too tiresome to those who aren\u2019t.\r\n-  The closest thing to an intuitive explainer than I know of is \u201c[The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/),\u201d but IMO it\u2019s too light on intuition and too heavy on near-pseudocode (including stuff like \u201cnow you divide by 8,\u201d as the third of six enumerated \u201csteps\u201d which themselves only cover part of the whole computation!).\r\n- This is a shame, because once you hack through all the surrounding weeds, the basic idea of the Transformer is really simple.  This post is my attempt at a explainer.","links":[{"article_link":"https://nostalgebraist.tumblr.com/post/185326092369/the-transformer-explained","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1178,"title":"Machine Learning with Fastai","description":"The fastai library is based on research into deep learning best practices undertaken at fast.ai, and includes support for Vision, Text, tabular and Collab","tags":["code","tutorial","python","pytorch","deep-learning","computer-vision"],"details":"Fastai is a deep learning library which provides practitioners with high-level components that can quickly and easily provide state-of-the-art results in standard deep learning domains, and provides researchers with low-level components that can be mixed and matched to build new approaches.\r\n\r\nFastai is making deep learning easier to use and getting more people from all backgrounds involved.\r\n\r\n**Credits**: Jeremy Howard(CEO, fastai)","links":[{"article_link":"","code_link":"https://github.com/timothykmulenga/Machine_Learning_with_Fastai.git","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://docs.fast.ai/index.html"}]},{"id":1176,"title":"doc2vec Paragraph Embeddings for Text Classification","description":"Text classification model which uses gensim's Doc2Vec for generating paragraph embeddings and scikit-learn Logistic Regression for classification. ","tags":["code","scikit-learn","document-embeddings","embeddings","natural-language-processing","sentiment-analysis","text-classification","gensim","doc2vec"],"details":"- Text classification model which uses gensim's Doc2Vec for generating paragraph embeddings and scikit-learn Logistic Regression for classification. \r\n\r\n- The classification use-case is sentiment analysis, IMDb movie reviews dataset is used, 25000  reviews, the sentiment of reviews is binary (1 for positive, 0 for negative).\r\n\r\n- Doc2vec embeddings are used as features for the classification model, as they provide distributed semantic representations for sentences/documents, think word2vec but for sentences instead of words.\r\n\r\n- References:\r\n\r\n\t1.     [Kaggle \u2013 Bag of Words Meets Bags of Popcorn](https://www.kaggle.com/c/word2vec-nlp-tutorial)\r\n\t\r\n\t2.    [Gensim \u2013 Deep learning with paragraph2vec](https://radimrehurek.com/gensim/models/doc2vec.html)\r\n\t\r\n\t3.     [Quoc Le and Tomas Mikolov. Distributed Representations of Sentences and Documents](https://arxiv.org/pdf/1405.4053v2.pdf)","links":[{"article_link":"","code_link":"https://github.com/ibrahimsharaf/Doc2vec","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1173,"title":"Rocopicker","description":"Practice for Classifying  the game character by using CNN\r\n","tags":["article","code","notebook","tutorial","tensorflow","tensorflow-js","convolutional-neural-networks","transfer-learning"],"details":"This notebook was written by KOREAN\r\nThis github repository is including these codes.\r\n\r\n* Jupyter notebook to make Model using tensorflow (in 'model/rocoPicker.ipynb')\r\n* Django project to use Model","links":[{"article_link":"https://www.notion.so/ymgym/f4d8f6de0a0e415ebe2eee5462f01983?v=5ccd482ffc0f41b0ad452e984a3f87a7","code_link":"https://github.com/YMGYM/rocopicker_django/blob/master/model/rocoPicker.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1172,"title":"Converting images to TF Records","description":"A Colab Notebook showing how to convert an image dataset (for classification) to TF Records and more.","tags":["code","notebook","tutorial","tensorflow","computer-vision","images","tf-records"],"details":"A notebook for your covering the following:\r\n\r\n- Loading up the cats-vs-dogs dataset from TensorFlow Datasets (tfds).\r\n- Converting the dataset to TF Records and moving them to a publicly available GCS Bukcet.\r\n- Parsing the TF Records' files and visualizing them.\r\n- Timing the performance.\r\n","links":[{"article_link":"","code_link":"https://colab.research.google.com/drive/1A3TALnuDj0FXqvSBM96Es6BEKaZwbkVz?usp=sharing","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1171,"title":"New York Yellow Cab Fares","description":"Created a predictor using classification algorithms to predict the fare of a new york taxi cab.","tags":["code","research","transportation"],"details":"Project is completed.\r\nA potential area to improve on is to balance out the classes, because most of the misclassification errors are stemming from class imbalance.","links":[{"article_link":"","code_link":"https://github.com/Rachel-188428/Fare-Prediction1","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1169,"title":"Regression Testing","description":"This project leverages machine learning techniques to clean, analyze, and make predictions on any inputted csv dataset.","tags":["code","flask","library","plotly","regression-tests"],"details":"This [website](https://regression-testing.herokuapp.com) cleans and performs a thorough analysis on any csv file that a user enters.\r\n\r\nThe cleaning process takes advantage of different techniques such as basic mappings , one hot encoding, and feature elimination for uninformative variables.\r\n\r\nThe website then generates various visualizations based on the data entered to help the user get a better grasp of all the distributions and correlations going on. Both the raw and the cleaned+normalized distributions are generated for all of the variables, and they are fully interactive. After that, a full correlation matrix and list ranking the 15 most important variables (in regard to predicting the final column) are displayed. All the visualizations in this project are created to be simple, interactive, and informative.\r\n\r\nFinally, a series of regression algorithms is run on an 80-20 split of the entered data to help the user find a good starting point to build out advanced prediction models. The current regression models demonstrated are Linear Regression, K-Nearest Neighbor, Extra Trees, and Xgboost. A summary of all the results generated from those algorithms is then laid out at the bottom.\r\n\r\nHere is a sample dataset if you want to try it out for yourself: [Avocado_Data](https://raw.githubusercontent.com/SidTheKid007/RegressionTesting/master/static/example/avocadoCA.csv)\r\n\r\nEnjoy :)","links":[{"article_link":"","code_link":"https://github.com/SidTheKid007/RegressionTesting","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://angel.co/projects/1149526-regression-testing"}]},{"id":1168,"title":"Integrated Gradients","description":"This tutorial walks you through an implementation of Integrated Gradients, an ML interpretabilit technique described in Axiomatic Attribution for Deep Networks.","tags":["article","code","notebook","paper","research","interpretability","gradients","integrated-gradients","arxiv:1703.01365"],"details":"","links":[{"article_link":"https://distill.pub/2020/attribution-baselines/","code_link":"https://colab.research.google.com/drive/13wIR1RYT2118kmqsHI3ItHuYCIzK_9h9?usp=sharing","research_link":"https://arxiv.org/abs/1703.01365","media_link":"","dataset_link":"","demo_link":"","other_link":"https://github.com/ankurtaly/Integrated-Gradients"}]},{"id":1167,"title":"From Pre-trained Word Embeddings to Pre-trained Language Models","description":"from Static Word Embedding to Dynamic (Contextualized) Word Embedding.","tags":["article","tutorial","attention","bert","transformers","contextualized-embeddings","embeddings","language-modeling","natural-language-processing","word-embeddings","pretraining"],"details":"rom Static Word Embedding to Dynamic (Contextualized) Word Embedding.","links":[{"article_link":"https://towardsdatascience.com/from-pre-trained-word-embeddings-to-pre-trained-language-models-focus-on-bert-343815627598","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1166,"title":"Acme: A Research Framework for Reinforcement Learning","description":"A library of reinforcement learning components and agents.","tags":["code","paper","research","library","reinforcement-learning","acme","deepmind","arxiv:2006.00979"],"details":"Acme is a library of reinforcement learning (RL) agents and agent building blocks. Acme strives to expose simple, efficient, and readable agents, that serve both as reference implementations of popular algorithms and as strong baselines, while still providing enough flexibility to do novel research. The design of Acme also attempts to provide multiple points of entry to the RL problem at differing levels of complexity.","links":[{"article_link":"","code_link":"https://github.com/deepmind/acme","research_link":"https://arxiv.org/abs/2006.00979","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1165,"title":"YOLOv4","description":"A TensorFlow 2.0 implementation of YOLOv4: Optimal Speed and Accuracy of Object Detection.","tags":["code","tutorial","tensorflow","computer-vision","object-detection","yolo","yolo-v4"],"details":"This implementation runs (for now) inference with the original Darknet weights from [AlexeyAB](https://github.com/AlexeyAB/darknet). See the roadmap section to see what's next.","links":[{"article_link":"","code_link":"https://github.com/sicara/tf2-yolov4","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1162,"title":"Deep Q-Network on Space Invaders. ","description":"This is a PyTorch implementation of a Deep Q-Network agent trained to play the Atari 2600 game of Space Invaders.","tags":["article","code","paper","research","tutorial","pytorch","deep-q-networks","q-learning","reinforcement-learning","arxiv:1312.5602"],"details":"In this article, I will start by laying out the mathematics of RL before moving on to describe the DQN architecture and its application to the Atari game of Space Invaders. Lastly, I will go through some implementation details, whose code is available on my Github repository.","links":[{"article_link":"https://qarchli.github.io/2020-06-04-dqn-to-play-space-invaders/","code_link":"https://github.com/qarchli/dqn-on-space-invaders","research_link":"https://arxiv.org/abs/1312.5602","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1159,"title":"Learning To Classify Images Without Labels","description":"A two-step approach where feature learning and clustering are decoupled.","tags":["code","paper","research","tutorial","clustering","computer-vision","image-classification","self-supervised-learning","unsupervised-learning","arxiv:2005.12320"],"details":"**Note**: code + pretrained models + configuration files will be released (in a few weeks) to produce numbers even better than in the current version of the paper.","links":[{"article_link":"","code_link":"https://github.com/wvangansbeke/Unsupervised-Classification","research_link":"https://arxiv.org/abs/2005.12320","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1155,"title":"GaborNet","description":"Modified network architecture that focuses on improving convergence and reducing training complexity.","tags":["code","paper","research","python","pytorch","convolutional-neural-networks","library","computer-vision","arxiv:1904.13204"],"details":"CNNs with GaborLayers show better performanceon several datasets. \r\n\r\nToDo:\r\n* refactoring\r\n* adapt to new pytorch syntax\r\n* add poetry","links":[{"article_link":"","code_link":"https://github.com/iKintosh/GaborNet","research_link":"https://arxiv.org/abs/1904.13204","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1154,"title":"Data Scientist: The Dirtiest Job of the 21st Century","description":"I am a data scientist\u2026 \r\nI don\u2019t find my job sexy. \r\nI am 40% a vacuum, another 40% a janitor. \r\nAnd the last 20%\u2026 A fortune-teller. ","tags":["article","tutorial","careers","jobs"],"details":"According to the Harvard Business Review, a data scientist has the sexiest job of the 21st century. Indeed, the emergence of cloud and movement of businesses to the internet has let to an explosion of data. This has driven the demand and shortage of data scientists in some sectors.\r\n\r\nBut what does a data scientists job entail on a day-to-day basis? According to surveys, the majority of a data scientist\u2019s time is on collecting datasets and cleaning and organising data. High demand data janitor of the 21st century.","links":[{"article_link":"https://towardsdatascience.com/data-scientist-the-dirtiest-job-of-the-21st-century-7f0c8215e845?source=friends_link&sk=4a19193cb50580e59c9c481fd840bbec","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1152,"title":"Cardiovascular Disease EDA ( Detailed )","description":"To predict the presence or absence of cardiovascular disease (CVD) using the patient examination results.","tags":["code","research","tutorial","python","health","data-science","exploratory-data-analysis","eda","cardiovascular"],"details":"To predict the presence or absence of cardiovascular disease (CVD) using the patient examination results.","links":[{"article_link":"","code_link":"https://www.kaggle.com/robinreni/cardiovascular-disease-eda-detailed","research_link":"","media_link":"https://www.kaggle.com/sulianova/cardiovascular-disease-dataset","dataset_link":"","demo_link":"","other_link":""}]},{"id":1151,"title":"Web Mining and Information theory","description":"Mining the Web and playing with Natural Language processing. Implementing Information retrieval System tasks. Going towards the NLP and Performing Machine Learning algorithms. Through these codes and problems, I have understood the information retrieval process of any search engine. These are very useful problems towards sentiment analysis.","tags":["code","information-extraction","information-retrieval","natural-language-inference","natural-language-processing","natural-language-understanding","web-mining"],"details":"","links":[{"article_link":"","code_link":"https://github.com/BharatDadwaria/Web-Mining-NLP-and-Information-Retrieval","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://web.stanford.edu/~jurafsky/slp3/"}]},{"id":1150,"title":"Practical Sampling Distribution and Central limit theorem ","description":"Whenever it comes to Statistical Data Analysis or Exploratory Data Analysis, we have to go through the distribution of the data. So while working on the very big datasets mostly we apply our analysis on a sample, not the whole population which may lead to certain variations between the sample analysis and population analysis. This approximation introduces us with the Sampling Distribution","tags":["article","code","notebook","tutorial","library","data-analysis","data-science","sampling-distribution","central-limit-theorem","data-engineers"],"details":"","links":[{"article_link":"https://medium.com/thecyphy/practical-sampling-distribution-and-central-limit-theorem-for-data-engineers-95591bb900b7","code_link":"https://github.com/BharatDadwaria/Statistical-Data-Analysis/blob/master/Sampling_distribution_EDA.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1148,"title":"A Practical guide to building a conversational chatbot","description":"Building a Chatbot from scratch using Keras and NLTK library for a customer service company","tags":["article","code","tutorial","keras","tensorflow","library","natural-language-processing","conversational-ai"],"details":"What is a Conversational Chat Bot???\r\nIn the Essence of the world, it is a robot, that enables a machine to simulate human-like conversations.\r\nTo achieve this, the user interface needs to be as humanlike and conversational as possible. A conversational chatbot must understand the user\u2019s intents and how to respond to the user.\r\nWhen creating a chatbot, writing a script that flows is an important part of the design process. People expect bots to have human-level conversational abilities \u2014 from intelligence to humor, it requires a lot of creativity and planning ahead. \r\n*Decide the chatbot Purpose\r\n*Give your chatbot a persona\r\n* Create a conversation diagram\r\n* Train your chatbot and interact with it","links":[{"article_link":"https://medium.com/@imonemmanuel/a-practical-guide-to-building-a-conversational-chat-bot-using-keras-79755ed86462","code_link":"https://GitHub.com/ImonEmmanuel/Chatbot","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1146,"title":"Physics \u2229 ML","description":"A a virtual hub at the interface of theoretical physics and deep learning.","tags":["research","machine-learning","physics","journal"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"http://physicsmeetsml.org/"}]},{"id":1145,"title":"Learning Dexterity End-to-End","description":"We trained a human-like robot hand to manipulate physical objects with unprecedented dexterity.","tags":["article","tutorial","reinforcement-learning","robotics","wandb","openai","dexterity"],"details":"This article gives great insight into wow the OpenAI Robotics team uses W&B reports.","links":[{"article_link":"https://app.wandb.ai/openai/published-work/Learning-Dexterity-End-to-End--VmlldzoxMTUyMDQ","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://openai.com/blog/learning-dexterity/"}]},{"id":1139,"title":"RoBERTa \u2192 Longformer: Build a \"Long\" Version of Pretrained Models","description":"This notebook replicates the procedure descriped in the Longformer paper to train a Longformer model starting from the RoBERTa checkpoint. ","tags":["code","notebook","paper","research","huggingface","attention","bert","transformers","natural-language-processing","pretraining","roberta","longformer","arxiv:2004.05150"],"details":"The same procedure can be applied to build the \"long\" version of other pretrained models as well. For example, the [Longformer for Question Answering](https://colab.research.google.com/github/patil-suraj/Notebooks/blob/master/longformer_qa_training.ipynb).","links":[{"article_link":"","code_link":"https://colab.research.google.com/github/allenai/longformer/blob/master/scripts/convert_model_to_long.ipynb","research_link":"https://arxiv.org/abs/2004.05150","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1136,"title":"Integrated Gradients for Interpretability","description":"Integrated Gradients is a technique for attributing a classification model's prediction to its input features. ","tags":["paper","research","tutorial","convolutional-neural-networks","deep-learning","interpretability","gradients","arxiv:1703.01365"],"details":"","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/1703.01365","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.kaggle.com/aakashnain/integratedgradients-for-interpretability"}]},{"id":1135,"title":"Melanoma Detection with Pytorch","description":"In this video, I show you how you can build a deep learning model to detect melanoma with a very high accuracy.","tags":["code","tutorial","video","pytorch","health","computer-vision","resnet","melanoma"],"details":"In this video, I show you how you can build a deep learning model to detect melanoma with a very high accuracy. Melanoma is skin cancer which is very deadly but can be prevented if we can do early detection. Models like these might be useful to medical community.","links":[{"article_link":"","code_link":"https://www.kaggle.com/abhishek/melanoma-detection-with-pytorch","research_link":"","media_link":"https://www.youtube.com/watch?v=WaCFd-vL4HA","dataset_link":"","demo_link":"","other_link":"https://www.kaggle.com/c/siim-isic-melanoma-classification"}]},{"id":1134,"title":"Artificial Neural Networks Back Then","description":"Development of neural networks over history.","tags":["article","code","notebook","tutorial","neural-networks","multilayer-perceptrons","history","perceptron"],"details":"Neural Network today has come a long way from the first computational model of the Neuron. The development of this technology happened in a series of invention, failures and correction of the problems over time. \r\n\r\nObjectives:    \r\n1) Understand the algorithms used back then (Hebbian Learning, Perceptron).    \r\n2) Visualize the working of the algorithms and see the limitations.","links":[{"article_link":"https://tsumansapkota.github.io/algorithm/2020/05/24/Neural-Network-Then/","code_link":"https://colab.research.google.com/github/tsumansapkota/Blog_Post/blob/master/03_Neural_Network_History/00_Early_days.ipynb","research_link":"","media_link":"https://github.com/tsumansapkota/Blog_Post/tree/master/03_Neural_Network_History","dataset_link":"","demo_link":"","other_link":""}]},{"id":1133,"title":"Getting Started with Time Series analysis using Pandas","description":"An introductory guide to get started with the Time Series datasets in Python","tags":["article","code","tutorial","time-series","pandas","kaggle"],"details":"In this notebook, we will introduce some common techniques used in time-series analysis and walk through the iterative steps required to manipulate, visualize time-series data.","links":[{"article_link":"https://www.kaggle.com/parulpandey/getting-started-with-time-series-using-pandas","code_link":"https://github.com/parulnith/Kaggle-Starter-Codes","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1132,"title":"T5 for Sentiment Span Extraction","description":"Exploring how T5 works and applying it for sentiment span extraction.","tags":["code","notebook","tutorial","video","transformers","natural-language-processing","sentiment-analysis","t5"],"details":"Goals for this talk:\r\n\r\n1. Introduce T5 and how it works\r\n1. Explain T5's significance for the future of NLP\r\n1. Illustrate how to use T5 for Sentiment Span Extraction\r\n\r\nTraining T5 with 5 epochs gives an accuracy (Jaccard score) of 0.665. This is still much lower than the 0.714 at the top 10%\r\nBut, much is yet to be done in terms of post training optimization\r\nEnsembling, stacking, etc The amazing thing for me is the confirmation that a generative model like T5 can perform extractive tasks with an accuracy comparable to a token classification version of BERT.","links":[{"article_link":"","code_link":"https://colab.research.google.com/github/enzoampil/t5-intro/blob/master/t5_qa_training_pytorch_span_extraction.ipynb","research_link":"","media_link":"https://www.youtube.com/watch?v=4LYw_UIdd4A","dataset_link":"","demo_link":"","other_link":"https://github.com/enzoampil/t5-intro"}]},{"id":1131,"title":"Sized Fill-in-the-blank or Multi Mask filling with RoBERTa","description":"Sized fill-in-the-blank or conditional text filling is the idea of filling missing words of a sentence with the most probable choice of words.","tags":["article","code","tutorial","huggingface","attention","bert","transformers","language-modeling","natural-language-processing","slot-filling","roberta","mask-filling","multi-mask-filling"],"details":"Original Sentence:  Tom has fully ___ ___ ___ illness.\r\nOriginal Sentence replaced with mask:  Tom has fully <mask> <mask> <mask> illness.\r\n\r\n\r\nMask  1 Guesses :  ['**recovered**', 'returned', 'recover', 'healed', 'cleared']\r\nMask  2 Guesses :  ['**from**', 'his', 'with', 'to', 'the']\r\nMask  3 Guesses :  ['**his**', 'the', 'her', 'mental', 'this']\r\n\r\nBest guess for fill in the blank :::  **recovered from his**","links":[{"article_link":"https://medium.com/@ramsrigouthamg/sized-fill-in-the-blank-or-multi-mask-filling-with-roberta-and-huggingface-transformers-58eb9e7fb0c","code_link":"https://gist.github.com/ramsrigouthamg/90e9a3d802b1e98d6f31b082ec89c385","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1130,"title":"Generate True or False questions from any content","description":"Automatically generate \u201cTrue or False\u201d questions like the ones you see in school textbooks using  OpenAI GPT2, Sentence BERT, and Berkley parser","tags":["article","code","research","tutorial","attention","bert","gpt2","transformers","constituency-parsing","natural-language-processing","question-generation","text-generation"],"details":"Automatically generate \u201cTrue or False\u201d questions like the ones you see in school textbooks using state of the art AI algorithms.\r\n\r\n**Input: **The input to our program will be any content like the following \u2014\r\n> There is a lot of volcanic activity at divergent plate boundaries in the oceans. For example, many undersea volcanoes are found along the Mid-Atlantic Ridge. This is a divergent plate boundary that runs north-south through the middle of the Atlantic Ocean. As tectonic plates pull away from each other at a divergent plate boundary, they create deep fissures, or cracks, in the crust. Molten rock, called magma, erupts through these cracks onto Earth\u2019s surface. At the surface, the molten rock is called lava. It cools and hardens, forming rock. Divergent plate boundaries also occur in the continental crust. Volcanoes form at these boundaries, but less often than in ocean crust. That\u2019s because continental crust is thicker than oceanic crust. This makes it more difficult for molten rock to push up through the crust. Many volcanoes form along convergent plate boundaries where one tectonic plate is pulled down beneath another at a subduction zone. The leading edge of the plate melts as it is pulled into the mantle, forming magma that erupts as volcanoes. When a line of volcanoes forms along a subduction zone, they make up a volcanic arc. The edges of the Pacific plate are long subduction zones lined with volcanoes. This is why the Pacific rim is called the \u201cPacific Ring of Fire.\u201d\r\n\r\n**Output:** The output will be a set of automatically generated True and False sentences , with** true **sentences coming **directly** from the above article and **false** sentences generated by **OpenAI GPT2 **using the true sentences from the article.\r\n\r\n> **1) True Sentence (from the story) :**\r\n> \r\n> As tectonic plates pull away from each other at a divergent plate boundary, they create deep fissures, or cracks, in the crust\r\n> \r\n> **False Sentences (GPT-2 Generated)**\r\n> \r\n> a) As tectonic plates pull away from each other at a divergent plate boundary, they create deep fissures, or cracks, in the crust that provide access to oxygen-rich water.\r\n> \r\n> b) As tectonic plates pull away from each other at a divergent plate boundary, they create deep fissures, or cracks, in the seafloor that are more sensitive to wind velocity and pressure than most continental surfaces.\r\n> \r\n> **2) True Sentence (from the story) :**\r\n> \r\n> Divergent plate boundaries also occur in the continental crust\r\n> \r\n> **False Sentences (GPT-2 Generated)**\r\n> \r\n> a) Divergent plate boundaries also occur in the low and high latitudes.\r\n> \r\n> b) Divergent plate boundaries also occur in regions with more frequent rainfall.\r\n> \r\n> c) Divergent plate boundaries also occur in the brain of mammals and vertebrates.\r\n> \r\n> d) Divergent plate boundaries also have been proposed.\r\n> \r\n> e) Divergent plate boundaries also may be used to map and reduce traffic congestion.\r\n> \r\n> f) Divergent plate boundaries also had to be adjusted and the data collected from different cities was sent on a regular basis.\r\n> \r\n> **3) True Sentence (from the story) :**\r\n> \r\n> Volcanoes form at these boundaries, but less often than in ocean crust\r\n> \r\n> **False Sentences (GPT-2 Generated)**\r\n> \r\n> a) Volcanoes form at these boundaries, but less often than in any other country,\" he says.\r\n> \r\n> b) Volcanoes form at these boundaries, but less often than in a large coastal country (such as the USA) they must be found along well-defined water bodies such that their location can become clear.\r\n> \r\n> **4) True Sentence (from the story) :**\r\n> \r\n> Many volcanoes form along convergent plate boundaries where one tectonic plate is pulled down beneath another at a subduction zone\r\n> \r\n> **False Sentences (GPT-2 Generated)**\r\n> \r\n> a) Many volcanoes form along convergent plate boundaries where one tectonic plate is pulled down beneath another at a rate of 1.1, 3\u20134 km/h (5).\r\n> \r\n> b) Many volcanoes form along convergent plate boundaries where one tectonic plate is pulled down beneath another at about 25% of its original location.\r\n> \r\n> c) Many volcanoes form along convergent plate boundaries where one tectonic plate is pulled down beneath another at a rate of about 100 million km/year.","links":[{"article_link":"https://medium.com/swlh/practical-ai-automatically-generate-true-or-false-questions-from-any-content-with-openai-gpt2-9081ffe4d4c9?source=friends_link&sk=d2ec8d09b5ada16af0c0ca7c36404b9f","code_link":"https://github.com/ramsrigouthamg/Generate_True_or_False_OpenAI_GPT2_Sentence_BERT","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1128,"title":"Arabic Movie Genres Multi-Label Classifier","description":"Using CNNs to predict the genres of Arabic movies based on their posters.","tags":["code","convolutional-neural-networks","deep-learning","multi-label"],"details":"","links":[{"article_link":"","code_link":"https://github.com/moaaztaha/Arabic-Movie-Genres-Multi-Label-Classifier","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1127,"title":"Spam Mail Classifier","description":"Spam Mail Classifier based on Apache Spam Assassin dataset and part of Enron dataset Using ML and DL\r\n","tags":["code","fastai","deep-learning","machine-learning"],"details":"","links":[{"article_link":"","code_link":"https://github.com/moaaztaha/Spam-Mail-Classifier","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1126,"title":"Face Recognition","description":"Face Recognition using face_recognition library which used dlib models to identify faces and generate encoding for each face, then using ML model to classify f ","tags":["code","dlib","python","machine-learning"],"details":"**Face Recognition** using face_recognition library which uses dlib models to identify faces and generate encodings for each face, then using ML model to classify encodings.\r\n\r\n\r\n## System Output\r\n![](https://github.com/moaaztaha/Attendance-Face-Recognition/raw/master/out.png)","links":[{"article_link":"","code_link":"https://github.com/moaaztaha/Attendance-Face-Recognition","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1125,"title":"Money Ball","description":"Applying data wrangling and exploratory data analysis to baseball data. Finding if Moneyball worked for Oakland A's or not.","tags":["code","python","exploratory-data-analysis","data-wrangling"],"details":"","links":[{"article_link":"","code_link":"https://github.com/moaaztaha/money-ball","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1124,"title":"Spark Fortress Discrimination","description":"Testing whether a company \"Spark Fortress\" is discriminating against some of its employees on ethnicity or gender basis.","tags":["code","data-science","hypothesis-testing","explanatory-data-analysis"],"details":"* Data Cleaning \r\n* Exploratory Data Analysis \r\n* Hypothesis Testing","links":[{"article_link":"","code_link":"https://github.com/moaaztaha/Spark-Fortress-Discrimination","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1122,"title":"Machine Learning: Tests and Production","description":"Best practices for testing ML-based systems.","tags":["article","tutorial","e2e-tests","production","unit-tests","testing","systems-design","checklist","tests"],"details":"> \u201cCreating reliable, production-level machine learning systems brings on a host of concerns not found in small toy examples or even large offline research experiments. Testing and monitoring are key considerations for ensuring the production-readiness of an ML system, and for reducing technical debt of ML systems.\u201d - **The ML Test Score: A Rubric for ML Production Readiness and Technical Debt Reduction**","links":[{"article_link":"https://millengustavo.github.io/ml-test-production/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1121,"title":"Motion2Vec","description":"Semi-Supervised Representation Learning from Surgical Videos","tags":["paper","research","tutorial","video","health","computer-vision","motion-estimation","representation-learning","semi-supervised-learning","surgery"],"details":"Learning meaningful visual representations in an embedding space can facilitate generalization in downstream tasks such as action segmentation and imitation. In this paper, we learn a motion-centric representation of surgical video demonstrations by grouping them into action segments/sub-goals/options in a semi-supervised manner. We present Motion2Vec, an algorithm that learns a deep embedding feature space from video observations by minimizing a metric learning loss in a Siamese network: images from the same action segment are pulled together while pushed away from randomly sampled images of other segments, while respecting the temporal ordering of the images. ","links":[{"article_link":"","code_link":"","research_link":"http://www.ajaytanwani.com/docs/Tanwani_Motion2Vec_arxiv_2020.pdf","media_link":"https://www.youtube.com/watch?v=N9A-Yr2Ukx0","dataset_link":"","demo_link":"","other_link":""}]},{"id":1119,"title":"Creating Professional Data Visualzations","description":"Learn how to make professional looking charts, the likes of New York Times, using Python and Altair.","tags":["article","tutorial","visualization","altair"],"details":"","links":[{"article_link":"https://armsp.github.io/covidviz/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1118,"title":"Knowledge Distillation","description":"Distilling dark knowledge of neural networks into smaller student networks. ","tags":["article","tutorial","deep-learning","knowledge-distillation","model-compression"],"details":"","links":[{"article_link":"https://nervanasystems.github.io/distiller/knowledge_distillation.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1117,"title":"Knowledge Distillation with Keras","description":"Discusses the basics of Knowledge Distillation for Neural Nets. ","tags":["article","code","tutorial","deep-learning","knowledge-distillation","model-compression"],"details":"","links":[{"article_link":"https://www.intel.com/content/www/us/en/develop/articles/knowledge-distillation-with-keras.html","code_link":"https://github.com/Ujjwal-9/Knowledge-Distillation","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1115,"title":"Softbot design with WANNS","description":"Soft robots are robots built from highly compliant materials, similar to those found in living organisms. This project explored CPPNs and WANNs to design them","tags":["article","code","research","python","reinforcement-learning","numpy","neuroevolution","alife"],"details":"","links":[{"article_link":"https://joaogui1.netlify.app/post/softbot-design-with-wanns/","code_link":"https://github.com/joaogui1/CPPN-WANNS","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1114,"title":"Reinforcement Learning in JAX","description":"Implementation of interesting Deep Reinforcement Learning Algorithms using JAX based libraries (flax, haiku and rlax) As of now tasks come from OpenAI gym","tags":["code","tutorial","jax","reinforcement-learning"],"details":"","links":[{"article_link":"","code_link":"https://github.com/joaogui1/RL-JAX","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1113,"title":"VAE Explorer","description":"A tool that can be used to explore pre-trained tensorflow VAE models and interpolate between data points. Trained on MNIST and Fashion-MNIST.","tags":["code","tensorflow","tensorflow-js","autoencoders","variational-autoencoders","interactive"],"details":"A tool I created to learn more about tensorflow-js and how run those models in your browser. ","links":[{"article_link":"","code_link":"https://github.com/BioTerran/vae-explorer","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://bioterran.github.io/vae-explorer/"}]},{"id":1112,"title":"Document search engine","description":"NLP based search engine for single page pdf files.","tags":["code","tutorial","tensorflow","natural-language-processing","search","document-search"],"details":"","links":[{"article_link":"","code_link":"https://github.com/Satkarjain/Document-search-engine","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1111,"title":"Movement Pruning: Adaptive Sparsity by Fine-Tuning","description":"We propose the use of movement pruning, a simple, deterministic first-order weight pruning method that is more adaptive to pretrained model fine-tuning.","tags":["code","paper","research","tutorial","huggingface","attention","bert","transformers","fine-tuning","model-compression","natural-language-processing","pruning","sparsity","movement-pruning","adaptive-sparsity","arxiv:2005.07683"],"details":"This page contains information on how to fine-prune pre-trained models such as BERT to obtain extremely sparse models with movement pruning. In contrast to magnitude pruning which selects weights that are far from 0, movement pruning retains weights that are moving away from 0.\r\n\r\nFor more information, we invite you to check out our [paper](https://arxiv.org/abs/2005.07683). You can also have a look at this fun Explain Like I'm Five introductory [slide deck](https://www.slideshare.net/VictorSanh/movement-pruning-explain-like-im-five-234205241).","links":[{"article_link":"","code_link":"https://github.com/huggingface/transformers/tree/master/examples/movement-pruning","research_link":"https://arxiv.org/abs/2005.07683","media_link":"https://www.slideshare.net/VictorSanh/movement-pruning-explain-like-im-five-234205241","dataset_link":"","demo_link":"","other_link":""}]},{"id":1110,"title":"Deep learning Architecture: AlexNet","description":"Explaining network architecture for AlexNet","tags":["article","code","tutorial","tensorflow","deep-learning","computer-vision"],"details":"","links":[{"article_link":"https://prabinnepal.com/alexnet-architecture-explained/","code_link":"https://github.com/nepalprabin/deeplearning-paper-implementation/tree/master/AlexNet","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://prabinnepal.com"}]},{"id":1107,"title":"2nd Place Solution to Ship Identification Hackathon ","description":"The problem statement was to identify the type of ship from photos taken from the survey boats. The hackathon was organized by Analytics Vidhya.","tags":["code","research","fastai","pytorch","computer-vision","image-classification"],"details":"","links":[{"article_link":"","code_link":"https://github.com/salilmishra23/AnalyticsVidhya_GameOfDeepLearning","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1105,"title":"torchdata","description":"Equip PyTorch's Dataset with map, cache etc. (like tf.data)","tags":["code","dataset","pytorch","tensorflow","library","data","cache","map","filter","tensorflow-data"],"details":"* Use `map`, `apply`, `reduce` or `filter` directly on `Dataset` objects\r\n* `cache` data in RAM/disk or via your own method (partial caching supported)\r\n* Full PyTorch's [`Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) and [`IterableDataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset>) support\r\n* General `torchdata.maps` like `Flatten` or `Select`\r\n* Extensible interface (your own cache methods, cache modifiers, maps etc.)\r\n* Useful `torchdata.datasets` classes designed for general tasks (e.g. file reading)\r\n* Support for `torchvision` datasets (e.g. `ImageFolder`, `MNIST`, `CIFAR10`) via `td.datasets.WrapDataset`\r\n* Minimal overhead (single call to `super().__init__()`)\r\n\r\n\r\nSee project's description, examples etc. under this link: [https://github.com/szymonmaszke/torchdata](https://github.com/szymonmaszke/torchdata) ","links":[{"article_link":"","code_link":"https://github.com/szymonmaszke/torchdata","research_link":"","media_link":"https://github.com/szymonmaszke/torchdata#bulb-examples","dataset_link":"","demo_link":"","other_link":"https://szymonmaszke.github.io/torchdata/"}]},{"id":1104,"title":"Convnet Galaxy Morphology Classifier","description":"Classify galaxies from Hubble Tuning Fork using Convnet. ","tags":["code","research","tutorial","tensorflow","convolutional-neural-networks","deep-learning","astronomy","computer-vision","image-classification"],"details":"A simple galaxy classifier using Tensorflow Keras. \r\n\r\nImage from http://astro.physics.uiowa.edu/ITU/labs/foundational-labs/classifying-galaxies/part-1-hubbles-tuning-fork.html\r\n\r\nAs now, the classifier could only returns elliptical, irregular, and spiral type (on develoment for broader datasets).\r\n\r\nNext objective:\r\n* add more galaxy classes.\r\n* Including data from SDSS fits images.\r\n* Augmentation and multi wavelength images.\r\n* Image segmentation. ","links":[{"article_link":"","code_link":"https://github.com/salmanhiro/Galaxy-Zoo-CNN","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1100,"title":"Movie Recommendation System","description":"This is a web app which recommends movies based on their plots found on IMDb.","tags":["code","tutorial","flask","python","natural-language-processing","recommendation-systems","heroku"],"details":"This is an end-to-end data science project. We have used concepts of Natural Language Processing here. The flow of the project is as follows - \r\nWe scraped data from the IMDb website, our features included movie title, genre and summary. This dataset consists of only Hollywood movies. Data pre-processing steps include removing stopwords and lemmatizing the movie summary column, and one hot encoding the genre columns (as there can be multiple genres). We used None-negative Matrix Factorization on the summary column and transformed it accordingly, that was then concatenated with the one-hot encoded genre columns. After this, our recommendations part started, where we print the 10 most similar movies to the movie which the user entered.\r\n\r\nYou can find the recommendation system by clicking on the other tab found on the left.","links":[{"article_link":"","code_link":"https://github.com/mananjhaveri/Movie-Recommendation-System","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://movie-recommendations-system.herokuapp.com/"}]},{"id":1099,"title":"Supervised Contrastive Learning","description":"Implements the ideas presented in Supervised Contrastive Learning (https://arxiv.org/pdf/2004.11362v1.pdf) by Khosla et al. ","tags":["article","code","paper","research","tutorial","tensorflow","deep-learning","representation-learning","contrastive-learning","supervised-contrastive-learning","arxiv:2004.11362"],"details":"In the paper, the authors propose a two stage framework to enhance the performance of image classification systems. \r\n\r\n- In stage 1, we learn embeddings of the images using what they call is supervised contrastive loss.\r\n- In stage 2, we freeze the weights of the base encoder network, and train a single linear layer using the softmax loss. \r\n\r\nThis super simple framework enhances the performance of the previous SoTA image classification systems by good margins. \r\n\r\nThe authors showed that the AutoAugment augmentation policy yielded better results as opposed to the Augmentation Policy proposed in SimCLR. \r\n\r\nFor future work, they author plan to study the effect of augmentation methods like mixUp and CutMix. ","links":[{"article_link":"https://bit.ly/2UVZtm7","code_link":"https://github.com/sayakpaul/Supervised-Contrastive-Learning-in-TensorFlow-2","research_link":"https://arxiv.org/abs/2004.11362","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1095,"title":"Bitcoin Prediction","description":"Predict bitcoin values using Seq2Seq","tags":["code","research","bitcoin-prediction"],"details":"@bitcoin","links":[{"article_link":"","code_link":"https://github.com/parinazfa/Udacity_Capstone_Project","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1094,"title":"Paraphrase Any Question with T5  (Text-To-Text  Transformer)","description":"Given a question, generate paraphrased versions of the question with T5 transformer. Pretrained model and training script provided.","tags":["article","code","research","tutorial","huggingface","pytorch","transformers","natural-language-processing","question-generation","text-generation","t5","paraphrasing"],"details":"Using this program you can generate **paraphrases** of any given question.\r\n\r\n**Input**\r\n\r\nThe input to our program will be any **general question** that you can think of -\r\n\r\n> Which course should I take to get started in data Science?\r\n\r\n**Output**\r\n\r\nThe output will be **paraphrased **versions of the same question. Paraphrasing a question means, you create a new question that expresses the **same meaning** using a **different choice of words**.\r\n\r\n**Paraphrased Questions generated from the T5 Model :**\r\n\r\n> 0: What should I learn to become a data scientist?\r\n> \r\n> 1: How do I get started with data science?\r\n> \r\n> 2: How would you start a data science career?\r\n> \r\n> 3: How can I start learning data science?\r\n> \r\n> 4: How do you get started in data science?\r\n> \r\n> 5: What's the best course for data science?\r\n> \r\n> 6: Which course should I start with for data science?\r\n> \r\n> 7: What courses should I follow to get started in data science?\r\n> \r\n> 8: What degree should be taken by a data scientist?\r\n> \r\n> 9: Which course should I follow to become a Data Scientist?  \r\n\r\n**Pretrained model and training script are provided**\r\n\r\n**Practical use case**\r\n\r\nImagine a middle **school teacher** preparing a **quiz** for the class. Instead of giving a **fixed question** to every student he/she can generate **multiple variants** of a given question and distribute them across students. \r\n\r\nThe school can also **augment** their **question bank** with several variants of a given question using this technique.","links":[{"article_link":"https://towardsdatascience.com/paraphrase-any-question-with-t5-text-to-text-transfer-transformer-pretrained-model-and-cbb9e35f1555?source=friends_link&sk=3bbd1018eba7a0ef68beaac066e5e8e2","code_link":"https://github.com/ramsrigouthamg/Paraphrase-any-question-with-T5-Text-To-Text-Transfer-Transformer-","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1093,"title":"MedicalZoo PyTorch","description":"A pytorch-based deep learning framework for multi-modal 2D/3D medical image segmentation","tags":["article","code","notebook","research","tutorial","pytorch","deep-learning","machine-learning","library","computer-vision","segmentation","medical-image-segmentation","volumetric-segmentation","medical-image-proccessing","reproducible-medical-imaging"],"details":"We strongly believe in open and reproducible deep learning research. Our goal is to implement an open-source medical image segmentation library of state of the art 3D deep neural networks in PyTorch. We also implemented a bunch of data loaders of the most common medical image datasets. This project started as an MSc Thesis and is currently under further development. Although this work was initially focused on 3D multi-modal brain MRI segmentation we are slowly adding more architectures and data-loaders.\r\n\r\nIlias Papastatis and Nikolas Adaloglou","links":[{"article_link":"https://theaisummer.com/medical-image-deep-learning/","code_link":"https://github.com/black0017/MedicalZooPytorch/blob/master/Quickstart_MedicalZoo.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.linkedin.com/in/adaloglou17/"}]},{"id":1086,"title":"House Prices: Advanced Regression Techniques","description":"This project aims to predict the House Prices in Boston, given various features describing the house.","tags":["code","decision-trees","multinomial-regression","random-forests","regression","support-vector-machines","decision-tree","ada-boost"],"details":"","links":[{"article_link":"","code_link":"https://github.com/SINDHUSITA/Boston-House-Prices-Prediction","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1085,"title":"Book on Convex Optimization | Cambridge University Press ","description":"This book by Boyd and Vandenberghe. Copyright in this book is held by Cambridge University Press, who have kindly agreed to keep the book available on web.","tags":["article","research","convex-optimization","cambridge"],"details":"> A MOOC on convex optimization, *CVX101*, was run from 1/21/14 to 3/14/14. If you register for it, you can access all the course materials.\r\n\r\n> More material can be found at the web sites for [EE364A](https://web.stanford.edu/class/ee364a) (Stanford) or [EE236B](http://www.seas.ucla.edu/~vandenbe/ee236b/ee236b.html) (UCLA), and our own web pages. Source code for almost all examples and figures in part 2 of the book is available in [CVX](http://cvxr.com/cvx/) (in the [examples directory](http://cvxr.com/cvx/examples/)), in [CVXOPT](http://cvxopt.org/) (in the book examples directory), and in [CVXPY](http://cvxpy.org/). Source code for examples in Chapters 9, 10, and 11 can be found [here](https://web.stanford.edu/~boyd/cvxbook/cvxbook_examples/).","links":[{"article_link":"https://web.stanford.edu/~boyd/cvxbook/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1084,"title":"Beginner\u2019s guide to Machine Learning Model Deployment","description":"Are you a beginner in the field of machine learning and wondering how to bring your project to live. I'm was in the same situation when I started learning ML. M","tags":["api","article","code","tutorial","flask","machine-learning","production","deployment","beginner"],"details":"","links":[{"article_link":"https://medium.com/analytics-vidhya/beginners-guide-to-model-deployment-dcf3abcdcc4c","code_link":"https://github.com/leelamanikanta/Diabetes-prediction-model-deployment","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1083,"title":"Reverse Image Search","description":"Have you ever wondered how google image search works or How amazon can retrieve products similar to the image that we upload in the app/site? To achieve this ta","tags":["article","code","deep-learning","machine-learning","computer-vision","image-categorization"],"details":"","links":[{"article_link":"https://medium.com/swlh/reverse-image-search-using-resnet-50-f305d735385a","code_link":"https://github.com/leelamanikanta/Reverse_Image_Search","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1082,"title":"Ideal Restaurant Spot Finder","description":"To find ideal spots in the city where food retail stores can be put up, aiming at the demographic, thereby helping the owners of the outlets to earn profits.","tags":["code","notebook","paper","research","matplotlib","machine-learning","clustering","geospatial","data-science","geopy","chloropleth","folium","one-hot-encoding"],"details":"**Business Problem**\r\nCommuters who travel by bus are often in a hurry and are in need of food that can be prepared and consumed fast in order to reach their destination quickly. Foods that attract busy people on the go include egg sandwiches, fries, pizza, burgers,microwaveable or cold prepared meals. The main objective of the project will be to find ideal spots in the city where fast food retail chains can be put up, aiming at the above demographic, thereby helping the owners of the outlets to extract maximum profits out of them.\r\n\r\n**Coordinates of Neighborhoods**\r\nThe latitude and longitude of the neighborhoods are retrieved using geopy library. Geopy locate the coordinates of addresses, using third-party geocoders and other data sources. The geometric location values are then stored into the initial dataframe.\r\n\r\n**Folium**\r\nfolium builds on the data wrangling strengths of the Python ecosystem and the mapping strengths of the leaflet.js library. Manipulate your data in Python, then visualize it in on a\r\nLeaflet map via folium. It enables both the binding of data to a map for choropleth visualizations as well as passing rich vector/raster/HTML visualizations as markers on the map.\r\n\r\n**Conclusion**\r\nAs the middle class population will grow at a rapid rate in the next upcoming years, opening food outlets catered for that section of the society will see a massive increase in footfall, which would lead to a further increase in business.\r\n","links":[{"article_link":"","code_link":"https://github.com/tanishghosh/Coursera_Capstone/blob/master/Final Notebook.ipynb","research_link":"https://github.com/tanishghosh/Coursera_Capstone/blob/master/Applied Data Science Capstone _ Coursera.pdf","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1081,"title":"AI Basketball Analysis","description":"\ud83c\udfc0   AI web app and API to analyze basketball shots and shooting pose. ","tags":["api","code","tutorial","convolutional-neural-networks","sports","computer-vision","pose-estimation","application","r-cnn","coco","basketball","shot-analysis","pose-analysis","open-pose","faster-r-cnn"],"details":"This is an artificial intelligence application built on the concept of object detection. Analyze basketball shots by digging into the data collected from object detection. This project has three main features:\r\n\r\n* shot analysis\r\n* shot detection\r\n* detection API","links":[{"article_link":"","code_link":"https://github.com/chonyy/AI-basketball-analysis","research_link":"","media_link":"https://ai-basketball-analysis.herokuapp.com/","dataset_link":"","demo_link":"","other_link":""}]},{"id":1080,"title":"Dash DETR Detection App","description":"A User Interface for DETR built with Dash. 100% Python.","tags":["code","tutorial","computer-vision","object-detection","segmentation","interactive","plotly","dash","panoptic-segmentation","detr","end-to-end"],"details":"The release of DETR: End-to-End Object Detection with Transformers showed significant improvement in real-time object detection and panoptic segmentation (PS), while greatly simplifying the architecture. As a mean to test the model, we decided to build a simple Dash app that let you experiment and play with the model through a user interface.","links":[{"article_link":"","code_link":"https://github.com/plotly/dash-detr","research_link":"","media_link":"https://dash-gallery.plotly.host/dash-detr/","dataset_link":"","demo_link":"","other_link":""}]},{"id":1079,"title":"Book on Optimization Models and Applications","description":"Freely available book on optimisation methods mainly about constrained optimisation problems","tags":["article","tutorial","optimization","constrained-optimization"],"details":"**I DO NOT HOLD ANY AUTHORITY OF THIS BOOK**. \r\nThis e-book is free, online and authored by L. El Ghaoui, EECS Department, UC Berkeley. It offers an introduction to optimization models and their applications, with emphasis on numerically tractable problems,  such as linear or constrained least-squares optimization.\r\n\r\nThe contents are:\r\n 1. Introduction\r\n 2. Linear Algebra\r\n 3. Convex Models\r\n 4. Duality\r\n 5. Case Studies\r\n Appendix","links":[{"article_link":"http://livebooklabs.com/keeppies/c5a5868ce26b8125","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1078,"title":"Building Footprint Extraction","description":"The project retrieves satellite imagery from Google and performs building footprint extraction using a U-Net. ","tags":["code","tutorial","keras","tensorflow","deep-learning","computer-vision","gis","remote-sensing"],"details":"The main goal is to extract very accurate building polygons from low and medium-resolution satellite imagery. The pipeline is built as follows:\r\n\r\n1. Extract imagery from Google Maps Static API and stitch and georeference into a big mosaic.\r\n\r\n2. Use the trained model to generate building predictions for the complete image\r\n\r\n3. Convert it back to a georeferenced vector file for use in any GIS based application such as Google Earth, ArcGIS or QGIS.","links":[{"article_link":"","code_link":"https://github.com/shubhamgoel27/building_footprint_extraction","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1076,"title":"Adversial Auto Encoder (PyTorch)","description":"Adversial autoencoder, to generate mnist digit.","tags":["code","tutorial","pytorch","autoencoders","adversarial-learning","mnist"],"details":"","links":[{"article_link":"","code_link":"https://github.com/Gaurav927/Adversial_AutoEncoder","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1075,"title":"Zero-Shot Learning for Text Classification","description":"A visual summary of \u201cTrain Once, Test Anywhere\u201d paper for zero-shot text classification","tags":["article","tutorial","natural-language-processing","zero-shot-learning"],"details":"- Introduction to zero-shot learning and how it differs from regular transfer learning\r\n- Explanation of the first paper on zero-shot text classification with visualizations","links":[{"article_link":"https://amitness.com/2020/05/zero-shot-text-classification/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1072,"title":"Novice-AI Music Co-Creation via AI-Steering Tools","description":"Collaborative Convolutional Counterpoint","tags":["code","paper","research","library","music","audio","music-generation"],"details":"Collaborative Convolutional Counterpoint\r\n\r\nBach CoCoCo is an experimental user interface to collaboratively compose counterpoint with an AI agent trained on the chorale canon of the eminent JS Bach. The repo uses a modified tensorflow.js implementation of Coconet by Huang et. al, with a soft-prior-based strategy for tuning the output of the neural network.","links":[{"article_link":"","code_link":"https://github.com/pair-code/cococo","research_link":"https://dl.acm.org/doi/pdf/10.1145/3313831.3376739","media_link":"","dataset_link":"","demo_link":"","other_link":"https://pair-code.github.io/cococo/"}]},{"id":1071,"title":"Music Source Separation in the Waveform Domain","description":"We provide an implementation of Demucs and Conv-Tasnet for music source separation on the MusDB dataset. They can separate drums, bass and vocals from the rest ","tags":["code","paper","research","music"],"details":"We provide an implementation of Demucs and Conv-Tasnet for music source separation on the MusDB dataset. They can separate drums, bass and vocals from the rest with state-of-the-art results, surpassing previous waveform or spectrogram based methods. The architecture and results obtained are detailed in our paper Music Source Separation in the waveform domain.\r\n\r\nDemucs is based on U-Net convolutional architecture inspired by Wave-U-Net and SING, with GLUs, a BiLSTM between the encoder and decoder, specific initialization of weights and transposed convolutions in the decoder.\r\n\r\nConv-Tasnet is a separation model developed for speech which predicts a mask on a learnt over-complete linear representation using a purely convolutional model with stride of 1 and dilated convolutional blocks. We reused the code from the kaituoxu/Conv-TasNet repository and added support for multiple audio channels.","links":[{"article_link":"","code_link":"https://github.com/facebookresearch/demucs","research_link":"https://hal.archives-ouvertes.fr/hal-02379796/document","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1070,"title":"AI Debate Master","description":"Created and deployed a bot made to debate with a human on any\r\ngiven topic. Employed a Doc2Vec model using Gensim library in Python","tags":["code","tutorial","natural-language-processing","sentiment-analysis","conversational-ai","doc2vec"],"details":" By the sound of it, it would seem similar to IBM\u2019s Project Debate, but the implementation differs vastly in it\u2019s nature. The concept remains the same, to put a machine against a human and let them debate on a given topic. This project was implemented in Python.\r\n\r\nThe basic pipeline is as follows:\r\n\r\nIt would have a Speech-To-Text component, through which it would hear the opponent\u2019s argument as well as the announced topic before the preparation phase starts.\r\n\r\nAfter the topic is announced, the bot will use a Google Custom Search Engine(CSE) which has some sources pre-defined to gather data on the given topic, such as Wikipedia, news websites, etc. When links to relevant webpages are searched, separate scrapping methods devised for all the pre-defined sources are put to work, gathering all the articles and texts which would form the corpus for the bot to train on.\r\n\r\nThis corpus is then passed to a Doc2Vec model to get an embedding representation of all the different documents in the corpus. \r\n\r\nAt the same time, the corpus is used to train a Sentiment Analysis model.\r\n\r\nAfter the preparation phase is over, the continuous process for the bot is to listen to the argument of the opponent, assess the sentiment in terms of positivity and negativity as well as it\u2019s context using the embedding that it learned from the training over Doc2Vec model, and based on that select from the corpus, most appropriate argument to counter the opponent. And using a Text-To-Speech component gives the argument in the form of speech.\r\n\r\n\r\nDepending on the system components such as Text-To-Speech and Web Scrapping would take fairly less time and wouldn\u2019t impact the overall performance that much, but the Context Analysis and Sentiment Analysis models would highly impact the overall performance of the model. The choice of using a Doc2Vec model, over a Word2Vec or a TF-IDF model, was based on both the factors of speed as well as accuracy. \r\n\r\n\r\nA Word2Vec model uses one of the two strategies to get to the final word embedding. Skip-gram and Continuous-Bag-of-Words(CBoW) model. Both the models are 2 layered(a hidden embedding layer and an output layer) neural networks. Skip-gram model uses the strategy that, given a certain word it tries to predict nearby words called as context word, and CBoW does the opposite by trying to predict the target word given the context. The output layer uses a softmax activation to generate the probability of a word of being the context/target word for respective models. \r\n\r\n\r\nA Doc2Vec model uses a similar strategy along with the added knowledge that the next word in a context depends on the document/paragraph that it belongs to. For example, the sentence, \u201cMy computer has a lot of ____\u201d, can have the next word as virus/features depending on the entire document in which the sentence exists. So, in addition to the context words, a document token is also passed to the neural network model, and a matrix is maintained for all the documents in the corpus. The document token acts as the missing context to the remaining inputs. \r\n\r\nFor this project, I used the Gensim library, DM(Distributed Memory) Doc2Vec specifically, which is similar to the CBoW model. The document vectors are obtained by training the neural net on the task of inferring a target word based on the context and a context document. \r\n\r\n\r\nLater the knowledge of the embedding so formed is used to find the most similar sentences for the argument. Once we have all the chosen sentences, then using the sentiment analysis component the ones representing opposite sentiment to the argument by the opponent are filtered and collected together to be a presentable counter, and are sent for conversion from text to speech and are finally outputted.\r\n\r\n\r\nThe choice of using a Doc2Vec model was based on the fact that it performs better in terms of accuracy, and it saves time in training. With even a small corpus with just 100 documents of about 500 words, which are separated into paragraphs making the corpus of about 1000 documents, it good fairly good results in terms of speed. The best metric to test the model and tune it as per the results was to put it to work and to give it arguments to manually examine its performance. And after making modifications to it, the one problem that still persists is that the output along with the relevant output still has some unwanted text, as well as sentences that are in second and third person. \r\n\r\n\r\nFor the frontend part, to keep the performance fast, Flask framework was used to convert components such as preparation and argument into simple API calls and keep the frontend separate from the rest of the project and model training in the backend.","links":[{"article_link":"","code_link":"https://github.com/himanshu-dutta/ai-debate-master","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1069,"title":"NLP News Category","description":"The objective of this repository is to create a NLP bot for when you give the robot the headline of the news and a short description it will return the genre.","tags":["code","tutorial","machine-learning","natural-language-processing"],"details":"objectives: the objective of this repository is to create a nlp bot for when you give the robot the headline of the news and a short description it will return the genre of the news so you can automate the process when you post the news in it genre\r\n\r\nalgorithms used:\r\n\r\n1- LogisticRegression,\r\n\r\n2- MultinomialNB\r\n\r\nexperiments:\r\n\r\nat the beginning of the classification results process it was noted that the difference between the two algorithms was small but that the LogisticRegression would be the algorithm that would bring better results, another thing that can be noticed was that the text without stemming brings better results than the text with stemming applied, and also that tf-idf was better than CountVectorize.\r\n\r\nresults: the final accuracy of LogisticRegression model is 0.6018042776914805\r\n\r\nlink of the data set used in this repository: https://www.kaggle.com/rmisra/news-category-dataset\r\n\r\nlink of the raw_data that is used in the nootebook: https://raw.githubusercontent.com/dbstern/kaggle-news-category/master/input/News_Category_Dataset_v2.json","links":[{"article_link":"","code_link":"https://github.com/Eduardosilvafilho/nlp_news_category","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.kaggle.com/rmisra/news-category-dataset"}]},{"id":1068,"title":"Effects of News Sentiments on Stock Predictions","description":"Project is based on the Natural Language Processing technique called Sentiment Analysis. Stock market and news related to it as the subject of analysis.","tags":["code","tutorial","lstm","natural-language-processing","time-series","time-series-forecasting","stocks"],"details":"The project is based on the Natural Language Processing technique called Sentiment Analysis. In this project we chose as stock market and news related to it as our subject of analysis. The abstract of this project is that, we collected news related data for a period of time, and parallelly collected data related to stocks of that period. From the news data, we did an analysis of its polarity, of being positive or negative. And based on that polarity we observed change in daily market because of the news, which earlier wasn\u2019t visible just on the basis of stock data that was fed to the algorithm. Data: Our model comprised of two parts. One was of sentimental analysis and another model was to see its impact on stock market, which was done by a module that comprised of LSTM algorithm and ANN network. The data collection process for both of them were as follows. * For the first model, news data was to be collected. Our first attempt to this was using Twitter tweets data, which we reckoned to collect in a live fashion. For that purpose, we had to use the Twitter API, but since we couldn\u2019t get permission from the site in due time, we didn\u2019t go ahead with it. Next, we aimed at going with news from the world wide web and used another API known as NewsAPI. But we had to drop this as well, the hurdle being, availability of news content through the api. After scrambling the web a little, we found Reddit news data being readily available. And hence our final checkpoint in gathering the data was at Reddit news data. For this process we had to create a \u201cNews Extraction\u201d module from scratch in python (attached in the project files). Our final news related data was top 25 news of the day for a period spanning over about 8 years (1989 days) available on Reddit. * For the other part of data gathering, we had to collect stock related data. Initially it was decided to go with a particular company\u2019s stock data, Reliance Industries Limited to name the one. But since our attempt to collect news from NewsAPI ended in a truffle we resorted to DJIA(Dow Jones Industrial Average) data that was collected through Yahoo Finance. This data comprised of Opening, Closing, High and Low, with that Adjusted Closing price, which is the parameter which actually gets affected by the news of everyday.\r\n\r\nSentimental Analysis Model: For this model we chose to go with a rule-based(lexicon based) model. The reason for choosing this kind of a model was that, news data has words that depend on the context, and can be quite unpredictable. Hence the model needs to be constantly updated of the new words(tokens) that come into picture so as to adapt to the evolvement of the model. The model worked as follows. * For preprocessing part, the news data was as follows: The top 25 news were in different documents. But the data was labelled for the entire day as positive or negative. Hence, we combined the entirety of 25 news in one document. Now we had one document for each day. In totality, we had 1989x25 news documents, and after processing we had 1989x1 news documents.\r\n\r\n* Now, for training, a part of the data was passed through a frequency classifier function, TFIDFVectorizer. This function basically assigns a frequency value to the different tokens present in the entire corpus, as to it appearing in a positive or a negative document of the corpus. With this the preprocessing of the data was done. * A Deep Neural Network was created to pass on the processed frequencies of each token in each document present in the corpus so as to train the DNN to recognize the weightage of the document (probability) of being either positive or negative. This comprised the training part of this module.\r\n\r\n* For testing the part of the data that was unseen to the model was passed on, again ran through the preprocessing steps, and afterwards was passed to the DNN model. The task of the DNN model was to give as output the probability and hence the polarity of the sentence(document) as to being positive or negative, and how positive or negative it relatively is to other news documents the model has yet seen.\r\nStock Prediction Model: This model had three parameters as input, namely, Opening Price, Closing Price and Polarity Score (which was predicted by earlier model). Our main goal was, quantified analysis of stock prediction, with and without the use of sentimental data related to news. This was done through use of different LSTM models and an ANN network which took as parameters, the values predicted by the LSTM models. The steps are as follows: * The input given to the model was the past 60 days Opening and Closing price to predict the upcoming values of the respective, this data was predicted using two different LSTM models. * Sentiment data (scaled and unscaled) were passed on after prediction from previous model. * For the ANN portion, the ANN had two different structures which were as follows: One of them just had opening and closing price of the day as parameters and another one had, along with preceding two, sentiment polarity as well.\r\n* These two models were run and their performances were compared.\r\n\r\nDifference in r2_score before and after intoduction of polarity score of news sentiment\r\n\r\nThe comparitive results of both the models were found to be significantly differing in terms of variation of everyday price. The basic prediction task of the model is to show the significant change in the market, i.e, the relative ups and downs of market in everyday trading. There can be seen a very clear improvement in root-mean-square error of the model with introduction of the sentiment factor. Without the sentiment data, the predictions hardly show much variation, and hence if, for real stock, we wanted to do after hour trading, we wouldn\u2019t actually know what the market variation is. But knowing the variation, we would stand somewhere in terms of knowledge of market going high or low.","links":[{"article_link":"","code_link":"https://github.com/himanshu-dutta/sentiment_analysis_on_stock_news","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1067,"title":"COVID-19 EDA","description":"Performed exploratory analysis on COVID-19 data made\r\navailable by John Hopkins University. Wrote a notebook to explain SIR model and based the pandemic on same.","tags":["code","covid-19","eda"],"details":"Performed exploratory analysis on COVID-19 data made available by John Hopkins University. \r\n\r\n* Wrote a notebook to explain SARS model and modeled the pandemic on the same. \r\n* Employed mathematical models to compare situation in China and India as per their data.","links":[{"article_link":"","code_link":"https://github.com/himanshu-dutta/covid-19","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1064,"title":"One Shot Art","description":"Implemented one shot learning approach to classify paintings according to artists.","tags":["code","tutorial","art","few-shot-learning","one-shot-learning"],"details":"1. Understand Relation Networks\r\n1. Test the model on custom dataset ","links":[{"article_link":"","code_link":"https://github.com/Atharva-Phatak/One-Shot-Art","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1059,"title":"Wheat Detection \ud83c\udf3e","description":"This is a project for detecting and creating bounding box of wheat heads \ud83c\udf3e.","tags":["article","code","deep-learning","machine-learning","computer-vision","object-detection"],"details":"This Project takes an image of wheat and outputs the image with bounding box of wheat heads. The Dataset used is from a Kaggle competition Global Wheat Detection","links":[{"article_link":"https://www.notion.so/shubhamai/Object-Detection-with-Detectron2-a704198684684f5ab93282a0adf0418b","code_link":"https://github.com/Shubhamai/wheat-detection","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.kaggle.com/shubhamai/wheat-detection"}]},{"id":1058,"title":"SmartFeed.ai","description":"NLP Based Article Recommendation System ","tags":["code","flask","python","scikit-learn","latent-dirichlet-allocation","library","natural-language-processing","recommendation-systems"],"details":"# Contents\r\n- **Problem Statement**\r\n- **Introduction**\r\n- **How to use the Service**\r\n- **Components**\r\n- **Recommendation Engine Implementation**\r\n- **Further Improvements**\r\n\r\n<hr>\r\n\r\n# Problem Statement\r\nScarcity of information is equally  bad as Excess of it\r\n\r\nSheer Volume of newsletters which flood our inboxes overwhelms us into not sticking with the habit of reading\r\n\r\nThough there are implicit feedback mechanism on Reading Website Which based on your read-time and others interaction filter out personalized content for you, Wouldn't it be nice to have ubiquitous service/platform where we can explicitly tell a service the type of content their recommendations for us should reflect and have these delivered the very next day\r\n\r\nThis project is an attempt to address it.\r\n\r\n<hr>\r\n\r\n# Introduction\r\nSmartFeed serves users every day with a collection of articles related to topics you have subscribed,(5 Articles per topic),  with the objective to ensure keeping you reading feed interesting and worthwhile by aligning them to user preferences based on the explicit feedback given.\r\n\r\n<hr>\r\n\r\n\r\n\t \r\n# How to use the Service\r\n1. Signup to smartfeed.ai [here](https://smartfeed-ai.herokuapp.com/signup)\r\n\r\n   \r\n\r\n2. Subscribe to the topics,(*Highly recommended to limit it to no more than 3 Topics ,as more than 15 articles a day just feels overwhelming*)\r\n\r\n   \r\n\r\n3. You would be receiving an email with an invitation to join the slack channel(make sure to use the same username used to subscribe), This is the medium chosen to get explicit feedback from you(the user)\r\n![img](https://paper-attachments.dropbox.com/s_C44986F842155EEDF9274ADEA66CC474C9EBFA55B5A44BC9DDB17C60F799EA88_1589905059089_rsz_slack_subs.jpg)\r\n\r\n\r\n\r\n4. Every day you would be receiving your feed as an email in and around 6:30(IST) in the morning from [smartfeed.ai@gmail.com](mailto:smartfeed.ai@gmail.com), which will have your feed of the day, a  300-word Summary and keywords of the corresponding article are intended to assist you in deciding whether to open the article or skip it\r\n\r\n![img](https://paper-attachments.dropbox.com/s_C44986F842155EEDF9274ADEA66CC474C9EBFA55B5A44BC9DDB17C60F799EA88_1589905071506_rsz_email.jpg)\r\n\r\n- If you happen to come across an article which you liked reading and would want your feed to reflect this type of articles(it can be from the feed sent to you  or anywhere on the internet) then you can add the link to \u201cfavored\u201d channel on slack(sounds like quite a hassle to open slack and paste URL but Android makes it pretty handy )\r\n\r\n![img](https://paper-attachments.dropbox.com/s_C44986F842155EEDF9274ADEA66CC474C9EBFA55B5A44BC9DDB17C60F799EA88_1589905080083_pjimage.jpg)\r\n\r\nAnywhere in your phone given slack is downloaded share option can be accessed  from gmail, chrome, WhatsApp\r\n\r\n<hr>\r\n\r\n# Components\r\nThere are 5 components of the system\r\n\r\n* Flask Web-APP \r\n\r\n    * For users to signup and subscribe to related topics\r\n\r\n* Slack Bot \r\n\r\n    * To collect user feedback and push it to the database\r\n\r\n* Scraper \r\n\r\n    * which scrapes medium articles every day for each tag \r\n\r\n* Recommendation Engine\r\n\r\n\t*  It assigns a score for each article scraped and generates \r\n    recommendations based on these scores(Detailed procedure is mentioned below)\r\n\r\n* Feed Sender \r\n\r\n     * which sends the recommendations generated for each \r\n   user to their respective emails \r\n\t \r\n\r\n<hr>\r\n\r\n\r\n# Recommendation Engine Implementation\r\n5 Articles being sent to users are simple not just the Top-5 most similar articles user liked in the past, They have the following characteristics\r\n\r\nArticles are divided based on two factors freshness and similarity\r\n\r\n**Freshness** : \r\n\r\nThere are two categories of articles you get for each tag/topic\r\n\r\n- Archive edition, Its a collection of all articles for a tag from the past two years\r\n\r\n- Daily-edition, its a  is a collection of articles for a tag from the previous day\r\n\r\n**Similarity**  \r\n\r\nBased on the articles user liked in the past, there are two types\r\n\r\n- **Parallel Articles** :  These  articles are the one's which are most similar to the articles you have liked\r\n\r\n- **Perpendicular Articles** : These articles are the one's which are most dissimilar articles(Topic wise) from which you have liked\r\n\r\n\r\nFollowing are the distribution of the number of articles over the categories \r\n\r\n**Archive Edition: 2 articles**\r\n\r\n- 1 Parallel article\r\n- 1 Perpendicular article\r\n\r\n**Daily Edition: 3 articles**\r\n\r\n- 2 Parallel article\r\n- 1 Perpendicular article\r\n\r\n<br>\r\n\r\n\r\n\r\n**Note** The reason the  concept of perpendicular articles exists is to introduce novelty or diversify our exposure to different topics, failing to do so may lead to an echo chamber of preference.\r\n\r\n<br>\r\n\r\n**The underlining concept used resembles Content-Based Filtering, though it can be considered a hybrid approach**\r\n\r\nEach article scrapped is assigned a score, This score is a weighted average of multiple - signals(Semantic similarity and  number of claps ,responses combined ) which indicates how likely user would find the article interesting(readable)\r\n\r\n**Claps and responses**\r\n\r\n- In medium Claps are similar to likes with one major difference, Each user can clap as many times as he/she wants, Which makes it an unreliable as metric to measure popularity because of the pay model of medium to their writers (more about this [here](https://help.medium.com/hc/en-us/articles/213477928-Medium-Rules))\r\n\r\n- Responses which are same as comments(as we know it on other platforms)\r\n\r\nBoth the number of claps and responses are Scaled using MinaxScaler to have a range between 0 to 1 and are combined with a weight of 70% for claps and 30% for comments and the resultant score is called ClapRespScore indicating the popularity of the article\r\n\r\n```\r\nClapRespScore = (total_claps_scaled*0.7 + total_responses_scaled*0.3)\r\n```\r\n\r\n<br>\r\n\r\n**Topic Similarity** \r\n\r\nLDA(Latent Dirichlet Allocation) has been used to extract features from the article\r\n\r\n- Techniques like simple(TF-IDF) and more sophisticated like Doc2Vec were experimented with  but they were not suitable for the given use case\r\n\r\n- LDA on a high level is an unsupervised learning algorithm which for given n topics(as hyperparameter)  tries to estimate the probability distribution of each article over these topics, So for each article, we would be getting a list of n-numbers ranging from 0 to 1, we can consider this as a feature vector\r\n\r\n- Each article would be mapped with a feature vector where each basis vector in it is a probability that this article belongs to this topic, As it is fair to interpret these probability distribution as a vector we can exploit concepts from linear algebra(Like measuring similarity between vectors (articles) using various measures)\r\n\r\n- Cosine Distance is being calculated between the articles to determine their similarity(Though there are other measures such as Nearest Neighbors which uses Euclidean distance. but for our use case of also getting topics which are completely unrelated(perpendicular articles as we call them) cosine would make a lot more sense mathematically)\r\n\r\n<br>\r\n\r\n#### **Combining Cosine similarity(Topic similarity) with ClapRespScore(Popularity Score)**\r\n\r\n<br>\r\n\r\n\r\n**For** **Calculating** **Parallel Articles** (ie: Most similar articles), \r\n\r\n- To obtain the most similar articles to the user's feedback, Following is the combination used\r\n\r\n```\r\nParallel_Article_rank = cosin_sim*0.8+ClapRespScore*0.2\r\n```\r\n\r\n<br>\r\n\r\n**For Calculating Perpendicular Articles** **(Most** **Dissimilar)**\r\n\r\n- Our objective is to get articles that are completely  dissimilar from the one\u2019s user liked(the reason is mentioned above),  For this we can find an article whose feature vector is perpendicular to the user\u2019s liked article.\r\n\r\n- In case you're wondering why perpendicular vector indicate dissimilarity a simple answer would be ,X(Horizontal line)and Y(Vertical) axis are perpendicular to each other, there is no 'verticalness' in the x-axis and horizontal aspect in y-axis which is reflected in the numerical representation of their vectors of [1,0] and [0,1] Representing independence \r\n\r\n- We want articles with cosine distance of zero or close to zero, to obtain this we can simple subtract 1 from actual cosine similarity \r\n\r\n```\r\nPerpend_Article_rank = (1-cosin_sim))*0.8+ClapRespScore*0.2\r\n```\r\n\r\n<hr>\r\n\r\n# **Further Improvements**\r\n\r\n- Currently, Articles are being scraped only from medium, In future other regularly updated RSS feeds can be added\r\n\r\n- Pipeline can be built which periodically analyzes user logs and mines some sought of patterns and trends\r\n\r\n- Given sufficiently large users \r\n\t- based on the logs user's can be clustered and we can use the preferences of  median of each cluster for their respective cluster's recommendations\r\n\t-  Collaborative filtering also could be implemented\r\n\r\n- User conversations on slack channels can be monitored and used in making recommendations(with consent)\r\n\r\n- User Dashboard can be embedded into Web-App summarizing user favored feeds periodically (monthly or weekly)\r\n\r\n- Instead of just using explicit feedback in form of article URL's, user can be allowed to post other form of content(You-tube Search history or web search history) from which latent features can be extracted and transformed to our vector space to enhance recommendations\r\n\r\n- Apart from the accuracy of our LDA model we can track the emails sent to the user to identify his/her relative user interaction with recommended articles, this could be a good KPI(key performance indicator)\r\n","links":[{"article_link":"","code_link":"https://github.com/sai-krishna-msk/SmartFeed.ai","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://smartfeed-ai.herokuapp.com/"}]},{"id":1056,"title":"Font Recognition Using Deep Learning - DeepFont ( Adobe )","description":"DeepFont Paper is a technique created by Adobe.Inc to detect font from images using deep learning . They published their work as a paper for the public .","tags":["article","code","paper","research","tutorial","library","computer-vision","optical-character-recognition","adobe","arxiv:1507.03196"],"details":"Recognize Fonts from Image using Deep Learning.","links":[{"article_link":"https://blogs.adobe.com/adobelife/2015/12/03/adobe-intern-develops-font-recognition-system/","code_link":"https://github.com/robinreni96/Font_Recognition-DeepFont","research_link":"https://arxiv.org/abs/1507.03196","media_link":"https://youtu.be/5eJ3IXYcw3M","dataset_link":"","demo_link":"","other_link":""}]},{"id":1055,"title":"Automatic-Face-Detection-Annotation-and-Preprocessing","description":"Automatically detect , annotate , collect the coordinates , convert to csv and to tfrecord","tags":["code","tutorial","tensorflow","computer-vision","face-detection"],"details":"","links":[{"article_link":"","code_link":"https://github.com/robinreni96/Automatic-Face-Detection-Annotation-and-Preprocessing","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1054,"title":"Setup datascience project with Google Colab and Vscode-server","description":"Connect Google Colab and Vscode-server","tags":["article","tutorial","data-science"],"details":"What if we can connect Google Colab from our local pc terminal, clone GitHub project, add/modify/run scripts/notebooks with vscode-server using Google Colab\u2019s free GPU power, build a model and then publish code into GitHub, then it will be wonderful to get the best of 4 worlds:\r\n\r\n* Jupyter notebook (module testing)\r\n* Google colab\u2019s FREE computing power with GPU\r\n* VScode-server IDE (project management)\r\n* Github (versioning)\r\n\r\nThis blog aims to achieve this goal.","links":[{"article_link":"https://msank00.github.io/blog/2020/02/21/blog_704_DS_setup","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1053,"title":"Kick Assist","description":"An Interactive Dashboard enabling users to make data-driven decisions about their Kickstarter campaign to maximize the probability  for successful funding","tags":["code","flask","machine-learning","random-forests","library","web-services","feature-engineering","feature-importance","interpretability","decision-tree","xgboost","scraping","data-science","hypothesis-testing","dahboard"],"details":"# **Contents**\r\n\r\n1. **Introduction/Context**\r\n2. **Objective**\r\n3. **Domain Knowledge**\r\n4. **Data Source**\r\n5. **Framing into ML Problem**\r\n6. **Methodology and results**\r\n7. **Limitations**\r\n\r\n<hr>\r\n\r\n# Introduction/Context\r\n\r\nKickStarter is a crowd funding platform for ideas and projects of diverse categories such as films, games, and music to art, design, and technology.\r\n\r\nIndividuals/Entrepreneurs  with ideas or products start a campaign by creating a project on the platform explaining what the idea is about\r\n\r\n- Creator must specify a date and goal(amount) when creating a project which are not flexible\r\n\r\n- Creators are allowed to give rewards to Backers(AKA people who donated for the project) of the project based on the amount these rewards can be anything depending on the project mostly it's the product itself which is being donated for(if it's a course then early access to a course or if it's some tech product them limited edition of the product etc.)\r\n\r\n- If the project for some reason is not able to reach the goal amount by the given date then the money collected up until that point is returned back to the backers and the project gets nothing( **all-or-nothing funding model**)\r\n\r\n- So it is more like people bringing the project to life which makes it interesting\r\n\r\n<hr>\r\n\r\n# Objective\r\n\r\nAs discussed above there are a few decisions which creator needs to make when starting the campaign, Which include the following\r\n\r\n- Deciding when to start the campaign(Launch Date)\r\n\r\n- When to set the deadline\r\n\r\n- Goal Amount\r\n\r\n- Deciding the right amount for the rewards\r\n\r\nSince it is **all-or-nothing funding model** decisions creator takes with the above variables play a key role in deciding the success of the project\r\n\r\n**Therefore our objective is to Assist the creator of the campaign in deciding what would be the optimal values for the above 4 features which would maximize the probability of a successful campaign based on certain characteristics of the product**\r\n\r\n<hr>\r\n\r\n# Domain Knowledge\r\n\r\nCondensing most of the content about what goes into a successful campaign can be summarized by the following \r\n\r\n1. Having a well polished landing page with videos and images\r\n2. Interaction with donors(through comment section and others)\r\n3. Marketing and networking as a whole\r\n4. Well planned rewards\r\n5. Feasible duration for the given goal\r\n6. Delivering the rewards without delay\r\n\r\n<hr>\r\n\r\n# Data Source\r\n\r\nA Web Crawler Platform named [Web Robots](https://webrobots.io/) has a few free data projects one of them happens to be kickstarter data, which is scrapped every month of the platform.\r\n\r\nIt provides a bunch of csv files with data loaded as dictionaries(JSON), Following are the features which can be extracted from the source\r\n\r\n- Status(Success or failed)\r\n- Category and Sub Category of the project\r\n- lunch and deadline date\r\n- Author and creator information\r\n- Country of origin and currency to be used for transaction\r\n\r\nand a few other\r\n\r\n<hr>\r\n\r\n# Framing into ML Problem\r\n\r\n- Based on our objective and our data source, there are two kinds of features(variables)\r\n\r\n-  Variables Which are related to our product itself and are fixed, can not be changed for the purpose of increasing the chances of success, variables like category, sub category etc. These variables can not be changed after we decide what our campaign is going to be because they are about the product of the campaign itself, For naming reasons lets call them fixed variables.\r\n\r\n-  One's which are to be decided strategically  and which can(should) be altered if doing so increases our probability of being successfully funded, this type of variables include rewards, goal, deadline , launch date etc., Let's call them flexible variables\r\n\r\n- As the target feature(success or failed) is a categorical feature, it will be a classification problem\r\n\r\n- **Since our objective is not to make predictions about the campaign's success based on the features rather suggesting the optimal features for maximum chances for success, this slight variation in our problem statement demands our Model to be interpretable**\r\n\r\n- **Requirement for Interpretability does not only effect our choice of ML model but it essentially drives our Machine Learning pipeline from preprocessing to model deployment, It mainly effects our feature engineering process, where in we are bound not to make any transformations(like dimensionality reduction) to our variables, Therefore accuracy/performance is the price to pay for interpretability **\r\n\r\n- Model would be served to the end user as an **Interactive dashboard**, Where the creators can tune/adjust both their fixed, flexible variables and visualize not only the probability of success but also, How has each of the flexible variables effected the probability this way creators can adjust those variable's values to the closest plausible value to increase the chances for a successful campaign.\r\n\r\n- A model with 80% accuracy(given balanced dataset) seems to be an acceptable , as it e will be using the model for interpretation not the predictions themselves\r\n\r\n<hr>\r\n\r\n# Methodology and results\r\n\r\n*All the code and a clear procedure is provided* [*here*](https://github.com/sai-krishna-msk/KickAssist/tree/master/notebooks)\r\n\r\n- Extracting the data  from the source mentioned above\r\n\r\n- Exploring the variables and getting the feel of the data.\r\n \r\n- Performed basic cleaning like removed null values(beyond a threshold) and duplicate values.\r\n\r\n- Performed  basic preprocessing(Label Encoding, OneHot Encoding) and modeling\r\n\r\n-   As identified in the Introduction,  features present in the data source are not suffice to full fill our objective because  as identified in the  domain knowledge section,  rewards is an important feature and  there is no feature indicating any measure of rewards in the dataset and section also suggest marketing and networking increases the chances of success,  since we do not have any direct way of extracting that information for each campaign, therefore Scraping is performed on the kickstarter website and following are the features being scrapped from each campaign(200000 total)\r\n\r\n   - Rewards\r\n\r\n   - Number of Campaigns the Creator already had\r\n\r\n   - Number of Campaigns the creator has already funded\r\n\r\n   - When would the rewards be delivered\r\n\r\n- Scrapped data and source data are merged\r\n\r\n- EDA along with Statical tests(t-test, ANOVA) are performed to validate various assumptions and questions,One of the important findings in this process  is data prior to 3-4 years to the current date can be considered  stale as it does not have similar patterns, It not only  helps us reduce our training size by a large factor but also when updating the model each year it need not be trained on aggregated data of all the previous years.\r\n \r\n- As discussed previously due to the interpretability  constraints, Transformations such as dimensionality reduction(PCA) and polynomial interactions can not  be performed,  but clear distinction has been made between our features as fixed and flexible,   Fixed variables are not required to be  interpretable according to our business objective therefore, Feature encoding is used on categorical variables of flexible type, Helmert is used as \r\n our categorical vairbale have a natural sense of order to them which is ideal case for helmert encoding\r\n![img](https://github.com/sai-krishna-msk/KickAssist/blob/master/images//model.PNG?raw=true)\r\n\r\n\r\n- At this stage modeling is performed, as the relationships are clearly not linear as observed in EDA, Random Forest and XGBoost are trained  and XGBoost is chosen as it produces highest accuracy of 86% and is compatible with the tool being used for interpretation\r\n\r\n\r\n-   ELI5 package is used for interpreting the XGBoost Model, Which makes use of LIME algorithm, This implementation suits our objective as it generates feature contribution for each instance predicted, Allowing creators/users to experiment with various values of \r\nvariables \r\n![img](https://github.com/sai-krishna-msk/KickAssist/blob/master/images/eli5.png?raw=true)\r\n\r\n\r\n- Model(XGBoost) and ELI5 tool are  wrapped into an api so that it can serve dashboard built using plotly, App is  hosted on heroku for creators to validate and tune their decisions to maximize the probability of success, Dashboard can we accessed [here](https://kick-assist.herokuapp.com/)\r\n\r\n![img](https://github.com/sai-krishna-msk/KickAssist/blob/master/images/dashboard.png?raw=true)\r\n\r\n<hr>\r\n\r\n# Limitations\r\n\r\n-  Content such as videos and images used to present the project compel the donors to some degree and it's signal is not being taken into consideration\r\n-  Experience of the person hosting the project (how many backed and how many pledged) is not being taken into consideration which gives us an insight into, how well the creator can market is product \r\n-  Utility and relevance of the overall product is not being quantified ","links":[{"article_link":"","code_link":"https://github.com/sai-krishna-msk/KickAssist","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://kickassist.herokuapp.com/"}]},{"id":1052,"title":"Simple Python API for ML project","description":"A simple script to create machine learning API in python.","tags":["api","code","flask","python","machine-learning","library"],"details":"* A simple script to create machine learning API in python which includes a separate template for creating preprocessing, training, and prediction API along with logging and basic error handling facility.\r\n* The preprocessing, training, prediction module consists of dummy code which you can fill as per your wish.\r\n","links":[{"article_link":"","code_link":"https://github.com/msank00/api_in_python","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1049,"title":"Prediction of Eye State Using KNN algorithm","description":"Prediction of Eye State Using KNN algorithm with Walk-forward validation.","tags":["code","tutorial","scikit-learn","machine-learning","k-nearest-neighbors","data-science","walk-forward-validation"],"details":"","links":[{"article_link":"","code_link":"https://github.com/vikashov/Prediction-of-Eye-State-Using-KNN.git","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1047,"title":"Sparse Neural Networks (2/N): Understanding GPU Performance","description":"NVIDIA Ampere A100 introduces fine-grained structured sparsity.","tags":["article","tutorial","convolutional-neural-networks","gpu","sparsity","sparse-neural-networks"],"details":"\u2022\u00a0Part 1: https://medium.com/huggingface/is-the-future-of-neural-networks-sparse-an-introduction-1-n-d03923ecbd70\r\n\u2022\u00a0Part 2: https://medium.com/huggingface/sparse-neural-networks-2-n-gpu-performance-b8bc9ce950fca","links":[{"article_link":"https://medium.com/huggingface/sparse-neural-networks-2-n-gpu-performance-b8bc9ce950fca","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1046,"title":"Illustrated Guide to Transformers","description":"A component by component breakdown analysis.","tags":["article","code","tutorial","transformers","natural-language-processing","illustrated"],"details":"The Transformer model is the evolution of the encoder-decoder architecture, proposed in the paper Attention is All You Need. While encoder-decoder architecture has been relying on recurrent neural networks (RNNs) to extract sequential information, the Transformer doesn\u2019t use RNN. Transformer based models have primarily replaced LSTM, and it has been proved to be superior in quality for many sequence-to-sequence problems.","links":[{"article_link":"https://towardsdatascience.com/illustrated-guide-to-transformer-cf6969ffa067","code_link":"https://gist.github.com/jinglescode/a1751ee6c2bec1c61ca4833ce8c9b98e","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1045,"title":"Illustrated Guide to Transformers: Step by Step Explanation","description":"In this post, we\u2019ll focus on the one paper that started it all, \u201cAttention is all you need\u201d.","tags":["article","tutorial","video","attention","transformers","natural-language-processing","illustrated"],"details":"","links":[{"article_link":"https://www.michaelphi.com/illustrated-guide-to-transformers/","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=4Bdc55j80l8","dataset_link":"","demo_link":"","other_link":""}]},{"id":1044,"title":"Stop Installing Tensorflow using pip for performance sake!","description":"Stop installing Tensorflow using pip! Use conda instead.","tags":["article","tutorial","tensorflow","performance","pip","conda"],"details":"","links":[{"article_link":"https://www.michaelphi.com/stop-installing-tensorflow-using-pip-for-performance-sake/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1043,"title":"NBoost","description":"\u26a1 NBoost is a scalable, search-engine-boosting platform for developing and deploying state-of-the-art models to improve the relevance of search results.","tags":["code","library","search","elastic-search","nboost"],"details":"","links":[{"article_link":"","code_link":"https://github.com/koursaros-ai/nboost","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1040,"title":"Empirical study of Face Hallucination using limited data","description":"Deep Generative models that leverage cycle consistent adversarial networks to perform super-resolution on limited set of unaligned face images.","tags":["code","generative-adversarial-networks","cycle-consistent-adversarial-networks","image-superresolution","face-hallucination"],"details":"I explore literature from style transfer to understand distribution of noise in low resolution images. Empirically tested why some of the standard models in practice under performed in limited and unsupervised data setting (only 300 image pairs). The aim of this study is to explore different possibilities for performing super-resolution (SR) on limited noisy face images. I did not have ground truth high resolution images corresponding to each low resolution image that the existing SR networks are expected to match. However, my attempts to resolve the issue of unaligned HR-LR pairs by learning a noise transfer model, yielded networks that underperform. ","links":[{"article_link":"","code_link":"https://github.com/nprithviraj24/face-hallucination","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.cs.ait.ac.th/xmlui/handle/123456789/968"}]},{"id":1037,"title":"Satyrn","description":"A command-line based alternative to Jupyter notebooks. Built around backend multithreading and will eventually have GUI implemented.","tags":["code","notebook","python","library","jupyter","command-line","cli"],"details":"Create a viable alternative to Jupyter notebooks that implements backend mutlithreading and eventually a beginner-friendly GUI.","links":[{"article_link":"","code_link":"https://github.com/CharlesAverill/satyrn","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1036,"title":"KeraStroke","description":"Experimental generalization-improvement techniques for Keras","tags":["article","code","keras","python"],"details":"Improve model generalization during training by randomizing certain weights at certain times.","links":[{"article_link":"https://medium.com/dair-ai/nlp-newsletter-illustrated-gnn-guide-textvqa-and-textcaps-kerastroke-syfertext-torchlayers-482da18a8cd9","code_link":"https://github.com/CharlesAverill/kerastroke","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1035,"title":"Zero Shot Topic Classification","description":"Bart with a classification head trained on MNLI.","tags":["article","code","notebook","paper","research","tutorial","natural-language-processing","topic-modeling","zero-shot-learning","bart","text-processing","topic-classification","mnli","arxiv:1909.00161"],"details":"Recently, the NLP science community has begun to pay increasing attention to zero-shot and few-shot applications, such as in the paper from OpenAI introducing GPT-3. This demo shows how \ud83e\udd17 Transformers can be used for zero-shot topic classification, the task of predicting a topic that the model has not been trained on.","links":[{"article_link":"https://joeddav.github.io/blog/2020/05/29/ZSL.html","code_link":"https://colab.research.google.com/github/joeddav/blog/blob/master/_notebooks/2020-05-29-ZSL.ipynb","research_link":"https://arxiv.org/abs/1909.00161","media_link":"https://huggingface.co/zero-shot/","dataset_link":"","demo_link":"","other_link":""}]},{"id":1032,"title":"Pix2Pix with Tf-js","description":"Implementation of web friendly ML models using TensorFlow.js. pix2pix, face segmentation, fast style transfer and many more ...","tags":["tutorial","tensorflow","tensorflow-js","generative-adversarial-networks","computer-vision","segmentation","pix2pix"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://zaidalyafeai.github.io/pix2pix/celeb.html","dataset_link":"","demo_link":"","other_link":""}]},{"id":1031,"title":"Swift4TF","description":"A set of notebooks explaining swift for tensorflow optimized to run in Google Collaboratory.","tags":["code","tutorial","swift","tensorflow"],"details":"","links":[{"article_link":"","code_link":"https://github.com/zaidalyafeai/Swift4TF","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1030,"title":"AttentioNN","description":"All about attention in neural networks. Soft attention, attention maps, local and global attention and multi-head attention.","tags":["code","tensorflow","attention","multi-head-attention","attention-maps"],"details":"","links":[{"article_link":"","code_link":"https://github.com/zaidalyafeai/AttentioNN","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1029,"title":"Notebooks","description":"Machine learning notebooks in different subjects optimized to run in google collaboratory","tags":["code","machine-learning"],"details":"","links":[{"article_link":"","code_link":"https://github.com/zaidalyafeai/Notebooks","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1028,"title":"ARBML","description":"Implementation of many Arabic NLP and ML projects. Providing real time experience using many interfaces like web, command line and notebooks.","tags":["code","tutorial","library","natural-language-processing"],"details":"","links":[{"article_link":"","code_link":"https://github.com/zaidalyafeai/ARBML","research_link":"","media_link":"https://zaidalyafeai.github.io/ARBML/Interfaces/Website/","dataset_link":"","demo_link":"","other_link":"https://twitter.com/arabicml2"}]},{"id":1027,"title":"Don't Touch Your Face!","description":"Using machine learning to detect when you touch your face, to keep yourself and your surroundings safe of coronavirus.","tags":["code","tutorial","tensorflow-js","transfer-learning","covid19"],"details":"Don't Touch Your Face is a web application designed to help you break the habit of touching your face, to keep yourself and your surroundings safe of coronavirus. It uses machine learning to detect and alert when you're touching your face, collects and displays stats and shows tips and facts about coronavirus to keep you informed.","links":[{"article_link":"","code_link":"https://github.com/mfarberbrodsky/dont-touch-your-face","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.donttouchyourface.ml/"}]},{"id":1026,"title":"Lyrics-Based Music Genre Classifier","description":"Classify the genre (Rock, Pop, Hip-Hop, Not Available, Metal, Other, Country, Jazz, Electronic, R&B, Indie, Folk) of the song by its lyrics.","tags":["code","tutorial","deep-learning","machine-learning","natural-language-processing","text-classification"],"details":"Classify the genre (Rock, Pop, Hip-Hop, Not Available, Metal, Other, Country, Jazz, Electronic, R&B, Indie, Folk) of the song by its lyrics. Music genre classification, especially using lyrics alone, remains a challenging topic in Music Information Retrieval. The accuracy about the model is not good enough considering there is too much factors that effect song's genre instead of using song's lyrics only. ","links":[{"article_link":"","code_link":"https://github.com/penguinwang96825/Lyrics_Based_Multiclass_Classifier_for-Predicting_Song_Genre","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1025,"title":"Forex Prediction","description":"Using neural networks to predict movement of forex direction.","tags":["code","tutorial","deep-learning","machine-learning","finance","natural-language-processing","forex"],"details":"In the course of the last two decades the size and range of machine learning have grown enormously, and it is now widely recognized that they have many uses both in research and industries. One such use is the application of machine learning to finance-related studies. For instance, the foreign exchange market (Forex) is a global decentralized or over-the-counter market for the trading of currencies. In several companies, the main goal is to correctly predict the direction of future price movements of currency pairs. However, anticipating where the exchange rate is going on a consistent basis is far from easy, as dozens of different factors impact the forex market. In the past, investors and traders came up with a range of tools in trying to predict forex movements. In this study, I utilized different cutting-edge models to predict the direction of forex movement based on daily financial news headlines.","links":[{"article_link":"","code_link":"https://github.com/penguinwang96825/Forex-Prediction","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1024,"title":"Sentiment Classification for UtaPass & KKBOX Reviews","description":"Text classification for reviews of UtaPass & KKBOX using different deep learning models.","tags":["code","tutorial","deep-learning","machine-learning","natural-language-processing","text-classification"],"details":"This sentiment classification task is based on reviews data of UtaPass and KKBOX from Google Play platform. As a KKStreamer at KKBOX, I become more interested in Natural Language Processing, especially text classification. First, I crawled the text data using web crawler technique with BeautifulSoup and Selenium. Second, I developed several different neural network architectures, including simple-RNN, LSTM, GRU, and CNN, to name but a few, to detect the polarity of reviews from customers.","links":[{"article_link":"","code_link":"https://github.com/penguinwang96825/Text_Classifier_for_UtaPass_and_KKBOX","research_link":"","media_link":"https://github.com/penguinwang96825/Streamlit_for_Polarity_Classification","dataset_link":"","demo_link":"","other_link":""}]},{"id":1023,"title":"Gradient Descent  Algorithm","description":"This is a linear regression Machine Learning model based on the \"chirps dataset\" which has 'X' variable as number of chirps by a cricket and 'Y' as temperature.","tags":["article","code","linear-regression","regression","gradient-boosting"],"details":"In this example we're using the count of chirps per minute as the independent varible to then predict the dependent variable, temperature. In short, we're using a little data science to make ourselves a cricket thermometer.\r\n\r\nThis relationship is assumed to be linear and thus we use Gradient Descent Algorithm to reduce the loss function. I have given the code for python's function which directly does this job and an equivalent hand-written code for the same","links":[{"article_link":"https://ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html","code_link":"https://github.com/BalajiG2000/Gradient_descent_ML","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1022,"title":"The designer - gpt2 bot that talks about UX Design","description":"This twitter profile spits out thoughts on design and development. Trained with hundreds of Books on UX design and Front end development, it has opinions.","tags":["article","gpt2","transformers","natural-language-processing","npl"],"details":"1- See if it possible for gpt2 to understand and generate coherent thoughts on technical topics.\r\n2 - Poke fun at \"Thought leaders\" on design and show that it is easy to create twitter hot takes","links":[{"article_link":"https://twitter.com/des_iner","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1021,"title":"Sentiment analysis ","description":"Sentiment analysis by combining three dataset amazon,yelp, IMDb reviews to train our,model to classify if a comment is negative or positive denoted by 0 and 1.","tags":["code","tutorial","natural-language-processing"],"details":"","links":[{"article_link":"","code_link":"https://github.com/vortexash/sentiment-Analysis","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1020,"title":"Applying Modern Best Practices to Autoencoders","description":"This project applies best modern practices found in other areas of image research to autoencoders. Comparing models from other areas of image research.","tags":["article","code","research","autoencoders","computer-vision","dimensionality-reduction","image-classification","image-clustering","image-compression"],"details":"- Apply modern best practices from other areas of research such as super-resolution to autoencoders.\r\n- Look at methods which provide the best results in a low number of epochs making the results accessible to all.","links":[{"article_link":"https://henriwoodcock.github.io/2020/04/05/Autoencoders-best-practices/","code_link":"https://github.com/henriwoodcock/Applying-Modern-Best-Practices-to-Autoencoders","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1019,"title":"Visual Object Tracking using Adaptive Correlation Filters","description":"This article gives step by step tutorial with code on understanding MOSSE tracking algorithm","tags":["article","tutorial","computer-vision","object-tracking"],"details":"The objective of this article is to understand how correlation filters could be used for object tracking","links":[{"article_link":"https://nthere.dev/2017/09/14/Visual-Object-Tracking-using-Adaptive-Correlation-Filters/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1018,"title":"GOTURN-PyTorch","description":"PyTorch implementation of \"Learning to Track at 100 FPS with Deep Regression Networks\"","tags":["code","computer-vision","object-tracking"],"details":"This repository contains the reimplementation of GOTURN in PyTorch. If you are interested in the following, you should consider using this repository\r\n\r\nUnderstand different moving parts of the GOTURN algorithm, independently through code.\r\n\r\nPlug and play with different parts of the pipeline such as data, network, optimizers, cost functions.","links":[{"article_link":"","code_link":"https://github.com/nrupatunga/goturn-pytorch","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1013,"title":"Guided Uncertainty-Aware Policy Optimization","description":"Combining learning and model-based strategies for sample-efficient policy learning.","tags":["paper","research","video","reinforcement-learning","robotics","uncertainty","policy-optimization","arxiv:2005.10872 "],"details":"We combine the strengths of model-based methods with the flexibility of learning-based methods to obtain a general method that is able to overcome inaccuracies in the robotics perception/actuation pipeline, while requiring minimal interactions with the environment. ","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2005.10872 ","media_link":"https://www.youtube.com/watch?v=_RGBMdiSMgw","dataset_link":"","demo_link":"","other_link":""}]},{"id":1012,"title":"How We Scaled Bert To Serve 1+ Billion Daily Requests on CPUs","description":"The nitty-gritty optimizations needed to get our Bert PyTorch models from our labs to productio.","tags":["article","tutorial","pytorch","attention","bert","transformers","natural-language-processing","production","cpu","efficiency","roblox"],"details":"","links":[{"article_link":"https://medium.com/roblox-tech-blog/how-we-scaled-bert-to-serve-1-billion-daily-requests-on-cpus-d99be090db26","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1011,"title":"ML in Production - Deployment Series","description":"A multi-part blog series on deploying machine learning models in an automated, reproducible, and auditable manner.","tags":["article","tutorial","production","guide"],"details":"* [Guide 01: What Does it Mean to Deploy a Machine Learning Model?](https://mlinproduction.com/what-does-it-mean-to-deploy-a-machine-learning-model-deployment-series-01/) - What does it even mean to \"deploy a model?\" How does deployment fit into the machine learning process? What factors should you take into consideration when deciding how to deploy?\r\n* [Guide 02: Software Interfaces for Machine Learning Deployment](https://mlinproduction.com/software-interfaces-for-machine-learning-deployment-deployment-series-02/) - Deployment is considerably easier when you\u2019re working with the right interfaces. Doubly important when you\u2019re using models across different frameworks and languages. So what\u2019s the right interface to make deployment easier?\r\n* [Guide 03: Batch Inference for Machine Learning Deployment](https://mlinproduction.com/batch-inference-for-machine-learning-deployment-deployment-series-03/) - If you can precompute and cache predictions in batch, DO IT! It\u2019s much easier than deploying and maintaining APIs and other near real time infrastructure. Here\u2019s how to do batch inference.\r\n* [Guide 04: The Challenges of Online Inference](https://mlinproduction.com/the-challenges-of-online-inference-deployment-series-04/) - But when you need predictions in real time, you need online inference. There are many gotchas in online inference: you need to query data from multiple sources in real time, you\u2019ll need A/B testing, you need rollout strategies\u2026\r\n* [Guide 05: Online Inference for ML Deployment](https://mlinproduction.com/online-inference-for-ml-deployment-deployment-series-05/) - If after learning about those challenges you decide you still need online inference, bless your heart. There are a lot of posts on Flask APIs, but that\u2019s the easiest part. You need versioning, autoscaling, and the ability to A/B test models.\r\n* [Guide 06: Model Registries for ML Deployment](https://mlinproduction.com/model-registries-for-ml-deployment-deployment-series-06/) - Where do you store all these trained models? Where do you track metadata and lineage? How do you retrieve models at inference time? That\u2019s where you\u2019ll need a model registry.\r\n* [Guide 07: Test-Driven Machine Learning Development](https://mlinproduction.com/testing-machine-learning-models-deployment-series-07/) - It\u2019s not enough to use aggregate metrics to understand model performance. You need to know how the model does on sub-slices of data. You need machine learning unit tests.\r\n* [Guide 08: A/B Testing Machine Learning Models](https://mlinproduction.com/ab-test-ml-models-deployment-series-08/) - Just because a model passes its unit tests, doesn\u2019t mean it will move the product metrics. The only way to establish causality is through online validation. Like any other feature, models need to be A/B tested.\r\n","links":[{"article_link":"https://mlinproduction.com/deploying-machine-learning-models/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1010,"title":"GPT-3: Language Models are Few-Shot Learners","description":"We show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior SOTA.","tags":["article","code","research","tutorial","gpt","transformers","language-modeling","natural-language-processing","gpt-3"],"details":"GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans.","links":[{"article_link":"https://twitter.com/nottombrown/status/1266188687219384320","code_link":"https://github.com/openai/gpt-3","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1009,"title":"Train ALBERT for NLP with TensorFlow on Amazon SageMaker","description":"To train BERT in 1 hour, we efficiently scaled out to 2,048 NVIDIA V100 GPUs by improving the underlying infrastructure, network, and ML framework. ","tags":["article","code","tutorial","aws","tensorflow","attention","bert","transformers","training","natural-language-processing","sagemaker","albert"],"details":"","links":[{"article_link":"https://aws.amazon.com/blogs/machine-learning/train-albert-for-natural-language-processing-with-tensorflow-on-amazon-sagemaker/","code_link":"https://github.com/aws-samples/deep-learning-models/tree/master/models/nlp/albert","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1008,"title":"face mask detection ","description":"detects whether a person wearing a mask or not","tags":["code","research","tutorial","video","css","flask","html","python","tensorflow","deep-learning","library","computer-vision","transfer-learning"],"details":"speed detection\r\nhigh fps\r\nhigh accuracy","links":[{"article_link":"","code_link":"https://github.com/sumanth13131/Hack-Covid","research_link":"","media_link":"https://www.youtube.com/watch?v=Vn0ELuglnKE","dataset_link":"","demo_link":"","other_link":""}]},{"id":1007,"title":"Humour.ai : Language Model that can crack Jokes","description":"A Language model that can make you laugh. Humour.ai model tries to\r\ncomplete a sentence in a humourous way given some input words. ","tags":["code","huggingface","gpt2","transformers","language-modeling","natural-language-processing"],"details":"A Language model that can make you laugh. Humour.ai model tries to\r\ncomplete a sentence in a humourous way given some input words. Trained using Open-AI's GPT-2 and on 40,000 scrapped reddit jokes, It gives hilarious results even on data it has never seen before .","links":[{"article_link":"","code_link":"https://github.com/tanulsingh/Humour.ai-Language-model-that-can-crack-Jokes","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1005,"title":"Traffic Sign Detection","description":"Detecting traffic sign images using GSTRB dataset.","tags":["code","tutorial","python","scikit-learn","open-cv","template-matching"],"details":"1. Gives an introduction to a world of image recognition.\r\n2. Understanding to connect model building to end-to-end pipeline.\r\n3. Understanding of computer vision techniques","links":[{"article_link":"","code_link":"https://github.com/prakass1/detect-traffic-signs","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"http://benchmark.ini.rub.de/?section=gtsrb&subsection=news"}]},{"id":1004,"title":"Why initialization is important? ","description":"A small blog post explaining the importance of weight initialization in Neural Networks ","tags":["article","tutorial","deep-learning","machine-learning","weight-initialization","eigen-value","eigen-vectors"],"details":"- Learn about the importance of weight initialization in neural networks.\r\n- Connection with Eigenvalues and Eigenvectors.","links":[{"article_link":"https://shreyans92.github.io/2020-04-13-Weigh-Initialization/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1003,"title":"Exploratory Data Analysis using stack overflow data","description":"Data Visualization and simple EDA to produce insights for business insights using powerful graphing libraries like plotly.","tags":["article","code","research","data-science","exploratory-data-analysis"],"details":"","links":[{"article_link":"https://towardsdatascience.com/what-happens-to-developers-in-2020-5bdb59e09f84","code_link":"https://github.com/pr2tik1/developer-insights","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1002,"title":"yolov5,yolov3,yolov4 -> tensorRT","description":"The project is the encapsulation of nvidia official yolo-tensorrt implementation. And you must have the trained yolo model(.weights) and .cfg file from the dark","tags":["code","library","tensorrt","yolov4","jetson-nano","yolo-v3","darknet","ubuntu","yolov4-tiny","yolov3-tiny","win10","l4t","jetson-nx","yolov5"],"details":"![](https://github.com/enazoe/yolo-tensorrt/blob/master/configs/yolo-trt.png)","links":[{"article_link":"","code_link":"https://github.com/enazoe/yolo-tensorrt","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1001,"title":"TabNet : Attentive Interpretable Tabular Learning","description":"PyTorch implementation of TabNet paper.","tags":["article","code","paper","research","pytorch","attention","library","interpretability","tabular-data","tabnet","arxiv:1908.07442"],"details":"This is a PyTorch implementation of Tabnet (Arik, S. O., & Pfister, T. (2019). [TabNet: Attentive Interpretable Tabular Learning](https://arxiv.org/pdf/1908.07442.pdf).","links":[{"article_link":"","code_link":"https://github.com/dreamquark-ai/tabnet","research_link":"https://arxiv.org/abs/1908.07442","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1000,"title":"CMU LTI Low Resource NLP Bootcamp 2020","description":"A low-resource natural language and speech processing bootcamp held by the Carnegie Mellon University Language Technologies Institute in May 2020.","tags":["code","course","tutorial","video","natural-language-processing","low-resource"],"details":"","links":[{"article_link":"","code_link":"https://github.com/neubig/lowresource-nlp-bootcamp-2020","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":999,"title":"MediaPipe","description":"Simplest way for researchers and developers to build world-class ML solutions and applications for mobile, edge, cloud and the web. ","tags":["code","library","3d","computer-vision","face-detection","object-detection","segmentation","hand-tracking","mediapipe"],"details":"ML Solutions in MediaPipe:\r\n\r\n- Face Detection (web demo)\r\n- Face Mesh\r\n- Hand Detection\r\n- Hand Tracking (web demo)\r\n- Multi-hand Tracking\r\n- Hair Segmentation (web demo)\r\n- Object Detection\r\n- Object Detection and Tracking\r\n- Objectron: 3D Object Detection and Tracking\r\n- AutoFlip: Intelligent Video Reframing\r\n- KNIFT: Template Matching with Neural Image Features","links":[{"article_link":"","code_link":"https://github.com/google/mediapipe","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":998,"title":"ML Cheatsheets","description":"Set of illustrated Deep Learning cheatsheets covering the content of the CS 230 class","tags":["tutorial","machine-learning","guides","cheatsheets"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://stanford.edu/~shervine/teaching/"}]},{"id":997,"title":"AutoSweep: Recovering 3D Editable Objects from a Single Photo","description":"Fully automatic framework for extracting editable 3D objects directly from a single photograph.","tags":["article","paper","research","3d","computer-vision","autosweep","object-generation","arxiv:2005.13312"],"details":"","links":[{"article_link":"https://chenxin.tech/AutoSweep.html","code_link":"","research_link":"https://arxiv.org/abs/2005.13312","media_link":"https://chenxin.tech/files/Paper/TVCG2018_AutoSweep/AutoSweep_TVCG2018_video.mp4","dataset_link":"","demo_link":"","other_link":""}]},{"id":994,"title":"Large SVDs - Dask + CuPy + Zarr + Genomics","description":"Using Dask to perform Singular Value Decomposition on large datasets","tags":["article","code","video","genomics","cupy","dask","singular-value-decomposition","zarr"],"details":"","links":[{"article_link":"https://blog.dask.org/2020/05/13/large-svds","code_link":"https://github.com/dask/dask","research_link":"","media_link":"https://www.youtube.com/watch?v=6hmt1gARqp0","dataset_link":"","demo_link":"","other_link":""}]},{"id":993,"title":"DETR: End-to-End Object Detection with Transformers","description":"A new method that views object detection as a direct set prediction problem. ","tags":["article","code","notebook","paper","research","tutorial","transformers","computer-vision","natural-language-processing","object-detection","segmentation","panoptic-segmentation","arxiv:2005.12872"],"details":"Our approach streamlines the detection pipeline, effectively removing the need for many hand-designed components like a non-maximum suppression procedure or anchor generation that explicitly encode our prior knowledge about the task. ","links":[{"article_link":"https://ai.facebook.com/blog/end-to-end-object-detection-with-transformers","code_link":"https://github.com/facebookresearch/detr","research_link":"https://arxiv.org/abs/2005.12872","media_link":"","dataset_link":"","demo_link":"","other_link":"https://colab.research.google.com/drive/1rPm0-UrWHpJJRX9PsNb5SpzZiUlMh7wm"}]},{"id":992,"title":"Identifying the Number of Open Ion Channels with HMMs","description":"A write-up on how we almost won the \u201cUniversity of Liverpool \u2014 Ion Switching\u201d Kaggle competition using Hidden Markov Models.","tags":["article","tutorial","hidden-markov-models","biology","kaggle","ion-channels"],"details":"","links":[{"article_link":"https://towardsdatascience.com/identifying-the-number-of-open-ion-channels-with-hidden-markov-models-334fab86fc85","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":991,"title":"NLP Viewer \ud83e\udd17","description":"A simple website for browsing popular NLP datasets.","tags":["huggingface","library","natural-language-processing","streamlit","datasets"],"details":"A simple website for browsing SQuAD, MNLI, IMDB, SST, Yelp, drop, CommonsenseQA, billsum, CoQA, BoolQ, Jeopardy, RACE, SCAN, Super Glue, qangaroo, winogrande, CFQ, BLIMP, MLQA, opinosis, hellaswag, ...","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://huggingface.co/nlp/viewer/","dataset_link":"","demo_link":"","other_link":""}]},{"id":990,"title":"Solving Optimization Problems with JAX","description":"JAX can be used to solve a range of simple to complex optimization problems with matrix methods.","tags":["article","notebook","paper","research","tutorial","jax","xla","autograd","optimization"],"details":"JAX essentially augments the numpy library to create a nouvelle library with Autograd, Vector Mapping (vmap), Just In Time compilation (JIT), all compiled with Accelerated Linear Algebra (XLA) with Tensor processing unit (TPU) support and much more. With all of these features, problems that depend on linear algebra and matrix methods can be solved more efficiently. The purpose of this article is to show that indeed, these features can be used to solve a range of simple to complex optimization problems with matrix methods and to provide an intuitive understanding of the mathematics and implementation behind the code.","links":[{"article_link":"https://github.com/mazy1998/Solving-Optimization-Problems-with-JAX/blob/master/JaxOptimization.ipynb","code_link":"","research_link":"https://github.com/mazy1998/Solving-Optimization-Problems-with-JAX/blob/master/Opitimization_with_jax.pdf","media_link":"","dataset_link":"","demo_link":"","other_link":"https://medium.com/swlh/solving-optimization-problems-with-jax-98376508bd4f"}]},{"id":989,"title":"NLP for Developers: Shrinking Transformers | Rasa","description":"In this video, Rasa Senior Developer Advocate Rachael will talk about different approaches to make transformer models smaller.","tags":["tutorial","video","transformers","model-compression","natural-language-processing","pruning","quantization","distillation"],"details":"- \"A Primer in BERTology: What we know about how BERT works\" by Anna Rogers, Olga Kovaleva, Anna Rumshisky https://arxiv.org/abs/2002.12327\r\n- Paper reading video, part 1: https://www.youtube.com/watch?v=lmeDD2PKlxg&list=PL75e0qA87dlFvomavOFBIX6S9IvtGAXjM\r\n- Paper reading video, part 2: https://www.youtube.com/watch?v=5d1s85TG_eY\r\n- \"Rasa Algorithm Whiteboard: Attention 4 - Transformers\"  https://www.youtube.com/watch?v=EXNBy8G43MM","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=hU6lu15uA-o","dataset_link":"","demo_link":"","other_link":"https://www.youtube.com/watch?v=hU6lu15uA-o&list=PL75e0qA87dlFJiNMeKltWImhQxfFwaxvv"}]},{"id":987,"title":"Zero To One For NLP","description":"A collection of all resources for learning NLP","tags":["article","tutorial","deep-learning","natural-language-processing","natural-language-understanding"],"details":"","links":[{"article_link":"https://medium.com/modern-nlp/nlp-metablog-a-blog-of-blogs-693e3a8f1e0c?source=friends_link&sk=82ead7d8edc8870f96652c7411ac9d7a","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":986,"title":"Neural Topological SLAM for Visual Navigation","description":"Topological representations for space that effectively leverage semantics and afford approximate geometric reasoning.","tags":["article","paper","research","video","computer-vision","robotics","visual-navigation","cvpr-2020","slam","topology"],"details":"This paper studies the problem of image-goal navigation which involves navigating to the location indicated by a goal image in a novel previously unseen environment. To tackle this problem, we design topological representations for space that effectively leverage semantics and afford approximate geometric reasoning. At the heart of our representations are nodes with associated semantic features, that are interconnected using coarse geometric information. We describe supervised learning-based algorithms that can build, maintain and use such representations under noisy actuation.","links":[{"article_link":"https://www.cs.cmu.edu/~dchaplot/projects/neural-topological-slam.html","code_link":"","research_link":"http://www.cs.cmu.edu/~dchaplot/papers/cvpr20_neural_topological_slam.pdf","media_link":"https://www.youtube.com/watch?v=GEghE1dXTdY&feature=youtu.be","dataset_link":"","demo_link":"","other_link":"https://www.cs.cmu.edu/~dchaplot/talks/CVPR20_Neural_Topological_SLAM.pdf"}]},{"id":985,"title":"Translate RegEx in Natural Language Using Deep Learning","description":"A complete tutorial and code on how to build a model able to translate RegEx into natural language.","tags":["article","code","notebook","tutorial","deep-learning","library","regex","ml-on-code","machine-learning-on-code","regular-expression"],"details":"1. Present the data\r\n2.  Seq2Seq model setting and training\r\n3. Analyzing the result","links":[{"article_link":"https://medium.com/codist-ai/generating-natural-language-description-of-regex-using-deep-learning-679248a95dab","code_link":"https://colab.research.google.com/drive/1QibOifIJQB2tfLyy_mmw8N9LpchDWnIz","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":984,"title":"Tree-hugger","description":"Tree-hugger is a Python library to automate code mining. It is meant to be language-agnostic, extendable and high-level.","tags":["article","code","library","ml-on-code","code-mining","machine-learning-on-code"],"details":"\ud83c\udfc6 With a single API call, [tree-hugger](https://github.com/autosoft-dev/tree-hugger) enables you to mine source code accross 5 languages: \r\n\r\n* Python, \r\n* PHP, \r\n* Java\r\n* JavaScript\r\n* C++\r\n\r\n\ud83d\udcda Read the [docs]( https://lnkd.in/dgkiiQg)\r\n\r\n\ud83d\udd25 Build your own dataset of code in seconds (e.g. Code Search Net, Py150...)\r\n\r\nLibrary access \u25b6 [https://pypi.org/project/tree-hugger/](https://github.com/autosoft-dev/tree-hugger/blob/master/tree-hugger%20schema.PNG?raw=true)\r\n\r\n\r\n![tree-hugger-code-mining-schema](https://raw.githubusercontent.com/autosoft-dev/tree-hugger/master/tree-hugger%20schema.PNG)\r\n\r\n","links":[{"article_link":"https://medium.com/codist-ai/introducing-tree-hugger-source-code-mining-for-human-b5fcd31bef55?source=collection_home---6------0-----------------------","code_link":"https://github.com/autosoft-dev/tree-hugger","research_link":"","media_link":"https://github.com/autosoft-dev/tree-hugger/blob/master/tree-hugger schema.PNG?raw=true","dataset_link":"","demo_link":"","other_link":""}]},{"id":983,"title":"Telecom delinquency model","description":"Created 6 deliquency models based on logistic regression, SVM, KNN, Naive bayes,Decision tree and Random forest models and reported the results.","tags":["code","python","scikit-learn","machine-learning","classification","model-selection","hyperparameter-optimization"],"details":"","links":[{"article_link":"","code_link":"https://github.com/Aravindh-Gowtham/Delinquency-telecom-model","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":982,"title":"How to write Web apps using simple Python for Data Scientists?","description":"So, are we doomed to learn web frameworks? Or to call our developer friend for silly doubts in the middle of the night?\r\nThis is where StreamLit comes in and del","tags":["article","code","tutorial","flask","web-design","streamlit","data-science"],"details":"","links":[{"article_link":"https://towardsdatascience.com/how-to-write-web-apps-using-simple-python-for-data-scientists-a227a1a01582","code_link":"https://github.com/MLWhiz/data_science_blogs/tree/master/streamlit_football_demo","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":981,"title":"Applications of MCMC for Cryptography and Optimization","description":"This post is about understanding MCMC Methods with the help of some Computer Science problems.","tags":["article","code","tutorial","stochastic-optimization","datascience","mcmc"],"details":"","links":[{"article_link":"https://towardsdatascience.com/applications-of-mcmc-for-cryptography-and-optimization-1f99222b7132","code_link":"https://github.com/MLWhiz/data_science_blogs/tree/master/MCMCApplications","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":980,"title":"Super-BPD for Fast Image Segmentation","description":"We propose direction-based super-BPD, an alternative to superpixel, for fast generic image segmentation, achieving state-of-the-art real-time result.","tags":["code","paper","research","tutorial","computer-vision","segmentation","cvpr-2020","super-pixel","super-pizel"],"details":"In this paper, we propose a fast image segmentation method based on a novel super boundary-to-pixel direction (super-BPD) and a customized segmentation algorithm with super-BPD. Precisely, we define BPD on each pixel as a two-dimensional unit vector pointing from its nearest boundary to the pixel.","links":[{"article_link":"","code_link":"https://github.com/JianqiangWan/Super-BPD","research_link":"https://donglaiw.github.io/paper/2020_cvpr_super_bpd.pdf","media_link":"https://drive.google.com/file/d/1OdfkelacNMmcp3STVyGzPql-Z21Efxqk/view","dataset_link":"","demo_link":"","other_link":""}]},{"id":979,"title":"Taxi Demand Prediction NewYorkCity","description":"Predict the number of pickups as accurately as possible for each region in a 10 -min interval.","tags":["article","code","notebook","tutorial","python","time-series","time-series-forecasting"],"details":"1. At any time interval \u2018T\u2019 , Location you have to estimate/forecast number of pickups as accurately as possible for the end user.","links":[{"article_link":"https://medium.com/@balaramkolluru/taxi-demand-prediction-newyorkcity-9a8e44b72c16","code_link":"https://github.com/balaramkolluru/-Machine-learning-and-Deep-Learning/blob/master/NYC.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":978,"title":"TensorFlow.js - Gesture Controlled 2048","description":"Gesture Controlled 2048 built with TensorFlow.js","tags":["code","tutorial","tensorflow","tensorflow-js","video-games","computer-vision","gesture-recognition"],"details":"","links":[{"article_link":"","code_link":"https://github.com/jithurjacob/tensorflowjs-gesture-controlled-2048","research_link":"","media_link":"https://youtu.be/L0iSFf0VExQ","dataset_link":"","demo_link":"","other_link":""}]},{"id":975,"title":"Self-Supervised Learning -- UC Berkeley Spring 2020","description":"Lecture on self-supervised learning from CS294-158-SP20: Deep Unsupervised Learning.","tags":["code","course","notebook","video","self-supervised-learning","unsupervised-learning","berkeley"],"details":"","links":[{"article_link":"","code_link":"https://github.com/rll/deepul/blob/master/demos/lecture7_selfsupervised_demos.ipynb","research_link":"","media_link":"https://www.youtube.com/watch?v=dMUes74-nYY","dataset_link":"","demo_link":"","other_link":""}]},{"id":974,"title":"PixelLib","description":"Pixellib is a library for performing segmentation of images. ","tags":["code","library","computer-vision","semantic-segmentation","segmentation","instance-segmentation"],"details":"It supports the two major types of image segmentation:\r\n\r\n* Semantic segmentation\r\n* Instance segmentation\r\n* You can implement both semantic and instance segmentation with few lines of code.","links":[{"article_link":"","code_link":"https://github.com/ayoolaolafenwa/PixelLib","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://pixellib.readthedocs.io/en/latest/"}]},{"id":972,"title":"Next Word Prediction","description":"Using transformers to predict next word and predict <mask> word.","tags":["code","tutorial","transformers","language-modeling","natural-language-processing"],"details":"Simple application using transformers models to predict next word or a masked word in a sentence. The purpose is to demo and compare the main models available up to date.","links":[{"article_link":"","code_link":"https://github.com/renatoviolin/next_word_prediction","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":970,"title":"Job Classification","description":"Job Classification done using Techniques of NLP and ML.\r\n\r\nDataset used from Kaggle of Indeeed job posting.","tags":["code","natural-language-processing","supervised-learning"],"details":"","links":[{"article_link":"","code_link":"https://github.com/pbisaria007/Job-Classification","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":968,"title":"Self Supervised Representation Learning in NLP","description":"An overview of self-supervised pretext tasks in Natural Language Processing","tags":["article","tutorial","natural-language-processing","representation-learning","self-supervised-learning"],"details":"- Understand how self-supervised methods are applied to learn from raw text corpus without explicit labels\r\n- Know about papers that implement this ideas","links":[{"article_link":"https://amitness.com/2020/05/self-supervised-learning-nlp/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":966,"title":"Building an Intelligent Twitter Bot","description":"The volume of information going through Twitter per day makes it one of the best platforms to get information on any subject of interest. ","tags":["article","code","notebook","paper","research","tutorial","natural-language-processing","text-classification"],"details":"","links":[{"article_link":"https://medium.com/swlh/how-i-built-an-intelligent-twitter-bot-a7e5ea18f918?source=friends_link&sk=b4bc3d91dbcbeffdecd081050ea90028","code_link":"https://colab.research.google.com/drive/1cNGoYn-jk3y2hAz8JcZvXtvAtBu-6sgJ?usp=sharing","research_link":"https://hubofco.de/uploads/Machine%20Learning%20Approach%20To%20Tweet%20Spam%20Detection.pdf","media_link":"","dataset_link":"","demo_link":"","other_link":"https://github.com/abiodunjames/building-intelligent-twitter-bot-post"}]},{"id":965,"title":"GANs in Computer Vision : An article review series ","description":"An article series where we review the most important research papers on GANs from 2015 to today.  6 articles,  20 papers, 20000 words","tags":["article","tutorial","deep-learning","generative-adversarial-networks","computer-vision","generation","unsupervised-learning"],"details":"-  Introduction to Generative Learning\r\n-  Conditional image and object generation\r\n- Advanced criteria, game theory perspectives and incremental training\r\n- 2K image and video synthesis, and large-scale class-conditional image generation \r\n- Self-supervised adversarial training and high-resolution image synthesis with style incorporation","links":[{"article_link":"https://theaisummer.com/gan-computer-vision/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":964,"title":"Neural Network Intelligence (NNI)","description":"NNI is a lightweight but powerful toolkit to help users automate Feature Engineering, Neural Architecture Search, Hyperparameter Tuning and Model Compression.","tags":["code","library","automl","feature-engineering","model-compression","hyperparameter-optimization","neural-architecture-search","auto-tuning"],"details":"The tool manages automated machine learning (AutoML) experiments, dispatches and runs experiments' trial jobs generated by tuning algorithms to search the best neural architecture and/or hyper-parameters in different training environments like Local Machine, Remote Servers, OpenPAI, Kubeflow, FrameworkController on K8S (AKS etc.), DLWorkspace (aka. DLTS) and other cloud options.","links":[{"article_link":"","code_link":"https://github.com/microsoft/nni","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://nni.readthedocs.io/en/latest/"}]},{"id":963,"title":"Build your first data warehouse with Airflow on GCP","description":"What are the steps in building a data warehouse? What cloud technology should you use? How to use Airflow to orchestrate your pipeline?","tags":["article","code","tutorial","production","airflow","google-cloud-platforms","data-warehouse"],"details":"In this project, we will build a data warehouse on Google Cloud Platform that will help answer common business questions as well as powering dashboards. You will experience first hand how to build a DAG to achieve a common data engineering task: extract data from sources, load to a data sink, transform and model the data for business consumption.\r\n\r\nBackground on AirFlow: https://tuanchris.com/blog/2020-05-02-getting-started-with-airflow-locally-and-remotely/","links":[{"article_link":"https://tuanchris.com/blog/2020-05-23-build-your-first-data-warehouse-with-airflow-on-gcp/","code_link":"https://github.com/tuanchris/cloud-data-lake","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://tuanchris.com/blog/2020-05-02-getting-started-with-airflow-locally-and-remotely/"}]},{"id":962,"title":"Basic ML Algorithms from scratch.","description":"Implement basic Machine Learning Algorithms from scratch in python.","tags":["article","code","tutorial","python","machine-learning","library","natural-language-processing"],"details":"**Motivation:**\r\n\r\n1) Create a resource for someone who wants to learn by implementing things.\r\n\r\n2) Improve my understanding by implementing algorithms from scratch.\r\n\r\n**Algorithms Implemented**\r\n\r\n*  Bag of Words\r\n* Naive Bayes with Laplace Smooting\r\n* K Nearest Neighbour (Standard and Weighted)\r\n\r\n** To be Implemented**\r\n\r\n* Linear Regression\r\n* Logistic Regression\r\n* Evaluation metrics\r\n* K-fold cross validation\r\n* And a couple more \r\n\r\n","links":[{"article_link":"https://faizan-e-mustafa.github.io/scratch//","code_link":"https://github.com/Faizan-E-Mustafa/scratch","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":961,"title":"How to Build Robust Embeddings for Visual Similarity Tasks","description":"This repository I package a bunch of tips and tricks to efficiently train deep learning models in computer vision","tags":["article","code","pytorch","deep-learning","computer-vision","embeddings","metric-learning","triplet-loss"],"details":"- build  an efficient image representation for similarity tasks\r\n- organize a robust training pipeline\r\n- succeed in a data science competition","links":[{"article_link":"https://towardsdatascience.com/a-hackers-guide-to-efficiently-train-deep-learning-models-b2cccbd1bc0a","code_link":"https://github.com/ahmedbesbes/whales-classification","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":960,"title":"Neural ODE Explained","description":"Explains \"Neural Ordinary Differential Equations\", a very interesting idea came out in NIPS 2018.","tags":["article","code","tutorial","recurrent-neural-networks","differential-equation","neural-ode","ordinary-differential-equations"],"details":"1. Clear description of a reletively unconventional Neural ODE\r\n2. Understanding the reletion between DiffEqs and RNNs.","links":[{"article_link":"https://dasayan05.github.io/blog-tut/2020/03/20/neural-ode.html","code_link":"https://github.com/dasayan05/neuralode-pytorch","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":959,"title":"An Introduction to Bayes' Theorem","description":"This blog post introduces the reader to one of the most important concept in probability theory -  Bayes' Theorem","tags":["article","tutorial","bayesian-deep-learning","probabaility-and-statistics"],"details":"1. The aim of this blog is that reader has an understanding of Bayes' Theorem after reading it.\r\n2. If you are looking for refresher on Bayes' Theorem before diving into bayesian deep learning, then this blog can serve you well.","links":[{"article_link":"https://abhimanyu08.github.io/blog/probability-theory/2020/03/23/final.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":958,"title":"Machine Learning for Facies Classification of North Sea Well Logs","description":"The dataset is provided by GEOLINK in the Google Drive Public geoscience Data","tags":["code","machine-learning"],"details":"","links":[{"article_link":"","code_link":"https://github.com/yohanesnuwara/open-geoscience-repository/tree/master/geolink-northsea","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":957,"title":"Colbert AI","description":"Colbert AI is a Deep Learning Language Model that generates text in the style of Stephen Colbert's famous monologues.","tags":["article","code","huggingface","transformers","language-modeling","natural-language-processing"],"details":"","links":[{"article_link":"https://medium.com/@iamabbas/mimicking-stephen-colberts-humor-using-ai-a0f9b59009d5","code_link":"https://github.com/NextTechLabAP/Colbert-AI","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":956,"title":"FIFA-19 analysis and prediction","description":"Data visualisation and prediction of the overall score of a player using various linear regression algorithms, ensembling algorithms, and a neural network.","tags":["code","tutorial","feed-forward-neural-networks","regression","feature-selection"],"details":"To identify the important features for regression and learn about the various linear regression algorithms.","links":[{"article_link":"","code_link":"https://github.com/Hastin10/FIFA-19-analysis-and-prediction","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":955,"title":"Open Geoscience Computing Repository","description":"Open geoscience computing of open geoscience datasets available in open databases from Google Drive, SEG Wiki, and US DoE Geothermal Data Repository OpenEi","tags":["code","research","machine-learning","energy","geology","oil"],"details":"This repo offers tutorials on how to access open geoscience databases directly into Google Colab and how to perform computation on that open datasets. ","links":[{"article_link":"","code_link":"https://github.com/yohanesnuwara/open-geoscience-repository","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":954,"title":"How to Train Your Neural Net","description":"Deep learning for various tasks in the domains of Computer Vision, Natural Language Processing, Time Series Forecasting using PyTorch 1.0+.","tags":["article","code","research","tutorial","python","pytorch","deep-learning","classification","computer-vision","domain-adaptation","image-classification","model-compression","named-entity-recognition","natural-language-processing","pruning","text-classification","time-series"],"details":"","links":[{"article_link":"https://medium.com/tag/akshaj-wields-pytorch","code_link":"https://github.com/theairbend3r/how-to-train-your-neural-net","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":953,"title":"Cross-entropy for Classification","description":"Usages of cross-entropy for binary classification, multi-class classification, and multi-label classification.","tags":["article","tutorial","classification","cross-entropy","multi-class","multi-label"],"details":"\u2022\u00a0Cross-entropy \u2014 the general formula, used for calculating loss among two probability vectors. The more we are away from our target, the more the error grows \u2014 similar idea to square error.\r\n\r\n* Multi-class classification \u2014 we use multi-class cross-entropy \u2014 a specific case of cross-entropy where the target is a one-hot encoded vector. It can be computed with the cross-entropy formula but can be simplified.\r\n\r\n\u2022\u00a0Binary classification \u2014 we use binary cross-entropy \u2014 a specific case of cross-entropy where our target is 0 or 1. It can be computed with the cross-entropy formula if we convert the target to a one-hot vector like [0,1] or [1,0] and the predictions respectively. We can compute it even without this conversion, with the simplified formula.","links":[{"article_link":"https://medium.com/@martinekvlastimil95/cross-entropy-for-classification-d98e7f974451?source=friends_link&sk=eb2bc32cf64f8aa885238657bc13536b","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":952,"title":"Face Mask Detector","description":"A simple Streamlit frontend for face mask detection in images using a pre-trained Keras CNN model + OpenCV and model interpretability.","tags":["code","tutorial","keras","convolutional-neural-networks","computer-vision","interpretability","object-detection","opencv","streamlit","face-mask"],"details":"This example has been implemented as part of my evaluation of the Streamlit framework. It uses OpenCV to detect faces in the input images and a CNN as mask/no-mask binary classifier applied to the face ROI. The Deep Learning model currently used has the architecture suggested by Adrian Rosebrock here and has been trained using this image data set. The trained model has been shared in this repo. The face detector algorithm comes from here: the Caffe model and its descriptor are into the face_detector directory.","links":[{"article_link":"","code_link":"https://github.com/virtualramblas/streamlit-face-mask-detector","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":951,"title":"YoloV3 implementation in keras and tensorflow 2.2","description":"YoloV3 Real Time Object Detector in tensorflow 2.2.","tags":["code","tutorial","keras","tensorflow","computer-vision","object-detection","yolo","yolo-v3"],"details":"yolov3-keras-tf2 is an implementation of yolov3 (you only look once) which is is a state-of-the-art, real-time object detection system that is extremely fast and accurate.","links":[{"article_link":"","code_link":"https://github.com/emadboctorx/yolov3-keras-tf2","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":950,"title":"Sound Event Detection in Synthetic Domestic Environment","description":"We present a comparative analysis of the performance of state-of-the-art sound event detection system and study the robustness to noise and signal degradation. ","tags":["paper","research","audio","audio-classification","audio-tagging","sound"],"details":"We present a comparative analysis of the performance of state-of-the-art sound event detection systems.   In particular,  we study therobustness of the systems to noise and signal degradation, which isknown  to  impact  model  generalization.   Our  analysis  is  based  onthe results of task 4 of the DCASE 2019 challenge, where submit-ted systems were evaluated on, in addition to real-world recordings,a series of synthetic soundscapes that allow us to carefully controlfor different soundscape characteristics. Our results show that whileoverall systems exhibit significant improvements compared to previ-ous work, they still suffer from biases that could prevent them fromgeneralizing to real-world scenarios.","links":[{"article_link":"","code_link":"","research_link":"https://hal.inria.fr/hal-02355573/document","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":949,"title":"Generative Adversarial Networks for Outlier Detection ","description":"PyTorch implementation of a GAN architecture for the problem of outlier detection.","tags":["article","code","paper","research","pytorch","generative-adversarial-networks","anomaly-detection","outlier-detection","arxiv:1809.10816"],"details":"In this article, I will give an introduction to generative adversarial networks and the mathematics behind. Then I will use the Single-Objective Generative Adversarial Active Learning (SO-GAAL) model that was proposed in 2019, to solve a problem of outlier detection. ","links":[{"article_link":"https://qarchli.github.io/2020-04-12-gans-for-outlier-detection/","code_link":"https://github.com/qarchli/pytorch-gan-for-outlier-detection","research_link":"https://arxiv.org/abs/1809.10816","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":948,"title":"Plant Disease Detection","description":"This website help you to detect disease in your plant\ud83c\udf33 based to the plant's leaf\ud83c\udf43 image","tags":["article","code","machine-learning","environment","computer-vision","streamlit"],"details":"This project takes a apple plant leaf image and predicts that is the plant leaf is healthy or not using Machine learning and Computer Vision.","links":[{"article_link":"https://medium.com/@Shubhamai/from-getting-dataset-to-model-in-production-part-1-9b8c75a342b8","code_link":"https://github.com/Shubhamai/plant-disease-detection","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://rocky-mountain-81944.herokuapp.com/"}]},{"id":947,"title":"Self Driving Car","description":"This project is a demonstration of a working model of self driving car \ud83d\ude97\ud83d\ude97 identifying and following lanes using powerful computer vision \ud83d\udd76\ud83d\udd76 algorithms.","tags":["article","code","autonomous-vehicles","computer-vision"],"details":"Self drining car are the cars which drive by itself without any human feedback. One of the big company that is making very best self driving car is Tesla.\r\nSelf driving cars are the future cars and the one of the top inventions for mankind. Self driving cars can save millions of lives which get wasted due to road accidents.\r\n\r\nThere are a lot of things which are been controlled by self driving cars like steering , brakes, gears and the car takes a lot of sensors (especially lidar) and camera to operate and drive on lanes and other stuffs like stop on red signal, following lanes etc.\r\n\r\nSo, i got the idea and I also want to increase my skills of computer vision, so i think to make a self driving car model with raspberri pi and camera \ud83d\ude03\ud83d\ude03.","links":[{"article_link":"https://shubhamai.github.io/self-driving-car/","code_link":"https://github.com/Shubhamai/self-driving-car","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":946,"title":"Replicating Airbnb's Amenity Detection (documentary series)","description":"Airbnb's engineering team shared an article on how they used computer vision to detection amenities in photos. It read like a recipe so I replicated it.","tags":["article","code","tutorial","video","business","project-management","computer-vision","detectron2"],"details":"The goal: beat (or at least replicate) Airbnb's amenity detection (detecting key household items in images), publish all the code and have the model accessible in a demo app someone can use on their phone.\r\n\r\nThe full solution ended up being: data collected from Open Images, modelled with Detectron2, front-end application built with Streamlit and deployed using Docker, Google Container Registry and Google App Engine.\r\n\r\nI documented the entire journey day-by-day in Notion along with weekly YouTube videos discussing progress, open-sourced all code and built a tutorial in Colab where you can use my trained model (see the links).","links":[{"article_link":"https://www.mrdbourke.com/airbnb-amenity-detection","code_link":"https://github.com/mrdbourke/airbnb-amenity-detection/","research_link":"","media_link":"https://www.youtube.com/playlist?list=PL6vjgQ2-qJFeMrZ0sBjmnUBZNX9xaqKuM","dataset_link":"","demo_link":"","other_link":"https://dbourke.link/airbnb42days"}]},{"id":945,"title":"Migrating from OS.PATH to PATHLIB Module in Python","description":"Learn how to use the modern pathlib module to perform tasks you have been using os.path for.","tags":["article","tutorial","python","program-development"],"details":"","links":[{"article_link":"https://amitness.com/2019/12/migrating-to-pathlib/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":944,"title":"Math Symbols Explained with Python","description":"Learn the meaning behind mathematical symbols used in Machine Learning using your knowledge of Python.","tags":["article","tutorial","python"],"details":"- Understand common notations in research papers using its equivalent code in Python","links":[{"article_link":"https://amitness.com/2019/08/math-for-programmers/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":943,"title":"Transfer Learning in NLP with Tensorflow Hub and Keras","description":"Learn how to integrate and finetune tensorflow-hub modules in Tensorflow 2.0","tags":["article","tutorial","keras","tensorflow","natural-language-processing","transfer-learning","tf-hub"],"details":"- Learn how a combination of Keras and Tensor Hub can yield to quick prototyping in NLP","links":[{"article_link":"https://amitness.com/2020/02/tensorflow-hub-for-transfer-learning/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":942,"title":"Keras: The Next Five Years by Fran\u0107ois Chollet","description":"Keras: the next five years. Model training from simple -- e.g. http://model.fit() for simple experiments -- to arbitrarily flexible, e.g. custom training loops.","tags":["presentation","tutorial","video","keras","tensorflow","francois-chollet","matroid"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=HBqCpWldPII","dataset_link":"","demo_link":"","other_link":""}]},{"id":941,"title":"BiT: Exploring Large-Scale Pre-training for Compute","description":"We are excited to share the best BiT models pre-trained on public datasets, along with code in TF2, Jax, and PyTorch. ","tags":["article","code","tutorial","pytorch","tensorflow","computer-vision","object-detection","pretraining","models","tf-hub","bit"],"details":"Even though this pre-training works reasonably well in practice, it still falls short of the ability to both quickly grasp new concepts and understand them in different contexts. In a similar spirit to how BERT and T5 have shown advances in the language domain, we believe that large-scale pre-training can advance the performance of computer vision models.","links":[{"article_link":"https://ai.googleblog.com/2020/05/open-sourcing-bit-exploring-large-scale.html","code_link":"https://tfhub.dev/google/collections/bit/1","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":940,"title":"TAO: A Large-Scale Benchmark for Tracking Any Object","description":"A diverse dataset for Tracking Any Object (TAO) consisting of 2,907 high resolution videos, captured in diverse environments, which are half a minute long on ","tags":["article","dataset","paper","research","video","computer-vision","object-tracking","benchmark","tao","video-tracking","arxiv:2005.10356"],"details":"Importantly, we adopt a bottom-up approach for discovering a large vocabulary of 833 categories, an order of magnitude more than prior tracking benchmarks. To this end, we ask annotators to label objects that move at any point in the video, and give names to them post factum. Our vocabulary is both significantly larger and qualitatively different from existing tracking datasets.","links":[{"article_link":"http://taodataset.org/","code_link":"","research_link":"https://arxiv.org/abs/2005.10356","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":939,"title":"Time Series Classification Using Deep Learning","description":"In this article, I will introduce you to a new package called timeseries for fastai2 that I lately developed. ","tags":["article","code","tutorial","fastai","library","time-series"],"details":"The timeseries package allows you to train a Neural Network (NN) model in order to classify both univariate and multivariate time series using the powerful fastai2 library and achieve State Of The Art (SOTA) results.\r\n\r\nThe key objectives of this series of articles are:\r\n\r\n* Introduce you to time series classification using Deep Learning,\r\n* Show you a step by step how this package was built using fastai2 library,\r\n* Introduce you to some key concepts of the fastai2 library such as Datasets, DataLoaders, DataBlock, Transform, etc.","links":[{"article_link":"https://ai-fast-track.github.io/blog/timeseries/2020/05/21/time-series-using-deep-learning-part-1.html","code_link":"https://github.com/ai-fast-track/timeseries","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://ai-fast-track.github.io/timeseries/"}]},{"id":938,"title":"Content and Style Disentanglement for Artistic Style Transfer","description":"Hi-Res style transfer and interpolation between styles","tags":["code","paper","research","video","deep-learning","computer-vision","style-transfer"],"details":"","links":[{"article_link":"","code_link":"https://github.com/CompVis/content-style-disentangled-ST","research_link":"http://openaccess.thecvf.com/content_ICCV_2019/papers/Kotovenko_Content_and_Style_Disentanglement_for_Artistic_Style_Transfer_ICCV_2019_paper.pdf","media_link":"https://youtu.be/KN_WTcQBUsU","dataset_link":"","demo_link":"","other_link":"https://www.youtube.com/playlist?list=PLPXplX5Y1SzGOxo22bqZjV1V-_LgcmLnT"}]},{"id":937,"title":"In Model Extraction, Don\u2019t Just Ask \u2018How?\u2019: Ask \u2018Why?\u2019","description":"Designing an effective extraction attack requires that one first settle on a few critical details\u2014the adversary\u2019s goal, capabilities, and knowledge.","tags":["article","paper","research","tutorial","adversarial-learning","adversarial-attacks","model-extraction","arxiv:2003.04884"],"details":"Model extraction is far from being a simple vulnerability. Our work shows that we still understand relatively little of the attack surface. In particular, while our high-accuracy attacks scale up to very large models, we find that high-fidelity attacks have a lot of potential for adversaries interested in specificities of the victim model\u2019s decision surface. ","links":[{"article_link":"http://www.cleverhans.io/2020/05/21/model-extraction.html","code_link":"","research_link":"https://arxiv.org/abs/2003.04884","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":936,"title":"Kaggle Datasets","description":"Find and use datasets or complete tasks.","tags":["library","datasets","kaggle"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.kaggle.com/datasets?sort=votes"}]},{"id":935,"title":"Look inside the workings of \"Label Smoothing\"","description":"This blog post describes how and why does \"trick\" of label smoothing improves the model accuracy and when should we use it ","tags":["article","paper","research","tutorial","deep-learning","classification","computer-vision","image-classification","regularization","label-smoothing","arxiv:1906.02629","arxiv:1512.00567"],"details":"1. This blog posts aims at instilling an understanding of \"Label Smoothing\" in the minds of reader.\r\n2.  At the end of post, it is concluded that if your dataset has symantically similar classes or mislabelled images, label smoothing can  improve your model accuracy.\r\n3. This blog also explains a new way of thinking about increasing or decreasing of logits which was mentioned in the paper \"When Does Label Smoothing work\" by Rafael M\u00fcller et.al","links":[{"article_link":"https://abhimanyu08.github.io/blog/deep-learning/2020/05/17/final.html","code_link":"","research_link":"https://arxiv.org/abs/1906.02629","media_link":"","dataset_link":"","demo_link":"","other_link":"https://arxiv.org/abs/1512.00567"}]},{"id":934,"title":"\ud83d\udcc8 Automated Time Series Forecasting","description":"This data app uses Facebook's open-source Prophet library to automatically forecast values into the future. ","tags":["code","tutorial","forecasting","time-series","time-series-forecasting","streamlit"],"details":"You'll be able to import your data from a CSV file, visualize trends and features, and then download the created forecast \ud83d\ude35","links":[{"article_link":"","code_link":"https://github.com/zachrenwick/streamlit_forecasting_app","research_link":"","media_link":"https://autoforecast-prophet.herokuapp.com/","dataset_link":"","demo_link":"","other_link":""}]},{"id":933,"title":"d2l-pytorch","description":"Reproduces the book Dive Into Deep Learning (www.d2l.ai), adapting the code from MXNet into PyTorch.","tags":["code","tutorial","pytorch","book","d2l-ai"],"details":"","links":[{"article_link":"","code_link":"https://github.com/dsgiitr/d2l-pytorch","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":932,"title":"SymJAX","description":"A symbolic CPU/GPU/TPU programming","tags":["code","jax","library","xla","autograd","symjax","symbolic-programming"],"details":"\u2022\u00a0JAX = XLA + Autograd\r\n* SymJAX = JAX + symbolic programming + deep Learning","links":[{"article_link":"","code_link":"https://github.com/RandallBalestriero/SymJAX","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://symjax.readthedocs.io/en/latest/"}]},{"id":931,"title":"Bayesian Active Learning (BaaL)","description":"BaaL is an active learning library by ElementAI. This repository contains techniques and reusable components to make active learning accessible for all.","tags":["article","code","bayesian-deep-learning","library","active-learning","semi-supervised-learning","baal","elementai"],"details":"","links":[{"article_link":"https://www.elementai.com/news/2019/element-ai-makes-its-bayesian-active-learning-library-open-source","code_link":"https://github.com/ElementAI/baal","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://baal.readthedocs.io/en/latest/"}]},{"id":930,"title":"GrokNet","description":"Unified Computer Vision Model Trunk and Embeddings For Commerce.","tags":["article","paper","research","facebook","ecommerce","shopping","image-search","groknet"],"details":"GrokNet leverages a multi-task learning approach to train a single computer vision trunk. We achieve a 2.1x improvement in exact product match accuracy when compared to the previous state-of-the-art Facebook product recognition system. We achieve this by training on 7 datasets across\r\nseveral commerce verticals, using 80 categorical loss functions and\r\n3 embedding losses","links":[{"article_link":"https://ai.facebook.com/blog/powered-by-ai-advancing-product-understanding-and-building-new-shopping-experiences","code_link":"","research_link":"https://scontent.fphx1-1.fna.fbcdn.net/v/t39.8562-6/99353320_565175057533429_3886205100842024960_n.pdf?_nc_cat=110&_nc_sid=ae5e01&_nc_ohc=lMM8VRuEXL0AX8yms04&_nc_ht=scontent.fphx1-1.fna&oh=e4723151d6446930c8baf7c78a916a78&oe=5EEB7978","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":929,"title":"Contextual Residual Aggregation for Image Ipainting","description":"A Contextual Residual Aggregation (CRA) mechanism that can produce high-frequency residuals for missing contents by weighted aggregating residuals from context.","tags":["paper","research","inpainting","contextual-residual-aggregation","arxiv:2005.09704"],"details":"Our model can inpaint images as large as 8K with considerable hole sizes, which is intractable with previous learning-based approaches. We further elaborate on the light-weight design of the network architecture, achieving real-time performance on 2K images on a GTX 1080 Ti GPU. Codes are available at: Atlas200dk/sample-imageinpainting-HiFill.","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2005.09704","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":928,"title":"Lucent","description":"Lucid library adapted for PyTorch.","tags":["code","pytorch","library","interpretability","lucid","lucent"],"details":"","links":[{"article_link":"","code_link":"https://github.com/greentfrapp/lucent","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":927,"title":"FashionBERT","description":"Text and image matching with adaptive loss for cross-modal retrieval.","tags":["paper","research","attention","bert","transformers","fashion","natural-language-processing","adaptive-loss","arxiv:2005.09801"],"details":"In this paper, we address the text and image matching in cross-modal retrieval of the fashion industry. Different from the matching in the general domain, the fashion matching is required to pay much more attention to the fine-grained information in the fashion images and texts. ","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2005.09801","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":926,"title":"Which statistical test should I use?","description":"A flow chart to help you select the right statistical tests for evaluating your experiments.","tags":["article","code","tutorial","regression","statistics","a/b-testing","experiments"],"details":"Select the right frequentist statistical test to evaluate your experiments based on: the type of data you have, its underlying distribution and assumptions as well as the number of groups, sample size and confounding variables you are testing.","links":[{"article_link":"https://miro.com/app/board/o9J_ktaDHWU=/","code_link":"https://github.com/pleonova/stat-tests","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":925,"title":"Model-Agnostic Meta-Learning for Reinforcement Learning with TF2","description":"Reimplementation of Model-Agnostic Meta-Learning (MAML) applied on Reinforcement Learning problems in TensorFlow 2.","tags":["code","paper","research","tensorflow","meta-learning","reinforcement-learning","arxiv:1703.03400"],"details":"","links":[{"article_link":"","code_link":"https://github.com/MoritzTaylor/maml-rl-tf2","research_link":"https://arxiv.org/abs/1703.03400","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":924,"title":"Multi Class Classification - Amazon Planets","description":"Notebook for Kaggle Amazon Planets Competition F-Score: 0.67446 ","tags":["code","pytorch"],"details":"","links":[{"article_link":"","code_link":"https://github.com/jha-prateek/Amazon-Pytorch","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":923,"title":"Image Supersizer","description":"Our project enlarges graphics 2x - 8x without losing quality. We built this service by merging upscaling techniques from multiple models.","tags":["generative-adversarial-networks","graphic-design","photography","video-games"],"details":"Our goal is to help people upscale photos, icons, and other graphics without losing quality. If you want to use this free, please just send an email.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://hotpot.ai"}]},{"id":922,"title":"NLP Model Selection ","description":"NLP model selection guide to make it easier to select models. This is prescriptive in nature and has to be used with caution.","tags":["tutorial","deep-learning","neural-networks","transformers","natural-language-processing","transfer-learning"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"http://models.pratik.ai/","dataset_link":"","demo_link":"","other_link":""}]},{"id":921,"title":"Torch Points3D","description":"Pytorch framework for doing deep learning on point clouds.","tags":["article","code","pytorch","library","3d","computer-vision","point-cloud-generation","point-cloud"],"details":"Our framework, Torch Points3D, was developed to become the torchvision of point cloud data: a flexible and extensible framework for researchers and engineers alike working on point cloud-based machine vision. ","links":[{"article_link":"https://medium.com/@nicolas.chaulet/torch-points3d-a-unifying-framework-for-deep-learning-on-point-clouds-94115c0be4fb","code_link":"https://github.com/nicolas-chaulet/torch-points3d","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":920,"title":"Attentron","description":"Few-shot text-to-speech exploiting attention-based variable length embedding","tags":["article","code","paper","research","attention","embeddings","few-shot-learning","natural-language-processing","speech","text-to-speech","arxiv:2005.08484"],"details":"It introduces two special encoders, each serving different purposes. A fine-grained encoder extracts variable-length style information via an attention mechanism, and a coarse-grained encoder greatly stabilizes the speech synthesis, circumventing unintelligible gibberish even for synthesizing speech of unseen speakers. ","links":[{"article_link":"https://hyperconnect.github.io/Attentron/","code_link":"https://github.com/hyperconnect/Attentron","research_link":"https://arxiv.org/abs/2005.08484","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":919,"title":"IntelliCode Compose: Code Generation Using Transformer","description":"Code completion tool which is capable of predicting sequences of code tokens of arbitrary types, generating up to entire lines of syntactically correct code.","tags":["paper","research","tutorial","transformers","code-generation","natural-language-processing","arxiv:2005.08025"],"details":"(View video starting at 29:00) It leverages state-of-the-art generative transformer model trained on 1.2 billion lines of source code in Python, C#, JavaScript and TypeScript programming languages. IntelliCode Compose is deployed as a cloud-based web service. It makes use of client-side tree-based caching, efficient parallel implementation of the beam search decoder, and compute graph optimizations to meet edit-time completion suggestion requirements in the Visual Studio Code IDE and Azure Notebook.","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2005.08025","media_link":"https://twitter.com/i/broadcasts/1OyKAYWPRrWKb","dataset_link":"","demo_link":"","other_link":""}]},{"id":918,"title":"Accelerate your NLP pipelines using Hugging Face and ONNX","description":"How the ONNX Runtime team and Hugging Face are working together to address challenges in training and deployment of Transformer models.","tags":["article","tutorial","huggingface","onnx","transformers","natural-language-processing"],"details":"The result is a solution that simplifies training and reduces costs for inferencing.\r\n\r\n1. [Accelerate your NLP pipelines using Hugging Face Transformers and ONNX Runtime](https://medium.com/microsoftazure/accelerate-your-nlp-pipelines-using-hugging-face-transformers-and-onnx-runtime-2443578f4333)\r\n2. [Faster and smaller quantized NLP with Hugging Face and ONNX Runtime](https://medium.com/microsoftazure/faster-and-smaller-quantized-nlp-with-hugging-face-and-onnx-runtime-ec5525473bb7)","links":[{"article_link":"https://medium.com/microsoftazure/accelerate-your-nlp-pipelines-using-hugging-face-transformers-and-onnx-runtime-2443578f4333","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":917,"title":"Transfer Learning In NLP","description":"A brief history of Transfer Learning In NLP","tags":["article","tutorial","deep-learning","machine-learning","natural-language-inference","natural-language-processing","text-classification","transfer-learning"],"details":"","links":[{"article_link":"https://medium.com/modern-nlp/transfer-learning-in-nlp-f5035cc3f62f?source=friends_link&sk=e144b5899bbdeb36f97ff32b7fb6ef13","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":916,"title":"Get Subreddit Suggestions for a Post","description":"Trained on 4M Reddit posts from 4k Subreddits. End-to-end ML pipeline built with fasttext and FastAPI, deployed to Valohai.","tags":["article","code","fastapi","fasttext","library","natural-language-processing","recommendation-systems","reddit","valohai"],"details":"","links":[{"article_link":"https://blog.valohai.com/machine-learning-pipeline-classifying-reddit-posts ","code_link":"https://github.com/arimbr/valohai-fasttext-example","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://valohai.com/subreddit-finder"}]},{"id":915,"title":"Image inpainting with OpenCV and Python","description":"How to perform image inpainting with OpenCV and Python.","tags":["article","tutorial","opencv","inpainting","pyimagesearch"],"details":"Technology has advanced image painting significantly, allowing us to:\r\n\u2022\u00a0Restore old, degraded photos\r\n* Repair photos with missing areas due to damage and aging\r\n* Mask out and remove particular objects from an image (and do so in an aesthetically pleasing way)","links":[{"article_link":"https://www.pyimagesearch.com/2020/05/18/image-inpainting-with-opencv-and-python/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":914,"title":"How Hugging Face achieved a 2x performance boost for QA","description":"Question Answering with DistilBERT in Node.js","tags":["article","tutorial","huggingface","node-js","attention","bert","transformers","natural-language-processing","question-answering","distillbert"],"details":"We\u2019re going to showcase one of the paths we believe can help fulfill this goal: the use of \u201csmall\u201d, yet performant models (such as DistilBERT), and frameworks targeting ecosystems different from Python such as Node via TensorFlow.js.","links":[{"article_link":"https://blog.tensorflow.org/2020/05/how-hugging-face-achieved-2x-performance-boost-question-answering.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":913,"title":"aitextgen","description":"A robust Python tool for text-based AI training and generation using GPT-2.","tags":["code","gpt2","transformers","library","natural-language-processing"],"details":"aitextgen is a Python package that leverages PyTorch, Huggingface Transformers and pytorch-lightning with specific optimizations for text generation using GPT-2, plus many added features. It is the successor to textgenrnn and gpt-2-simple, taking the best of both packages.","links":[{"article_link":"","code_link":"https://github.com/minimaxir/aitextgen","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://docs.aitextgen.io"}]},{"id":912,"title":"CNNs from Scratch with NumPy","description":"This is an attempt at implementing a Convolutional Neural Network using only Python and Numpy. ","tags":["code","tutorial","convolutional-neural-networks","numpy","from-scratch","lenet5"],"details":"The goal is to create a neural network similar to LeNet-5 as described in Yann LeCun's paper and with a similar performance on the MNIST dataset (around 1% error).\r\n\r\nA number of neural network operations have been implemented in the ops.py folder to be used as a library for building neural networks. These include:\r\n\u2022\u00a02D Convolution\r\n\u2022\u00a0Max Pooling\r\n\u2022\u00a0Fully Connected\r\n\u2022\u00a0Flattening\r\n\u2022\u00a0ReLu Activation\r\n\u2022\u00a0Sigmoid Activation\r\n\u2022\u00a0Softmax\r\n\u2022\u00a0Cross Entropy Loss","links":[{"article_link":"","code_link":"https://github.com/alberto139/numpy_dl","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":911,"title":"Energy Demand Forecasting","description":"Medium Term  for Austin TX","tags":["code","notebook","research","tutorial","energy","forecasting"],"details":"","links":[{"article_link":"","code_link":"https://github.com/hvantil/ElectricityDemandForecasting/blob/master/ElectricityDemandForecasting.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":910,"title":"Short-Term Energy Demand Forecasting","description":"Building models to predict Energy demand in next 24 hours using:\r\nSARIMA\r\nProphet\r\nLSTM","tags":["code","tutorial","renewable-energy"],"details":"","links":[{"article_link":"","code_link":"https://github.com/nicholasjhana/short-term-energy-demand-forecasting","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":909,"title":"ML Drawings","description":"Rich repository of ML drawings exported to XML and PNG created using draw.io","tags":["code","machine-learning","visualizations","drawings"],"details":"","links":[{"article_link":"","code_link":"https://github.com/amitness/amitness.github.io/tree/source/content/drawings","research_link":"","media_link":"https://github.com/amitness/amitness.github.io/tree/source/content/images","dataset_link":"","demo_link":"","other_link":""}]},{"id":908,"title":"ML Visuals","description":"Introducing ML Visuals, a collaborative effort to help the ML community improve science communication by providing free professional & compelling visuals.","tags":["code","education","drawings","visuals"],"details":"ML Visuals is a new collaborative effort to help the machine learning community in improving science communication by providing free professional, compelling and adequate visuals and figures. You are free to use the visuals in your presentations or blog posts. You don\u2019t need to ask permission to use any of the visuals but it will be nice if you can provide credit to the designer/author (author information found in the slide notes). Check out the versions of the visuals below.\r\n\r\nThis is a project made by the dair.ai community. The latest version of the Google slides can be found in this GitHub repository. Our community members will continue to add more common figures and basic elements in upcoming versions. Think of this as free and open artifacts and templates which you can freely and easily download, copy, distribute, reuse and customize to your own needs.","links":[{"article_link":"","code_link":"https://github.com/dair-ai/ml-visuals","research_link":"","media_link":"https://docs.google.com/presentation/d/11mR1nkIR9fbHegFkcFq8z9oDQ5sjv8E3JJp1LfLGKuk/edit?usp=sharing","dataset_link":"","demo_link":"","other_link":""}]},{"id":907,"title":"TextAttack","description":"A Python framework for building adversarial attacks on NLP models.","tags":["code","paper","research","library","adversarial-text","data-augmentation","natural-language-processing","adversarial-learning","adversarial-attacks","arxiv:2005.05909"],"details":"TextAttack is a Python framework for running adversarial attacks against NLP models. TextAttack builds attacks from four components: a search method, goal function, transformation, and set of constraints. TextAttack's modular design makes it easily extensible to new NLP tasks, models, and attack strategies. TextAttack currently supports attacks on models trained for classification, entailment, and translation.\r\n\r\n![](https://camo.githubusercontent.com/7ad981f12e8f1498b1bc1f2655635c93cfe7cc3e/687474703a2f2f6a61636b786d6f727269732e636f6d2f66696c65732f7465787461747461636b2e676966)","links":[{"article_link":"","code_link":"https://github.com/QData/TextAttack","research_link":"https://arxiv.org/abs/2005.05909","media_link":"","dataset_link":"","demo_link":"","other_link":"https://textattack.readthedocs.io/en/latest/"}]},{"id":906,"title":"NLPAug","description":"Data augmentation for NLP","tags":["article","code","notebook","pytorch","library","audio","data-augmentation","natural-language-processing","demo"],"details":"This python library helps you with augmenting nlp for your machine learning projects. Augmenter is the basic element of augmentation while Flow is a pipeline to orchestra multi augmenter together.\r\n\r\nFeatures:\r\n\r\n* Generate synthetic data for improving model performance without manual effort\r\n* Simple, easy-to-use and lightweight library. Augment data in 3 lines of code\r\n* Plug and play to any neural network frameworks (e.g. PyTorch, TensorFlow)\r\n* Support textual and audio input","links":[{"article_link":"https://towardsdatascience.com/data-augmentation-in-nlp-2801a34dfc28","code_link":"https://github.com/makcedward/nlpaug","research_link":"","media_link":"","dataset_link":"","demo_link":"https://github.com/makcedward/nlpaug/blob/master/example/textual_augmenter.ipynb","other_link":""}]},{"id":905,"title":"Deep Reinforcement Learning for Supply Chain & Price Optimization","description":"Explore how deep reinforcement learning methods can be applied in several basic supply chain and price management scenarios.","tags":["article","tutorial","pytorch","industrial-engineering","reinforcement-learning","supply-chain","price-optimization"],"details":"This article is structured as a hands-on tutorial that describes how to develop, debug, and evaluate reinforcement learning optimizers using PyTorch and RLlib.","links":[{"article_link":"https://blog.griddynamics.com/deep-reinforcement-learning-for-supply-chain-and-price-optimization/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":904,"title":"Convoluted Stuff","description":"Optimising compilers, and how thousand-year-old math shaped deep learning.","tags":["article","tutorial","jax","convolutional-neural-networks","xla","matrix-multiplication","im2col","winograd"],"details":"\u2022\u00a0Convolution as matrix multiplication in the frequency domain\r\n\u2022\u00a0Convolution as vanilla matrix multiplication\r\n\u2022\u00a0Im2Col or the Caffe Trick\r\n\u2022\u00a0Winograd: The Final Frontier","links":[{"article_link":"https://gkaissis.github.io/blog/computer science/machine learning/python/2020/05/17/ConvolutedStuff.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":903,"title":"Semixup: In- and Out-of-Manifold Regularization","description":"Semixup is a semi-supervised learning method based on in/out-of-manifold regularization.","tags":["code","paper","research","health","computer-vision","medical-imaging","semi-supervised-learning","regularization","kl-divergence","manifold-regularization","arxiv:2003.01944"],"details":"In the task of automatic grading Kellgren-Lawrence (KL) score for knee osteoarthritis diagnosis, Semixup shows its data-efficiency as it performs statistically insignificant difference with over 6 times less labeled data compared to a well-tuned SL requires.","links":[{"article_link":"","code_link":"https://github.com/MIPT-Oulu/semixup","research_link":"https://arxiv.org/abs/2003.01944","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":902,"title":"Differentiable Adaptive Computation Time for Visual Reasoning ","description":"DACT, a new algorithm for achieving adaptive computation time that, unlike existing approaches, is fully differentiable. ","tags":["article","code","paper","research","tutorial","natural-language-processing","question-answering","visual-question-answering","cvpr-2020","modular-networks","arxiv:2004.12770"],"details":"DACT, a new algorithm for achieving adaptive computation time that, unlike existing approaches, is fully differentiable. We put it to the test on Visual Reasoning datasets and find that our models learns to actively adapt their architectures according, balancing high accuracy with as-little-as-possible computation.","links":[{"article_link":"https://ceyzaguirre4.github.io/DACT-for-Visual-Reasoning/","code_link":"https://github.com/ceyzaguirre4/DACT-MAC","research_link":"https://arxiv.org/abs/2004.12770","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":901,"title":"DoYouEvenLearn","description":"Essential Guide to keep up with AI/ML/DL/CV","tags":["code","deep-learning","machine-learning","computer-vision"],"details":" Here is the essential guide on how to keep up with the important news/papers/discussions/tutorials. Key highlights: local communities, websites, youtube channels, podcasts, and many more.","links":[{"article_link":"","code_link":"https://github.com/BAILOOL/DoYouEvenLearn","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":900,"title":"A Visual Survey of Data Augmentation in NLP","description":"An extensive overview of text data augmentation techniques for Natural Language Processing","tags":["article","tutorial","data-augmentation","natural-language-processing"],"details":"- Get an overview of existing literature on Text Data Augmentation\r\n- Explained with visuals to illustrate the concepts well","links":[{"article_link":"https://amitness.com/2020/05/data-augmentation-for-nlp/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":899,"title":"Hands-On Python Deep Learning for the Web","description":"Use the power of deep learning with Python to build and deploy intelligent web applications.","tags":["article","code","tutorial","azure","aws","django","flask","keras","tensorflow","tensorflow-js","deep-learning","library","gcp","web-development","dialogflow"],"details":"","links":[{"article_link":"https://www.packtpub.com/in/data/hands-on-python-deep-learning-for-web","code_link":"https://github.com/PacktPublishing/Hands-On-Python-Deep-Learning-for-Web","research_link":"","media_link":"https://www.packtpub.com/media/catalog/product/cache/ecd051e9670bd57df35c8f0b122d8aea/9/7/9781789956085-original.png","dataset_link":"","demo_link":"","other_link":""}]},{"id":898,"title":"Single-Stage Semantic Segmentation from Image Labels","description":"We attain competitive results by training a single network model\r\nfor segmentation in a self-supervised fashion using only\r\nimage-level annotations","tags":["code","research","tutorial","conditional-random-fields","computer-vision","self-supervised-learning","semantic-segmentation","segmentation","single-stage","pascal-voc"],"details":"We attain competitive results by training a single network model\r\nfor segmentation in a self-supervised fashion using only\r\nimage-level annotations (one run of 20 epochs on Pascal VOC).\r\n\r\n![](https://github.com/visinf/1-stage-wseg/raw/master/figures/results.gif)","links":[{"article_link":"","code_link":"https://github.com/visinf/1-stage-wseg","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":897,"title":"Prototypical Contrastive Learning (PCL) for Unsupervised Learning","description":"Prototypical Contrastive Learning (PCL), an unsupervised representation learning method that addresses the fundamental limitations of the popular instance-wise ","tags":["article","code","paper","research","representation-learning","self-supervised-learning","semi-supervised-learning","unsupervised-learning","contrastive-learning","arxiv:2005.04966"],"details":"PCL implicitly encodes semantic structures of the data into the learned embedding space, and prevents the network from solely relying on low-level cues for solving unsupervised learning tasks. Specifically, we introduce prototypes as latent variables to help find the maximum-likelihood estimation of the network parameters in an Expectation-Maximization framework.","links":[{"article_link":"https://blog.einstein.ai/prototypical-contrastive-learning-pushing-the-frontiers-of-unsupervised-learning/","code_link":"https://arxiv.org/abs/2005.04966","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":896,"title":"Optimizing the Design of Genetic Programs for Living Cells","description":"Talk by Joe Isaacson on designing genetic programs for cells at Asimov.","tags":["video","health","genetic-programming","genetics","asimov","scaledml"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=-1fqgrF7fXU","dataset_link":"","demo_link":"","other_link":""}]},{"id":895,"title":"Catalog of Variable Transformations To Make Your Models Work","description":"10+ Numeric Variable Transformations and 7 Categorical Variable Transformations","tags":["article","tutorial","encoding","box-cox","scaling","standardization","hashing","transformations"],"details":"Numeric Variable Transformation\r\n\u2022\u00a0Standardization\r\n\u2022\u00a0Min-max scaling\r\n\u2022\u00a0Logarithmic transformation\r\n\u2022\u00a0Box-Cox transformation\r\n\u2022\u00a0Yeo-Johnson transformation\r\n\u2022\u00a0Clipping\r\n\u2022\u00a0Binning\r\n\u2022\u00a0Rank\r\n\u2022\u00a0RankGauss\r\n\u2022\u00a0Other non-linear transformations\r\n\r\nCategorical Variable Transformations\r\n\u2022\u00a0One-hot encoding\r\n\u2022\u00a0Label encoding\r\n\u2022\u00a0Feature hashing\r\n\u2022\u00a0Binary encoding & BaseN encoding\r\n\u2022\u00a0Frequency encoding\r\n\u2022\u00a0Target encoding\r\n\u2022\u00a0Special treatment when there are levels only included in test set\r\n\u2022\u00a0More categorical variable transformations","links":[{"article_link":"https://towardsdatascience.com/catalog-of-variable-transformations-to-make-your-model-works-better-7b506bf80b97","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":894,"title":"A Large-Scale, Open-Domain, Mixed-Interface Dialogue-Based ITS ","description":"Korbit, a large-scale, open-domain, mixed-interface, dialogue-based intelligent tutoring system (ITS).","tags":["paper","research","natural-language-processing","teaching","tutoring","personalized-learning","intelligent-tutoring-systems","arxiv:2005.06616"],"details":"Korbit uses machine learning, natural language processing and reinforcement learning to provide interactive, personalized learning online. Korbit has been designed to easily scale to thousands of subjects, by automating, standardizing and simplifying the content creation process.","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2005.06616","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":893,"title":"ESTorch","description":"ESTorch is an Evolution Strategy Library build around PyTorch.","tags":["article","code","pytorch","library","reinforcement-learning","evolution-strategies","evolutionary-algorithms"],"details":"","links":[{"article_link":"https://github.com/goktug97/estorch/tree/master/examples","code_link":"https://github.com/goktug97/estorch","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://estorch.readthedocs.io/"}]},{"id":892,"title":"DPOD: Pose Estimator","description":"PyTorch recreation of a SOTA 6D Pose estimation research paper. ","tags":["code","paper","research","computer-vision","pose-estimation","arxiv:1902.11020"],"details":"Given an RGB input, the goal is to predict the pose.\r\nModel was trained and tested entirely on the Linemod dataset. For every 99 out of 100 images, MSCoco dataset was used to change the background of the input image for the correspondence block to prevent overfitting.","links":[{"article_link":"","code_link":"https://github.com/yshah43/DPOD","research_link":"https://arxiv.org/abs/1902.11020","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":891,"title":"Keras Debugging Tips","description":"Four simple tips to help you debug your Keras code.","tags":["article","tutorial","keras","tensorflow","debugging"],"details":"Here are some common examples:\r\n\u2022\u00a0Creating a new Layer subclass.\r\n\u2022\u00a0Creating a custom Metric subclass.\r\n\u2022\u00a0Implementing a custom train_step on a Model.\r\nThis document provides a few simple tips to help you navigate debugging in these situations.","links":[{"article_link":"https://keras.io/examples/keras_recipes/debugging_tips/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":890,"title":"cyBERT: Applying BERT to Windows event logs","description":"This blog shows how interpreting cybersecurity logs as a natural language, improving upon the standard regex-based parsing of log data.","tags":["article","attention","bert","transformers","cyber-security","natural-language-processing","rapidsai","rapids","logs","cybert"],"details":"","links":[{"article_link":"https://medium.com/rapids-ai/cybert-28b35a4c81c4","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":888,"title":"Hypothesis : T-test","description":"In this there is some introduction of Hypothesis and Testing. And also implemented the T-test also. (install from scipy  import stats)","tags":["code","tutorial","machine-learning"],"details":"1. Introduction to Hypothesis.\r\n2. Types of tests \r\n3. Implementation of T-test","links":[{"article_link":"","code_link":"https://www.kaggle.com/kush1729/hypothesis-ttest","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":887,"title":"Recommendation Systems Datasets","description":"This tool allows you download, unpack and read recommender systems datasets into pandas.DataFrame as easy as data = Dataset().","tags":["code","python","machine-learning","library","recommendation-systems","datasets","data-science","recommender-systems","research-tool","research-data-management"],"details":"Provide convenient, consistent, easy to use interface for most popular datasets in recsys.","links":[{"article_link":"","code_link":"https://github.com/Darel13712/rs_datasets","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://darel13712.github.io/rs_datasets/"}]},{"id":886,"title":"Diabetes Detection Web app StreamLit","description":"Pima Indian Diabetes Detection with Machine Learning Deep Learning and a web application with Streamlit.io and deployed in Heroku.","tags":["code","tutorial","keras","python","tensorflow","deep-learning","logistic-regression","machine-learning","naive-bayes","regression","support-vector-machines","healthcare","streamlit","data-science"],"details":"An accessible web application for diabetes prediction","links":[{"article_link":"","code_link":"https://github.com/AminTaheri23/Pima-indian-diabetes-Deep-Learning","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://diabetes-detection-amint23.herokuapp.com/"}]},{"id":885,"title":"Visualizing Optimization Trajectory of Neural Nets","description":"This is a project making animated plots for optimization paths inspired by the paper \"Visualizing the Loss Landscape of Neural Nets\". ","tags":["article","tutorial","deep-learning","library","multilayer-perceptrons"],"details":"This is a project making animated plots for optimization paths inspired by the paper \"Visualizing the Loss Landscape of Neural Nets\". The same method can be used for more complex models. The goal is to help visual learners get better intuitions.","links":[{"article_link":"https://towardsdatascience.com/from-animation-to-intuition-visualizing-optimization-trajectory-in-neural-nets-726e43a08d85?source=friends_link&sk=dae85760fb921ecacddbe1af903e3c69","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":884,"title":"Build a Textual Similarity Web App with TensorFlow.js","description":"Have you wondered how search engines understand your queries and retrieve relevant results? How chatbots extract your intent from your questions and provide the","tags":["article","code","tutorial","tensorflow","tensorflow-js","natural-language-processing","text-similarity"],"details":"word embeddings\r\nsentence embeddings\r\ncosine similarity\r\nbuild a textual similarity analysis web-app\r\nanalysis of results","links":[{"article_link":"https://jinglescode.github.io/textual-similarity-universal-sentence-encoder","code_link":"https://github.com/jinglescode/textual-similarity-universal-sentence-encoder","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://jinglescode.github.io/datascience/2020/02/10/build-textual-similarity-analysis-web-app/"}]},{"id":883,"title":"Reinforcement Learning Tic Tac Toe with Value Function","description":"A reinforcement learning algorithm for agents to learn the tic-tac-toe, using the value function\r\n\r\n","tags":["article","code","tutorial","javascript","machine-learning","reinforcement-learning"],"details":"At any progression state except the terminal stage (where a win, loss or draw is recorded), the agent takes an action which leads to the next state, which may not yield any reward but would result in the agent a move closer to receiving a reward.\r\n\r\nThe value function is the algorithm to determine the value of being in a state, the probability of receiving a future reward.\r\n\r\nThe value of each state is updated reversed chronologically through the state history of a game, with enough training using both explore and exploit strategy, the agent will be able to determine the true value of each state in the game.","links":[{"article_link":"https://jinglescode.github.io/reinforcement-learning-tic-tac-toe/","code_link":"https://github.com/jinglescode/reinforcement-learning-tic-tac-toe","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://jinglescode.github.io/datascience/2019/06/30/reinforcement-learning-value-function/"}]},{"id":882,"title":"Phrases extraction and D3 Wordcloud","description":"100% JavaScript solution to extracting phrases from text and display key points in a beautiful D3 wordcloud.","tags":["article","code","tutorial","javascript","machine-learning","natural-language-processing"],"details":"","links":[{"article_link":"https://jinglescode.github.io/phrases-extraction-wordcloud/","code_link":"https://github.com/jinglescode/phrases-extraction-wordcloud","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://jinglescode.github.io/datascience/2017/10/01/extract-phrases-display-wordcloud/"}]},{"id":881,"title":"Time Series Forecasting with TensorFlow.js","description":"Machine learning is becoming increasingly popular these days and a growing number of the world\u2019s population see it is as a magic crystal ball: predicting when a","tags":["article","code","tutorial","javascript","tensorflow","tensorflow-js","machine-learning","time-series","time-series-forecasting"],"details":"Get stocks data from online API\r\nCompute simple moving average for a given time window\r\nTrain LSTM neural network\r\nPredict and compare predicted values to the actual values","links":[{"article_link":"https://jinglescode.github.io/time-series-forecasting-tensorflowjs/","code_link":"https://github.com/jinglescode/time-series-forecasting-tensorflowjs","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://github.com/jinglescode/time-series-forecasting-tensorflowjs"}]},{"id":880,"title":"How Deep Is Your Love For Transfer Learning In NLP?","description":"A review of NLP research","tags":["article","deep-learning","natural-language-processing","transfer-learning"],"details":"The blog throws light on the best approaches for NLP modelling.","links":[{"article_link":"https://towardsdatascience.com/20-questions-to-test-your-skills-in-transfer-learning-for-nlp-7d9f6c5f8fdc?source=friends_link&sk=a310b5702894eee476f6eca54699753d","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":879,"title":"HighRes-net: Multi-Frame Super-Resolution of satellite imagery","description":"Pytorch implementation of HighRes-net, a neural network for multi-frame super-resolution, trained and tested on the European Space Agency\u2019s Kelvin competition.","tags":["article","code","paper","research","library","computer-vision","super-resolution","remote-sensing","multi-frame-super-resolution","earth-observation","satellite-imagery","proba-v","highres-net","arxiv:2002.06460"],"details":"HighRes-net is first deep learning approach to MFSR that learns its sub-tasks in an end-to-end fashion:\r\n(i) co-registration, (ii) fusion, (iii) up-sampling, and (iv) registration-at-the-loss.\r\n\r\nBy learning deep representations of multiple views, HighRes-net can super-resolve low-resolution signals and enhance Earth Observation data at scale.\r\n\r\nHighRes-net recently topped the European Space Agency's MFSR competition on real-world satellite imagery.","links":[{"article_link":"https://www.elementai.com/news/2019/computer-enhance-please","code_link":"https://github.com/ElementAI/HighRes-net","research_link":"https://arxiv.org/abs/2002.06460","media_link":"","dataset_link":"","demo_link":"","other_link":"https://kelvins.esa.int/proba-v-super-resolution/home/"}]},{"id":878,"title":"Exploratory Data Analysis on MS COCO Style Datasets","description":"A Simple Toolkit to do exploratory data analysis on MS COCO style formatted datasets.","tags":["code","deep-learning","library","computer-vision","object-detection"],"details":"EDA is rarely done on object detection datasets. So I made a helpful tool to understand object detection datasets which are in MSCOCO format.\r\n\r\n1. Class wise object distribution\r\n2. Image wise object distribution\r\n3. Sizes of bounding boxes.","links":[{"article_link":"","code_link":"https://github.com/svdesai/eda-coco","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":877,"title":"Semi-supervised image classification with GANs","description":"Shows how to perform semi-supervised image classification with GANs. The cover image is from Chapter 7, GANs in Action.","tags":["code","notebook","tutorial","keras","tensorflow","generative-adversarial-networks","computer-vision","semi-supervised-learning"],"details":"","links":[{"article_link":"","code_link":"https://colab.research.google.com/github/sayakpaul/GAN-Hacks/blob/master/Semi_supervised_classification_with_GANs.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":876,"title":"30x Faster Hyperparameter Search with Ray Tune and RAPIDS","description":"We will show how to both increase the accuracy of our Random Forest Classifier by 5% AND reduce tuning time by 30x.","tags":["article","tutorial","ray","rapidsai","hyperparameter-optimization"],"details":"\u2022\u00a0Ray Tune is a scalable HPO library that allows the optimization to be performed in a distributed manner. \r\n\u2022\u00a0RAPIDS is a suite of GPU-accelerated libraries for data science, including both ETL and machine learning tasks.","links":[{"article_link":"https://medium.com/rapids-ai/30x-faster-hyperparameter-search-with-raytune-and-rapids-403013fbefc5#cid=av01_so-twit_en-us","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":875,"title":"Differentiable Reasoning over Text","description":"We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB).","tags":["article","code","paper","research","tutorial","entity-linking","natural-language-processing","question-answering","multi-hop","reasoning","arxiv:2002.10640"],"details":"In particular, we describe a neural module, DrKIT, that traverses textual data like a KB, softly following paths of relations between mentions of entities in the corpus. At each step the module uses a combination of sparse-matrix TFIDF indices and a maximum inner product search (MIPS) on a special index of contextual representations of the mentions. This module is differentiable, so the full system can be trained end-to-end using gradient based methods, starting from natural language inputs.","links":[{"article_link":"https://iclr.cc/virtual_2020/poster_SJxstlHFPH.html","code_link":"https://github.com/google-research/language/tree/master/language/labs/drkit","research_link":"https://arxiv.org/abs/2002.10640","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":874,"title":"Interactive COVID-19 Analysis dashboard with Dash","description":"A Beautiful Dashboard to visualize large data with option to interact and filter out to visualize the desire result using Dash and Python.","tags":["article","code","python","data-science"],"details":"A Beautiful Dashboard to visualize large data with option to interact and filter out to visualize the desire result using Dash and Python.","links":[{"article_link":"https://towardsdatascience.com/interactive-covid-19-analysis-dashboard-with-dash-c0da1008b00","code_link":"https://github.com/benai9916/covid-19-analysis","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://interactive-covid-19-dashboard.herokuapp.com/"}]},{"id":873,"title":"Learning Machine Learning","description":"Whatever I know in Machine Learning. A Big collection of tutorials from which I learnt.","tags":["code","tutorial","machine-learning","education"],"details":" Note this is a mega repo containing stuff done by many people. I have tried it and learnt from them. Please provide suitable credits to them.\r\n","links":[{"article_link":"","code_link":"https://github.com/oke-aditya/Machine_Learning","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":872,"title":"AutoML - AutoGluon","description":"An open-source library that utilizes Automatic Machine Learning (AutoML) by deploying ML into itself.","tags":["code","mxnet","library","automl","autogluon"],"details":"AutoGluon enables easy-to-use and easy-to-extend AutoML with a focus on deep learning and real-world applications spanning image, text, or tabular data. Intended for both ML beginners and experts, AutoGluon enables you to:\r\n\r\nQuickly prototype deep learning solutions for your data with few lines of code.\r\n\r\nLeverage automatic hyperparameter tuning, model selection / architecture search, and data processing.\r\n\r\nAutomatically utilize state-of-the-art deep learning techniques without expert knowledge.\r\n\r\nEasily improve existing bespoke models and data pipelines, or customize AutoGluon for your use-case.","links":[{"article_link":"","code_link":"https://github.com/jmalhot/AutoML-AutoGluon","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://autogluon.mxnet.io/"}]},{"id":871,"title":"The Puppyteer Crawler","description":"Crawls a website for pictures of dogs! It uses a crawler that uses Puppeteer then for every image encountered, it uses Tensorflowjs' coco-ssd for classification","tags":["article","code","tutorial","node-js","tensorflow","tensorflow-js","machine-learning","puppeteer"],"details":"Determine the feasibility of combining a web crawler and machine learning to look for content at scale.  This particular example scoured a pet shelter's website for pictures of dogs and puppies.","links":[{"article_link":"https://evanhalley.dev/post/puppyteer/","code_link":"https://github.com/evanhalley/puppyteer-crawler","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":870,"title":"DeepRobust","description":"A pytorch adversarial library for attack and defense methods on images and graphs.","tags":["code","pytorch","library","adversarial-defense","computer-vision","graph-neural-networks","graphs","adversarial-learning","adversarial-attacks"],"details":"Usage:\r\n\u2022\u00a0Image Attack and Defense\r\n\u2022\u00a0Graph Attack and Defense","links":[{"article_link":"","code_link":"https://github.com/DSE-MSU/DeepRobust","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":869,"title":"ICLR 2020 Trends: Better & Faster Transformers for NLP","description":"A summary of promising directions from ICLR 2020 for better and faster pretrained tranformers language models. ","tags":["article","research","attention","deep-learning","self-attention","transformers","language-modeling","natural-language-processing","natural-language-understanding"],"details":"Summarize and categorize various approaches introduced in papers presented at the ICLR 2020 conference to improve the Transformer architecture applied to natural language processing.","links":[{"article_link":"https://gsarti.com/post/iclr2020-transformers/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":868,"title":"RXNMapper: Unsupervised Attention-Guided Atom-Mapping","description":"The atom-mapping information was learned by an ALBERT model trained in an unsupervised fashion on a large dataset of chemical reactions.","tags":["article","code","paper","research","attention","bert","transformers","natural-language-processing","unsupervised-learning","chemistry","albert","molecules","atom-mapping","rxnmapper","chemical-compounds"],"details":"* Enable robust atom mapping on valid reaction SMILES. The atom-mapping information was learned by an ALBERT model trained in an unsupervised fashion on a large dataset of chemical reactions.\r\n* Data: https://ibm.ent.box.com/v/RXNMapperData","links":[{"article_link":"http://rxnmapper.ai/","code_link":"https://github.com/rxn4chemistry/rxnmapper","research_link":"https://chemrxiv.org/articles/Unsupervised_Attention-Guided_Atom-Mapping/12298559","media_link":"http://rxnmapper.ai/demo.html?rxn=&selectedLayer=10&selectedHead=5&selectedTokenSide=null&selectedTokenInd=null","dataset_link":"","demo_link":"","other_link":"https://rxn4chemistry.github.io/rxnmapper/"}]},{"id":867,"title":"Multiple Linear Regression in python","description":"It is used to explain the relationship between independent variables and a single continuous dependent variable.","tags":["article","code","tutorial","linear-regression","multinomial-regression","regression"],"details":"","links":[{"article_link":"https://medium.com/@benaikumar2/multiple-linear-regression-extremely-simple-c26b0a8b80d6","code_link":"https://github.com/benai9916/Linear-Regression/tree/master/multiple-linear-regression","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":866,"title":"HuggingFace nlp library","description":"nlp is a lightweight and extensible library to easily share and load dataset and evaluation metrics, already providing access to ~100 datasets and ~10 evaluatio","tags":["code","notebook","huggingface","library","metrics","natural-language-processing","datasets"],"details":"Features:\r\n- Get them all: Built-in interoperability w. PyTorch, Tensorflow, Pandas, Numpy\r\n- Simple transparent pythonic API\r\n- Strive on large datasets: nlp frees you from RAM memory limits\r\n- Smart cache: process once reuse forever\r\n- Add your dataset!","links":[{"article_link":"","code_link":"https://github.com/huggingface/nlp","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://colab.research.google.com/github/huggingface/nlp/blob/master/notebooks/Overview.ipynb"}]},{"id":865,"title":"Simple Linear Regression","description":"This will cover Simple Liner Regression and its  Algorithm and the techniques that is used in along with the formula. I will also cover little bit of math.","tags":["article","code","tutorial","linear-regression","regression"],"details":"","links":[{"article_link":"https://medium.com/@benaikumar2/simple-linear-regression-made-simple-43f2e60bdbd5","code_link":"https://github.com/benai9916/Linear-Regression/tree/master/simple-linear-regression","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":864,"title":"Twitter Sentiment Analysis","description":"This project is based on Natural Language processing (NLP), in this we do sentiment analysis(i.e, how much it is positive or negative) of tweets of any account.","tags":["code","notebook","tutorial","machine-learning","natural-language-processing","sentiment-analysis"],"details":"1. Collect data(tweets) from the Twitter of which we have to do sentiment analysis.\r\n2.After this, the big part comes i.e,  Data Cleaning which is very important task in NLP .It consists  of the following steps:\r\n    i) Convert all words  into the lowercase.\r\n    ii)Remove the punctuations, numbers and  links\r\n    iii) Stemming\r\n    iv) Removing abbreviations.\r\n3. Then, with the help of textblob lib we do sentiment analysis of tweets.\r\n4. Finally, we visualize the sentiment analysis of tweets. ","links":[{"article_link":"","code_link":"https://github.com/kushknows/Twitter-Sentiment-Analysis/blob/master/Twitter_sentiment (1).ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":863,"title":"S2IGAN: Speech-to-Image Generation via Adversarial Learning","description":"A speech-to-image generation (S2IG) framework is proposed which translates speech descriptions to photo-realistic images without using any text information.","tags":["article","paper","research","computer-vision","image-generation","arxiv:2005.06968"],"details":"","links":[{"article_link":"https://xinshengwang.github.io/project/s2igan/","code_link":"","research_link":"https://arxiv.org/abs/2005.06968","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":862,"title":"DQN In Pytorch Livestream Series","description":"I'm doing a series of streams about reinforcement learning (starting from Q learning) focused on showing the work in as much detail as possible (e.g. debugging)","tags":["code","tutorial","video","pytorch","deep-q-networks","reinforcement-learning","atari","breakout","cartpole"],"details":"- Solve multiple reinforcement learning problems with Q learning live\r\n- Focus on debugging, tuning, logging, and optimizations","links":[{"article_link":"","code_link":"https://github.com/safijari/rl-tutorials","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.youtube.com/playlist?list=PLd_Oyt6lAQ8Q0MaTG41iwPdy9GQmoz8dG"}]},{"id":861,"title":"Flowtron","description":"Auto-regressive flow-based generative network for text to speech synthesis.","tags":["code","paper","research","library","computer-vision","natural-language-processing","speech","speech-synthesis","style-transfer","tacotron","flowtron","iaf","text-to-speech","arxiv:2005.05957"],"details":"In our recent paper we propose Flowtron: an autoregressive flow-based generative network for text-to-speech synthesis with control over speech variation and style transfer. Flowtron borrows insights from IAF and revamps Tacotron in order to provide high-quality and expressive mel-spectrogram synthesis. ","links":[{"article_link":"","code_link":"https://github.com/NVIDIA/flowtron","research_link":"https://arxiv.org/abs/2005.05957","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":860,"title":"Electra","description":"ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators","tags":["code","research","generative-adversarial-networks","natural-language-processing","electra","text-encoder"],"details":"","links":[{"article_link":"","code_link":"https://github.com/google-research/electra","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":859,"title":"An Approach for Table Scraping With Azure Form Recognizer","description":"Invoice handling is the most important task in many different fields that deal with large amounts of data in many different formats. ","tags":["article","research","tutorial","deep-learning","azure-form-recognizer","table-scraping"],"details":"","links":[{"article_link":"https://medium.com/@dileepdba1988/an-approach-for-table-scraping-with-azure-form-recognizer-f34ffc69b169","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":858,"title":"Open-Dialog Chatbots for Learning New Languages","description":"A tutorial for automatically generate code comments using Deep Learning.","tags":["article","code","notebook","tutorial","huggingface","gpt2","transformers","natural-language-processing","conversational-ai"],"details":"This notebook was adapted from the following project:\r\nhttps://github.com/huggingface/transformers/blob/master/examples/run_language_modeling.py","links":[{"article_link":"https://nathancooper.io/i-am-a-nerd/chatbot/deep-learning/gpt2/2020/05/12/chatbot-part-1.html","code_link":"https://github.com/ncoop57/i-am-a-nerd/blob/master/_notebooks/2020-05-12-chatbot-part-1.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":857,"title":"FastHugs: Sequence Classification with Transformers and Fastai","description":"Fine-tune a text classification model with HuggingFace \ud83e\udd17 transformers and fastai-v2.","tags":["article","code","notebook","tutorial","fastai","huggingface","transformers","library","natural-language-processing","sequence-classification","fasthugs"],"details":"* FastHugsTokenizer: A tokenizer wrapper than can be used with fastai-v2's tokenizer.\r\n* FastHugsModel: A model wrapper over the HF models, more or less the same to the wrapper's from HF fastai-v1 articles mentioned below\r\n* Padding: Padding settings for the padding token index and on whether the transformer prefers left or right padding\r\n* Model Splitters: Functions to split the classification head from the model backbone in line with fastai-v2's new definition of Learner (in splitters.py","links":[{"article_link":"https://www.ntentional.com/nlp/training technique/classification/2020/04/17/fasthugs_seq_classification.html","code_link":"https://github.com/morganmcg1/ntentional/blob/master/_notebooks/2020-04-17-fasthugs_seq_classification.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://github.com/morganmcg1/fasthugs"}]},{"id":856,"title":"Chest X-Ray Classification ","description":"Learning to classify chest x-ray in the compressed domain of high-resolution medical images.","tags":["code","paper","research","covid","chestx-ray","x-ray","chestx-ray14","pneumonia","thoracic-disease","lung-disease","lung","corona"],"details":"* Generally, very high dimensional medical images are down-sampled by using interpolation techniques before feeding them to deep learning models that are ImageNet compliant and accept only low-resolution images of size 224 \u00d7224px. \r\n\r\n* This popular technique may lead to the loss of key information thus hampering the classi\ufb01cation. Signi\ufb01cant pathological features in medical images typically being small sized and highly affected. ","links":[{"article_link":"","code_link":"https://github.com/ekagra-ranjan/AE-CNN","research_link":"https://dl.acm.org/doi/abs/10.1145/3293353.3293408","media_link":"https://github.com/ekagra-ranjan/AE-CNN/raw/master/Paper55.pptx","dataset_link":"","demo_link":"","other_link":""}]},{"id":855,"title":"Fake new detection Pytorch","description":"Fake News Detection by Learning Convolution Filters through Contextualized Attention.","tags":["code","paper","research","pytorch","attention","convolutional-neural-networks","fake-news-detection","natural-language-processing","liar"],"details":"* Fake news classification on the LIAR dataset.\r\n\r\n* To learn context-aware convolution filter for incorporating the side-information while attending the relevant part of new text during its classification.","links":[{"article_link":"","code_link":"https://github.com/ekagra-ranjan/fake-news-detection-LIAR-pytorch","research_link":"https://www.researchgate.net/publication/341378920_Fake_News_Detection_by_Learning_Convolution_Filters_through_Contextualized_Attention","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":854,"title":"ASAP: Pooling for Graph Neural Network (AAAI 2020)","description":"ASAP is a sparse and differentiable pooling method that addresses the limitations of previous graph pooling layers.","tags":["code","paper","research","attention","graph-convolutional-networks","self-attention","graph-classification","graph-neural-networks","graphs","pool","molecule","graph","arxiv:1911.07979"],"details":"* A sparse and differential pooling layer for GNN (graph neural network).\r\n\r\n* A new form of self-attention better suited for global or cluster level tasks.\r\n\r\n* Need for a GNN that can learn functions of local extremas in a graph substructure. ","links":[{"article_link":"","code_link":"https://github.com/malllabiisc/ASAP","research_link":"https://arxiv.org/abs/1911.07979","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":853,"title":"Plant Disease Detection Web Application ","description":"Detection of disease in plant leaves using fastai library ","tags":["code","tutorial","fastai","flask","deep-learning","agriculture","library","web-design","plants"],"details":"","links":[{"article_link":"","code_link":"https://github.com/imskr/Plant_Disease_Detection","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":852,"title":"Scene Classification using Pytorch and Fast.ai","description":"The objective is to classify Multi-label images using deep learning. Here I have used Fast.ai library for implementing the model. ","tags":["code","research","fastai","pytorch","deep-learning","computer-vision","image-classification","transfer-learning"],"details":"1. To classify given scenes into 6 different classes\r\n2. Use Densenet-161 and transfer learning to do the same\r\n","links":[{"article_link":"","code_link":"https://github.com/adamdavis99/Nature-scene-classification-using-fastai","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.kaggle.com/adamdavis99/intel-fastai-challenge?scriptVersionId=33957599"}]},{"id":851,"title":"Pleural Effusion Detection","description":"Attempting a Convolutional Neural Network to detect pleural effusion in frontal chest radiographs.","tags":["code","research","keras","tensorflow","convolutional-neural-networks"],"details":"","links":[{"article_link":"","code_link":"https://github.com/ashok133/Pleural-Effusion-Detection","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":850,"title":"Transformers from Scratch","description":"Attempt to explain directly how modern transformers work, and why, without some of the historical baggage.","tags":["article","code","tutorial","transformers","natural-language-processing","from-scratch"],"details":"Transformers are a very exciting family of machine learning architectures. Many good tutorials exist (e.g. [1, 2]) but in the last few years, transformers have mostly become simpler, so that it is now much more straightforward to explain how modern architectures work. This post is an attempt to explain directly how modern transformers work, and why, without some of the historical baggage.","links":[{"article_link":"http://www.peterbloem.nl/blog/transformers","code_link":"https://github.com/pbloem/former","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":849,"title":"Top Down Introduction to BERT with HuggingFace and PyTorch","description":"I will also provide some intuition into how BERT works with a top down approach (applications to algorithm).","tags":["article","tutorial","huggingface","pytorch","attention","bert","transformers","natural-language-processing","top-down"],"details":"If you're just getting started with BERT, this article is for you. I will explain the most popular use cases, the inputs and outputs of the model, and how it was trained. I will also provide some intuition into how it works, and will refer your to several excellent guides if you'd like to get deeper.","links":[{"article_link":"https://skok.ai/2020/05/11/Top-Down-Introduction-to-BERT.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":848,"title":"Using Custom spaCy Components in Rasa","description":"Get a custom spaCy model working inside of Rasa on your local machine.","tags":["article","tutorial","spacy","rasa"],"details":"In this guide we're going to show you how you can get a custom spaCy model working inside of Rasa on your local machine. The document does expect that you're already familiar with spaCy and Rasa. If you're not, feel free to check out the spaCy online course or spaCy introductory youtube series. The getting started guide for Rasa can be found here.","links":[{"article_link":"https://blog.rasa.com/custom-spacy-components/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":847,"title":"HuggingTweets","description":"Tweet Generation with Huggingface.","tags":["code","tutorial","huggingface","transformers","natural-language-processing","text-generation","wandb"],"details":"* This project fine-tunes a pre-trained transformer on a user's tweets using HuggingFace.\r\n* Training and results are logged on W&B (which is integrated in HuggingFace).","links":[{"article_link":"","code_link":"https://github.com/borisdayma/huggingtweets","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":846,"title":"Guitar Chords Recognition","description":"An application that predicts the chords when Mel spectrograms of guitar sound are fed into a CNN.","tags":["code","video","convolutional-neural-networks","library","audio","audio-classification","streamlit","chords"],"details":"1. A CNN based architecture to classify guitar chords.\r\n2. A web app built using streamlit which can record, play, and classify chords and also displays the Mel spectrogram of the chord recorded.","links":[{"article_link":"","code_link":"https://github.com/ayushkumarshah/Guitar-Chords-recognition","research_link":"","media_link":"https://www.youtube.com/watch?v=KJ4sJupEfpg","dataset_link":"","demo_link":"","other_link":""}]},{"id":845,"title":"Creating and deploying static websites using Markdown and Pelican","description":"A series of articles consisting of a detailed step by step tutorial on how to create and host your personal static website using only Markdown and Python","tags":["article","code","tutorial","python","analytics","pelican","markdown","website","disqus"],"details":"1: Setting up Pelican - Installation and Theme\r\n2: Writing content using Markdown\r\n3: Hosting your website to GitHub Pages and custom domain\r\n4: Setting up Travis-CI for automating deployment\r\n5: Integrate Disqus comments with Pelican\r\n6: Integrate Google Analytics with Pelican","links":[{"article_link":"https://shahayush.com/2020/03/web-pelican-intro/","code_link":"https://github.com/ayushkumarshah/ayushkumarshah.github.io","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":844,"title":"Little Ball of Fur","description":"Little Ball of Fur is a graph sampling extension library for NetworkX.","tags":["code","library","graph-classification","graph-clustering","graphs","node-classification","community-detection","network-science","network-sampling"],"details":"- Exploration sampling\r\n- Node sampling\r\n- Edge sampling","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/littleballoffur","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":843,"title":"T5 fine-tuning","description":"A colab notebook to showcase how to fine-tune T5 model on various NLP tasks (especially non text-2-text tasks with text-2-text approach)","tags":["code","notebook","paper","research","tutorial","transformers","natural-language-processing","t5","text-2-text","arxiv:1910.10683"],"details":"- Demonstrate how to fine-tune T5 model. \r\n- Explore the text-2-text framework as proposed in the T5 paper to see how it performs on non text-2-text tasks by casting them in text-2-text settings. \r\n- Write a generic trainer that can be used for any problem which can  be formulated as text-2-text. No need to change model, hyperparameters or add a task specific head. Just change the dataset and that's it!! ","links":[{"article_link":"","code_link":"https://colab.research.google.com/drive/176NSaYjc2eeI-78oLH_F9-YV3po3qQQO","research_link":"https://arxiv.org/abs/1910.10683","media_link":"","dataset_link":"","demo_link":"","other_link":"https://huggingface.co/transformers/model_doc/t5.html"}]},{"id":842,"title":"Identifying Brain Tumor from MRI images using FastAI -DynamicUnet","description":"To use FASTAI unet learner to identify tumours from MRI of Brain, logging loss metrics in Neptune AI logger and compare the results after hyperparameter tuning.","tags":["article","code","fastai","pytorch","deep-learning","computer-vision","segmentation","neptune-ai"],"details":"The objective of this project is to explore the use of Dynamic UNet architecture of FastAI to identify brain tumor from MRI images and to log various loss parameters in Neptune AI logger to do a comparative analysis between the performance of the model basis hyper-parameter tuning. The project will explore the architecture of Dynamic UNet architecture used  in detail and will also explore how Neptune AI can be used for easy and organised tracking of various loss matrices and to do easy comparisons between various model performances after hyper-parameter tuning.","links":[{"article_link":"https://medium.com/analytics-vidhya/identifying-brain-tumor-from-mri-images-using-fastai-and-metrics-tracking-using-neptune-ai-71fbc56febba","code_link":"https://github.com/Conformist101/BrainMRI_Scan_FastAI_segmentation","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":841,"title":"BLEURT: Learning Robust Metrics for Text Generation","description":"A metric for Natural Language Generation based on transfer learning.","tags":["code","paper","research","tutorial","metrics","natural-language-processing","text-generation","transfer-learning","language-generation","bleu","sentence-bleu","bertscore","arxiv:2004.04696"],"details":"BLEURT is an evaluation metric for Natural Language Generation. It takes a pair of sentences as input, a reference and a candidate, and it returns a score that indicates to what extent the candidate is grammatical and conveys the mearning of the reference. It is comparable to sentence-BLEU and BERTscore.","links":[{"article_link":"","code_link":"https://github.com/google-research/bleurt","research_link":"https://arxiv.org/abs/2004.04696","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":840,"title":"Machine Learning on Graphs: A Model and Comprehensive Taxonomy","description":"We propose a simple framework (GraphEDM) and a comprehensive Taxonomy to review and unify several graph representation learning methods.","tags":["paper","research","autoencoders","graph-convolutional-networks","graph-neural-networks","graphs","representation-learning","survey","graph-regularization","arxiv:2005.03675"],"details":"There has been a surge of recent interest in learning representations for graph-structured data. Graph representation learning methods have generally fallen into three main categories, based on the availability of labeled data. The first, network embedding (such as shallow graph embedding or graph auto-encoders), focuses on learning unsupervised representations of relational structure. The second, graph regularized neural networks, leverages graphs to augment neural network losses with a regularization objective for semi-supervised learning. The third, graph neural networks, aims to learn differentiable functions over discrete topologies with arbitrary structure. However, despite the popularity of these areas there has been surprisingly little work on unifying the three paradigms. Here, we aim to bridge the gap between graph neural networks, network embedding and graph regularization models. We propose a comprehensive taxonomy of representation learning methods for graph-structured data, aiming to unify several disparate bodies of work. Specifically, we propose a Graph Encoder Decoder Model (GRAPHEDM), which generalizes popular algorithms for semi-supervised learning on graphs (e.g. GraphSage, Graph Convolutional Networks, Graph Attention Networks), and unsupervised learning of graph representations (e.g. DeepWalk, node2vec, etc) into a single consistent approach. To illustrate the generality of this approach, we fit over thirty existing methods into this framework. We believe that this unifying view both provides a solid foundation for understanding the intuition behind these methods, and enables future research in the area.","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2005.03675","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":839,"title":"Underrated ML","description":"A podcast that pitches underrated ideas in Machine Learning.","tags":["podcast","tutorial","machine-learning","underrated-topics"],"details":"This is a way for us to have some quality transatlantic catch-up about some of our favorite machine learning topics, have fun and invite some amazing researchers to pitch an underrated idea. ","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.underratedml.com/"}]},{"id":838,"title":"mljar-supervised","description":"\u2728 Automated Machine Learning Python package designed to save time for a data scientist \ud83d\ude0e","tags":["code","linear-regression","regression","library","automl","supervised-learning","multi-class-classification"],"details":"The mljar-supervised is an Automated Machine Learning Python package that works with tabular data. It is designed to save time for a data scientist \ud83d\ude0e. It abstracts the common way to preprocess the data, construct the machine learning models, and perform hyper-parameters tuning to find the best model \ud83c\udfc6. It is no black-box as you can see exactly how the ML pipeline is constructed (with a detailed Markdown report for each ML model).\r\n\r\n* binary classification\r\n* multi-class classification\r\n* regression","links":[{"article_link":"","code_link":"https://github.com/mljar/mljar-supervised","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":837,"title":"torchdyn","description":"A PyTorch based library for all things neural differential equations","tags":["code","pytorch","library","neural-differential-equations","torchdyn"],"details":"End-to-end Pytorch suite for continuous neural architectures featuring several models, training methods and visualization tools for research, industry and amateurs.","links":[{"article_link":"","code_link":"https://github.com/DiffEqML/torchdyn","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://torchdyn.readthedocs.io/en/latest/"}]},{"id":836,"title":"Epipolar Transformers","description":"Differentiable \"epipolar transformer\", which enables the 2D detector to leverage 3D-aware features to improve 2D pose estimation.","tags":["code","paper","research","tutorial","video","transformers","3d","computer-vision","natural-language-processing","pose-estimation","epipoplar","cvpr-2020","arxiv:2005.04551"],"details":"The intuition is: given a 2D location p in the current view, we would like to first find its corresponding point p' in a neighboring view, and then combine the features at p' with the features at p, thus leading to a 3D-aware feature at p. Inspired by stereo matching, the epipolar transformer leverages epipolar constraints and feature matching to approximate the features at p'.","links":[{"article_link":"","code_link":"https://github.com/yihui-he/epipolar-transformers","research_link":"https://arxiv.org/abs/2005.04551","media_link":"https://www.youtube.com/watch?v=s0J1YzxdWL0","dataset_link":"","demo_link":"","other_link":""}]},{"id":835,"title":"Toward Better Storylines with Sentence-Level Language Models","description":"We propose a sentence-level language model which selects the next sentence in a story from a finite set of fluent alternatives.","tags":["paper","research","language-modeling","natural-language-processing","text-generation","storytelling","arxiv:2005.05255"],"details":"We propose a sentence-level language model which selects the next sentence in a story from a finite set of fluent alternatives. Since it does not need to model fluency, the sentence-level language model can focus on longer range dependencies, which are crucial for multi-sentence coherence. Rather than dealing with individual words, our method treats the story so far as a list of pre-trained sentence embeddings and predicts an embedding for the next sentence, which is more efficient than predicting word embeddings. Notably this allows us to consider a large number of candidates for the next sentence during training. We demonstrate the effectiveness of our approach with state-of-the-art accuracy on the unsupervised Story Cloze task and with promising results on larger-scale next sentence prediction tasks.","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2005.05255","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":834,"title":"TailorGAN: Making User-Defined Fashion Designs","description":"Generate a photo-realistic image which combines the texture from reference A and the new attribute from reference B.","tags":["code","paper","research","tutorial","generative-adversarial-networks","design","fashion","computer-vision","image-generation","generative-modeling","arxiv:2001.06427"],"details":"Given a reference garment image A and another image B with target attribute (collar/sleeve), generate a photo-realistic image which combines the texture from reference A and the new attribute from reference B. ","links":[{"article_link":"","code_link":"https://github.com/gli-27/TailorGAN","research_link":"https://arxiv.org/abs/2001.06427","media_link":"https://drive.google.com/file/d/11WMP0uCgzF--Kt18Dwh75Ja-nK1llMcx/view","dataset_link":"","demo_link":"","other_link":""}]},{"id":833,"title":"Plan2Explore: Plan to Explore via Self-Supervised World Models","description":"A self-supervised reinforcement learning agent that tackles task-specific and the sample efficiency challenges.","tags":["article","code","paper","research","video","reinforcement-learning","self-supervised-learning","plan2explore","arxiv:2005.05960"],"details":"Reinforcement learning allows solving complex tasks, however, the learning tends to be task-specific and the sample efficiency remains a challenge. We present Plan2Explore, a self-supervised reinforcement learning agent that tackles both these challenges through a new approach to self-supervised exploration and fast adaptation to new tasks, which need not be known during exploration.","links":[{"article_link":"https://ramanans1.github.io/plan2explore/","code_link":"https://github.com/ramanans1/plan2explore","research_link":"https://arxiv.org/abs/2005.05960","media_link":"https://www.youtube.com/watch?v=GyEzjW1m7kU","dataset_link":"","demo_link":"","other_link":""}]},{"id":832,"title":"Image segmentation in 2020","description":"Architectures, Losses, Datasets, and Frameworks","tags":["article","computer-vision","semantic-segmentation","segmentation","instance-segmentation"],"details":"* what image segmentation is\r\n* a couple of image segmentation architectures\r\n* some image segmentation losses\r\n* image segmentation tools and frameworks","links":[{"article_link":"https://neptune.ai/blog/image-segmentation-in-2020?utm_source=devto&utm_medium=crosspost&utm_campaign=blog-image-segmentation-2020","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":831,"title":"CCNet_PyTorch","description":"A PyTorch Implementation of  CCNet: Criss-Cross Attention for Semantic Segmentation","tags":["article","code","paper","research","pytorch","attention","computer-vision","semantic-segmentation","segmentation","ccnet","arxiv:1811.11721"],"details":"A PyTorch Implementation of CCA-Module parallel connection with ASPP-Module in Deeplabv3","links":[{"article_link":"http://yearing1017.cn/2020/03/26/CCNet-paper/","code_link":"https://github.com/yearing1017/CCNet_PyTorch","research_link":"https://arxiv.org/abs/1811.11721","media_link":"","dataset_link":"","demo_link":"","other_link":"http://yearing1017.cn"}]},{"id":830,"title":"DeepRecommender","description":"Training Deep AutoEncoders for Collaborative Filtering.","tags":["code","paper","research","tutorial","pytorch","autoencoders","recommendation-systems","arxiv:1708.01715"],"details":"The repository is an implementation of the research paper by NVIDIA : Training Deep AutoEncoders for Collaborative Filtering. Detailed description of the research paper and work is provided in the repository.","links":[{"article_link":"","code_link":"https://github.com/Chinmayrane16/DeepRecommender","research_link":"https://arxiv.org/abs/1708.01715","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":829,"title":"Unsupervised Reinforcement Learning","description":"Lecture on unsupervised reinforcement learning by Sergey Levine. Originally prepared for AAMAS 2020.","tags":["tutorial","video","reinforcement-learning","unsupervised-learning","unsupervised-reinforcement-learning"],"details":"Lecture on unsupervised reinforcement learning by Sergey Levine. Originally prepared for AAMAS 2020.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=4vK6X9Jrncs","dataset_link":"","demo_link":"","other_link":""}]},{"id":828,"title":"BART version of closed-book QA","description":"This is a BART version of sequence-to-sequence model for open-domain QA in a closed-book setup, based on PyTorch and Huggingface's Transformers.","tags":["code","paper","research","tutorial","huggingface","pytorch","transformers","natural-language-processing","question-answering","bart","arxiv:1910.13461","arxiv:2002.08910"],"details":"* The model is a sequence-to-sequence model that takes a question as an input and outputs the answer, without reading any external resource (e.g. passages). Please refer to Roberts et al., 2020, How Much Knowledge Can You Pack Into the Parameters of a Language Model? to learn more about closed-book QA setup and the original model based on T5. Their code and model checkpoints are available here.\r\n\u2022\u00a0The model is based on BART-large. Please refer to Lewis et al., ACL 2020, BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension to learn more about BART.\r\n\r\nRelevant papers:\r\n\u2022\u00a0How Much Knowledge Can You Pack Into the Parameters of a Language Model?: https://arxiv.org/abs/2002.08910\r\n\u2022\u00a0BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension: https://arxiv.org/abs/1910.13461","links":[{"article_link":"","code_link":"https://github.com/shmsw25/bart-closed-book-qa","research_link":"https://arxiv.org/abs/1910.13461","media_link":"","dataset_link":"","demo_link":"","other_link":"https://arxiv.org/abs/2002.08910"}]},{"id":827,"title":"SupContrast: Supervised Contrastive Learning","description":"PyTorch implementation of \"Supervised Contrastive Learning\" (and SimCLR incidentally)","tags":["code","paper","research","tutorial","pytorch","self-supervised-learning","simclr","contrastive-learning","arxiv:2004.11362","arxiv:2002.05709"],"details":"* Supervised Contrastive Learning: https://arxiv.org/abs/2004.11362\r\n\u2022\u00a0A Simple Framework for Contrastive Learning of Visual Representations: https://arxiv.org/abs/2002.05709","links":[{"article_link":"","code_link":"https://github.com/HobbitLong/SupContrast","research_link":"https://arxiv.org/abs/2004.11362","media_link":"","dataset_link":"","demo_link":"","other_link":"https://arxiv.org/abs/2002.05709"}]},{"id":826,"title":"DANet PyTorch","description":"A Pytorch implementation of Dual Attention Network for Scene Segmentation","tags":["article","code","paper","research","pytorch","attention","computer-vision","semantic-segmentation","segmentation","danet","arxiv:1809.02983"],"details":"Implementation of DANet; \r\nAttention;\r\nimprovement of deeplabv3 with attention\r\n\r\n \r\n","links":[{"article_link":"http://yearing1017.cn/2020/04/06/DAN-paper/","code_link":"https://github.com/yearing1017/DANet_PyTorch","research_link":"https://arxiv.org/abs/1809.02983","media_link":"","dataset_link":"","demo_link":"","other_link":"http://yearing1017.cn"}]},{"id":825,"title":"Neural Networks for NLP (CMU CS 11-747)","description":"This class will start with a brief overview of neural networks, then spend the majority of the class demonstrating how to apply neural networks to language.","tags":["course","tutorial","video","neural-networks","natural-language-processing","carnegie-mellon"],"details":"Neural networks provide powerful new tools for modeling language, and have been used both to improve the state-of-the-art in a number of tasks and to tackle new problems that were not easy in the past. This class will start with a brief overview of neural networks, then spend the majority of the class demonstrating how to apply neural networks to natural language problems. Each section will introduce a particular problem or phenomenon in natural language, describe why it is difficult to model, and demonstrate several models that were designed to tackle this problem. In the process of doing so, the class will cover different techniques that are useful in creating neural network models, including handling variably sized and structured sentences, efficient handling of large data, semi-supervised and unsupervised learning, structured prediction, and multilingual modeling.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/playlist?list=PL8PYTP1V4I8CJ7nMxMC8aXv8WqKYwj-aJ","dataset_link":"","demo_link":"","other_link":"http://www.phontron.com/class/nn4nlp2020/"}]},{"id":824,"title":"Normalising a distribution","description":"A Kaggle kernel/Jupyter Notebook illustrating a number of methods (including experimental ones), on how to normalise a distribution in `Python`.","tags":["code","notebook","python","scikit-learn","distribution","data-science","jupyter-notebook","normalisation","transformation","data-transformation","kaggle-kernel","kaggle"],"details":"","links":[{"article_link":"","code_link":"https://www.kaggle.com/neomatrix369/normalising-a-distribution","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":823,"title":"Feature importance","description":"A python source file illustrating multiple methods to extract Feature importance from a dataset","tags":["code","python","scikit-learn","feature-engineering","feature-importance","feature-selection","data-science","data"],"details":"","links":[{"article_link":"","code_link":"https://github.com/neomatrix369/awesome-ai-ml-dl/blob/master/examples/data/feature-importance-filtering/feature_importance.py","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":822,"title":"In-Domain GAN Inversion for Real Image Editing","description":"We propose an in-domain GAN inversion method, which faithfully reconstructs the input image but also ensures the inverted code to be semantically meaningful.","tags":["article","code","paper","research","tutorial","video","generative-adversarial-networks","computer-vision","image-generation","inversion","image-editing"],"details":"Basically, the in-domain GAN inversion contains two steps:\r\n\u2022\u00a0Training domain-guided encoder.\r\n\u2022\u00a0Performing domain-regularized optimization.","links":[{"article_link":"https://genforce.github.io/idinvert/","code_link":"https://github.com/genforce/idinvert","research_link":"https://genforce.github.io/idinvert/IDInvert.pdf","media_link":"https://www.youtube.com/watch?v=3v6NHrhuyFY","dataset_link":"","demo_link":"","other_link":""}]},{"id":821,"title":"Hidden Technical Debt in Machine Learning Systems","description":"Using the software engineering framework of technical debt, we find it is common to incur massive ongoing maintenance costs in real-world ML systems. ","tags":["paper","research","production","systems-design","industry","technical-debt"],"details":"Machine learning offers a fantastically powerful toolkit for building useful complex prediction systems quickly. This paper argues it is dangerous to think of these quick wins as coming for free. Using the software engineering framework of technical debt, we find it is common to incur massive ongoing maintenance costs in real-world ML systems. We explore several ML-specific risk factors to account for in system design. These include boundary erosion, entanglement, hidden feedback loops, undeclared consumers, data dependencies, configuration issues, changes in the external world, and a variety of system-level anti-patterns.","links":[{"article_link":"","code_link":"","research_link":"https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":820,"title":"A Comprehensive Survey on Graph Neural Networks","description":"A Comprehensive Survey on Graph Neural Networks.","tags":["paper","research","tutorial","graph-convolutional-networks","graph-neural-networks","graphs","graph-autoencoders","spatial-temporal-gnns","arxiv:1901.00596"],"details":"We propose a new taxonomy to divide the state-of-the-art graph neural networks into four categories, namely recurrent graph neural networks, convolutional graph neural networks, graph autoencoders, and spatial-temporal graph neural networks.","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/1901.00596","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":819,"title":"TensorFlow Extended Workshop","description":"Slides for teaching a complete workshop on TensorFlow Extended.  ","tags":["article","code","tutorial"],"details":"Slides for teaching a complete workshop on TensorFlow Extended.  ","links":[{"article_link":"https://docs.google.com/presentation/d/1hGjEkTk4NFs30fXQIGwQ1StoswDs340fZboUox8U1PI/edit#slide=id.g62b665252a_0_5","code_link":"https://github.com/tensorflow/workshops","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":817,"title":"On-device Learning of Activity Recognition Networks","description":"Personalized machine learning on the smartphone.","tags":["article","code","tutorial","on-device-learning"],"details":"Leverage the power of on-device machine learning for training personalized models without the need of sharing your data.","links":[{"article_link":"https://aqibsaeed.github.io/on-device-activity-recognition","code_link":"https://github.com/aqibsaeed/on-device-activity-recognition","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":815,"title":"keras.io Guides and Examples","description":"Official keras.io guides and code examples.","tags":["article","code","tutorial","keras","tensorflow","deep-learning"],"details":"\u2022\u00a0Our developer guides are deep-dives into specific topics such as layer subclassing, fine-tuning, or model saving. They're one of the best ways to become a Keras expert.\r\n\u2022\u00a0Our code examples are short (less than 300 lines of code), focused demonstrations of vertical deep learning workflows.\r\n","links":[{"article_link":"https://keras.io/guides","code_link":"https://keras.io/examples/","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":813,"title":"Inside TensorFlow: tf.Keras ","description":"Walkthrough of the high-level Keras API of TensorFlow. ","tags":["article","tutorial","video","keras","tensorflow","deep-learning"],"details":"Take an inside look into the TensorFlow team\u2019s own internal training sessions--technical deep dives into TensorFlow by the very people who are building it! \r\n\r\n* Part 1: https://www.youtube.com/watch?v=UYRBHFAvLSs\r\n* Part 2: https://www.youtube.com/watch?v=uhzGTijaw8A","links":[{"article_link":"https://www.youtube.com/watch?v=uhzGTijaw8A","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":811,"title":"tf.keras for Researchers: Crash Course","description":"A crash course on how to best use Keras when doing research. ","tags":["code","notebook","research","tutorial","keras","tensorflow","deep-learning"],"details":"Are you a deep learning researcher? Wondering if all this TensorFlow 2.0 stuff is relevant to you? This notebook is a crash course on everything you need to know to use TensorFlow 2.0 for deep learning research.","links":[{"article_link":"","code_link":"https://colab.research.google.com/drive/17u-pRZJnKN0gO5XZmq8n5A2bKGrfKEUg","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":807,"title":"Introduction to Machine Learning Problem Framing","description":"This course helps you frame machine learning (ML) problems.","tags":["article","tutorial","deep-learning","machine-learning","production"],"details":"Welcome to Introduction to Machine Learning Problem Framing! This course helps you frame machine learning (ML) problems. ","links":[{"article_link":"https://developers.google.com/machine-learning/problem-framing","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":806,"title":"Deep Generative Models","description":"CS236: A comprehensive course to learn about generative modeling techniques in deep learning. ","tags":["article","research","tutorial","autoencoders","generative-adversarial-networks","autoregressive-models","normalizing-flow-models"],"details":"CS236: A comprehensive course to learn about generative modeling techniques in deep learning. ","links":[{"article_link":"https://deepgenerativemodels.github.io/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":805,"title":"Generative Adversarial Networks: A Crash Course in GANs","description":"This course covers GAN basics, and also how to use the TF-GAN library to create GANs.","tags":["article","tutorial","tensorflow","deep-learning","generative-adversarial-networks","generative-modeling"],"details":"This course covers GAN basics, and also how to use the TF-GAN library to create GANs.","links":[{"article_link":"https://developers.google.com/machine-learning/gan","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":804,"title":"Generative Adversarial Networks with Python","description":"Deep Learning Generative Models for Image Synthesis and Image Translation. ","tags":["article","tutorial","deep-learning","generative-adversarial-networks","library","generative-modeling"],"details":"","links":[{"article_link":"https://machinelearningmastery.com/generative_adversarial_networks/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":803,"title":"Image Semantic Segmentation of UAV mining area based on Deeplabv3","description":"Data: UAV mining area image\r\nTools: PyTorch\r\nFrame: Deeplabv3\r\nSemantic Segmentation ","tags":["article","code","research","pytorch","computer-vision","semantic-segmentation","segmentation","deeplabv3"],"details":"UAV mining area image\r\nSemantic Segmentation \r\nDeeplabv3\r\nPyTorch\r\n","links":[{"article_link":"http://yearing1017.cn/2019/12/28/\u56fe\u50cf\u5207\u5272\u4e0e\u53ef\u89c6\u5316/","code_link":"https://github.com/yearing1017/Deeplabv3_Pytorch","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"http://yearing1017.cn/"}]},{"id":800,"title":"Feature Stores for ML","description":"List of production ML groups and their open-source feature store architectures.","tags":["article","tutorial","library","production","feature-store","industry"],"details":"Data scientists are duplicating work because they don\u2019t have a centralized feature store. Everybody I talk to really wants to build or even buy a feature store\u2026\u2026if an organization had a feature store, the ramp-up period [for Data Scientists can be much faster.","links":[{"article_link":"http://featurestore.org/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":799,"title":"Injecting Inductive Bias in Graph Neural Networks (MIT talk)","description":"Equivariant Mesh Neural Networks and Neural Augmented (Factor) Graph Neural Networks.","tags":["tutorial","video","graph-neural-networks","graphs"],"details":"In this talk I will extend graph neural nets in two directions. First, we will ask if we can formulate a GNN on meshes of two dimensional manifolds. Previous approaches mostly used standard GNNs which are invariant to permutations of the input nodes. ","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=JWswItMRvg4","dataset_link":"","demo_link":"","other_link":""}]},{"id":798,"title":"TF callbacks in action ","description":"This article consist, about how to use Tenserflow callbacks.\r\nI've covered some really important Tensorflow callbacks guides. \r\n","tags":["article","code","keras","tensorflow","deep-learning","feed-forward-neural-networks"],"details":"I've added these callbacks guide in my article :\r\n1 .custom  callbacks\r\n2. Model Checkpoint callback \r\n3. Learning Rate scheduler callback \r\n4. ReduceLRonPlateu callback \r\n5.Early stopping callback ","links":[{"article_link":"https://link.medium.com/A60xOlD1l6","code_link":"https://github.com/abhinavsp0730/callback_blog","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":797,"title":"Data augmentation recipes in tf.keras image-based models","description":"Learn about different ways of doing data augmentation when training an image classifier in tf.keras.","tags":["article","code","notebook","tutorial","keras","tensorflow","deep-learning","computer-vision","data-augmentation","image-classification","recipe"],"details":"Here\u2019s a brief overview of the different ways we are going to cover\r\n\r\n* Using the standard ImageDataGenerator class\r\n* Using TensorFlow image ops with a TensorFlow dataset\r\n* Using Keras\u2019s (experimental) image processing layers\r\n* Mix-matching different image ops & image processing layers","links":[{"article_link":"https://sayak.dev/tf.keras/data_augmentation/image/2020/05/10/augmemtation-recipes.html","code_link":"https://colab.research.google.com/github/sayakpaul/portfolio/blob/master/_notebooks/2020-05-10-augmemtation-recipes.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":796,"title":"Age and Gender Estimation using Multi-Task CNN","description":"Used a multi task CNN to predict the age group and gender of the person in the image.","tags":["code","tutorial","convolutional-neural-networks","deep-learning","computer-vision","image-classification","multi-task-learning"],"details":"Used a multi task CNN to predict the age group and gender of the person in the image.","links":[{"article_link":"","code_link":"https://github.com/Aditya-Gupta1/Data-Science-Portfolio/tree/master/7 - Age and Gender Estimation using Multi-Task CNN","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":795,"title":"U^2-Net","description":"The code for our newly accepted paper in Pattern Recognition 2020: \"U^2-Net: Going Deeper with Nested U-Structure for Salient Object Detection.\"","tags":["code","research","tutorial","computer-vision","object-detection","segmentation","unet","salient-object-detection"],"details":"U^2-Net: Going Deeper with Nested U-Structure for Salient Object Detection.","links":[{"article_link":"","code_link":"https://github.com/NathanUA/U-2-Net","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":794,"title":"W4995 Applied Machine Learning","description":"This class offers a hands-on approach to machine learning and data science.","tags":["article","code","course","tutorial","video","machine-learning","applied-machine-learning","columbia","w4995"],"details":"The class discusses the application of machine learning methods like SVMs, Random Forests, Gradient Boosting and neural networks on real world dataset, including data preparation, model selection and evaluation. This class complements COMS W4721 in that it relies entirely on available open source implementations in scikit-learn and tensor flow for all implementations. Apart from applying models, we will also discuss software development tools and practices relevant to productionizing machine learning models.","links":[{"article_link":"https://www.cs.columbia.edu/~amueller/comsw4995s20/","code_link":"https://github.com/amueller/COMS4995-s20","research_link":"","media_link":"https://www.youtube.com/playlist?list=PL_pVmAaAnxIRnSw6wiCpSvshFyCREZmlM","dataset_link":"","demo_link":"","other_link":"https://amueller.github.io/COMS4995-s20/slides/"}]},{"id":793,"title":"MapExtrackt","description":"PyTorch Feature Map Extractor","tags":["code","notebook","video","pytorch","convolutional-neural-networks","library","feature-maps"],"details":"MapExtrakt makes viewing feature maps a breeze.","links":[{"article_link":"","code_link":"https://github.com/lewis-morris/mapextrackt","research_link":"","media_link":"https://www.youtube.com/watch?v=LZTGIYxczFc","dataset_link":"","demo_link":"","other_link":"https://github.com/lewis-morris/mapextrackt/blob/master/examples/examples.ipynb"}]},{"id":792,"title":"A Commit History of BERT and its Forks","description":"What a commit history of version-controlled research papers could look like?","tags":["article","research","tutorial","natural-language-processing"],"details":"- Showcase a fun hypothesis where new research papers are code diffs of previous papers","links":[{"article_link":"https://amitness.com/2020/05/git-log-of-bert/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":791,"title":"Pose Animator","description":"Takes a 2D vector illustration and animates its containing curves in real-time based on the recognition result from PoseNet and FaceMesh.","tags":["code","tutorial","tensorflow-js","computer-vision","pose-estimation","posenet","facemesh"],"details":"Pose Animator takes a 2D vector illustration and animates its containing curves in real-time based on the recognition result from PoseNet and FaceMesh. It borrows the idea of skeleton-based animation from computer graphics and applies it to vector characters.","links":[{"article_link":"","code_link":"https://github.com/yemount/pose-animator/","research_link":"","media_link":"https://pose-animator-demo.firebaseapp.com/","dataset_link":"","demo_link":"","other_link":""}]},{"id":790,"title":"Interpretability in Deep Learning with W&B - CAM and GradCAM","description":"This report will review how CAM and Grad-CAM counters the common criticism that neural networks are not interpretable.","tags":["article","code","paper","research","tutorial","interpretability","wandb","arxiv:1610.02391"],"details":"We'll look at 3 techniques that address this criticism and shed light into neural networks' \u201cblack-box\u201d nature of learning. Here's a quick outline:\r\n* Visualize learned features.\r\n* Class Activation Map(CAM)\r\n* Gradient CAM\r\n* You also get these powerful interpretability tools as easy to use custom callbacks in Keras.\r\n","links":[{"article_link":"https://app.wandb.ai/ayush-thakur/interpretability/reports/Interpretability-in-Deep-Learning-with-W&B-CAM-and-GradCAM--Vmlldzo5MTIyNw?utm_source=social_reddit&utm_medium=report&utm_campaign=report_author","code_link":"https://github.com/ayulockin/interpretabilitycnn","research_link":"https://arxiv.org/abs/1610.02391","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":789,"title":"Mathematics of Neural Networks","description":"Text on \"the mathematics of neural networks\" for a general audience.","tags":["paper","research","tutorial","convolutional-neural-networks","math"],"details":"Text on \"the mathematics of neural networks\" for a general audience.","links":[{"article_link":"","code_link":"","research_link":"https://www.dropbox.com/s/ec3y4khbk38e29i/NeuralNetworksEN.pdf","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":788,"title":"NER model for 40 languages trained with the new TFTrainer","description":"This model is a fine-tuned XLM-Roberta-base over the 40 languages proposed in XTREME from Wikiann. ","tags":["code","tutorial","huggingface","tensorflow","attention","bert","transformers","library","language-modeling","multilingual","named-entity-recognition","natural-language-processing","tftrainer"],"details":"Reproducing the results:\r\n\u2022\u00a0Download and prepare the dataset from the [https://github.com/google-research/xtreme#download-the-data](XTREME repo).","links":[{"article_link":"","code_link":"https://huggingface.co/jplu/tf-xlm-r-ner-40-lang","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":787,"title":"Semantic Cord19 Paper Explorer","description":"Semantic research paper explorer to search Research Papers in COVID and CoronaVirus. Can be easily modified to any Research Paper Database","tags":["code","fasttext","natural-language-processing","streamlit","cord19"],"details":"An app to intelligently search through COVID-19 Open Research Dataset (CORD-19)link and find similar papers powered with Machine Learning and NLP. ","links":[{"article_link":"","code_link":"https://github.com/sagarkar10/CORD-19-Browse.git","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":786,"title":"G-MARC : GUI for Model Agnostic IML on Rupture risk Classifier","description":"Study and Visualization of Model Agnostic Interpretable ML Approaches on the classification of Rupture status of Intracranial Aneurysms","tags":["code","python","machine-learning","graphic-design","healthcare","interpretability","model-selection","explainability","gui","interface","plots","cxfreeze"],"details":"1. To understand why a black-box model predicted the way it did with the help of model-agnostic explanations and make it more trustable.\r\n2. Working on simple model-agnostic interpretable approaches that make even the technical side easy to understand.\r\n3. Create a Windows executable file that helps the user to get hold of model's interoperability by means of proper visualizations for each model-agnostic interpretable machine learning approaches employed. Also provides the user with a download option to download and save the visualizations as a PDF report. ","links":[{"article_link":"","code_link":"https://github.com/sachn1/IML-GUI","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":785,"title":"SimCLR in TensorFlow 2","description":"(Minimally) implements SimCLR (https://arxiv.org/abs/2002.05709) in TensorFlow 2.","tags":["article","code","paper","research","tensorflow","deep-learning","computer-vision","representation-learning","self-supervised-learning","simclr","wandb","arxiv:2002.05709"],"details":"(Minimally) implements SimCLR (A Simple Framework for Contrastive Learning of Visual Representations by Chen et al.) in TensorFlow 2. Uses many delicious pieces of tf.keras and TensorFlow's core APIs.","links":[{"article_link":"https://app.wandb.ai/sayakpaul/simclr/reports/Towards-self-supervised-image-understanding-with-SimCLR--VmlldzoxMDI5NDM","code_link":"https://github.com/sayakpaul/SimCLR-in-TensorFlow-2","research_link":"https://arxiv.org/abs/2002.05709","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":784,"title":"Haystack \u2014 Neural Question Answering At Scale","description":"Scaling Question Answering models to find answers in large document stores via retriever and reader approach.","tags":["code","library","information-retrieval","natural-language-processing","question-answering","search","neural-search"],"details":"\ud83d\udcc8 Scalable backend for storing & querying documents (currently: Elasticsearch) \r\n\ud83d\ude80 Fast Retrievers (currently: TF-IDF, BM25, Embeddings)\r\n\ud83d\udc53 Flexible Reader Models (currently: Transformers or FARM)\r\n\ud83d\udd04 Modular API for Inference & Feedback (using FastAPI)","links":[{"article_link":"","code_link":"https://github.com/deepset-ai/haystack","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":783,"title":"NeuralCook \u2014 Image2Ingredients and Cooking Recommendation","description":"Deep learning application to identify ingredients from cooking dishes images and recommend dishes to cook, given a set of ingredients.","tags":["article","code","paper","research","tutorial","video","clustering","natural-language-processing","recommendation-systems","text-generation","cooking","joint-embeddings","neuralcook","image2ingredients","semantic-distance"],"details":"* This application leverages NLP and Computer Vision to learn semantic knowledge using joint embeddings.\r\n* We built web application and consumable REST APIs for users to integrate them into their applications, evaluate and capture feedback. ","links":[{"article_link":"https://medium.com/neuralcook/neuralcook-image2ingredients-and-cooking-recommendation-using-deep-learning-94b51d4429c9","code_link":"https://github.com/SumithBaddam/NeuralCook","research_link":"https://github.com/SumithBaddam/NeuralCook/blob/master/NeuralCook.pdf","media_link":"https://www.youtube.com/watch?v=LZZms_tspOI","dataset_link":"","demo_link":"","other_link":""}]},{"id":782,"title":"Digit Recognizer","description":"Simple MNIST based digit recognizer. Deployed over Heroku using Flask.\r\nhttps://digit-detect.herokuapp.com/","tags":["code","tutorial","flask","onnx","deep-learning","mnist"],"details":"The aim is to learn how to easily deploy apps using Flask framework. \r\nMany people train Machine Learning model but do not know how to deploy it. I have deployed a trained CNN using ONNX format.\r\nPlus, we use the ONNX format which makes it easy to export and run using OpenCV. It does not require other heavy libraries.\r\nDeploying a simple web app over Heroku.\r\n","links":[{"article_link":"","code_link":"https://github.com/oke-aditya/digit_recognizer","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://digit-detect.herokuapp.com/"}]},{"id":781,"title":"Various Generative Adversarial Nets in TensorFlow2","description":"GANs-TensorFlow2 is a repository that implements a variety of popular Generative Adversarial Network algorithms using TensorFlow2. The key to this repository ..","tags":["code","keras","tensorflow","deep-learning","generative-adversarial-networks","machine-learning"],"details":"GANs-TensorFlow2 is a repository that implements a variety of popular Generative Adversarial Network algorithms using TensorFlow2. The key to this repository is an easy-to-understand code. Therefore, if you are a student or a researcher studying Deep Reinforcement Learning, I think it would be the best choice to study with this repository. One algorithm relies only on one python script file. So you don't have to go in and out of different files to study specific algorithms. This repository is constantly being updated and will continue to add a new Generative Adversarial Network algorithm.","links":[{"article_link":"","code_link":"https://github.com/marload/GANs-TensorFlow2","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":780,"title":"Med7 - clinical natural language processing for EHR","description":"Med7 is a transferable clinical natural language processing model for electronic health records, compatible with spaCy, for named-entity recognition task","tags":["article","code","paper","research","tutorial","spacy","health","healthcare","library","named-entity-recognition","natural-language-processing","clinical-ner","med7","arxiv:2003.01271"],"details":"The `en_core_med7_lg` model is trained on MIMIC-III free-text electronic health records. Contains a full pipeline with: tagger, parser and clinical NER with seven categories (dosage, drugs, duration, form, frequency, route and strength).","links":[{"article_link":"https://medium.com/@kormilitzin/med7-clinical-information-extraction-system-in-python-and-spacy-5e6f68ab1c68","code_link":"https://github.com/kormilitzin/med7","research_link":"https://arxiv.org/abs/2003.01271","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":779,"title":"Neural Nets- Easy(Keras) vs Hard(Numpy)","description":"Building MLPs in Keras vs Numpy","tags":["article","code","tutorial","keras","feed-forward-neural-networks","machine-learning","multilayer-perceptrons"],"details":"- Building a Neural net architecture\r\n- Working of Backpropagation\r\n- Implementation of a four-layered network from scratch","links":[{"article_link":"https://towardsdatascience.com/neural-networks-from-scratch-easy-vs-hard-b26ddc2e89c7","code_link":"https://github.com/chmodsss/Neural-Networks/tree/master/NN-Keras-vs-Numpy","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":778,"title":"Harry Potter and the Deep Learning Experiment","description":"RNN built with TensorFlow to generate text based on Harry Potter's books.","tags":["article","code","tutorial","tensorflow","deep-learning","recurrent-neural-networks","natural-language-processing","text-generation"],"details":"","links":[{"article_link":"https://towardsdatascience.com/harry-potter-and-the-deep-learning-experiment-7b312d4b03c0","code_link":"https://github.com/santiviquez/harry-potter-rnn","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://harry-dl.uc.r.appspot.com/"}]},{"id":745,"title":"Rusklainer","description":"Identification of contributing features towards the rupture risk prediction of intracranial aneurysms using LIME explainer","tags":["research","tutorial","machine-learning","front-end-design","health","healthcare","library","interpretability","lime","explainability"],"details":"1. To study the effects of LIME surrogate models on a tabular dataset of intracranial aneurysms\r\n2. Study the hyperparameters of LIME\r\n3. Provide a interactive web application for users to perceive the effects of LIME as well as derive inferences from the same.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://rusklainer.herokuapp.com"}]},{"id":744,"title":"Automobile Sales Pipeline Forecast ","description":"To plan the marketing spends and target meet monthly, sales pipeline forecast using machine learning model at line of business level.","tags":["code","tutorial","random-forests","automobile","finance","sales","forecasting","decision-tree","xgboost","hyperparameter-optimization"],"details":"To plan the marketing spends and target meet monthly, sales pipeline forecast using machine learning model at line of business level.","links":[{"article_link":"","code_link":"https://github.com/ankit013/Projects-R-programming/blob/master/Automotive_Sales_Pipeline_Prediction.R","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":743,"title":"A tale of quantization in TF Lite","description":"Model optimization strategies and quantization techniques to help deploy machine learning models in resource-constrained environments.","tags":["article","code","tutorial","tensorflow","model-compression","quantization","tensorflow-lite","wandb"],"details":"In this report, I will show you how TensorFlow Lite (TF Lite) can really shine in situations like this. We'll cover model optimization strategies and quantization techniques supported by TensorFlow.","links":[{"article_link":"https://bit.ly/2W9Fst5","code_link":"https://github.com/sayakpaul/Adventures-in-TensorFlow-Lite","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":742,"title":"AIMET - Model Efficiency Toolkit","description":"AIMET is a library that provides advanced model quantization and compression techniques for trained neural network models.","tags":["code","library","model-compression","quantization","aimet","qualcomm"],"details":"Quantization\r\n\u2022\u00a0Cross-Layer Equalization: Equalize weight tensors to reduce amplitude variation across channels\r\n\u2022\u00a0Bias Correction: Corrects shift in layer outputs introduced due to quantization\r\n\u2022\u00a0Quantization Simulation: Simulate on-target quantized inference accuracy\r\n\u2022\u00a0Fine-tuning: Use quantization simulation to train the model further to improve accuracy\r\n\r\nModel Compression\r\n\u2022\u00a0Spatial SVD: Tensor decomposition technique to split a large layer into two smaller ones\r\n\u2022\u00a0Channel Pruning: Removes redundant input channels from a layer and reconstructs layer weights\r\n\u2022\u00a0Per-layer compression-ratio selection: Automatically selects how much to compress each layer in the model\r\n\r\nVisualization\r\n\u2022\u00a0Weight ranges: Inspect visually if a model is a candidate for applying the Cross Layer Equalization technique. And the effect after applying the technique\r\n\u2022\u00a0Per-layer compression sensitivity: Visually get feedback about the sensitivity of any given layer in the model to compression","links":[{"article_link":"","code_link":"https://github.com/quic/aimet","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://quic.github.io/aimet-pages/index.html"}]},{"id":741,"title":"Zero-shot Neural Retrieval via Domain-targeted Synthetic Queries","description":"Zero-shot learning for ad-hoc retrieval models that relies on synthetic query generation.","tags":["article","paper","research","transformers","information-retrieval","natural-language-processing","question-answering","covid-19","semantic-search","arxiv:2004.14503"],"details":"Crucially, the query generation system is trained on general domain data, but is applied to documents in the targeted domain. This allows us to create arbitrarily large, yet noisy, query-document relevance pairs that are domain targeted. On a number of benchmarks, we show that this is an effective strategy for building neural retrieval models for specialised domains.","links":[{"article_link":"https://ai.googleblog.com/2020/05/an-nlu-powered-tool-to-explore-covid-19.html","code_link":"","research_link":"https://arxiv.org/abs/2004.14503","media_link":"","dataset_link":"","demo_link":"","other_link":"https://covid19-research-explorer.appspot.com/"}]},{"id":740,"title":"ML-Neural Networks","description":"Designing an Artificial Neural Network for Multi-class classification of MNIST data using NumPy.","tags":["code","tutorial","feed-forward-neural-networks","backpropagation"],"details":"Designing an Artificial Neural Network for Multi-class classification of MNIST data using NumPy.","links":[{"article_link":"","code_link":"https://github.com/vj2050/ML-Neural-Networks.git","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":739,"title":"Breast-Cancer Prediction and Classification","description":"Implementing Different Classification Models for Breast Cancer Prediction and comparing their performance using scikit-learn.","tags":["code","tutorial","scikit-learn","machine-learning","health","classification"],"details":"Implementing Different Classification Models for Breast Cancer Prediction and comparing their prediction accuracies.","links":[{"article_link":"","code_link":"https://github.com/vj2050/Classification.git","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":738,"title":"Machine-Learning-Single-Layer-Multiclass-Perceptron","description":"Implemented a Single Layer Perceptron and applied it on the MNIST dataset for multi-class classification using NumPy.","tags":["code","tutorial","machine-learning","computer-vision","image-classification"],"details":"Implemented a Single Layer Perceptron and applied it on the MNIST dataset for multi-class classification using NumPy.","links":[{"article_link":"","code_link":"https://github.com/vj2050/Machine-Learning-Perceptron.git","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":737,"title":"Nature-Scene Classification using FASTAI","description":"Classifying Nature-scene images using deep learning  with fastai library","tags":["code","tutorial","fastai","deep-learning","computer-vision","image-classification"],"details":"The objective is to classify Multi-label images using deep learning. \r\nHere I have used Fastai library for implementing the model. ","links":[{"article_link":"","code_link":"https://github.com/dhruvbpatel/deep_learning_projects/tree/master/Intel-Multiclass-Image-Classification-Using-fastai","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.kaggle.com/dhruvpatel1057/image-classification-using-fastai-94-accuracy"}]},{"id":736,"title":"Mixed-precision training for tf.keras models","description":"Discusses several methods to incorporate mixed-precision training for tf.keras models. ","tags":["article","code","tutorial","keras","tensorflow","deep-learning","wandb","mixed-precision-training","fast-training-methods"],"details":"In this article, we are going to see how to incorporate mixed precision (MP) training in your tf.keras training workflows. Mixed precision training was proposed by NVIDIA in this paper (https://arxiv.org/abs/1710.03740).","links":[{"article_link":"https://www.wandb.com/articles/mixed-precision-training-with-tf-keras","code_link":"https://github.com/sayakpaul/Mixed-Precision-Training-in-tf.keras-2.0","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":735,"title":"Lead Scoring Model for Hospitality industry","description":"Build a propensity model to identify the leads with higher chances to sales.","tags":["code","research","r","logistic-regression","regression","hospitality","lead-scoring","binaryclassification"],"details":"Build a propensity model to identify the leads with higher chances to sales.","links":[{"article_link":"","code_link":"https://github.com/ankit013/Lead-Scoring-Model","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":734,"title":"Generating SOAP Notes from Doctor-Patient Conversations","description":"Evaluate complete pipelines for leveraging these transcripts to train machine learning model to generate these notes.","tags":["paper","research","health","natural-language-processing","text-generation","text-summarization","soap-notes","arxiv:2005.01795"],"details":"Following each patient visit, physicians must draft detailed clinical summaries called SOAP notes. Moreover, with electronic health records, these notes must be digitized. For all the benefits of this documentation the process remains onerous, contributing to increasing physician burnout. In a parallel development, patients increasingly record audio from their visits (with consent), often through dedicated apps. In this paper, we present the first study to evaluate complete pipelines for leveraging these transcripts to train machine learning model to generate these notes. We first describe a unique dataset of patient visit records, consisting of transcripts, paired SOAP notes, and annotations marking noteworthy utterances that support each summary sentence. We decompose the problem into extractive and abstractive subtasks, exploring a spectrum of approaches according to how much they demand from each component.","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2005.01795","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":733,"title":"LandCover.ai","description":"Dataset for automatic mapping of buildings, woodlands and water from aerial imagery.","tags":["dataset","paper","research","library","computer-vision","aerial-imagery","landcover","arxiv:2005.02264"],"details":"The LandCover.ai (Land Cover from Aerial Imagery) dataset is a dataset for automatic mapping of buildings, woodlands and water from aerial images.\r\n\u2022\u00a0land cover from Poland, Central Europe\r\n\u2022\u00a0three spectral bands - RGB\r\n\u2022\u00a033 orthophotos with 25 cm per pixel resolution (~9000x9500 px)\r\n\u2022\u00a08 orthophotos with 50 cm per pixel resolution (~4200x4700 px)\r\n\u2022\u00a0segmentation masks for three classes: buildings, woodlands and water\r\n\u2022\u00a0total area of 216.27 km2 (1.85 km2 of buildings, 72.22 km2 of woodlands, 13.25 km2 of water)","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2005.02264","media_link":"","dataset_link":"","demo_link":"","other_link":"http://landcover.ai/"}]},{"id":732,"title":"StellarGraph - Machine Learning on Graphs","description":"State-of-the-art algorithms for graph machine learning, making it easy to discover patterns and answer questions about graph-structured data.","tags":["code","graph-convolutional-networks","library","graph-neural-networks","graphs","stellargraph"],"details":"It can solve many machine learning tasks:\r\n\u2022\u00a0Representation learning for nodes and edges, to be used for visualisation and various downstream machine learning tasks;\r\n\u2022\u00a0Classification and attribute inference of nodes or edges;\r\n\u2022\u00a0Classification of whole graphs;\r\n\u2022\u00a0Link prediction;\r\n\u2022\u00a0Interpretation of node classification [8].","links":[{"article_link":"","code_link":"https://github.com/stellargraph/stellargraph","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.stellargraph.io/"}]},{"id":731,"title":"Introduction to Geometric Deep Learning","description":"Geometric Deep Learning (GDL) -  interpreting it in the context of relational inductive bias, a statistical reasoning term.","tags":["article","tutorial","graph-classification","graphs","geometric-deep-learning","graph-segmentation"],"details":"\u2022\u00a0Introduction\r\n\u2022\u00a0Geometric Deep Learning\r\n\u2022\u00a0Statistical Reasoning\r\n\u2022\u00a0Interesting use-cases\r\n\u2022\u00a0Graph Segmentation\r\n\u2022\u00a0Graph Classification\r\n\u2022\u00a0Real use-cases\r\n\u2022\u00a0Conclusion","links":[{"article_link":"https://blog.paperspace.com/introduction-to-geometric-deep-learning/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":730,"title":"cuML - GPU Machine Learning Algorithms","description":"cuML is a suite of libraries that implement ML algorithms and mathematical primitives functions that share compatible APIs with other RAPIDS projects.","tags":["code","library","rapidsai","nvidia","cuml"],"details":"\u2022\u00a0cuML enables data scientists, researchers, and software engineers to run traditional tabular ML tasks on GPUs without going into the details of CUDA programming. In most cases, cuML's Python API matches the API from scikit-learn.\r\n\u2022\u00a0For large datasets, these GPU-based implementations can complete 10-50x faster than their CPU equivalents. For details on performance, see the cuML Benchmarks Notebook.","links":[{"article_link":"","code_link":"https://github.com/rapidsai/cuml","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://rapids.ai/"}]},{"id":729,"title":"Fast Support Vector Classification with RAPIDS cuML","description":"In this post, we will discuss how you can use the SVM package in RAPIDS cuML to perform fast support vector classification on a GPU.","tags":["article","support-vector-machines","library","rapidsai","nvidia","cuml"],"details":"cuML SVM can provide a speedup of 500x relative to scikit-learn SVM and it is up to 50x faster than the multi-threaded ThunderSVM library on a CPU.","links":[{"article_link":"https://medium.com/rapids-ai/fast-support-vector-classification-with-rapids-cuml-6e49f4a7d89e","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":728,"title":"PCGrad: Gradient Surgery for Multi-Task Learning","description":"Code for \"Gradient Surgery for Multi-Task Learning\"","tags":["code","paper","research","tutorial","pytorch","tensorflow","library","multi-task-learning","loss","pcgrad","arxiv:2001.06782"],"details":"This repository contains code for Gradient Surgery for Multi-Task Learning in TensorFlow v1.0+ (PyTorch implementation forthcoming).\r\n\r\nPCGrad is a form of gradient surgery that projects a task\u2019s gradient onto the normal plane of the gradient of any other task that has a conflicting gradient, which achieves substantial gains in efficiency and performance on a range of supervised multi-task learning and multi-task reinforcement learning domains. Moreover, it is model-agnostic and can be combined with previously-proposed multitask architectures for enhanced performance.","links":[{"article_link":"","code_link":"https://github.com/tianheyu927/PCGrad","research_link":"https://arxiv.org/abs/2001.06782","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":727,"title":"Exploring Bayesian Optimization","description":"Breaking Bayesian Optimization into small, sizeable chunks.","tags":["article","tutorial","bayesian-deep-learning","bayesian-optimization","hyperparameter-optimization"],"details":"Many modern machine learning algorithms have a large number of hyperparameters. To effectively use these algorithms, we need to pick good hyperparameter values. In this article, we talk about Bayesian Optimization, a suite of techniques often used to tune hyperparameters. More generally, Bayesian Optimization can be used to optimize any black-box function.","links":[{"article_link":"https://distill.pub/2020/bayesian-optimization/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":726,"title":"ConvNets-TensorFlow2","description":"Implementing a variety of popular and important CNN architectures","tags":["code","tutorial","keras","tensorflow","convolutional-neural-networks","deep-learning","computer-vision"],"details":"\u26f5\ufe0f Implementation a variety of popular Image Classification Models using TensorFlow2. [ResNet, GoogleNet, VGG, Inception-v3, Inception-v4, MobileNet, MobileNet-v2, ShuffleNet, ShuffleNet-v2, etc...]","links":[{"article_link":"","code_link":"https://github.com/marload/ConvNets-TensorFlow2","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":725,"title":"CNN Block Image PuzzleSolver","description":"Solving Block Image Puzzle with neural networks (WebApp Solution)","tags":["article","code","tutorial","library","puzzles","streamlit","cnn","webapp"],"details":"How it works\r\n* The solution image will split into the blocks the same as provided into shuffle image\r\n* The neural networks will be developed to find the closest block from the training data to match with solution block\r\n* The result set will be the ordered list of the block from training images to solve the puzzle\r\n* Using the order list of the block, the final solution image is generated from the blocks of shuffle image","links":[{"article_link":"https://medium.com/@avkashchauhan/solving-block-image-puzzle-with-neural-networks-webapp-solution-5ade03e5bc8","code_link":"https://github.com/Avkash/demoapps/tree/master/PuzzleSolver","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":724,"title":"First Steps with Tensorflow","description":"Learn LinearRegression with Tensorflow","tags":["code","notebook","tutorial","python","tensorflow","linear-regression","regression"],"details":"Use the LinearRegressor class in TensorFlow to predict median housing price, at the granularity of city blocks, based on one input feature\r\nEvaluate the accuracy of a model's predictions using Root Mean Squared Error (RMSE)\r\nImprove the accuracy of a model by tuning its hyperparameters","links":[{"article_link":"","code_link":"https://colab.research.google.com/notebooks/mlcc/first_steps_with_tensor_flow.ipynb#scrollTo=4f3CKqFUqL2-","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":723,"title":"DeepWay: Autonomous navigation for blind.","description":"I have tried to make something which can be used by blind people to navigate around the streets. Have a look at the video and GitHub repo for details.","tags":["code","video","library","computer-vision","segmentation","unet","blind-navigation","arduino","jetson-nano"],"details":"The key highlights are navigation for the blind. There are other solutions which use audion ques to communicate the decision of the system to the blind person. I thought of using touch feedback. Also, the entire system runs on an embedded device(Jetson nano).","links":[{"article_link":"","code_link":"https://github.com/satinder147/DeepWay.v2","research_link":"","media_link":"https://www.youtube.com/watch?v=ks8Rsd65RnM","dataset_link":"","demo_link":"","other_link":""}]},{"id":721,"title":"Mutual Fund Ratings Predictions ","description":"To predict the ratings of mutual fund. In order to help investors decide on which mutual fund to pick for an investment.","tags":["code","notebook","tutorial","scikit-learn","random-forests","finance","pandas","numpy","gradient-boosting","decision-tree","xgboost","mutual-funds","multiclass-classification","light-gbm","cat-boost","voting-classifier","ovr-classifier"],"details":"To predict the ratings of mutual fund. In order to help investors decide on which mutual fund to pick for an investment.","links":[{"article_link":"","code_link":"https://github.com/ankit013/Mutual-Fund-Rating-Prediction-using-LightGBM-Tree-based-Classifier","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":720,"title":"Sentiment Prediction of Google Play Store Reviews with Tensorflow","description":"How to train your own algorithm to classify the sentiment of the reviews of your app from scratch.","tags":["article","tutorial","keras","tensorflow"],"details":"Steps:\r\n\u2022\u00a0Get the data\r\n\u2022\u00a0Preprocess the data\r\n\u2022\u00a0Preprocess the text\r\n\u2022\u00a0Vectorize the data\r\n\u2022\u00a0Create the model\r\n\u2022\u00a0Train the model","links":[{"article_link":"https://www.google.com/amp/s/mc.ai/sentiment-prediction-of-google-play-store-reviews-with-tensorflow-2-0/?amp","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":719,"title":"Interactive Machine Learning Experiments","description":"\ud83e\udd16 Interactive Machine Learning experiments: \ud83c\udfcb\ufe0fmodels training + \ud83c\udfa8models demo","tags":["article","code","tutorial","javascript","python","tensorflow","tensorflow-js","artificial-general-intelligence","machine-learning"],"details":"Although the models may be a little dumb (remember, these are just experiments, not a production ready code), they will try to do their best to:\r\n\r\n* \ud83d\udd8c Recognize digits or sketches you draw in your browser\r\n* \ud83d\udcf8 Detect and recognize the objects you'll show to your camera\r\n* \ud83c\udf05 Classify your uploaded image\r\n* \ud83d\udcdd Write a Shakespeare poem with you\r\n* \u270a\ud83d\udd90\u270c\ufe0f Play with you in Rock-Paper-Scissors game","links":[{"article_link":"https://dev.to/trekhleb/interactive-machine-learning-experiments-3ga7","code_link":"https://github.com/trekhleb/machine-learning-experiments","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://trekhleb.github.io/machine-learning-experiments/#/"}]},{"id":718,"title":"Movie Recommendation Engine","description":"Content-Based Recommendations: Content-Based Recommendation algorithm takes into account the likes and dislikes of the user and generates a User Profile.","tags":["article","tutorial","machine-learning","recommendation-systems","data-science"],"details":"Content-Based Recommendations: Content-Based Recommendation algorithm takes into account the likes and dislikes of the user and generates a User Profile. For generating a user profile, we take into account the item profiles( vector describing an item) and their corresponding user rating. The user profile is the weighted sum of the item profiles with weights being the rating user rated. Once the user profile is generated, we calculate the similarity of the user profile with all the items in the dataset, which is calculated using cosine similarity between the user profile and item profile. Advantages of Content-Based approach is that data of other users is not required and the recommender engine can recommend new items which are not rated currently, but the recommender algorithm doesn\u2019t recommend the items outside the category of items the user has rated.","links":[{"article_link":"http://ailearnings.org/movie-recommendation-engine/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":717,"title":"Synthesizer: Rethinking Self-Attention in Transformer Models","description":"The dot product self-attention is known to be central and indispensable to state-of-the-art Transformer models. But is it really required?","tags":["paper","research","attention","transformers","natural-language-processing","synthesizers","arxiv:2005.00743"],"details":"This paper investigates the true importance and contribution of the dot product-based self-attention mechanism on the performance of Transformer models.","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2005.00743","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":716,"title":"RIP correlation. Introducing the Predictive Power Score","description":"We define and open-source the Predictive Power Score (PPS). The PPS is an alternative to the correlation that finds more patterns in your data.","tags":["article","code","library","metrics","correlation","predictive-power-score","pps"],"details":"","links":[{"article_link":"https://8080labs.com/blog/posts/rip-correlation-introducing-the-predictive-power-score-pps/","code_link":"https://github.com/8080labs/ppscore","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":715,"title":"Taxonomy of Real Faults in Deep Learning Systems","description":"Large taxonomy of faults in deep learning (DL) systems.","tags":["paper","research","deep-learning","checklist","bugs","arxiv:1910.11015"],"details":"We have manually analysed 1059 artefacts gathered from GitHub commits and issues of projects that use the most popular DL frameworks (TensorFlow, Keras and PyTorch) and from related Stack Overflow posts. Structured interviews with 20 researchers and practitioners describing the problems they have encountered in their experience have enriched our taxonomy with a variety of additional faults that did not emerge from the other two sources. Our final taxonomy was validated with a survey involving an additional set of 21 developers, confirming that almost all fault categories (13/15) were experienced by at least 50% of the survey participants.","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/1910.11015","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":714,"title":"Digit Classification of MNIST Dataset using Tensorflow Lite","description":"Created an Android App which classifies and reconizes digit of MNIST dataset using Tensorflow-Lite and Keras.Trained the model on Laptop and deployed it on the ","tags":["code","keras","tensorflow","library","classification","tensorflow-lite","mnist"],"details":"The objective of the project was to understand how the tf-lite model works on mobile devices","links":[{"article_link":"","code_link":"https://github.com/pdx97/Digit-Classification-of-MNIST-Dataset-using-Tensorflow-Lite","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":713,"title":"Cognito : Data wrangling toolkit","description":"Cognito is an exclusive python data preprocessing library and command-line utility that helps any developer to transform raw data into a machine-learning format","tags":["article","code","machine-learning","library","automl","imputation","preprocessing","time-series","audit"],"details":"1. Data Preprocessing\r\n2. Auto Data Imputation\r\n3. Data Audit\r\n4. AutoML","links":[{"article_link":"https://cognito.readthedocs.io","code_link":"https://github.com/CleverInsight/cognito","research_link":"","media_link":"https://youtu.be/BMulWSXEopc","dataset_link":"","demo_link":"","other_link":""}]},{"id":712,"title":"Covid-19: A-Geo-Statistical-Analysis","description":"Analysis with the time series data available for various countries.","tags":["code","research","tutorial","time-series","covid19"],"details":"Data Source - https://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset","links":[{"article_link":"","code_link":"https://github.com/sauravmishra1710/Covid-19---A-Geo-Statistical-Analysis","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset"}]},{"id":711,"title":"C++ Implementation of PyTorch Tutorials for Everyone","description":"This repository provides tutorial code in C++ to learn PyTorch by building CNNs, RNNs, etc. Tutorials are divided into three sections based on complexity.","tags":["code","research","tutorial","c++","pytorch","torch","convolutional-neural-networks","deep-learning","machine-learning","neural-networks","recurrent-neural-networks","libtorch","torchscript"],"details":"This repository provides tutorial code in C++ to learn PyTorch by building CNNs, RNNs, etc. Tutorials are divided into three sections based on complexity.","links":[{"article_link":"","code_link":"https://github.com/prabhuomkar/pytorch-cpp","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":710,"title":"Differential Subspace Search in High-Dimensional Latent Space","description":"Differential subspace search to allow efficient iterative user exploration in such a space, without relying on domain- or data-specific assumptions.","tags":["paper","research","video","audio","audio-generation","computer-vision","dimensionality-reduction","generation","image-generation","generative-models","latent-space","singular-value-decompoition"],"details":"We develop a general framework to extract low-dimensional subspaces based on a local differential analysis of the generative model, such that a small change in such a subspace would provide enough change in the resulting data. We do so by applying singular value decomposition to the Jacobian of the generative model and forming a subspace with the desired dimensionality spanned by a given number of singular vectors stochastically selected on the basis of their singular values, to maintain ergodicity. ","links":[{"article_link":"","code_link":"","research_link":"http://www.cg.it.aoyama.ac.jp/yonghao/sig20/dss.pdf","media_link":"https://www.youtube.com/watch?v=AQCmzGz4kTg&feature=youtu.be","dataset_link":"","demo_link":"","other_link":"http://www.cg.it.aoyama.ac.jp/yonghao/sig20/abstsig20.html"}]},{"id":709,"title":"Expertise Style Transfer: A New Task Towards Better Communication","description":"A New Task Towards Better Communication between Experts and Laymen","tags":["paper","research","computer-vision","natural-language-processing","style-transfer","text-generation","communication","arxiv:2005.00701"],"details":"We propose a new task of expertise style transfer and contribute a manually annotated dataset with the goal of alleviating such cognitive biases. ","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2005.00701","media_link":"","dataset_link":"","demo_link":"","other_link":"https://srhthu.github.io/expertise-style-transfer/"}]},{"id":708,"title":"POINTER: Constrained Text Generation","description":"Constrained Text Generation via Insertion-based Generative Pre-training","tags":["paper","research","attention","bert","transformers","natural-language-processing","text-generation","lexical-constraints","arxiv:2005.00558"],"details":"we present POINTER, a simple yet novel insertion-based approach for hard-constrained text generation. The proposed method operates by progressively inserting new tokens between existing tokens in a parallel manner. This procedure is recursively applied until a sequence is completed. The resulting coarse-to-fine hierarchy makes the generation process intuitive and interpretable. Since our training objective resembles the objective of masked language modeling, BERT can be naturally utilized for initialization. We pre-train our model with the proposed progressive insertion-based objective on a 12GB Wikipedia dataset, and fine-tune it on downstream hard-constrained generation tasks. Non-autoregressive decoding yields a logarithmic time complexity during inference time. Experimental results on both News and Yelp datasets demonstrate that POINTER achieves state-of-the-art performance on constrained text generation. ","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2005.00558","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":707,"title":"The Big Bad NLP Database","description":"A collection of 400+ NLP datasets with papers included.","tags":["library","natural-language-processing","datasets"],"details":"A collection of 400+ NLP datasets with papers included.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://datasets.quantumstat.com/"}]},{"id":706,"title":"GNNExplainer: Generating Explanations for Graph Neural Networks","description":"General tool for explaining predictions made by graph neural networks (GNNs).","tags":["code","research","tutorial","library","graph-neural-networks","graphs","interpretability","explainability"],"details":"Given a trained GNN model and an instance as its input, the GNN-Explainer produces an explanation of the GNN model prediction via a compact subgraph structure, as well as a set of feature dimensions important for its prediction.","links":[{"article_link":"","code_link":"https://github.com/RexYing/gnn-model-explainer","research_link":"","media_link":"https://ls11-www.cs.tu-dortmund.de/staff/morris/graphkerneldatasets","dataset_link":"","demo_link":"","other_link":"http://snap.stanford.edu/gnnexplainer/"}]},{"id":705,"title":"Deep Learning With Graph-Structured Representations","description":"Novel approaches based on the theme of structuring the representations and computations of neural network-based models in the form of a graph.","tags":["article","research","tutorial","graph-convolutional-networks","graph-neural-networks","graphs","graph-auto-encoders","relational-graph-convolutional-networks","neural-relational-inference"],"details":"Contributions: \r\n\r\n* graph convolutional networks (GCNs)\r\n* graph auto-encoders (GAEs)\r\n* relational GCNs\r\n* neural relational inference (NRI) \r\n* compositional imitation learning and execution (CompILE)\r\n* contrastively-trained structured world models (C-SWMs)","links":[{"article_link":"https://pure.uva.nl/ws/files/46900201/Thesis.pdf","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":704,"title":"Training Batch Norm and Only Batch Norm","description":"Experiments with the ideas presented in https://arxiv.org/abs/2003.00152 by Frankle et al. ","tags":["article","code","paper","research","deep-learning","computer-vision","representation-learning","wandb","sparse-networks","arxiv:2003.00152"],"details":"Batch normalization (BatchNorm) has become an indispensable tool for training deep neural networks, yet it is still poorly understood. Although previous work has typically focused on its normalization component, BatchNorm also adds two per-feature trainable parameters: a coefficient and a bias. However, the role and expressive power of these parameters remains unclear. To study this question, we investigate the performance achieved when training only these parameters and freezing all others at their random initializations.","links":[{"article_link":"https://app.wandb.ai/sayakpaul/training-bn-only/reports/The-Power-of-Random-Features-of-a-CNN--VmlldzoxMTIxODA","code_link":"https://github.com/sayakpaul/Training-BatchNorm-and-Only-BatchNorm","research_link":"https://arxiv.org/abs/2003.00152","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":703,"title":"Implementing Graph Neural Networks with JAX","description":"I\u2019ll talk about my experience on how to build and train Graph Neural Networks (GNNs) with JAX.","tags":["article","tutorial","jax","graph-neural-networks","graphs"],"details":"In this post I\u2019ll focus on Graph Convolutional Networks (GCNs) and Graph Attention Networks (GATs), but there are several more models.","links":[{"article_link":"http://gcucurull.github.io/deep-learning/2020/04/20/jax-graph-neural-networks/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":702,"title":"Unsupervised Question Decomposition for Question Answering","description":"Decompose hard (multi-hop) questions into several, easier (single-hop) questions using unsupervised learning, and get better accuracy on multi-hop QA.","tags":["article","code","paper","research","deep-learning","machine-learning","natural-language-processing","question-answering","unsupervised-learning","arxiv:2002.09758"],"details":"We aim to improve question answering (QA) by decomposing hard questions into easier sub-questions that existing QA systems can answer. Since collecting labeled decompositions is cumbersome, we propose an unsupervised approach to produce sub-questions. Specifically, by leveraging >10M questions from Common Crawl, we learn to map from the distribution of multi-hop questions to the distribution of single-hop sub-questions. We answer sub-questions with an off-the-shelf QA model and incorporate the resulting answers in a downstream, multi-hop QA system. On a popular multi-hop QA dataset, HotpotQA, we show large improvements over a strong baseline, especially on adversarial and out-of-domain questions. Our method is generally applicable and automatically learns to decompose questions of different classes, while matching the performance of decomposition methods that rely heavily on hand-engineering and annotation.","links":[{"article_link":"https://medium.com/@ethanperez18/unsupervised-question-decomposition-for-question-answering-9b81c5f7a71d","code_link":"https://github.com/facebookresearch/UnsupervisedDecomposition","research_link":"https://arxiv.org/abs/2002.09758","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":701,"title":"A Collection of Conference & School Notes in Machine Learning","description":"Machine Learning Conference & Summer School Notes. \ud83e\udd84\ud83d\udcdd\ud83c\udf89","tags":["code","tutorial","machine-learning","illustrated","conferences","notes"],"details":"In this repo I collect my visual conference & summer school notes - to prevent things getting messy. Feel free to have a look and enjoy, @RobertTLange!","links":[{"article_link":"","code_link":"https://github.com/visual-ml-notes/visual-machine-learning-notes","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://visual-ml-notes.github.io/"}]},{"id":700,"title":"Fastai2 Vision Module","description":"A detailed guide to using fastai2 Datablock API for common computer vision tasks","tags":["article","tutorial","fastai","computer-vision"],"details":"Understand how the datablock API works for the most common vision tasks.","links":[{"article_link":"https://tezike.github.io/blog/posts/2020/04/01/Understanding-fastai-vision.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":699,"title":"Linear Algebra Series","description":"This Linear Algebra series is a set of 12 blog posts to provide intuitions/drawing/python code on basics of Linear Algebra.","tags":["code","tutorial","linear-algebra"],"details":"This linear algebra series based on The Deep Learning Book is a set of 12 blog posts and Python notebooks going through the chapter on linear algebra from the Deep Learning Book by Goodfellow, I., Bengio, Y., and Courville, A. (2016).","links":[{"article_link":"","code_link":"https://github.com/hadrienj/deepLearningBook-Notes","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://hadrienj.github.io/deep-learning-book-series-home/"}]},{"id":698,"title":"Breast Cancer Classification","description":"I have used the KNN algorithm to classify the tumor as benign or malignant","tags":["code","tutorial","scikit-learn","health","pandas","k-nearest-neighbors","tumor-prediction"],"details":"Using sklearn with pandas and KNN algorithm to develop a prediction model for malignant and benign tumors.","links":[{"article_link":"","code_link":"https://github.com/digs1998/Breast_Cancer_Classification","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":697,"title":"Explainable Deep Learning: A Field Guide for the Uninitiated","description":"A field guide to deep learning explainability for those uninitiated in the field.","tags":["paper","research","deep-learning","interpretability","explainability","survey","arxiv:2004.14545"],"details":"* Discusses the traits of a deep learning system that researchers enhance in explainability research.\r\n* Places explainability in the context of other related deep learning research areas\r\n* Introduces three simple dimensions defining the space of foundational methods that contribute to explainable deep learning. ","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2004.14545","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":696,"title":"Deep Learning Drizzle","description":"Collection of freely available Deep Learning, Machine Learning, Reinforcement Learning, Optimization, Natural Language Processing, and Computer Vision lectures.","tags":["article","code","tutorial","machine-learning","collection"],"details":"Learn the fundamentals as well as advanced concepts from a wide range of freely available courses from top schools around the world.\r\n\r\n\"stay hungry. stay smarter!\"","links":[{"article_link":"https://deep-learning-drizzle.github.io/","code_link":"https://github.com/kmario23/deep-learning-drizzle","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":695,"title":"Five Cool Python Libraries for Data Science","description":"Python is a best friend for the majority of the Data Scientists. Libraries make their life simpler. I have come across five cool Python libraries while working ","tags":["article","tutorial","python","machine-learning","library","natural-language-processing","data-science"],"details":"1. Numerizer: amazing library to convert text numerics into int and float.\r\n2. Missingo: offers a quick and helpful way to visualize the missing values.\r\n3. Faker: generate fake data for you very quickly when you need to.\r\n4. EMOT: convert the emojis and emoticons into words.\r\n5. Chartify: visualization library that aims to make it as easy as possible for data scientists to create charts.","links":[{"article_link":"https://medium.com/towards-artificial-intelligence/five-cool-python-libraries-for-data-science-7f1fce402b90","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":694,"title":"BLINK: Better entity LINKing","description":"Entity Linking python library that uses Wikipedia as the target knowledge base.","tags":["code","paper","research","library","named-entity-recognition","natural-language-processing","wikification","arxiv:1911.03814"],"details":"In a nutshell, BLINK uses a two stage approach for entity linking, based on fine-tuned BERT architectures. In the first stage, BLINK performs retrieval in a dense space defined by a bi-encoder that independently embeds the mention context and the entity descriptions. Each candidate is then examined more carefully with a cross-encoder, that concatenates the mention and entity text. BLINK achieves state-of-the-art results on multiple datasets.","links":[{"article_link":"","code_link":"https://github.com/facebookresearch/BLINK","research_link":"https://arxiv.org/abs/1911.03814","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":693,"title":"SciTLDR: Extreme Summarization of Scientific Documents","description":"A new automatic summarization task with high source compression requiring expert background knowledge and complex language understanding.","tags":["code","paper","research","tutorial","transformers","natural-language-processing","text-summarization","bart","arxiv:2004.15011"],"details":"This demo generates TLDRs for scientific articles, using our best performing model, which works best when given the abstract, introduction, and conclusion of a paper. However, it will still work if you only provide an abstract. Currently, our model is only trained on English-language papers in the Computer Science domain, although we hope future work will expand to more domains/languages!","links":[{"article_link":"","code_link":"https://github.com/allenai/scitldr","research_link":"https://arxiv.org/abs/2004.15011","media_link":"https://github.com/allenai/scitldr/tree/master/SciTLDR-Data","dataset_link":"","demo_link":"","other_link":"https://scitldr.apps.allenai.org/"}]},{"id":692,"title":"Hands on One-Shot Learning","description":"One-shot learning can be seen as an attempt to create an approach to train machines with a similar ability to learn like humans. Hands-On One-Shot Learning with","tags":["code"],"details":"","links":[{"article_link":"","code_link":"https://github.com/shruti-jadon/Hands-on-One-Shot-Learning","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":691,"title":"scarpet-nn: Programmable Neural Networks in Minecraft","description":"\u26cfTools and libraries to run neural networks in Minecraft.","tags":["code","video","deep-learning","neural-networks","library","minecraft"],"details":"\u2022\u00a0Supports reconfiguring neural networks on the fly\r\n\u2022\u00a0Supports both convolution and fully connected layers\r\n\u2022\u00a0Allows running multiple neural networks in single world\r\n\u2022\u00a0Allows block-by-block visualizations of intermediate activation calculations\r\n\u2022\u00a0Drawingboard \u2013 Lets users draw on a black concrete wall by right clicking with sword","links":[{"article_link":"","code_link":"https://github.com/ashutoshbsathe/scarpet-nn","research_link":"","media_link":"https://www.youtube.com/watch?v=LVmOcAYbYdU","dataset_link":"","demo_link":"","other_link":"https://ashutoshbsathe.github.io/scarpet-nn/"}]},{"id":690,"title":"VIP AI 101 CheatSheet for All (Montr\u00e9al.AI)","description":" Artificial intelligence 101 first world-class overview of AI for all.","tags":["article","tutorial","deep-learning","machine-learning","cheatsheet","montreal-ai"],"details":"For the purpose of entrusting all sentient beings with powerful AI tools to learn, deploy and scale AI\r\nin order to enhance their prosperity, to settle planetary-scale problems and to inspire those who, with\r\nAI, will shape the 21st Century, MONTR\u00c9AL.AI introduces this VIP AI 101 CheatSheet for All.","links":[{"article_link":"http://www.montreal.ai/ai4all.pdf","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://montrealartificialintelligence.com/"}]},{"id":689,"title":"Ensemble Forecasts ","description":"Time series forecasting using classical methods (ETS, Holt-Winter's, SARIMA) and Prophet. I show and discuss advantages of Ensemble Forecast","tags":["article","tutorial","arima","time-series","time-series-forecasting","sarima","ensemble-forecast","fbprophet","ets","holt-winter"],"details":"","links":[{"article_link":"https://pawarbi.github.io/blog/forecasting/r/python/rpy2/altair/fbprophet/ensemble_forecast/uncertainty/simulation/2020/04/21/timeseries-part2.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":688,"title":"Gotchas of Transfer Learning for Image Classification","description":"Discover the things you should care about while doing transfer learning for image classification. ","tags":["article","tutorial","deep-learning","library","computer-vision","transfer-learning"],"details":"I am going to speaking about some of the tricky stuff that come to play while doing transfer learning for image classification. I hope it\u2019d be useful for other domains too. \r\n","links":[{"article_link":"http://bit.ly/tl-sayak","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":687,"title":"Exploratory Data Analysis of Time Series","description":"Exploratory Data Analysis of Time Series data in Python. It uses lot of the principles and concepts discussed in Prof. Hyndman's book. The focus is on understa\r\n","tags":["article","code","notebook","tutorial","time-series","time-series-forecasting"],"details":"Exploratory Data Analysis of Time Series data in Python. It uses lot of the principles and concepts discussed in Prof. Hyndman's book. The focus is on understanding and describing the data in qualitative and quantitative terms, in preparation  for forecasting.","links":[{"article_link":"https://pawarbi.github.io/blog/forecasting/r/python/rpy2/altair/2020/04/21/timeseries-part1.html","code_link":"https://github.com/pawarbi/blog/blob/master/_notebooks/2020-04-24-timeseries-powerbi.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":686,"title":"Jukebox: A Generative Model for Music","description":"We\u2019re introducing Jukebox, a neural net that generates music, including rudimentary singing, as raw audio in a variety of genres and artist styles. ","tags":["article","code","notebook","paper","research","convolutional-neural-networks","transformers","library","audio","music-generation","natural-language-processing","jukebox","openai"],"details":"","links":[{"article_link":"https://openai.com/blog/jukebox/","code_link":"https://github.com/openai/jukebox/","research_link":"https://cdn.openai.com/papers/jukebox.pdf","media_link":"https://colab.research.google.com/github/openai/jukebox/blob/master/jukebox/Interacting_with_Jukebox.ipynb","dataset_link":"","demo_link":"","other_link":"https://jukebox.openai.com/"}]},{"id":685,"title":"CNN Explainer","description":"CNN Explainer uses TensorFlow.js, an in-browser GPU-accelerated deep learning library to load the pretrained model for visualization. ","tags":["code","tutorial","video","d3","tensorflow","tensorflow-js","convolutional-neural-networks","library","interpretability","interactive"],"details":"CNN Explainer uses TensorFlow.js, an in-browser GPU-accelerated deep learning library to load the pretrained model for visualization. ","links":[{"article_link":"","code_link":"https://github.com/poloclub/cnn-explainer","research_link":"","media_link":"https://www.youtube.com/watch?v=HnWIHWFbuUQ","dataset_link":"","demo_link":"","other_link":"https://poloclub.github.io/cnn-explainer/"}]},{"id":684,"title":"WT5?! Training Text-to-Text Models to Explain their Predictions","description":"We leverage the text-to-text framework proposed by Raffel et al.(2019) to train language models to output a natural text explanation alongside their prediction.","tags":["code","paper","research","tutorial","transformers","interpretability","language-modeling","natural-language-processing","t5","text-to-text-transfer-transformer","arxiv:2004.14546"],"details":"","links":[{"article_link":"","code_link":"https://github.com/google-research/google-research/tree/master/wt5","research_link":"https://arxiv.org/abs/2004.14546","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":683,"title":"TAPAS: Weakly Supervised Table Parsing via Pre-training","description":"Using neural networks to find answers in tables.","tags":["article","code","paper","research","attention","bert","transformers","library","natural-language-processing","weak-supervision","table-parsing","tables","tapas","arxiv:2004.02349"],"details":"TAPAS trains from weak supervision, and predicts the denotation by selecting table cells and optionally applying a corresponding aggregation operator to such selection. TAPAS extends BERT's architecture to encode tables as input, initializes from an effective joint pre-training of text segments and tables crawled from Wikipedia, and is trained end-to-end. ","links":[{"article_link":"https://ai.googleblog.com/2020/04/using-neural-networks-to-find-answers.html","code_link":"https://github.com/google-research/tapas","research_link":"https://arxiv.org/abs/2004.02349","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":682,"title":"Using Optuna to Optimize PyTorch Hyperparameters","description":"Let's see how PyTorch and Optuna can work together!","tags":["article","tutorial","pytorch","hyperparameter-optimization","optuna"],"details":"Optuna is a hyperparameter optimization framework applicable to machine learning frameworks and black-box optimization solvers. PyTorch is an open source machine learning framework use by may deep learning programmers and researchers. Let\u2019s see how they can work together!","links":[{"article_link":"https://medium.com/pytorch/using-optuna-to-optimize-pytorch-hyperparameters-990607385e36","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":681,"title":"The AI Economist","description":"Improving Equality and Productivity with AI-Driven Tax Policies","tags":["article","paper","research","library","reinforcement-learning","economics","equality","tax","arxiv:2004.13332"],"details":"The AI Economist learns dynamic tax policies that optimize equality along with productivity in simulated economies, outperforming alternative tax systems.","links":[{"article_link":"https://www.salesforce.com/company/news-press/stories/2020/4/salesforce-ai-economist/","code_link":"","research_link":"https://arxiv.org/abs/2004.13332","media_link":"","dataset_link":"","demo_link":"","other_link":"https://blog.einstein.ai/the-ai-economist/"}]},{"id":680,"title":"Neural Additive Models: Interpretable ML with Neural Nets","description":"Neural Additive Models (NAMs) which combine some of the expressivity of DNNs with the inherent intelligibility of generalized additive models.","tags":["article","code","paper","research","tutorial","feed-forward-neural-networks","interpretability","neural-additive-models","additive-models","arxiv:2004.13912"],"details":"We propose Neural Additive Models (NAMs) which combine some of the expressivity of DNNs with the inherent intelligibility of generalized additive models. NAMs learn a linear combination of neural networks that each attend to a single input feature. These networks are trained jointly and can learn arbitrarily complex relationships between their input feature and the output. \r\n\r\nOfficial Google implementation: [https://github.com/google-research/google-research/tree/master/neural_additive_models](https://github.com/google-research/google-research/tree/master/neural_additive_models)","links":[{"article_link":"https://twitter.com/nickfrosst/status/1255889440083447810","code_link":"https://github.com/theSparta/neural_additive_models/","research_link":"https://arxiv.org/abs/2004.13912","media_link":"","dataset_link":"","demo_link":"","other_link":"https://github.com/google-research/google-research/tree/master/neural_additive_models"}]},{"id":679,"title":"Geometric and Relational Deep Learning","description":"Videos from emerging fields of Graph Representation Learning and Geometric Deep Learning.","tags":["tutorial","graph-convolutional-networks","graph-neural-networks","graphs","representation-learning","graph-representation-learning","grdl-2020","geometric-deep-learning"],"details":"This workshop aims to bring together researchers and practitioners from the emerging fields of Graph Representation Learning and Geometric Deep Learning. ","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://geometric-relational-dl.github.io/","dataset_link":"","demo_link":"","other_link":""}]},{"id":678,"title":"Real-Estate-Transaction-Price-Prediction","description":"In this Project, client has provided us a real estate dataset to predict the Transaction_Price(Sale_Price) of a Property with 42 Explanatory Variables.","tags":["code","notebook","tutorial","linear-regression","logistic-regression","random-forests","regression","decision-tree"],"details":"The Random Forest model far outperformed the other approaches on the test and validation sets.\r\n\r\nRandom Forest : MAE = 68069.1971 Gradient Boosting: MAE = 70647.2441 Lasso Regression: MAE = 85072.8543 Ridge Regression: MAE = 85012.1669 ElasticNet Regression: MAE = 86325.61","links":[{"article_link":"","code_link":"https://github.com/asaane88/Project-1-Real-Estate-Transaction-Price-Prediction-Model/blob/master/Project1#5_Model_Training.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":676,"title":"Customizing Training Loops in TensorFlow 2.0","description":"Learn to use all the delicacies of Keras' modular recipes and put them in a custom training loop. ","tags":["article","code","notebook","tutorial","keras","tensorflow","wandb","custom-training-loops"],"details":"Experiment a lot with the TensorFlow 2.0 features presented in the article Show us how you customize your training loops and use W&B to automatically keep track of the training progress of your models.","links":[{"article_link":"https://www.wandb.com/articles/wandb-customizing-training-loops-in-tensorflow-2","code_link":"https://colab.research.google.com/drive/1JCpAbjkCFhYMT7LCQ399y35TS3jlMpvM","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":675,"title":"Transfer Learning with EfficientNet family of models","description":"Learn to use the EfficientNet family of models for transfer learning in TensorFlow using TFHub.","tags":["article","code","notebook","tutorial","tensorflow","transfer-learning","wandb","efficientnet"],"details":"There are certain gotchas one needs to consider while using the EfficientNet family of models (at least from TF Hub) for transfer learning. In this report, I shed some light on those and also present a number of relevant experiments for the task of image classification.","links":[{"article_link":"https://app.wandb.ai/sayakpaul/efficientnet-tl/reports/Transfer-Learning-with-EfficientNet-family-of-models--Vmlldzo4OTg1Nw","code_link":"https://colab.research.google.com/drive/1UXnXGGoHVceDi0xtLxqUO6iUlYs8_vEs","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":674,"title":"YOLOv4: Optimal Speed and Accuracy of Object Detection","description":"A minimal implementation of YOLOv4.","tags":["code","paper","research","pytorch","library","computer-vision","object-detection","yolo","yolov4","arxiv:2004.10934"],"details":"\u2022\u00a0PyTorch: https://github.com/Tianxiaomo/pytorch-YOLOv4\r\n\u2022\u00a0TensorFlow 2.0: https://github.com/hunglc007/tensorflow-yolov4-tflite","links":[{"article_link":"","code_link":"https://github.com/Tianxiaomo/pytorch-YOLOv4","research_link":"https://arxiv.org/abs/2004.10934","media_link":"","dataset_link":"","demo_link":"","other_link":"https://pjreddie.com/darknet/yolo/"}]},{"id":673,"title":"Intro to Keras for Engineers","description":"Everything you need to know to use Keras & TF 2.0 to build real-world machine learning solutions.","tags":["code","notebook","tutorial","keras","tensorflow","deep-learning"],"details":"In this guide, you will learn about:\r\n* How to prepare you data before training a model (by turning it into either NumPy arrays or tf.data.Dataset objects).\r\n* How to do data preprocessing, for instance feature normalization or vocabulary indexing.\r\n* How to build a model that turns your data into useful predictions, using the Keras Functional API.\r\n* How to train your model with the built-in Keras fit() method, while being. mindful of checkpointing, metrics monitoring, and fault tolerance.\r\n* How to evaluate your model on a test data and how to use it for inference on new data.\r\n* How to customize what fit() does, for instance to build a GAN.\r\n* How to speed up training by leveraging multiple GPUs.\r\n* How to refine your model through hyperparameter tuning.","links":[{"article_link":"","code_link":"https://colab.research.google.com/drive/1lWUGZarlbORaHYUZlF9muCgpPl8pEvve","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":672,"title":"Geocoding in Python Using Google Maps API","description":"The article will focus on geocoding in Python which is getting coordinates for an address or any place around the world and calculating distances  between them.","tags":["api","article","tutorial","python","geography"],"details":"Table of contents:\r\n\u2022\u00a0Introduction\r\n\u2022\u00a0Geocoding addresses and locations in Python\r\n\u2022\u00a0Calculate geodesic distance in Python\r\n\u2022\u00a0Calculate driving distance using Google Distance Matrix API in Python\r\n\u2022\u00a0Conclusion","links":[{"article_link":"https://pyshark.com/geocoding-in-python/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":671,"title":"MedCAT - Medical Concept Annotation Tool","description":"A tool used to extract information from Electronic Health Records (EHRs) and link it to biomedical ontologies like SNOMED-CT and UMLS.","tags":["code","paper","research","spacy","health","healthcare","library","active-learning","annotation","named-entity-recognition","natural-language-processing","semi-supervised-learning","arxiv:1912.10166"],"details":"1. Named Entity Recognition and Linking\r\n2. Meta annotations (concept negation, temporality, ...)\r\n3. Organizing and structuring free text in Electronic Health Records.\r\n4. Supervised and Online learning via MedCATtrainer.","links":[{"article_link":"","code_link":"https://github.com/CogStack/MedCAT","research_link":"https://arxiv.org/abs/1912.10166","media_link":"https://towardsdatascience.com/medcat-introduction-analyzing-electronic-health-records-e1c420afa13a","dataset_link":"","demo_link":"","other_link":"https://github.com/CogStack/MedCATtrainer/"}]},{"id":670,"title":"Attribute2Font: Creating Fonts You Want From Attributes","description":"Official PyTorch implementation of the Attribute2Font: Creating Fonts You Want From Attributes.","tags":["article","code","tutorial","pytorch","generative-adversarial-networks","transformers","design","natural-language-processing","font-generation"],"details":"Attribute2Font is trained to perform font style transfer between any two fonts conditioned on their attribute values. After training, our model can generate glyph images in accordance with an arbitrary set of font attribute values.","links":[{"article_link":"https://hologerry.github.io/Attr2Font/","code_link":"https://github.com/hologerry/Attr2Font","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":669,"title":"Pandas Profiling","description":"Generates profile reports from a pandas DataFrame.","tags":["code","library","pandas","profiling"],"details":"The pandas df.describe() function is great but a little basic for serious exploratory data analysis. pandas_profiling extends the pandas DataFrame with df.profile_report() for quick data analysis.","links":[{"article_link":"","code_link":"https://github.com/pandas-profiling/pandas-profiling","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://pandas-profiling.github.io/pandas-profiling/docs/"}]},{"id":668,"title":"Intro to Linear Algebra for Applied Machine Learning with Python","description":"Intro to fundamental topics on linear algebra for machine learning with Numpy and Python.  Suited for beginner/intermediate Lvl practitioners. Work in progress.","tags":["article","tutorial","linear-algebra","math"],"details":"- Learn about essential topics on linear algebra for applied ML and DS\r\n- Integrate Numpy and Python code (when appropriated) to solve fundamental linear algebra problems like norms, systems of equations, etc.\r\n- Serve as a quick reference for practitioners and people just learning about linear algebra","links":[{"article_link":"https://pabloinsente.github.io/intro-linear-algebra","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":667,"title":"No Trump Social Chrome Plugin","description":"An AI-driven Browser Extension to Replace Trump Pics with Puppies!","tags":["article","tensorflow-js","library","computer-vision","trump","chrome-extension"],"details":"An AI-driven Browser Extension to Replace Trump Pics with Puppies!\r\nThis extension uses machine learning to identify pictures of Donald Trump in your Twitter feed (Facebook support coming soon) and, when it's reasonably confident it has a match, it replaces the image with an adorable puppy!","links":[{"article_link":"https://notrumpsocial.com/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":666,"title":"AIDeveloper","description":"GUI-based software for training, evaluating and applying deep neural nets for image classification ","tags":["code","paper","research","deep-learning","library","computer-vision","image-classification","image-processing","graphical-user-interface"],"details":"AIDeveloper (AID) is an easy-to-use, adaptable, open source software, to train neural nets (NN) for image classification without the need for programming. The software provides a variety of NN-architectures that can be simply selected for training. AID allows the user to apply trained models on new data, obtain metrics for classification performance, and export final models to different formats.","links":[{"article_link":"","code_link":"https://github.com/maikherbig/AIDeveloper","research_link":"https://www.biorxiv.org/content/10.1101/2020.03.03.975250v1","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":665,"title":"Object-detection with multi-template matching","description":"This python package allows to perform object detection using one or a few template images, it provides a simpler alternative to deep-learning methods","tags":["code","paper","research","video","python","library","computer-vision","object-detection","object-localization","object-recognition"],"details":"- higher detection capacity than single-template matching\r\n- Overlap-based Non-Maxima Suppression","links":[{"article_link":"","code_link":"https://github.com/multi-template-matching/MultiTemplateMatching-Python","research_link":"https://doi.org/10.1186/s12859-020-3363-7","media_link":"https://www.youtube.com/playlist?list=PLHZOgc1s26MJ8QjYau7NcG5k0zh9SjHpo","dataset_link":"","demo_link":"","other_link":""}]},{"id":664,"title":"Understanding the Backpropagation Algorithm(101)","description":"Starting from neural networks, I've tried to explain Back-Propagation Algorithim with an example.","tags":["article","tutorial","deep-learning","feed-forward-neural-networks","neural-networks"],"details":"The context of this article are:-\r\n1. Giving you a brief intro about the neural networks.\r\n2. Try to make you understand Back Propagation in a simpler way.\r\n3. And, finally, we\u2019ll deal with the algorithm of Back Propagation with a concrete example.","links":[{"article_link":"https://medium.com/towards-artificial-intelligence/understanding-back-propagation-in-an-easier-way-you-never-before-42fe26d44a47","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":663,"title":"Recipes for building an open-domain chatbot","description":"Python framework for sharing, training and testing dialogue models, from open-domain chitchat to VQA (Visual Question Answering).","tags":["code","paper","research","library","chatbot","natural-language-processing","conversational-ai","visual-question-answering","open-domain","arxiv:2004.13637"],"details":"Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation.","links":[{"article_link":"","code_link":"https://github.com/facebookresearch/ParlAI","research_link":"https://arxiv.org/abs/2004.13637","media_link":"","dataset_link":"","demo_link":"","other_link":"https://parl.ai/projects/blender/"}]},{"id":662,"title":"Why Sigmoid: A Probabilistic Perspective","description":"A comprehensive set of explanations for why the logistic sigmoid function is chosen for logistic regression from a probabilistic perspective. ","tags":["article","tutorial","video","logistic-regression","machine-learning","regression","statistics","activation","sigmoid"],"details":"This is for people who wonder why we can interpret the output of the sigmoid as a probability. It is not a tutorial for application nor new research, but it aims to provide insights that are not usually well-explained and documented in classes and introductory textbooks.","links":[{"article_link":"https://towardsdatascience.com/why-sigmoid-a-probabilistic-perspective-42751d82686?source=friends_link&sk=22734a30506f544851b50ff70658c825","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=oxGC9LLY6ZQ","dataset_link":"","demo_link":"","other_link":""}]},{"id":661,"title":"Better NLP project","description":"This is a wrapper program/library that encapsulates a couple of NLP libraries that are popular among the AI and ML communities.","tags":["code","library","natural-language-processing"],"details":"Examples have been used to illustrate usage as much as possible. Not all the APIs of the underlying libraries have been covered.\r\n\r\nThe idea is to keep the API language as high-level as possible, so its easier to use and stays human-readable.","links":[{"article_link":"","code_link":"https://github.com/neomatrix369/awesome-ai-ml-dl/tree/master/examples/better-nlp","research_link":"","media_link":"https://github.com/neomatrix369/awesome-ai-ml-dl/blob/master/examples/better-nlp/presentations/09-Mar-2019/Better-NLP-Presentation-Slides.pdf","dataset_link":"","demo_link":"","other_link":"https://www.kaggle.com/neomatrix369/better-nlp-class-notebook"}]},{"id":660,"title":"Awesome AI/ML/DL","description":"Awesome Artificial Intelligence, Machine Learning and Deep Learning as we learn it. Study notes and a curated list of awesome resources of such topics.","tags":["article","code","research","tutorial","artificial-general-intelligence","deep-learning","machine-learning","computer-vision","natural-language-processing","collection"],"details":"This repo is dedicated to engineers, developers, data scientists and all other professions that take interest in AI, ML, DL and related sciences. To make learning interesting and to create a place to easily find all the necessary material. Please contribute, watch, star, fork and share the repo with others in your community.","links":[{"article_link":"https://medium.com/oracledevs/two-years-in-the-life-of-ai-ml-dl-and-java-6bfe6eb8182a?source=---------11------------------","code_link":"https://github.com/neomatrix369/awesome-ai-ml-dl","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":659,"title":"Neural-Backed Decision Trees","description":"Combine interpretability of a decision tree with accuracy of a neural network.","tags":["code","paper","research","tutorial","decision-trees","deep-learning","neural-networks","interpretability","arxiv:2004.00221"],"details":"Making decision trees competitive with neural networks on CIFAR10, CIFAR100, TinyImagenet200, Imagenet. ","links":[{"article_link":"","code_link":"https://github.com/alvinwan/neural-backed-decision-trees","research_link":"https://arxiv.org/abs/2004.00221","media_link":"http://nbdt.alvinwan.com/demo/","dataset_link":"","demo_link":"","other_link":"http://nbdt.alvinwan.com/"}]},{"id":658,"title":"Gutenberg Dialog","description":"Build a dialog dataset from online books in many languages.","tags":["code","dataset","paper","research","library","language-modeling","natural-language-processing","datasets","arxiv:2004.12752"],"details":"Code for downloading and building your own version of the Gutenberg Dialog Dataset. Easily extendable with new languages.","links":[{"article_link":"","code_link":"https://github.com/ricsinaruto/gutenberg-dialog","research_link":"https://arxiv.org/abs/2004.12752","media_link":"","dataset_link":"","demo_link":"","other_link":"https://docs.google.com/spreadsheets/d/15v7lhZJusknd6UfnPfaHIriKvIlShFq2tqTsU7M82bI/edit#gid=0"}]},{"id":657,"title":"Optimizing Multiple Loss Functions with Loss-Conditional Training","description":" We propose a method that allows replacing multiple models trained on one loss function each by a single model trained on a distribution of losses. ","tags":["article","research","optimization","loss","multiple-losses"],"details":"In many machine learning applications the performance of a model cannot be summarized by a single number, but instead relies on several qualities, some of which may even be mutually exclusive.","links":[{"article_link":"https://ai.googleblog.com/2020/04/optimizing-multiple-loss-functions-with.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":656,"title":"Deploying Huggingface\u2018s BERT to production with Torch Serve","description":"Torch Serve is a new awesome framework to serve torch models in production. This story teaches you how to use it for Huggingface/transformers models like BERT.","tags":["article","code","tutorial","huggingface","pytorch","attention","bert","transformers","natural-language-processing","production","torch-serve"],"details":"","links":[{"article_link":"https://medium.com/@freidankm_39840/deploy-huggingface-s-bert-to-production-with-pytorch-serve-27b068026d18","code_link":"https://gist.github.com/MFreidank/3463d407a94ffe53d0d0daa137ad3973","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":655,"title":"Automating the Art of Data Augmentation","description":"Learning to Compose Domain-Specific Transformations for Data Augmentation","tags":["article","code","tutorial","library","data-augmentation","tanda"],"details":"Using data augmentation on benchmark machine learning tasks, like MNIST and CIFAR-10, yields large performance gains. But using data augmentation on new tasks can prove difficult. We've found that while it's usually easy for practitioners to\r\n\r\n\u2022\u00a0obtain large quantities of labeled data; and\r\n\u2022\u00a0come up with individual label-preserving data transformations (e.g. small image rotations),\r\n\r\nconstructing and tuning the more sophisticated compositions typically needed to achieve state-of-the-art results is a time-consuming manual task. The TANDA library unlabeled data points and arbitrary, user-provided transformation functions as input, and learns how to compose them to generate realistic, augmented data points.","links":[{"article_link":"https://hazyresearch.stanford.edu/data-aug-part-1","code_link":"https://github.com/HazyResearch/tanda","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":654,"title":"Automating Data Augmentation: Practice, Theory and New Direction","description":"A new framework for exploiting data augmentation to patch a flawed model and improve performance on crucial subpopulation of data.","tags":["article","tutorial","data-augmentation"],"details":"In this blog post, we provide a broad overview of recent efforts in this exciting research area, which resulted in new algorithms for automating the search process of transformation functions, new theoretical insights that improve the understanding of various augmentation techniques commonly used in practice, and a new framework for exploiting data augmentation to patch a flawed model and improve performance on crucial subpopulation of data.","links":[{"article_link":"https://ai.stanford.edu/blog/data-augmentation/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":653,"title":"Semantic Graphs for Generating Deep Questions","description":"Deep Question Generation (DQG), which aims to generate complex questions that require reasoning over multiple pieces of information of the input passage. ","tags":["code","paper","research","tutorial","attention","graphs","natural-language-processing","question-generation","semantic-graphs","arxiv:2004.12704"],"details":"This paper proposes the problem of Deep Question Generation (DQG), which aims to generate complex questions that require reasoning over multiple pieces of information of the input passage. In order to capture the global structure of the document and facilitate reasoning, we propose a novel framework which first constructs a semantic-level graph for the input document and then encodes the semantic graph by introducing an attention-based GGNN (Att-GGNN). Afterwards, we fuse the document-level and graph-level representations to perform joint training of content selection and question decoding.","links":[{"article_link":"","code_link":"https://github.com/WING-NUS/SG-Deep-Question-Generation","research_link":"https://arxiv.org/abs/2004.12704","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":652,"title":"Optimal Transport and the Sinkhorn Transformer","description":"Understand optimal transport and the Sinkhorn-Knopp algorithm before diving into the Sinkhorn Transformer.","tags":["article","tutorial","attention","transformers","natural-language-processing","sinkhorn","optimal-transport"],"details":"This week I'm diving into \"Sparse Sinkhorn Attention\" by Yi Tay, Dara Bahri, Liu Yang, Donald Metzler, and Da-Cheng Juan. \"Sparse Sinkhorn Attention\" uses the concept of differentiable sorting to construct an attention algorithm with memory complexity that scales approximately linearly with sequence length.","links":[{"article_link":"https://www.pragmatic.ml/sparse-sinkhorn-attention/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":651,"title":"GCAN: Graph-aware Co-Attention Networks","description":"For Explainable Fake News Detection on Social Media","tags":["code","paper","research","tutorial","attention","social-media","fake-news-detection","graph-neural-networks","graphs","natural-language-processing","co-attention","gcan","arxiv:2004.11648"],"details":"This paper solves the fake news detection problem under a more realistic scenario. Given the source short-text tweet and its retweet users without text comments, we aim at predicting whether it is fake or not, and generating explanation by highlighting the evidences on suspicious retweeters and the words they concern. We develop a novel neural networkbased model, Graph-aware Co-Attention Networks (GCAN) to achieve the goal. Extensive experiments on real tweet datasets exhibit that GCAN can significantly outperform state-ofthe- art methods by 16% in accuracy on average,and produce reasonable explanation.","links":[{"article_link":"","code_link":"https://github.com/l852888/GCAN","research_link":"https://arxiv.org/abs/2004.11648","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":650,"title":"Unsupervised Speech Decomposition","description":"This demo webpage provides sound examples for SpeechSplit, an autoencoder that can decompose speech into content, timbre, rhythm and pitch.","tags":["paper","research","autoencoders","speech","unsupervised-learning","decomposition","arxiv:2004.11284"],"details":"In this paper, we propose SpeechSplit, which can blindly decompose speech into its four components by introducing three carefully designed information bottlenecks. SpeechSplit is among the first algorithms that can separately perform style transfer on timbre, pitch and rhythm without text labels.","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2004.11284","media_link":"","dataset_link":"","demo_link":"","other_link":"https://anonymous0818.github.io/"}]},{"id":649,"title":"Spektral","description":"Graph Neural Networks with Keras and Tensorflow 2.","tags":["code","keras","tensorflow","graph-convolutional-networks","library","graph-neural-networks","graphs"],"details":"Spektral is a Python library for graph deep learning, based on the Keras API and TensorFlow 2. The main goal of this project is to provide a simple but flexible framework for creating graph neural networks (GNNs).\r\n\r\nYou can use Spektral for classifying the nodes of a network, predicting molecular properties, generating new graphs with GANs, clustering nodes, predicting links, and any other task where data is described by graphs.","links":[{"article_link":"","code_link":"https://github.com/danielegrattarola/spektral/","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://spektral.graphneural.network/"}]},{"id":648,"title":"Indian Scriptures Dataset","description":"This project contains various Indian scriptures \ud83d\udcdc in a structured .csv format. The files contain the verses in their original Sanskrit language and their ve","tags":["code","tutorial"],"details":"The project aims to create a single source dataset for all the Indian scriptures in their original as well as translated texts.","links":[{"article_link":"","code_link":"https://github.com/hrgupta/indian-scriptures","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":647,"title":"A Visual Guide to Recurrent Layers in Keras","description":"Understand how to use Recurrent Layers like RNN, GRU and LSTM in Keras with diagrams.","tags":["article","tutorial","keras","tensorflow","lstm","recurrent-neural-networks"],"details":"- Clarify what different arguments in the RNN API in Keras do\r\n- Illustrate with some example usecases","links":[{"article_link":"https://amitness.com/2020/04/recurrent-layers-keras/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":646,"title":"Doing more with TensorFlow Lite","description":"Learn about different usage scenarios of TensorFlow Lite along with some best practices. ","tags":["article","tutorial","model-compression","quantization","tensorflow-lite","on-device"],"details":"* Motivation behind on-device ML\r\n* What is TensorFlow Lite (TF Lite)?\r\n* What can it do?\r\n* Different TF Lite usage scenarios\r\n* Model optimization\r\n* Model maker\r\n* For mobile, embedded, and microcontroller devices\r\n* Some best practices\r\n* Q&A","links":[{"article_link":"http://bit.ly/tfl-pune","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":645,"title":"Visual Machine Learning","description":"\ud83d\udc40This application has been created to help people to visually understand how machine learning works. ","tags":["code","tutorial","tensorflow-js","linear-regression","regression","full-stack","firebase","front-end","vue-js"],"details":"Technologies\r\n\r\n- Tensorflow.js ~ machine learning\r\n- Vue.js ~ front-end framework\r\n- Vuetify.js ~ material design library\r\n- Firebase ~ hosting","links":[{"article_link":"","code_link":"https://github.com/FelixBecquart1990/visualmachinelearning","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://visualmachinelearning.web.app/"}]},{"id":644,"title":"Adversarial Latent Autoencoders","description":"Introducing the Adversarial Latent Autoencoder (ALAE), a general architecture that can leverage recent improvements on GAN training procedures.","tags":["code","paper","research","tutorial","autoencoders","generative-adversarial-networks","computer-vision","image-generation","latent-space","disentanglement","arxiv:2004.04467"],"details":"We designed two autoencoders: one based on a MLP encoder, and another based on a StyleGAN generator, which we call StyleALAE. We verify the disentanglement properties of both architectures. We show that StyleALAE can not only generate 1024x1024 face images with comparable quality of StyleGAN, but at the same resolution can also produce face reconstructions and manipulations based on real images.","links":[{"article_link":"","code_link":"https://github.com/podgorskiy/ALAE","research_link":"https://arxiv.org/abs/2004.04467","media_link":"","dataset_link":"","demo_link":"","other_link":"https://drive.google.com/drive/folders/1iZodDA4q1IKRRgV2nJuAyyuCwQGtL4vp"}]},{"id":643,"title":"Albert-base for Sanskrit","description":"Trained Albert-base from scratch on Sanskrit corpus of Wikipedia. I have also added a link to how to train your own Language model from scratch.","tags":["article","code","notebook","tutorial","huggingface","attention","bert","transformers","library","language-modeling","natural-language-processing","albert"],"details":"1. Trained a small model (ALBERT) on Sanskrit corpus\r\n2. Can be used to get embedding from Sanskrit text\r\n3. Uploaded on HuggingFace's models' list\r\n4. Tutorial on training from scratch","links":[{"article_link":"https://parmarsuraj99.github.io/suraj-parmar/jupyter/nlp/huggingface/2020/05/02/SanskritALBERT.html","code_link":"https://github.com/parmarsuraj99/suraj-parmar/blob/master/_notebooks/2020-05-02-SanskritALBERT.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://huggingface.co/surajp/albert-base-sanskrit"}]},{"id":642,"title":"Introduction to Linear Regression - Mathematics and Application","description":"Introduction to linear regression covering the math, basic theory, and implementation with Python and sklearn. ","tags":["article","tutorial","scikit-learn","linear-regression","machine-learning","regression"],"details":"Understand the theory and mathematics of linear regression in a friendly way\r\nImplement a basic example of both simple and multivariable linear regression","links":[{"article_link":"https://pabloinsente.github.io/intro-linear-regression","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":641,"title":"Torchmeta","description":"A collection of extensions and data-loaders for few-shot learning & meta-learning in PyTorch","tags":["code","pytorch","library","few-shot-learning","meta-learning","zero-shot-learning"],"details":"A collection of extensions and data-loaders for few-shot learning & meta-learning in PyTorch. Torchmeta contains popular meta-learning benchmarks, fully compatible with both torchvision and PyTorch's DataLoader.","links":[{"article_link":"","code_link":"https://github.com/tristandeleu/pytorch-meta","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://tristandeleu.github.io/pytorch-meta/"}]},{"id":640,"title":"The Science of Assisting Medical Diagnosis","description":"From Expert systems to Machine-learned models","tags":["article","paper","research","health","knowledge-base","medical-diagnosis","expert-systems","differential-diagnosis","arxiv:1804.08033"],"details":"Wwe present a method to merge both approaches by using expert systems as generative models that create simulated data on which models can be learned. We demonstrate that such a learned model not only preserves the original properties of the expert systems but also addresses some of their limitations. Furthermore, we show how this approach can also be used as the starting point to combine expert knowledge with knowledge extracted from other data sources, such as electronic health records.","links":[{"article_link":"https://medium.com/curai-tech/the-science-of-assisting-medical-diagnosis-from-expert-systems-to-machine-learned-models-cc2ef0b03098","code_link":"","research_link":"https://arxiv.org/abs/1804.08033","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":639,"title":"ML Foundations and Methods for Precision Medicine and Healthcare","description":"This tutorial will discuss ideas from machine learning that enable personalization (useful for applications in education, retail, medicine and recsys).","tags":["article","bayesian-deep-learning","deep-learning","health","medicine","causal-inference","reinforcement-learning","what-if","causal-risk"],"details":"1. Bayesian hierarchical models\r\n2. Transfer learning and multi-resolution sharing\r\n3. Functional data analysis\r\n4. Causal inference and individualized treatment effects\r\n\u2022\u00a0Potential outcomes\r\n\u2022\u00a0Strategies for adjusting for confounding\r\n\u2022\u00a0Sequential and time-varying treatments\r\n\u2022\u00a0Bayesian estimation of individualized treatment response\r\n5. \"Causal Risk\" and What-if Reasoning\r\n6. Dynamic treatment regimes\r\n\u2022\u00a0Estimating optimal treatment rules\r\n\u2022\u00a0Connections to reinforcement learning","links":[{"article_link":"http://media.nips.cc//Conferences/2016/Slides/6204-Slides.pdf","code_link":"","research_link":"","media_link":"https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/ML-Foundations-and-Methods-for-Precision-Medicine-and-Healthcare","dataset_link":"","demo_link":"","other_link":"https://nips.cc/Conferences/2016/Schedule?showEvent=6204"}]},{"id":638,"title":"Reliable Decision Support using Counterfactual Models","description":"We propose using a different learning objective that predicts counterfactuals instead of predicting outcomes under an existing action policy as in supervised le","tags":["paper","research","video","health","medicine","counterfactual-gaussian-processes","counterfactuals","arxiv:1703.10651"],"details":"Practitioners commonly use supervised learning algorithms to fit predictive models that help decision-makers reason about likely future outcomes, but we show that this approach is unreliable, and sometimes even dangerous. The key issue is that supervised learning algorithms are highly sensitive to the policy used to choose actions in the training data, which causes the model to capture relationships that do not generalize. We propose using a different learning objective that predicts counterfactuals instead of predicting outcomes under an existing action policy as in supervised learning.","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/1703.10651","media_link":"https://www.youtube.com/watch?v=TOpJ4g9v-H4","dataset_link":"","demo_link":"","other_link":""}]},{"id":637,"title":"Label Encoding in Python","description":"A detailed guide to label encoding in Python with code examples.","tags":["article","tutorial","python","scikit-learn","machine-learning","labeling"],"details":"Table of Contents:\r\n\u2022\u00a0Introduction\r\n\u2022\u00a0Understanding Label Encoding\r\n\u2022\u00a0Label Encoding in Python\r\n\u2022\u00a0Conclusion","links":[{"article_link":"https://pyshark.com/label-encoding-in-python/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":636,"title":"Visualization of Multidimensional Datasets Using t-SNE in Python","description":"This article will focus on t-Distributed Stochastic Neighbor Embedding (t-SNE) in Python and its application to data visualization of multidimensional datasets.","tags":["article","research","tutorial","python","scikit-learn","dimensionality-reduction","embeddings","tsne","visualization"],"details":"Table of Contents:\r\n\u2022\u00a0Introduction\r\n\u2022\u00a0Stochastic Neighbor Embedding (SNE) Overview\r\n\u2022\u00a0t-Distributed Stochastic Neighbor Embedding (t-SNE) Overview\r\n\u2022\u00a0t-Distributed Stochastic Neighbor Embedding (t-SNE) in Python\r\n\u2022\u00a0t-Distributed Stochastic Neighbor Embedding (t-SNE) \u2022\u00a0Hyperparameter Tuning\r\n\u2022\u00a0Additional Information\r\n\u2022\u00a0Conclusion","links":[{"article_link":"https://pyshark.com/visualization-of-multidimensional-datasets-using-t-sne-in-python/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":635,"title":"Principal Component Analysis for Dimensionality Reduction","description":"This article will focus on a walkthrough for principal component analysis in Python.","tags":["article","tutorial","python","machine-learning","dimensionality-reduction","principal-component-analysis"],"details":"Table of Contents:\r\n\u2022\u00a0Introduction\r\n\u2022\u00a0Principal component analysis (Overview)\r\n\u2022\u00a0Principal component analysis in Python\r\n\u2022\u00a0Conclusion","links":[{"article_link":"https://pyshark.com/principal-component-analysis-in-python/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":634,"title":"Market Basket Analysis Using Association Rule Mining in Python","description":"Detailed introduction to market basket analysis using association rule mining in Python. Complete tutorial with code examples using mlxtend library.","tags":["article","tutorial","python","machine-learning","market-research","data-mining"],"details":"\u2022\u00a0Introduction\r\n\u2022\u00a0Association Rule Learning (Overview)\r\n\u2022\u00a0Concepts\r\n\u2022\u00a0Apriori Algorithm\r\n\u2022\u00a0ECLAT\r\n\u2022\u00a0F-P Growth\r\n\u2022\u00a0Comparison\r\n\u2022\u00a0Python Code Example\r\n\u2022\u00a0Conclusion","links":[{"article_link":"https://pyshark.com/market-basket-analysis-using-association-rule-mining-in-python/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":633,"title":"Towards Deep Generative Modeling with W&B","description":"In this report, we will learn about the evolution of generative modeling.","tags":["article","tutorial","autoencoders","variational-autoencoders","wandb","generative-modeling","adversarial-learning"],"details":"We'll start with Autoencoders and Variational Autoencoders and then dive into Generative Adversarial Modeling.","links":[{"article_link":"https://app.wandb.ai/ayush-thakur/keras-gan/reports/Towards-Deep-Generative-Modeling-with-W%26B--Vmlldzo4MDI4Mw","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":632,"title":"Lagrangian Neural Networks","description":"Trying to learn a simulation? Try Lagrangian Neural Networks, which explicitly conserve energy and may generalize better!","tags":["article","code","paper","research","tutorial","jax","deep-learning","graph-neural-networks","graphs","interpretability","arxiv:2003.04630"],"details":"In this project we describe Lagrangian Neural Networks (LNNs), which can parameterize arbitrary Lagrangians using neural networks. In contrast to Hamiltonian Neural Networks, these models do not require canonical coordinates and perform well in situations where generalized momentum is difficult to compute (e.g., the double pendulum). This is particularly appealing for use with a learned latent representation, a case where HNNs struggle. Unlike previous work on learning Lagrangians, LNNs are fully general and extend to non-holonomic systems such as the 1D wave equation.","links":[{"article_link":"https://greydanus.github.io/2020/03/10/lagrangian-nns/","code_link":"https://github.com/MilesCranmer/lagrangian_nns","research_link":"https://arxiv.org/abs/2003.04630","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":631,"title":"How to Plan and Execute Your ML and DL Projects","description":"This tutorial presents ways to structure ML and DL projects in a systematic manner. ","tags":["article","tutorial","deep-learning","machine-learning","product-management","systems-design"],"details":"This article is the first one in a series that will be dedicated to forming a path for channeling out deep learning projects in a holistic manner.","links":[{"article_link":"https://blog.floydhub.com/structuring-and-planning-your-machine-learning-project/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":630,"title":"Facial Points Detection in Javascript","description":"Implementation of  Facial Points detection in Javascript using OpenCVJs and TensorflowJs","tags":["code","research","video","javascript","tensorflow","tensorflow-js","convolutional-neural-networks","facial-points-detection","facial-detection"],"details":"It is a neural network model that detects 15 facial points.\r\n* The Dataset : Kaggle Dataset: https://lnkd.in/fp9nhXg\r\n\u2022\u00a0The Model : Created a basic NN using Keras sequential containing 1 cov2d and 1 max pool and 2 hidden layer (128 and 64) and output layer (30)\r\n\u2022\u00a0Training accuracy : 74-75 percent\r\n\u2022\u00a0The Detector and Predictor : I used opencv Haar cascade to detect faces. Loaded the above created model(h5 file) to create a instance of model. Faces based on the detector are feeded to the model.predict() function to get the prediction and (15)key points.\r\n","links":[{"article_link":"","code_link":"https://github.com/shubham-chhimpa/Facial-Points-Detection-in-Javascript-","research_link":"","media_link":"https://www.youtube.com/watch?v=9Zie7wCYeGg","dataset_link":"","demo_link":"","other_link":""}]},{"id":629,"title":"ARIMA Modeling - Guide to Time Series Forecasting in Python","description":"How ARIMA models works . How to train and forecast using ARIMA, SARIMA, SARIMAX and find the optimal model with Python","tags":["article","tutorial","arima","time-series","time-series-forecasting","box-jenkins","sarimax","autoarima"],"details":"Using ARIMA model, you can forecast a time series using the series past values. In this post, we build an optimal ARIMA model from scratch and extend it to Seasonal ARIMA (SARIMA) and SARIMAX models. You will also see how to build autoarima models in python.","links":[{"article_link":"https://www.machinelearningplus.com/time-series/arima-model-time-series-forecasting-python/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":628,"title":"Concrete Compressive Strength Prediction using Machine Learning","description":"Predicting Strength of the most important materials in Civil Engineering. ","tags":["article","code","notebook","tutorial","civil-engineering","concrete-engineering","concrete-strength"],"details":"Concrete is one of the most important materials in Civil Engineering. Knowing the compressive strength of concrete is very important when constructing a building or a bridge. The Compressive Strength of Concrete is a highly nonlinear function of ingredients used in making it and their characteristics. Thus, using Machine Learning to predict the Strength could be useful in generating a combination of ingredients which result in high Strength.","links":[{"article_link":"https://towardsdatascience.com/concrete-compressive-strength-prediction-using-machine-learning-4a531b3c43f3?source=friends_link&sk=e1734fbde495aea664a85a1daa903881","code_link":"https://github.com/pranaymodukuru/Concrete-compressive-strength/blob/master/ConcreteCompressiveStrengthPrediction.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":625,"title":"NSFW JS","description":"A JavaScript library for identifying indecent content in JavaScript on the client.","tags":["article","code","javascript","tensorflow","tensorflow-js","machine-learning","library"],"details":"To let devs with ZERO AI/ML experience implement a classification model to identify indecent content in the browser.","links":[{"article_link":"https://shift.infinite.red/avoid-nightmares-nsfw-js-ab7b176978b1","code_link":"https://github.com/infinitered/nsfwjs","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://nsfwjs.com/"}]},{"id":624,"title":"How to Train a New Language Model From Scratch Using Transformers","description":"In this post we\u2019ll demo how to train a \u201csmall\u201d model (84 M parameters = 6 layers, 768 hidden size, 12 attention heads).","tags":["article","code","notebook","tutorial","huggingface","attention","transformers","language-modeling","natural-language-processing","tokenizers"],"details":"In this post we\u2019ll demo how to train a \u201csmall\u201d model (84 M parameters = 6 layers, 768 hidden size, 12 attention heads) \u2013 that\u2019s the same number of layers & heads as DistilBERT \u2013 on Esperanto. We\u2019ll then fine-tune the model on a downstream task of part-of-speech tagging.","links":[{"article_link":"https://huggingface.co/blog/how-to-train","code_link":"https://colab.research.google.com/github/huggingface/blog/blob/master/notebooks/01_how_to_train.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":623,"title":"medaCy","description":"\ud83c\udfe5 Medical Text Mining and Information Extraction with spaCy","tags":["code","spacy","health","library","information-extraction","named-entity-recognition","natural-language-processing","text-mining","medical-text-mining","clinical-text-mining","metamap","ontologies"],"details":"MedaCy is a text processing and learning framework built over spaCy to support the lightning fast prototyping, training, and application of highly predictive medical NLP models. It is designed to streamline researcher workflow by providing utilities for model training, prediction and organization while insuring the replicability of systems.","links":[{"article_link":"","code_link":"https://github.com/NLPatVCU/medaCy","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://medacy.readthedocs.io/en/latest/"}]},{"id":622,"title":"MT-Clinical BERT","description":"Scaling Clinical Information Extraction with Multitask Learning","tags":["code","paper","research","tutorial","attention","bert","transformers","health","information-extraction","named-entity-recognition","natural-language-processing","pretraining","multi-task-learning","clinical-information-extraction","entailment","similarity","arxiv:2004.10220"],"details":"Multitask-Clinical BERT: a single deep learning model that simultaneously performs eight clinical tasks spanning entity extraction, PHI identification, language entailment and similarity by sharing representations amongst tasks.","links":[{"article_link":"","code_link":"https://github.com/AndriyMulyar/multitasking_transformers","research_link":"https://arxiv.org/abs/2004.10220","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":621,"title":"MixNMatch","description":"Multifactor Disentanglement and Encoding for Conditional Image Generation","tags":["code","paper","research","tutorial","video","pytorch","generative-adversarial-networks","computer-vision","image-generation","generative-models","disentanglement","finegan","mixnmatch","arxiv:1911.11758"],"details":"We present MixNMatch, a conditional generative model that learns to disentangle and encode background, object pose, shape, and texture from real images with minimal supervision, for mix-and-match image generation. ","links":[{"article_link":"","code_link":"https://github.com/Yuheng-Li/MixNMatch","research_link":"https://arxiv.org/abs/1911.11758","media_link":"https://www.youtube.com/watch?v=w36vnkIbyjs","dataset_link":"","demo_link":"","other_link":""}]},{"id":620,"title":"ELECTRA ","description":"Explaining the new self-supervised task for language representation learning, ELECTRA which uses \"replace token detection\".","tags":["article","tutorial","attention","bert","generative-adversarial-networks","transformers","language-modeling","natural-language-processing","representation-learning","electra"],"details":"In this article, I have tried to explain the recent framework for self-supervised Language representation. Which is faster to train.\r\nI have discussed.\r\n* Language Modeling\r\n* Generative Training\r\n* Replaced Token Detection\r\n\r\n","links":[{"article_link":"https://parmarsuraj99.github.io/suraj-parmar/jupyter/nlp/2020/04/14/ELECTRA.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":619,"title":"Implementing Portrait Bokeh Mode using OpenCV and NumPy (Python)","description":"Do you love the portrait mode in your smartphone? This code will help you do the same using OpenCV and NumPy! Detects the faces, asks if you want to blur them!","tags":["code","video","python","library","computer-vision","opencv","numpy","image-processing"],"details":"Cropping a circle isn't that easy in OpenCV, this project helps you do that! Detects faces using Face Haarcascade in OpenCV, asks if you want to keep that face or not.\r\n","links":[{"article_link":"","code_link":"https://github.com/krshrimali/Portrait-Bokeh-using-OpenCV-and-NumPy","research_link":"","media_link":"https://www.youtube.com/watch?v=4aweeJGS4so","dataset_link":"","demo_link":"","other_link":""}]},{"id":618,"title":"Introduction to Anomaly Detection in Python","description":"Learn how anomalies are created/generated, why they are important to consider while developing machine learning models, how they can be detected.","tags":["article","code","tutorial","scikit-learn","machine-learning"],"details":"We will see how they are created/generated, why they are important to consider while developing machine learning models, how they can be detected. We will also do a small case study in Python to even solidify our understanding of anomalies. ","links":[{"article_link":"https://blog.floydhub.com/introduction-to-anomaly-detection-in-python/","code_link":"https://github.com/sayakpaul/FloydHub-Anomaly-Detection-Blog","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":617,"title":"Understanding how Vectors push_back in C++ (GCC)","description":"This blog is not just another blog explaining how to push elements into Vector container in C++. It takes you through the source code and shows how GCC does it.","tags":["article","tutorial","c++","gcc","vectors","coding"],"details":"This is Part-1 in the series for Vector Containers. Please note that this takes you through the source code of GCC, and tells you want happens in the backend. If you want to be better at C++, learn about the design patterns, this is a blog for you! :)","links":[{"article_link":"https://krshrimali.github.io/How-Vectors-Work-in-C++-Part-1/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":616,"title":"Custom Data Loading using PyTorch C++ API","description":"How can you load a custom dataset in C++ using PyTorch C++ API? This blog helps you with that.","tags":["article","tutorial","c++","pytorch","opencv","libtorch","custom-data-loading"],"details":"Loading Custom Dataset will be easier now, with this blog. You need to have OpenCV installed (from source if you are on Linux) in order to load the dataset.","links":[{"article_link":"https://krshrimali.github.io/Custom-Data-Loading-Using-PyTorch-CPP-API/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":615,"title":"Setting up Jupyter Notebook in C++ for PyTorch and OpenCV","description":"This blog explains how to run any code using PyTorch C++ API and OpenCV (C++) in the Jupyter Notebook.","tags":["article","tutorial","c++","pytorch","opencv","jupyter","libtorch","xeus-cling","jupyter-notebook"],"details":"Shows how to load PyTorch C++ libraries, and OpenCV libraries in Xeus Cling (for both OSX and Linux Systems). Sample code and demonstration is also included.","links":[{"article_link":"https://krshrimali.github.io/Setting-Up-Xeus-Cling-Libtorch-OpenCV/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":614,"title":"Applying Transfer Learning using PyTorch C++ API (Dogs vs Cats)","description":"Loading Custom Dataset in the PyTorch C++ API isn't straight forward. This blog helps you do that, and explains transfer learning implementation in C++.","tags":["article","code","tutorial","c++","pytorch","deep-learning","library","transfer-learning","libtorch","dogs-vs-cats"],"details":"The blog discusses difference between fine tuning vs transfer learning, then talks about Custom Dataset loading in C++ and then talks about using transfer learning on a Custom Dogs vs Cats dataset using PyTorch C++ Frontend API.","links":[{"article_link":"https://krshrimali.github.io/Applying-Transfer-Learning-Dogs-Cats/","code_link":"https://github.com/BuffetCodes/Transfer-Learning-Dogs-Cats-Libtorch","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":613,"title":"Linear Regression on a CSV File using PyTorch in C++ (Libtorch)","description":"Use any CSV file in C++ to perform Linear Regression using Fully Connected layers in PyTorch is now easy with this project! :)","tags":["code","tutorial","video","c++","pytorch","linear-regression","regression","library","libtorch"],"details":"The objective is to be able to use FC layers just like in Deep Learning, to perform linear regression in C++ (using PyTorch C++ API). The code also contains sample code to use random data to perform linear regression. From loading CSV files to performing Linear Regression, everything is in C++.","links":[{"article_link":"","code_link":"https://github.com/BuffetCodes/Linear-Regression-using-PyTorch-CPP","research_link":"","media_link":"https://www.youtube.com/watch?v=6raFznPFy2Y","dataset_link":"","demo_link":"","other_link":""}]},{"id":612,"title":"Implementing DCGANs using PyTorch C++ API (Libtorch)","description":"The blog discusses the paper review of DCGANs and implementation using PyTorch C++ API in detail. From loading models to visualizing batch of the data, in C++! ","tags":["article","code","tutorial","c++","pytorch","deep-learning","generative-adversarial-networks","computer-vision","dcgan","libtorch"],"details":"Deep Learning in C++ is challenging, but thanks to the PyTorch Team at Facebook and awesome contributors for bringing the C++ API closer to what we have in Python. This blog discusses the implementation of DCGAN, from training to validation, loading checkpoints, visualizing batches in C++! It also discusses the review of the paper that introduced DCGAN.","links":[{"article_link":"https://krshrimali.github.io/DCGAN-using-PyTorch-CPP/","code_link":"https://github.com/BuffetCodes/DCGAN-CelebA-PyTorch-CPP","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://krshrimali.github.io/DCGAN-using-PyTorch-CPP-Part-2/"}]},{"id":611,"title":"Transfer Learning - Machine Learning's Next Frontier","description":"This post gives an overview of transfer learning, motivates why it warrants our application, and discusses practical applications and methods.","tags":["article","tutorial","transfer-learning"],"details":"An in-depth look at transfer learning, its applications and methods, and related research areas.","links":[{"article_link":"https://ruder.io/transfer-learning/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":610,"title":"A Comprehensive Hands-on Guide to Transfer Learning","description":"Deep Learning on Steroids with the Power of Knowledge Transfer!","tags":["article","tutorial","deep-learning","transfer-learning"],"details":"In this article, we will do a comprehensive coverage of the concepts, scope and real-world applications of transfer learning and even showcase some hands-on examples. ","links":[{"article_link":"https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":609,"title":"Google's Python Class","description":"This is a free class for people with a little bit of programming experience who want to learn Python","tags":["article","tutorial","python"],"details":"A free class for people with a little bit of programming experience who want to learn Python. The class includes written materials, lecture videos, and lots of code exercises to practice Python coding. These materials are used within Google to introduce Python to people who have just a little programming experience. ","links":[{"article_link":"https://developers.google.com/edu/python","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":608,"title":"PyImageSearch","description":"An online platform of blogs on Computer Vision and Deep Learning.","tags":["article","tutorial","deep-learning","machine-learning","computer-vision","pyimagesearch"],"details":"I\u2019ve taken some of my best material from the past 5 years running PyImageSearch and designed a fully personalized, 17-lesson crash course on how to learn Computer Vision, Deep Learning, and OpenCV.","links":[{"article_link":"https://www.pyimagesearch.com/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":607,"title":"Synchronizing Facial Movements with Video Frame Orientation","description":"I am seeing the #TFDevSummit 2020 video. whenever I move my face while watching the video that video frames also will move as per my face movement. ","tags":["code","video","tensorflow","tensorflow-js"],"details":"I have used the #tensorflowjs blaze face model to track our face and show the videos on the face. it will be very useful to see the videos.","links":[{"article_link":"","code_link":"https://github.com/balavenkatesh3322/tensorflowjs-demo","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.youtube.com/watch?v=djSRxOou7us&feature=youtu.be"}]},{"id":606,"title":"Hyperparameter search with W&B and Kubernetes","description":"An end-to-end guide on training your models on a Kubernetes cluster, and tracking them with Weights & Biases.","tags":["article","code","tutorial","kubernetes","deep-learning","library","wandb"],"details":"- Highlighting the importance of rigorous experiment tracking in deep learning\r\n- Practical guide on how to deploy multiple experiments in kubernetes and track results with W&B ","links":[{"article_link":"https://www.wandb.com/articles/model-explorations-and-hyperparameter-search-with-w-b-and-kubernetes","code_link":"https://gist.github.com/rmporsch/aa357fe7b16130bef64395f9e739712d","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":605,"title":"Upside Down Reinforcement Learning","description":"Implementation of UDRL as outlined by Juergen Schmidhuber in https://arxiv.org/abs/1912.02875","tags":["code","tutorial","reinforcement-learning"],"details":"To experiment with the effectiveness of using supervised learning to solve reinforcement learning tasks.","links":[{"article_link":"","code_link":"https://github.com/drozzy/upsidedown","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":604,"title":"A Basic Soft-Margin Kernel SVM Implementation in Python","description":"This is a basic implementation of a soft-margin kernel SVM solver in Python using numpy and cvxopt.","tags":["article","code","tutorial","python","support-vector-machines"],"details":"For now, we'll just give an introduction to the basic theory of soft-margin kernel SVMs. The classical treatment is to start with hard-margin linear SVMs, then introduce the kernel trick and the soft-margin formulation, so this is somewhat faster-moving than other presentations.","links":[{"article_link":"http://tullo.ch/articles/svm-py/","code_link":"https://github.com/ajtulloch/svmpy","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":603,"title":"Tpus, Systolic Arrays, and bfloat16: Accelerate Your DL","description":"Systolic arrays and bfloat16 multipliers, two components of tensor processing units (TPUs) that are responsible for accelerating your deep learning training.","tags":["tutorial","video","training","tpu","bfloat16"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=JC84GCU7zqA","dataset_link":"","demo_link":"","other_link":""}]},{"id":602,"title":"DialoGPT: Toward Human-Quality Conversational Response Generation","description":"Large-scale pre-training for dialogue.","tags":["article","code","paper","research","tutorial","gpt","transformers","chatbot","natural-language-processing","transfer-learning","conversational-ai","arxiv:1911.00536"],"details":"The DialoGPT project establishes a foundation for building versatile open-domain chatbots that can deliver engaging and natural conversational responses across a variety of conversational topics, tasks, and information requests, without resorting to heavy hand-crafting.","links":[{"article_link":"https://www.microsoft.com/en-us/research/project/large-scale-pretraining-for-response-generation/","code_link":"https://github.com/microsoft/DialoGPT","research_link":"https://arxiv.org/abs/1911.00536","media_link":"","dataset_link":"","demo_link":"","other_link":"https://huggingface.co/microsoft/DialoGPT-medium"}]},{"id":601,"title":"How I Used Deep Learning To Train A Chatbot To Talk Like Me","description":"Facebook chatbot that I trained to talk like me using Seq2Seq.","tags":["article","code","tutorial","tensorflow","deep-learning","sequence-to-sequence","chatbot","natural-language-processing","conversational-ai"],"details":"In this post, we\u2019ll be looking at how we can use a deep learning model to train a chatbot on my past social media conversations in hope of getting the chatbot to respond to messages the way that I would.","links":[{"article_link":"https://adeshpande3.github.io/How-I-Used-Deep-Learning-to-Train-a-Chatbot-to-Talk-Like-Me","code_link":"https://github.com/adeshpande3/Facebook-Messenger-Bot","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":600,"title":"Building a Simple Chatbot from Scratch in Python (using NLTK)","description":"A look at retrieval based and generative conversational AI for creating chatbots.","tags":["article","tutorial","chatbot","natural-language-processing","conversational-ai","nltk"],"details":"","links":[{"article_link":"https://medium.com/analytics-vidhya/building-a-simple-chatbot-in-python-using-nltk-7c8c8215ac6e","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":599,"title":"MONAI","description":"AI Toolkit for Healthcare Imaging.","tags":["article","code","tutorial","pytorch","healthcare","computer-vision","medical-imaging","imaging","nvidia","monai"],"details":"MONAI is a freely available, community-supported, PyTorch-based framework for deep learning in healthcare imaging. It provides domain-optimized foundational capabilities for developing healthcare imaging training workflows in a native PyTorch paradigm.","links":[{"article_link":"https://blogs.nvidia.com/blog/2020/04/21/monai-open-source-framework-ai-healthcare/","code_link":"https://github.com/Project-MONAI/MONAI","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://monai.io/"}]},{"id":598,"title":"The Future of (Transfer Learning in) Natural Language Processing","description":"Transfer Learning in Natural Language Processing (NLP): Open questions, current trends, limits, and future directions.","tags":["tutorial","video","natural-language-processing","transfer-learning"],"details":"A walk through interesting papers and research directions in late 2019/early-2020 on:\r\n- model size and computational efficiency,\r\n- out-of-domain generalization and model evaluation,\r\n- fine-tuning and sample efficiency,\r\n- common sense and inductive biases.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=G5lmya6eKtc","dataset_link":"","demo_link":"","other_link":""}]},{"id":597,"title":"CS229: Machine Learning","description":"A broad introduction to machine learning and statistical pattern recognition. ","tags":["code","course","tutorial","video","machine-learning","stanford","cs229","andrew-ng"],"details":"This course provides a broad introduction to machine learning and statistical pattern recognition. Topics include: supervised learning (generative/discriminative learning, parametric/non-parametric learning, neural networks, support vector machines); unsupervised learning (clustering, dimensionality reduction, kernel methods); learning theory (bias/variance tradeoffs, practical advice); reinforcement learning and adaptive control. The course will also discuss recent applications of machine learning, such as to robotic control, data mining, autonomous navigation, bioinformatics, speech recognition, and text and web data processing.","links":[{"article_link":"","code_link":"https://github.com/zhixuan-lin/cs229-ps-2018","research_link":"","media_link":"https://www.youtube.com/watch?v=jGwO_UgTS7I&list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU","dataset_link":"","demo_link":"","other_link":"http://cs229.stanford.edu/"}]},{"id":596,"title":"Turning Machine Learning Models into APIs in Python","description":"Learn to how to create a simple API from a machine learning model in Python using Flask.","tags":["article","code","tutorial","machine-learning","rest-api"],"details":"- Options to implement machine learning models\r\n- What are APIs?\r\n- Flask basics\r\n- Creating a machine learning model\r\n- Saving the machine learning model: Serialization & Deserialization\r\n- Creating an API from a machine learning model using Flask\r\n- Testing your API in Postman","links":[{"article_link":"https://www.datacamp.com/community/tutorials/machine-learning-models-api-python","code_link":"https://github.com/sayakpaul/DataCamp-blogs/tree/master/DataCamp API Blog","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":595,"title":"Reproducible Models with W&B","description":"Discover simple techniques to make your ML experiments as reproducible as possible.","tags":["article","code","tutorial","machine-learning","wandb","reproducible-ml"],"details":"There are different levels of stochasticity in machine learning. Sometimes they're in the process of sampling the dataset, and other times in the machine learning models (specifically neural networks) themselves. While stochasticity brings a number of advantages in model training, it also introduces some gnarly problems with reproducibility. In this report, we'll go over some of the methods that promise to make our machine learning experiments more reproducible.","links":[{"article_link":"https://bit.ly/2Kqhu6c","code_link":"https://github.com/sayakpaul/Reproducibility-in-tf.keras-with-wandb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":594,"title":"TorchServe & TorchElastic PyTorch Libraries for Serving/Training","description":"The officially supported way to deploy and manage models with PyTorch.","tags":["article","code","kubernetes","pytorch","model-management","library","training","production","experiment-tracking","logging","torchserve","torchelastic","eks","ec2","serving"],"details":"\u2022\u00a0TorchServe - a new open-source model serving library providing a clean, well supported, and industrial-grade path to deploying PyTorch models for inference at scale.\r\n\u2022\u00a0TorchElastic - a library for fault-tolerant and elastic training in PyTorch. With the TorchElastic Kubernetes controller, developers can create fault-tolerant distributed training jobs in PyTorch using their Kubernetes clusters, including Amazon EC2 Spot instances on Amazon Elastic Kubernetes Service (EKS).","links":[{"article_link":"https://medium.com/pytorch/torchserve-and-torchelastic-for-kubernetes-new-pytorch-libraries-for-serving-and-training-models-2efd12e09adc","code_link":"https://github.com/pytorch/elastic","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://pytorch.org/serve/"}]},{"id":593,"title":"A Primer on Private Statistics","description":"We show how to privately estimate the CDF of a distribution (i.e., estimate the distribution in Kolmogorov distance), and conclude with pointers to research.","tags":["article","paper","research","tutorial","statistics","search-results-web-results--cumulative-distribution-function","kolmogorov-distance"],"details":"Part 2 of my series of educational blog posts on differentially private statistics with Jon Ullman! This time, privately estimating the CDF of a distribution + a survey. \r\n\r\nPart 1: https://kamathematics.wordpress.com/2020/04/14/a-primer-on-private-statistics-part-i/\r\nPart 2: https://kamathematics.wordpress.com/2020/04/21/a-primer-on-private-statistics-part-ii/\r\nPDF of both parts: http://www.gautamkamath.com/writings/primer.pdf","links":[{"article_link":"https://kamathematics.wordpress.com/2020/04/21/a-primer-on-private-statistics-part-ii/","code_link":"","research_link":"http://www.gautamkamath.com/writings/primer.pdf","media_link":"","dataset_link":"","demo_link":"","other_link":"https://kamathematics.wordpress.com/2020/04/14/a-primer-on-private-statistics-part-i/"}]},{"id":592,"title":"Beam Search in Sequence to Sequence Models","description":"In this video, you learn about the beam search algorithm in the context of generating sequences.","tags":["tutorial","sequence-to-sequence","beam-search"],"details":"In this video, you learn about the beam search algorithm in the context of generating sequences from Andrew Ng's Cousera ML course.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.coursera.org/lecture/nlp-sequence-models/beam-search-4EtHZ","dataset_link":"","demo_link":"","other_link":""}]},{"id":591,"title":"Overriding  train/test steps for custom training  in TF2.2","description":"Custom training loops in tf.keras can't make use of things like callbacks,etc. by default and you have to write one for yourself. How to overcome it?","tags":["article","code","tutorial","keras","tensorflow","health","unet","custom-training-loops","bone-drr","kaggle"],"details":"Here are the biggest changes. Although in this case, this isn't necessary, this is to show that how can you override the train and test steps. Why though? Two reasons:\r\n\u2022\u00a0When writing custom training loops, you often lose some good things like callbacks, checkpointing, etc and you have to write these as well with the custom logic.\r\n* If you override train and test steps, all you have to change the code at two place only and rest everything would work as with a native Keras model. Then, you won't have to write functionalities like custom callbacks and all","links":[{"article_link":"","code_link":"https://www.kaggle.com/aakashnain/bone-drr-unet-extended","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":589,"title":"Dive into Deep Learning","description":"An interactive deep learning book with code, math, and discussions, based on the NumPy interface.","tags":["article","code","course","tutorial","mxnet","deep-learning","numpy"],"details":"An interactive deep learning book with code, math, and discussions, based on the NumPy interface.","links":[{"article_link":"https://d2l.ai/","code_link":"https://github.com/d2l-ai/d2l-en","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":588,"title":"Machine Learning Crash Course","description":"Machine Learning Crash Course features a series of lessons with video lectures, real-world case studies, and hands-on practice exercises.","tags":["article","course","tutorial","tensorflow","machine-learning"],"details":"A self-study guide for aspiring machine learning practitioners Machine Learning Crash Course features a series of lessons with video lectures, real-world case studies, and hands-on practice exercises.","links":[{"article_link":"https://developers.google.com/machine-learning/crash-course","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":587,"title":"ndindex","description":"A Python library for manipulating indices of ndarrays.","tags":["article","code","library","numpy","arrays"],"details":"ndindex is a library that allows representing and manipulating objects that can be valid indices to numpy arrays, i.e., slices, integers, ellipses, None, integer and boolean arrays, and tuples thereof.","links":[{"article_link":"https://labs.quansight.org/blog/2020/04/introducing-ndindex-a-python-library-for-manipulating-indices-of-ndarrays/","code_link":"https://github.com/Quansight/ndindex","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://quansight.github.io/ndindex/"}]},{"id":586,"title":"Retrieve: Automate wget-ting pre-trained models","description":"No-frills library to download pre-trained models, cache it and return the local path.","tags":["code","python","deep-learning","library","pretraining","pre-trained-models","models"],"details":"* When using pre-trained ML models in your projects, majority of them require you to manually download the data/model weights and then specify the path in your code. Everyone in your team has to go through the same trouble of manually setting this up before they can run your models.\r\n* The idea with this library is automate this and make using pre-trained models as easy as possible.\r\n","links":[{"article_link":"","code_link":"https://github.com/amitness/retrieve","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":585,"title":"fastpages","description":"An easy to use blogging platform, with enhanced support for Jupyter Notebooks. ","tags":["code","fastai","library","github-actions","fastpages","blogging"],"details":"fastpages uses GitHub Actions to simplify the process of creating Jekyll blog posts on GitHub Pages from a variety of input formats.","links":[{"article_link":"","code_link":"https://github.com/fastai/fastpages","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://fastpages.fast.ai/"}]},{"id":584,"title":"GitHub Actions: Providing Data Scientists With New Superpowers","description":"A Tutorial on GitHub Actions For Data Scientists","tags":["article","github","tutorial","github-actions"],"details":"Recently, I\u2019ve been able to use GitHub Actions to build some very unique tools for Data Scientists, which I want to share with you today. Most importantly, I hope to get you excited about GitHub Actions, and the promise it has for giving you new superpowers as a Data Scientist.","links":[{"article_link":"https://fastpages.fast.ai/actions/markdown/2020/03/06/fastpages-actions.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":583,"title":"CS294-158-SP19 Deep Unsupervised Learning","description":"This course will cover two areas of deep learning in which labeled data is not required: Deep Generative Models and Self-supervised Learning. ","tags":["course","tutorial","video","self-supervised-learning","unsupervised-learning","generative-models"],"details":"Recent advances in generative models have made it possible to realistically model high-dimensional raw data such as natural images, audio waveforms and text corpora. Strides in self-supervised learning have started to close the gap between supervised representation learning and unsupervised representation learning in terms of fine-tuning to unseen tasks. This course will cover the theoretical foundations of these topics as well as their newly enabled applications.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/playlist?list=PLwRJQ4m4UJjPiJP3691u-qWwPGVKzSlNP","dataset_link":"","demo_link":"","other_link":"https://sites.google.com/view/berkeley-cs294-158-sp19/"}]},{"id":582,"title":"CS285: Deep Reinforcement Learning","description":"A course on deep reinforcement learning, transfer and multi-task learning.","tags":["course","tutorial","video","reinforcement-learning","multi-task-learning"],"details":"\u2022\u00a0Lecture 1: Introduction and Course Overview\r\n\u2022\u00a0Lecture 2: Supervised Learning of Behaviors\r\n\u2022\u00a0Lecture 3: TensorFlow and Neural Nets Review Session (notebook)\r\n\u2022\u00a0Lecture 4: Introduction to Reinforcement Learning\r\n\u2022\u00a0Lecture 5: Policy Gradients\r\n\u2022\u00a0Lecture 6: Actor-Critic Algorithms\r\n\u2022\u00a0Lecture 7: Value Function Methods\r\n\u2022\u00a0Lecture 8: Deep RL with Q-functions\r\n\u2022\u00a0Lecture 9: Advanced Policy Gradients\r\n\u2022\u00a0Lecture 10: Model-based Planning\r\n\u2022\u00a0Lecture 11: Model-based Reinforcement Learning\r\n\u2022\u00a0Lecture 12: Model-based Policy Learning\r\n\u2022\u00a0Lecture 13: Variational Inference and Generative Models\r\n\u2022\u00a0Lecture 14: Control as Inference\r\n\u2022\u00a0Lecture 15: Inverse Reinforcement Learning\r\n\u2022\u00a0Lecture 16: Transfer and Multi-task Learning\r\n\u2022\u00a0Lecture 17: Distributed RL\r\n\u2022\u00a0Lecture 18: Exploration (Part 1)\r\n\u2022\u00a0Lecture 19: Exploration (Part 2)\r\n\u2022\u00a0Lecture 20: Meta-learning\r\n\u2022\u00a0Lecture 21: Information Theory, Open Problems","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/playlist?list=PLkFD6_40KJIwhWJpGazJ9VSj9CFMkb79A","dataset_link":"","demo_link":"","other_link":"http://rail.eecs.berkeley.edu/deeprlcourse/"}]},{"id":581,"title":"How To Create Semantic Search For Arbitrary Objects","description":"An end-to-end example of how to build a system that can search objects semantically. By Hamel Husain & Ho-Hsiang Wu","tags":["article","code","tutorial","deep-learning","natural-language-processing","semantic-search","code-search"],"details":"Today, we share a reproducible, minimally viable product that illustrates how you can enable semantic search for arbitrary objects! Concretely, we will show you how to create a system that searches python code semantically \u2014 but this approach can be generalized to other entities (such as pictures or sound clips).","links":[{"article_link":"https://towardsdatascience.com/semantic-code-search-3cd6d244a39c","code_link":"https://github.com/hamelsmu/code_search","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":580,"title":"GitHub Actions & Machine Learning Workflows with Hamel Husain","description":" In this talk, Hamel will provide a brief tutorial on GitHub Actions, and will show you how you can use this new tool to automate your ML workflows.","tags":["tutorial","video","machine-learning","mlops","github-actions","workflows","ci-cd"],"details":"Successful machine learning projects often involve employing techniques and practices from software engineering. GitHub Actions provide a new way to incorporate some of these practices in a way that is tailored to data science. In this talk, Hamel will provide a brief tutorial on GitHub Actions, and will show you how you can use this new tool to automate and bring new innovations to your machine learning workflow.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"http://www.youtube.com/watch?v=S-kn4mmlxFU","dataset_link":"","demo_link":"","other_link":"https://www.youtube.com/watch?v=Ll50l3fsoYs"}]},{"id":579,"title":"Transfer Learning & Fine-Tuning With Keras","description":"Your 100% up-to-date guide to transfer learning & fine-tuning with Keras.","tags":["article","code","notebook","tutorial","keras","tensorflow","computer-vision","fine-tuning","transfer-learning"],"details":"\u2022\u00a0First, we will go over the Keras trainable API in detail, which underlies most transfer learning & fine-tuning workflows.\r\n\u2022\u00a0Then, we'll demonstrate the typical workflow by taking a model pretrained on the ImageNet dataset, and retraining it on the Kaggle \"cats vs dogs\" classification dataset.","links":[{"article_link":"https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html","code_link":"https://colab.research.google.com/drive/17vHSAj7no7RMdJ18MJomTf8twqw1suYC","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":578,"title":"Micrograd","description":"A tiny scalar-valued autograd engine and a neural net library on top of it with PyTorch-like API","tags":["code","neural-networks","library","autograd"],"details":"A tiny Autograd engine (with a bite! :)). Implements backpropagation (reverse-mode autodiff) over a dynamically built DAG and a small neural networks library on top of it with a PyTorch-like API. Both are tiny, with about 100 and 50 lines of code respectively. The DAG only operates over scalar values, so e.g. we chop up each neuron into all of its individual tiny adds and multiplies. However, this is enough to build up entire deep neural nets doing binary classification, as the demo notebook shows. Potentially useful for educational purposes.","links":[{"article_link":"","code_link":"https://github.com/karpathy/micrograd","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":577,"title":"Intro to Keras for Researchers","description":"Everything you need to know to use Keras & TF 2.0 for deep learning research.","tags":["code","notebook","tutorial","keras","tensorflow","deep-learning"],"details":"","links":[{"article_link":"","code_link":"https://colab.research.google.com/drive/1qKPITTI879YHTxbTgYW_MAWMHFkbOBIk","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":576,"title":"Customizing What Happens in Fit()","description":"How to leverage the convenient features of fit() with a custom training loop. ","tags":["code","notebook","tutorial","keras","tensorflow","training"],"details":"What if you need a custom training algorithm, but you still want to benefit from the convenient features of fit(), such as callbacks, built-in distribution support, or step fusing?","links":[{"article_link":"","code_link":"https://colab.research.google.com/drive/1ZshwEPDDCHKZHkpmbVPvGoDEt1O1kICw","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":575,"title":"Addition RNN","description":"An implementation of sequence to sequence learning for performing addition.","tags":["code","notebook","tutorial","recurrent-neural-networks","math","arithmetic"],"details":"In this example, we train a model to learn to add two numbers, provided as strings. Example:\r\n\u2022\u00a0Input: \"535+61\"\r\n\u2022\u00a0Output: \"596\"","links":[{"article_link":"","code_link":"https://colab.research.google.com/drive/1yabxTmMA_-iZ8Dyifta28ux5FxDL90Ak#scrollTo=7mrjD9nFUI7k","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":574,"title":"The Abstraction and Reasoning Corpus (ARC)","description":"Can a computer learn complex, abstract tasks from just a few examples? ARC can be used to measure a human-like form of general fluid intelligence.","tags":["code","dataset","paper","research","tutorial","artificial-general-intelligence","common-sense-reasoning","natural-language-processing","arc","arxiv:1911.01547"],"details":"We argue that ARC can be used to measure a human-like form of general fluid intelligence and that it enables fair general intelligence comparisons between AI systems and humans.","links":[{"article_link":"","code_link":"https://github.com/fchollet/ARC","research_link":"https://arxiv.org/abs/1911.01547","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.kaggle.com/c/abstraction-and-reasoning-challenge"}]},{"id":572,"title":"Introduction to Differential Calculus","description":"Introduces differential calculus: derivatives, partial derivatives and gradients.","tags":["code","notebook","tutorial","linear-algebra","math","differential-calculus"],"details":"Differential calculus is at the core of Deep Learning, so it is important to understand what derivatives and gradients are, how they are used in Deep Learning, and understand what their limitations are.","links":[{"article_link":"","code_link":"https://colab.research.google.com/github/ageron/handson-ml2/blob/master/math_differential_calculus.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":571,"title":"Tools - matplotlib","description":"This notebook demonstrates how to use the matplotlib library to plot beautiful graphs.","tags":["code","notebook","tutorial","matplotlib","visualization"],"details":"","links":[{"article_link":"","code_link":"https://colab.research.google.com/github/ageron/handson-ml2/blob/master/tools_matplotlib.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":570,"title":"Introduction to Image Inpainting With Deep Learning","description":"In this article, we are going to learn how to do \u201cimage inpainting\u201d, i.e. fill in missing parts of images precisely using deep learning.","tags":["article","code","tutorial","deep-learning","computer-vision","wandb","inpainting","unet"],"details":"\u2022\u00a0Introduction to image inpainting\r\n\u2022\u00a0Traditional computer vision-based approaches\r\n\u2022\u00a0Deep learning-based approaches \u2013 Vanilla Autoencoders and Partial convolutions\r\n\u2022\u00a0Future directions and ending note","links":[{"article_link":"https://www.wandb.com/articles/introduction-to-image-inpainting-with-deep-learning","code_link":"https://github.com/ayulockin/deepimageinpainting","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":569,"title":"An Introduction to Transfer Learning and HuggingFace","description":"In this talk I'll start by introducing the recent breakthroughs in NLP that resulted from the combination of Transfer Learning schemes and Transformer architect","tags":["tutorial","video","huggingface","transformers","natural-language-processing","transfer-learning"],"details":"In this talk I'll start by introducing the recent breakthroughs in NLP that resulted from the combination of Transfer Learning schemes and Transformer architectures. The second part of the talk will be dedicated to an introduction of the open-source tools released by HuggingFace, in particular our Transformers and Tokenizers libraries and our distilled models.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=rEGB7-FlPRs","dataset_link":"","demo_link":"","other_link":""}]},{"id":568,"title":"EvoNorm layers in TensorFlow 2","description":"Presents implementations of EvoNormB0 and EvoNormS0 layers as proposed in Evolving Normalization-Activation Layers by Liu et al.","tags":["article","code","paper","research","keras","tensorflow","deep-learning","automl","batch-normalization","wandb","normalization","batch-norm-relu","arxiv:2004.02967"],"details":"- Implements EvoNorm B0 and S0 layers. \r\n- Tests on Mini Inception architecture with CIFAR10 dataset.\r\n- Compares against Mini Inception architecture with CIFAR10 dataset with BatchNorm-ReLU layers. \r\n- Runs Hyperparameter Search on the `groups` hyperparameters of `EvoNormS0` layer.","links":[{"article_link":"https://app.wandb.ai/sayakpaul/EvoNorm-TensorFlow2/reports/EvoNorm-layers-in-TensorFlow-2--Vmlldzo4Mzk3MQ","code_link":"https://github.com/sayakpaul/EvoNorms-in-TensorFlow-2","research_link":"https://arxiv.org/abs/2004.02967","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":567,"title":"Neural Arithmetic Logic Units in TensorFlow 2.0","description":"TensorFlow 2.0 implementation of NALU (https://arxiv.org/abs/1808.00508). ","tags":["code","paper","research","keras","tensorflow","deep-learning","arxiv:1808.00508"],"details":" I present my implementation of Neural Arithmetic Logic Units that was proposed by Trask et al. The paper presents a solution to a very important problem in neural networks. Despite having the capability of approximating any arbitrary functions, neural networks show very poor performance at counting. Put in other words, they fail to extrapolate to the values that were seen by them during the training process.\r\n\r\nThe novelty of the paper lies in two main components as proposed by the authors: Neural Accumulator (NAC) and Neural Arithmetic Logic Gates (NALU) which build on top of NAC.","links":[{"article_link":"","code_link":"https://github.com/sayakpaul/TF-2.0-Hacks/tree/master/NALU in TF 2.0","research_link":"https://arxiv.org/abs/1808.00508","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":566,"title":"Machine learning deserves its own flavor of Continuous Delivery","description":"When traveling in the data science world, I'm homesick for a smooth continuous delivery flow. My thoughts on approachable CD4ML.","tags":["article","tutorial","cd4ml","data-version-control","mlops"],"details":"An ML project ties together large datasets, a slow training process without clear pass/fail acceptance tests, and contains multiple types of deliverables. By comparison, a classical software project just contains code and has a single deliverable (an application). Thankfully, it\u2019s possible to create a Machine Learning-specific flavor of Continuous Delivery (CD4ML) for non-enterprise organizations with existing tools today. This article:\r\n\r\n* introduces the concept of Continuous Delivery\r\n* explores why classical CD doesn\u2019t work for machine learning\r\n* suggests a set of open-source packages for creating a CD4ML tool chain.\r\n\r\nI build on work by Daniel Sato, Arif Wider, and Christoph Windheuser of Thoughtworks, Elle O\u2019Brien, Christopher Samiullah, and Lj Miranda.","links":[{"article_link":"https://booklet.ai/blog/continuous-delivery-machine-learning-cd4ml/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":565,"title":"Wasserstein GAN with Gradient Penalty in TensorFlow 2.0","description":"TensorFlow 2.0 implementation of W-GAN with GP. ","tags":["code","notebook","tutorial","keras","tensorflow","generative-adversarial-networks","fashion-mnist"],"details":"* Lipschutz constraint using the gradient penalty instead of clipping the weights of the critic. \r\n* Wasserstein distance or earth mover distance. ","links":[{"article_link":"","code_link":"https://colab.research.google.com/drive/1q6s9ohyreMhaGnn78xJNhcborV2fZ3lg","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":564,"title":"Optimize your ML models","description":"Learn to use optimize your custom image classification models (built-in tf.keras) using TensorFlow Lite and gain 10x reduction in model's size. ","tags":["code","notebook","tutorial","keras","tensorflow","computer-vision","image-classification","tpu","tensorflow-lite","embedded-systems","on-device"],"details":"Many of you might be deploying ML models on mobile devices or even embedded devices. Due to the resource-constrained nature of such devices, it's useful to optimize your model in terms of their sizes without having to worry about compensating for performance.\r\n\r\nI made a Colab Notebook that shows you how to train a custom image classification model using tf.keras and then how to optimize it using TensorFlow Lite. So, the initial model weighs 38 MB and gives ~97.5% validation accuracy and the optimized model weighs 3.4 MB and gives ~96% validation accuracy. Sounds interesting?","links":[{"article_link":"","code_link":"https://colab.research.google.com/drive/1hXfJfa8Kx96jTdvS1o_2Apx0b9-soSZZ","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":563,"title":"AWS vs Paperspace vs FloydHub : Choosing your cloud GPU partner","description":"A look at various features of the top three cloud GPU service providers. ","tags":["article","tutorial","aws","training","distributed-training","gpu","floydhub","paperspace"],"details":"A look at various features of the top three cloud GPU service providers. ","links":[{"article_link":"https://medium.com/@rupak.thakur/aws-vs-paperspace-vs-floydhub-choosing-your-cloud-gpu-partner-350150606b39","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":562,"title":"Bootstrap","description":"The most popular HTML, CSS, and JavaScript framework for developing responsive, mobile first projects on the web.","tags":["article","code","css","html","javascript","front-end-design","library","bootstrap"],"details":"Get started with Bootstrap, the world\u2019s most popular framework for building responsive, mobile-first sites, with BootstrapCDN and a template starter page.","links":[{"article_link":"https://getbootstrap.com/docs/4.0/getting-started/introduction/","code_link":"https://github.com/twbs/bootstrap","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://getbootstrap.com/"}]},{"id":561,"title":"How Docker Can Help You Become A More Effective Data Scientist","description":"A look at Docker from the perspective of a data scientist.","tags":["article","tutorial","docker","production"],"details":" I wanted to figure out how this technology could make me more effective but I found tutorials online either too detailed: elucidating features I would never use as a data scientist, or too shallow: not giving me enough information to help me understand how to be effective with Docker quickly.","links":[{"article_link":"https://towardsdatascience.com/how-docker-can-help-you-become-a-more-effective-data-scientist-7fc048ef91d5","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":560,"title":"Machine Learning Model with FLASK REST API","description":"In this tutorial we will see how you can make your first REST API for Machine Learning Model using FLASK.","tags":["api","article","tutorial","flask","machine-learning"],"details":"In this tutorial we will see how you can make your first REST API for Machine Learning Model using FLASK. We will start by creating machine learning model. Then we will see step-by-step procedure to create API using Flask and test it using Postman. ","links":[{"article_link":"https://hackernoon.com/machine-learning-w22g322x","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":559,"title":"Creating an End-to-End Machine Learning Application","description":"A complete, end-to-end ML application, implemented in both TensorFlow 2.0 and PyTorch.","tags":["api","code","tutorial","fastapi","flask","python","pytorch","tensorflow","production","wandb","systems-design"],"details":"- **Overview**: [https://github.com/madewithml/e2e-ml-app-pytorch#overview](https://github.com/madewithml/e2e-ml-app-pytorch#overview)\r\n- **PyTorch**: [https://github.com/madewithml/e2e-ml-app-pytorch]( https://github.com/madewithml/e2e-ml-app-pytorch)\r\n- **TensorFlow**: [https://github.com/madewithml/e2e-ml-app-tensorflow](https://github.com/madewithml/e2e-ml-app-tensorflow)\r\n\r\n**Videos will be released for each section over the next couple weeks.**","links":[{"article_link":"","code_link":"https://github.com/madewithml","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":558,"title":"PyTorch Notebooks","description":"\ud83d\udd25A collection of PyTorch notebooks for learning and practicing deep learning","tags":["code","tutorial","pytorch","attention","bert","deep-learning","transformers","natural-language-processing"],"details":"A collection of PyTorch notebooks for studying and practicing deep learning. Each notebook contains a set of exercises that are specifically designed to engage and encourage the learner to conduct more research and experiments. (Work in progress!)","links":[{"article_link":"","code_link":"https://github.com/dair-ai/pytorch_notebooks","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":557,"title":"When Not to Choose the Best NLP Model","description":"While these models are indeed incredible and do show unparalleled results, they may not be suited for your NLP task or your business. ","tags":["article","tutorial","natural-language-processing","production","systems-design"],"details":"","links":[{"article_link":"https://blog.floydhub.com/when-the-best-nlp-model-is-not-the-best-choice/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":556,"title":"Horovod","description":"Distributed training framework for TensorFlow, Keras, PyTorch, and Apache MXNet.","tags":["article","code","distribution","library","uber","horovod"],"details":"Horovod is a distributed deep learning training framework for TensorFlow, Keras, PyTorch, and Apache MXNet. The goal of Horovod is to make distributed deep learning fast and easy to use.","links":[{"article_link":"https://eng.uber.com/horovod/","code_link":"https://github.com/horovod/horovod","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":555,"title":"A Gentle Introduction to Multi GPU/Node Distributed Training","description":"High-level overview of the different types of training regimes that you'll encounter as you move from single GPU to multi GPU to multi node distributed training","tags":["article","tutorial","distributed-training"],"details":"This presentation is a high-level overview of the different types of training regimes that you'll encounter as you move from single GPU to multi GPU to multi node distributed training. It briefly describes where the computation happens, how the gradients are communicated, and how the models are updated and communicated. ","links":[{"article_link":"https://lambdalabs.com/blog/introduction-multi-gpu-multi-node-distributed-training-nccl-2-0/","code_link":"","research_link":"","media_link":"https://lambdalabs-files.s3-us-west-2.amazonaws.com/lambdalabs.com_presents_distributed-training-a-gentle-introduction.pdf","dataset_link":"","demo_link":"","other_link":""}]},{"id":554,"title":"Distributed Training With TensorFlow","description":"tf.distribute.Strategy can be used with a high-level API like Keras, and can also be used to distribute custom training loops.","tags":["article","tutorial","keras","tensorflow","distributed-training"],"details":"tf.distribute.Strategy has been designed with these key goals in mind:\r\n\u2022\u00a0Easy to use and support multiple user segments, including researchers, ML engineers, etc.\r\n\u2022\u00a0Provide good performance out of the box.\r\n\u2022\u00a0Easy switching between strategies.","links":[{"article_link":"https://www.tensorflow.org/guide/distributed_training","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":553,"title":"\u201cReparameterization\u201d trick in Variational Autoencoders","description":"In this article, we are going to learn about the \u201creparameterization\u201d trick that makes Variational Autoencoders (VAE) an eligible candidate for Backpropagation.","tags":["article","tutorial","autoencoders","generative-modeling","reparameterization"],"details":"* Learn about the caveats of the vanilla autoencoders\r\n* Learn about Variational Autoencoders (VAE) at a high level\r\n* Learn about the \"re-parameterization\" trick that makes VAEs eligible for gradient-based learning","links":[{"article_link":"https://towardsdatascience.com/reparameterization-trick-126062cfd3c3","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":552,"title":"Holopix50k: A Large-Scale In-the-wild Stereo Image Dataset","description":"The largest dataset of in-the-wild stereo image pairs (50K) crowd-sourced from the Holopix lightfield image-sharing social network.","tags":["article","code","paper","research","deep-learning","computer-vision","depth-estimation","disparity-estimation","self-supervised-learning","datasets","computational-photography","stereo-dataset","arxiv:2003.11172"],"details":"Holopix50k is a large-scale dataset of stereo-images collected in-the-wild from the Holopix social media platform. The dataset consists of 49,368 stereo pairs, making it one of the largest stereo datasets published to-date, filling in a need for enabling generalizability to real-world scenarios. In the paper, the authors show that using the Holopix50k dataset also improves a variety of stereo tasks such as self-supervised depth estimation and stereo super-resolution over existing SOTA methods.","links":[{"article_link":"https://heartbeat.fritz.ai/holopix50k-a-large-scale-in-the-wild-stereo-image-dataset-3fb89bb03c09","code_link":"https://github.com/LeiaInc/holopix50k","research_link":"https://arxiv.org/abs/2003.11172","media_link":"https://www.linkedin.com/posts/punkohl_deeplearning-machinelearning-dataset-activity-6650140228579405824-qAyz","dataset_link":"","demo_link":"","other_link":"https://leiainc.github.io/holopix50k/"}]},{"id":551,"title":"Embedding an image processing function in a tf.keras model","description":"Learn how to embed an image preprocessing function in a tf.keras model. ","tags":["article","code","notebook","tutorial","keras","tensorflow","embeddings","image-preprocessing","serving"],"details":"In this tutorial, we are going to see how to embed a simple image preprocessing function within a trained model (tf.keras) while exporting it for serving. This is a useful feature to have because it can help us reduce a lot of boilerplate code needed while using any model for serving purposes. With this capability, you get a lot more flexibility and modularity to your model.","links":[{"article_link":"https://sayak.dev/tf.keras/preprocessing/2020/04/13/embedding-image-preprocessing-functions.html","code_link":"https://colab.research.google.com/github/sayakpaul/portfolio/blob/master/_notebooks/2020-04-13-embedding-image-preprocessing-functions.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":550,"title":"Cycle GAN in TensorFlow 2.0 with Custom Loops","description":"Implementation of \"Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks\" by Jun-Yan Zhu et al. ","tags":["code","notebook","paper","research","tutorial","tensorflow","generative-adversarial-networks","computer-vision","image-to-image-translation","unpaired-images","arxiv:1703.10593"],"details":"* Readable custom loops to make the implementation consistent with the original paper\r\n* Tested on Monet2Photo dataset\r\n* According to the paper, the discriminators were trained using a history of previously generated images rather than ones produced during the current mini-batch. However, to keep it a bit simpler, I did not implement this. \r\n* Did not decay the learning rate for the second half of the training.","links":[{"article_link":"","code_link":"https://colab.research.google.com/drive/17hPcW5taO3n_CNpk-ZQyQiSXrT8U61ib","research_link":"https://arxiv.org/abs/1703.10593","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":549,"title":"15 Best Tools for Tracking Machine Learning Experiments","description":"A feature comparison of all the open-source and commercial options for experiment tracking.","tags":["article","tutorial","experiment-tracking"],"details":"In this article, I will explain why you, as data scientists and machine learning engineers, need a tool for tracking machine learning experiments and what is the best software you can use for that.","links":[{"article_link":"https://neptune.ai/blog/best-ml-experiment-tracking-tools","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":548,"title":"Hyperparameter Tuning for Machine Learning Models","description":"An in-depth look at hyperparameter optimization.","tags":["article","tutorial","ray","bayesian-optimization","hyperparameter-optimization","optuna","hyperopt","sigopt"],"details":"Parameters which define the model architecture are referred to as hyperparameters and thus this process of searching for the ideal model architecture is referred to as hyperparameter tuning.","links":[{"article_link":"https://www.jeremyjordan.me/hyperparameter-tuning/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":547,"title":"Automated Machine Learning Hyperparameter Tuning in Python","description":"A complete walk through using Bayesian optimization for automated hyperparameter tuning in Python","tags":["article","tutorial","bayesian-optimization","hyperparameter-optimization"],"details":"Increasingly, hyperparameter tuning is done by automated methods that aim to find optimal hyperparameters in less time using an informed search with no manual effort necessary beyond the initial set-up.","links":[{"article_link":"https://towardsdatascience.com/automated-machine-learning-hyperparameter-tuning-in-python-dfda59b72f8a","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":546,"title":"Streamlit","description":"The fastest way to build custom ML tools.","tags":["code","library","visualization","streamlit","dashboard"],"details":"Streamlit is an open-source app framework for Machine Learning and Data Science teams. Create beautiful data apps in hours, not weeks. All in pure Python. All for free.","links":[{"article_link":"","code_link":"https://github.com/streamlit/streamlit","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.streamlit.io/"}]},{"id":545,"title":"1000x Faster Data Augmentation","description":"Population Based Augmentation (PBA), an algorithm that quickly and efficiently learns a state-of-the-art approach to augmenting data for neural network training","tags":["article","code","paper","research","tutorial","data-augmentation","arxiv:1905.05393"],"details":"PBA matches the previous best result on CIFAR and SVHN but uses one thousand times less compute, enabling researchers and practitioners to effectively learn new augmentation policies using a single workstation GPU. You can use PBA broadly to improve deep learning performance on image recognition tasks.","links":[{"article_link":"https://bair.berkeley.edu/blog/2019/06/07/data_aug/","code_link":"https://github.com/arcelien/pba","research_link":"https://arxiv.org/abs/1905.05393","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":544,"title":"Data Augmentation | How to use Deep Learning With Limited Data","description":"This article is a comprehensive review of Data Augmentation techniques for Deep Learning, specific to images.","tags":["article","tutorial","data-augmentation","pretraining"],"details":"","links":[{"article_link":"https://nanonets.com/blog/data-augmentation-how-to-use-deep-learning-when-you-have-limited-data-part-2/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":543,"title":"The Process for Data Preparation and Feature Engineering","description":"To get our predictions right, we must construct the data set and transform the data correctly.","tags":["article","tutorial","feature-engineering","systems-design","data-collection"],"details":"The process shown is not always sequential. You might, for example, split your data after you transform it. You might need to collect more data. You might need to modify the feature set, even after training begins, as you learn empirically what works and what doesn't.","links":[{"article_link":"https://developers.google.com/machine-learning/data-prep/process","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":542,"title":"How (And Why) to Create a Good Validation Set","description":"Steps for creating a representative validation set for training.","tags":["article","tutorial","systems-design","data-collection","checklist","validation-set"],"details":"A key property of the validation and test sets is that they must be representative of the new data you will see in the future. This may sound like an impossible order! By definition, you haven\u2019t seen this data yet. But there are still a few things you know about it.","links":[{"article_link":"https://www.fast.ai/2017/11/13/validation-sets/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":541,"title":"Interpretable Machine Learning","description":"Extracting human understandable insights from any Machine Learning model.","tags":["article","tutorial","interpretability","ermutation-importance","partial-dependence-plots","shap-values"],"details":"Machine Learning doesn\u2019t have to be a black box anymore. What use is a good model if we cannot explain the results to others. Interpretability is as important as creating a model. To achieve wider acceptance among the population, it is crucial that Machine learning systems are able to provide satisfactory explanations for their decisions. As Albert Einstein said,\u201d If you can\u2019t explain it simply, you don\u2019t understand it well enough\u201d.\r\n\r\nSome of the benefits that interpretability brings along are:\r\n\r\n* Reliability\r\n* Debugging\r\n* Informing feature engineering\r\n* Directing future data collection\r\n* Informing human decision-making\r\n* Building Trust","links":[{"article_link":"https://towardsdatascience.com/interpretable-machine-learning-1dec0f2f3e6b","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":540,"title":"Deep Learning Is Not Good Enough, We Need Bayesian Deep Learning","description":"In this post I\u2019m going to introduce Bayesian deep learning (BDL), which provides a deep learning framework which can also model uncertainty.","tags":["article","tutorial","bayesian-deep-learning","deep-learning","uncertainty"],"details":"In this post I\u2019m going to introduce a resurging field known as Bayesian deep learning (BDL), which provides a deep learning framework which can also model uncertainty. BDL can achieve state-of-the-art results, while also understanding uncertainty. I\u2019m going to explain the different types of uncertainty and show how to model them. Finally, I\u2019ll discuss a recent result which shows how to use uncertainty to weight losses for multi-task deep learning. ","links":[{"article_link":"https://alexgkendall.com/computer_vision/bayesian_deep_learning_for_safe_ai/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":539,"title":"Advances in Few-Shot Learning: A Guided Tour","description":"A deep dive into matching networks, prototypical networks and model-agnostic meta-learning.","tags":["article","code","tutorial","few-shot-learning","meta-learning"],"details":"In this article I will explore some recent advances in few-shot learning through a deep dive into three cutting-edge papers:\r\n\r\n* Matching Networks: A differentiable nearest-neighbours classifier\r\n* Prototypical Networks: Learning prototypical representations\r\n* Model-agnostic Meta-Learning: Learning to fine-tune","links":[{"article_link":"https://towardsdatascience.com/advances-in-few-shot-learning-a-guided-tour-36bc10a68b77","code_link":"https://github.com/oscarknagg/few-shot","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":538,"title":"N-Shot Learning: Learning More with Less Data","description":"An in-depth look at zero-shot learning and few-shot learning.","tags":["article","tutorial","few-shot-learning","one-shot-learning","n-shot-learning"],"details":"","links":[{"article_link":"https://blog.floydhub.com/n-shot-learning/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":537,"title":"An Overview of Multi-Task Learning in Deep Neural Networks","description":"This post gives a general overview of the current state of multi-task learning.","tags":["article","tutorial","multi-task-learning"],"details":"Multi-task learning is becoming more and more popular. This post gives a general overview of the current state of multi-task learning. In particular, it provides context for current neural network-based methods by discussing the extensive multi-task learning literature.","links":[{"article_link":"https://ruder.io/multi-task/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":536,"title":"Active Learning: Curious AI Algorithms","description":"Discover active learning, a case of semi-supervised machine learning: from its definition and its benefits, to applications and modern research into it.\r\n","tags":["article","tutorial","active-learning","semi-supervised-learning"],"details":"You will learn more about how you can use active learning in conjunction with transfer learning to optimally leverage existing (and new) data.","links":[{"article_link":"https://www.datacamp.com/community/tutorials/active-learning","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":535,"title":"Machine Learning for Humans, Part 3: Unsupervised Learning","description":"Clustering and dimensionality reduction: k-means clustering, hierarchical clustering, principal component analysis (PCA), singular value decomposition (SVD)","tags":["article","tutorial","clustering","dimensionality-reduction","unsupervised-learning","principal-component-analysis","svd"],"details":"Clustering and dimensionality reduction: k-means clustering, hierarchical clustering, principal component analysis (PCA), singular value decomposition (SVD)","links":[{"article_link":"https://medium.com/machine-learning-for-humans/unsupervised-learning-f45587588294","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":533,"title":"Generative Modeling with Sparse Transformers","description":"Sparse Transformer, a deep neural network which sets new records at predicting what comes next in a sequence\u2014whether text, images, or sound.","tags":["article","code","paper","research","tutorial","transformers","audio","computer-vision","image-generation","music-generation","natural-language-processing","generative-modeling","sparse-transformers","arxiv:1904.10509"],"details":"Transformers are powerful sequence models, but require time and memory that grows quadratically with the sequence length. In this paper we introduce sparse factorizations of the attention matrix which reduce this to O(nn\u203e\u221a). We also introduce a) a variation on architecture and initialization to train deeper networks, b) the recomputation of attention matrices to save memory, and c) fast attention kernels for training. We call networks with these changes Sparse Transformers, and show they can model sequences tens of thousands of timesteps long using hundreds of layers. We use the same architecture to model images, audio, and text from raw bytes, setting a new state of the art for density modeling of Enwik8, CIFAR-10, and ImageNet-64. We generate unconditional samples that demonstrate global coherence and great diversity, and show it is possible in principle to use self-attention to model sequences of length one million or more.","links":[{"article_link":"https://openai.com/blog/sparse-transformer/","code_link":"https://github.com/openai/sparse_attention","research_link":"https://arxiv.org/abs/1904.10509","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":532,"title":"Magenta","description":"Making music and art using machine learning.","tags":["article","code","notebook","tensorflow","art","library","music","audio","music-generation","magenta"],"details":"An open source research project exploring the role of machine learning as a tool in the creative process.","links":[{"article_link":"https://magenta.tensorflow.org/","code_link":"https://github.com/tensorflow/magenta","research_link":"","media_link":"https://colab.research.google.com/notebooks/magenta/hello_magenta/hello_magenta.ipynb","dataset_link":"","demo_link":"","other_link":""}]},{"id":531,"title":"GANSynth: Making music with GANs","description":"In this post, we introduce GANSynth, a method for generating high-fidelity audio with Generative Adversarial Networks (GANs).","tags":["article","code","paper","research","tutorial","tensorflow","generative-adversarial-networks","music","audio","music-generation","magenta","gansynth","arxiv:1902.08710"],"details":"GANSynth learns to produce individual instrument notes like the NSynth Dataset. With pitch provided as a conditional attribute, the generator learns to use its latent space to represent different instrument timbres. This allows us to synthesize performances from MIDI files, either keeping the timbre constant, or interpolating between instruments over time.","links":[{"article_link":"https://magenta.tensorflow.org/gansynth","code_link":"https://github.com/tensorflow/magenta/tree/master/magenta/models/gansynth","research_link":"https://arxiv.org/abs/1902.08710","media_link":"https://storage.googleapis.com/magentadata/papers/gansynth/index.html","dataset_link":"","demo_link":"","other_link":""}]},{"id":530,"title":"Neural Nets for Generating Music","description":"A look at the use of deep learning on music generation. ","tags":["article","tutorial","deep-learning","audio","music-generation"],"details":"A look at the use of deep learning on music generation. ","links":[{"article_link":"https://medium.com/artists-and-machine-intelligence/neural-nets-for-generating-music-f46dffac21c0","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":529,"title":"Real-Time Voice Cloning","description":"Clone a voice in 5 seconds to generate arbitrary speech in real-time. Code for Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech.","tags":["code","paper","research","tutorial","video","natural-language-processing","speech","speech-synthesis","sv2tts","text-to-speech","arxiv:1806.04558"],"details":"SV2TTS is a three-stage deep learning framework that allows to create a numerical representation of a voice from a few seconds of audio, and to use it to condition a text-to-speech model trained to generalize to new voices.","links":[{"article_link":"","code_link":"https://github.com/CorentinJ/Real-Time-Voice-Cloning","research_link":"https://arxiv.org/abs/1806.04558","media_link":"https://www.youtube.com/watch?v=-O_hYhToKoA","dataset_link":"","demo_link":"","other_link":""}]},{"id":528,"title":"Tacotron 2 (without wavenet)","description":"PyTorch implementation with faster-than-realtime inference.","tags":["article","code","paper","research","tutorial","speech","speech-synthesis","tacotron","tts","arxiv:1712.05884"],"details":"This implementation includes distributed and automatic mixed precision support and uses the LJSpeech dataset. Distributed and Automatic Mixed Precision support relies on NVIDIA's Apex and AMP.","links":[{"article_link":"https://devblogs.nvidia.com/generate-natural-sounding-speech-from-text-in-real-time/","code_link":"https://github.com/NVIDIA/tacotron2","research_link":"https://arxiv.org/abs/1712.05884","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":527,"title":"Frameworks For End-to-End Speech Recognition ","description":"Deep Learning-Based Automatic Speech Recognition","tags":["article","tutorial","speech","speech-recognition","asr"],"details":"In this blog post, we\u2019ll learn how to perform speech recognition with 3 different implementations of popular deep learning frameworks.\r\n\r\n1. Connectionist Temporal Classification\r\n2. Sequence-To-Sequence\r\n3. Online Sequence-to-Sequence","links":[{"article_link":"https://heartbeat.fritz.ai/the-3-deep-learning-frameworks-for-end-to-end-speech-recognition-that-power-your-devices-37b891ddc380","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":526,"title":"How to do Speech Recognition with Deep Learning","description":"Let\u2019s learn how to do speech recognition with deep learning!","tags":["article","tutorial","deep-learning","speech","speech-recognition"],"details":"","links":[{"article_link":"https://medium.com/@ageitgey/machine-learning-is-fun-part-6-how-to-do-speech-recognition-with-deep-learning-28293c162f7a","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":525,"title":"DoWhy","description":"DoWhy is a Python library for causal inference that supports explicit modeling and testing of causal assumptions. ","tags":["article","code","bayesian-deep-learning","library","causal-inference","dowhy","microsoft"],"details":"DoWhy is a Python library for causal inference that supports explicit modeling and testing of causal assumptions. DoWhy is based on a unified language for causal inference, combining causal graphical models and potential outcomes frameworks. ","links":[{"article_link":"https://towardsdatascience.com/introducing-dowhy-cc58b75d61ac","code_link":"https://github.com/microsoft/dowhy","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://microsoft.github.io/dowhy/"}]},{"id":524,"title":"Causal Inference in Machine Learning","description":"An illustrated look at causal inference in machine learning.","tags":["tutorial","causal-inference","counterfactuals","causality"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"http://www.homepages.ucl.ac.uk/~ucgtrbd/talks/imperial_causality.pdf","dataset_link":"","demo_link":"","other_link":"http://www.homepages.ucl.ac.uk/~ucgtrbd/papers/causality.pdf"}]},{"id":523,"title":"Causality in Machine Learning 101 for Dummies like Me","description":"Exploring causality through the lens of machine learning.","tags":["article","tutorial","causal-inference","causality"],"details":"","links":[{"article_link":"https://towardsdatascience.com/causality-in-machine-learning-101-for-dummies-like-me-f7f161e7383e","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":522,"title":"Survival Analysis: Intuition & Implementation in Python","description":"An overview and implementation of survival analysis.","tags":["article","code","tutorial","survival-analysis","time-to-event","lifelines","kaplan-meier-estimate","cox-proportional-hazard-model"],"details":"\u2022\u00a0Introduction\r\n\u2022\u00a0Definitions\r\n\u2022\u00a0Mathematical Intuition\r\n\u2022\u00a0Kaplan-Meier Estimate\r\n\u2022\u00a0Cox Proportional Hazard Model\r\n\u2022\u00a0End Note\r\n\u2022\u00a0Additional Resources","links":[{"article_link":"https://towardsdatascience.com/survival-analysis-intuition-implementation-in-python-504fde4fcf8e","code_link":"https://github.com/anurag-code/Survival-Analysis-Intuition-Implementation-in-Python","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":521,"title":"Lifelines","description":"Survival analysis in Python ","tags":["article","code","library","survival-analysis","pandas"],"details":"\u2022\u00a0built on top of Pandas\r\n\u2022\u00a0internal plotting methods\r\n\u2022\u00a0simple and intuitive API\r\n\u2022\u00a0only focus is survival analysis\r\n\u2022\u00a0handles right, left and interval censored data","links":[{"article_link":"https://lifelines.readthedocs.io/en/latest/Survival%20Analysis%20intro.html","code_link":"https://github.com/CamDavidsonPilon/lifelines","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://lifelines.readthedocs.io/"}]},{"id":520,"title":"10 Clustering Algorithms With Python","description":"Clustering or cluster analysis is an unsupervised learning problem.","tags":["article","tutorial","scikit-learn","clustering","unsupervised-learning","affinity-propagation","agglomerative-clustering","birch","dbscan","k-means","mean-shift","gaussian-mixture-model"],"details":"\u2022\u00a0Clustering is an unsupervised problem of finding natural groups in the feature space of input data.\r\n\u2022\u00a0There are many different clustering algorithms and no single best method for all datasets.\r\n\u2022\u00a0How to implement, fit, and use top clustering algorithms in Python with the scikit-learn machine learning library.","links":[{"article_link":"https://machinelearningmastery.com/clustering-algorithms-with-python/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":519,"title":"Clustering Algorithms","description":"A look at different types of clustering.","tags":["article","tutorial","clustering","unsupervised-learning"],"details":"\u2022\u00a0Centroid-based Clustering\r\n\u2022\u00a0Density-based Clustering\r\n* Distribution-based Clustering\r\n* Hierarchical Clustering","links":[{"article_link":"https://developers.google.com/machine-learning/clustering/clustering-algorithms","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":518,"title":"Topic Modeling with Gensim (Python)","description":"Application of LDA for topic modeling using Gensim.","tags":["article","tutorial","latent-dirichlet-allocation","topic-modeling","gensim","perplexity"],"details":"Latent Dirichlet Allocation (LDA) is a popular algorithm for topic modeling with excellent implementations in the Python\u2019s Gensim package. The challenge, however, is how to extract good quality of topics that are clear, segregated and meaningful. This depends heavily on the quality of text preprocessing and the strategy of finding the optimal number of topics. This tutorial attempts to tackle both of these problems.","links":[{"article_link":"https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":517,"title":"An Intuitive Guide to Deep Network Architectures","description":"Intuition behind base network architectures like MobileNets, Inception, and ResNet.","tags":["article","tutorial","computer-vision","image-classification","object-detection","transfer-learning"],"details":"\u2022\u00a0VGG16\r\n\u2022\u00a0VGG19\r\n\u2022\u00a0ResNet50\r\n\u2022\u00a0Inception v3\r\n\u2022\u00a0Xception\r\n\u2022\u00a0MobileNet","links":[{"article_link":"https://towardsdatascience.com/an-intuitive-guide-to-deep-network-architectures-65fdc477db41","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":516,"title":"Deep Learning for Object Detection: A Comprehensive Review","description":"A closer look at Tensorflow\u2019s object detection models: Faster R-CNN, R-FCN, and SSD.","tags":["article","tutorial","tensorflow","convolutional-neural-networks","computer-vision","object-detection","rcnn"],"details":"\u2022\u00a0Single Shot Multibox Detector (SSD) with MobileNets\r\n\u2022\u00a0SSD with Inception V2\r\n\u2022\u00a0Region-Based Fully Convolutional Networks (R-FCN) with Resnet 101\r\n\u2022\u00a0Faster RCNN with Resnet 101\r\n\u2022\u00a0Faster RCNN with Inception Resnet v2","links":[{"article_link":"https://towardsdatascience.com/deep-learning-for-object-detection-a-comprehensive-review-73930816d8d9","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":515,"title":"AI Fairness 360 Open Source Toolkit","description":"A comprehensive set of fairness metrics for datasets and ML models, explanations for metrics, and algorithms to mitigate bias in datasets and models.","tags":["article","code","paper","research","library","fairness","bias","ibm","arxiv:1810.01943"],"details":"The AI Fairness 360 Python package includes:\r\n\r\n* a comprehensive set of metrics for datasets and models to test for biases,\r\n* explanations for these metrics, and\r\n* algorithms to mitigate bias in datasets and models. It is designed to translate algorithmic research from the lab into the actual practice of domains as wide-ranging as finance, human capital management, healthcare, and education. We invite you to use it and improve it.","links":[{"article_link":"https://aif360.mybluemix.net/","code_link":"https://github.com/IBM/AIF360","research_link":"https://arxiv.org/abs/1810.01943","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":514,"title":"Algorithmic Solutions to Algorithmic Bias: A Technical Guide","description":"Technical approaches to mitigating algorithmic bias.","tags":["article","tutorial","autoencoders","variational-autoencoders","adversarial-learning","fairness","bias","de-biasing","upsampling"],"details":"* adversarial de-biasing of models through protection of sensitive attributes\r\n* encoding invariant representations with semi-supervised, variational \u201cfair\u201d autoencoders\r\n* dynamic upsampling of training data based on learned latent representations, and\r\n* preventing disparity amplification through distributionally robust optimization.","links":[{"article_link":"https://towardsdatascience.com/algorithmic-solutions-to-algorithmic-bias-aef59eaf6565","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":513,"title":"lda2vec: Tools for interpreting natural language","description":"The lda2vec model tries to mix the best parts of word2vec and LDA into a single framework.","tags":["code","paper","research","video","latent-dirichlet-allocation","library","embeddings","interpretability","natural-language-processing","topic-modeling","word-embeddings","word2vec","lda2vec","arxiv:1605.02019"],"details":"The lda2vec model tries to mix the best parts of word2vec and LDA into a single framework. word2vec captures powerful relationships between words, but the resulting vectors are largely uninterpretable and don't represent documents. LDA on the other hand is quite interpretable by humans, but doesn't model local word relationships like word2vec. We build a model that builds both word and document topics, makes them interpreable, makes topics over clients, times, and documents, and makes them supervised topics.","links":[{"article_link":"","code_link":"https://github.com/cemoody/lda2vec","research_link":"https://arxiv.org/abs/1605.02019","media_link":"https://www.youtube.com/watch?v=eHcBeVnAiD4","dataset_link":"","demo_link":"","other_link":"https://lda2vec.readthedocs.io/en/latest/"}]},{"id":512,"title":"Topic Modeling and Latent Dirichlet Allocation (LDA) in Python","description":"Apply LDA to a set of documents and split them into topics. ","tags":["article","code","notebook","tutorial","latent-dirichlet-allocation","topic-modeling","tfidf"],"details":"Topic modeling is a type of statistical modeling for discovering the abstract \u201ctopics\u201d that occur in a collection of documents. Latent Dirichlet Allocation (LDA) is an example of topic model and is used to classify text in a document to a particular topic. It builds a topic per document model and words per topic model, modeled as Dirichlet distributions.","links":[{"article_link":"https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24","code_link":"https://github.com/susanli2016/NLP-with-Python/blob/master/LDA_news_headlines.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":511,"title":"Complete Guide to Topic Modeling","description":"An overview of topic modeling with scikit-learn and gensim.","tags":["article","tutorial","scikit-learn","topic-modeling","gensim"],"details":"An overview of topic modeling with scikit-learn and gensim.","links":[{"article_link":"https://nlpforhackers.io/topic-modeling/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":510,"title":"Dask","description":"A flexible library for parallel computing in Python.","tags":["code","python","scikit-learn","library","pandas","numpy","parallel-computing","dask","dataframes"],"details":"Dask provides advanced parallelism for analytics, enabling performance at scale for the tools you love.","links":[{"article_link":"","code_link":"https://github.com/dask/dask","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://dask.org/"}]},{"id":509,"title":"Time Series Prediction with LSTM Using PyTorch","description":"Time series applied to forecasting on the Airplane Passengers Dataset.","tags":["code","notebook","tutorial","pytorch","lstm","forecasting","time-series"],"details":"Time series applied to forecasting on the Airplane Passengers Dataset.","links":[{"article_link":"","code_link":"https://github.com/spdin/time-series-prediction-lstm-pytorch/blob/master/Time_Series_Prediction_with_LSTM_Using_PyTorch.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":508,"title":"STEFANN: Scene Text Editor using Font Adaptive Neural Network","description":"A generalized method for realistic modification of textual content present in a scene image. \u2b50\ufe0f Accepted in CVPR 2020.","tags":["article","code","paper","research","tutorial","video","convolutional-neural-networks","deep-learning","computer-vision","image-generation","stefann","colornet","scene-text-editor","cvpr","font-generation","cvpr-2020","scene-image","font-adaptive","font-color-transfer","single-observation","fannet","generative-networks","arxiv:1903.01192"],"details":"We approach the problem in two stages. At first, the unobserved character (target) is generated from an observed character (source) being modified. We propose two different neural network architectures - (a) FANnet to achieve structural consistency with source font and (b) Colornet to preserve source color. Next, we replace the source character with the generated character maintaining both geometric and visual consistency with neighboring characters. Our method works as a unified platform for modifying text in images. We present the effectiveness of our method on COCO-Text and ICDAR datasets both qualitatively and quantitatively.","links":[{"article_link":"https://prasunroy.github.io/stefann","code_link":"https://github.com/prasunroy/stefann","research_link":"https://arxiv.org/abs/1903.01192","media_link":"https://www.youtube.com/watch?v=HTVQXHPIKKo","dataset_link":"","demo_link":"","other_link":""}]},{"id":507,"title":"Almost Everything You Need to Know About Time Series","description":"Understand moving average, exponential smoothing, stationarity, autocorrelation, SARIMA, and more.","tags":["article","tutorial","time-series","autocorrelation","sarima","moving-average"],"details":"In this post, I will introduce different characteristics of time series and how we can model them to obtain accurate (as much as possible) forecasts.","links":[{"article_link":"https://towardsdatascience.com/almost-everything-you-need-to-know-about-time-series-860241bdc578","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":506,"title":"Deep Learning for Anomaly Detection","description":"Techniques and applications of anomaly detection.","tags":["article","tutorial","autoencoders","generative-adversarial-networks","sequence-to-sequence","support-vector-machines","variational-autoencoders","anomaly-detection","self-supervised-learning","semi-supervised-learning","unsupervised-learning","systems-design"],"details":"For this report we built two prototypes: \r\n\u2022\u00a0Blip - https://blip.fastforwardlabs.com/\r\n\u2022\u00a0Anomagram - https://anomagram.fastforwardlabs.com/#/","links":[{"article_link":"https://ff12.fastforwardlabs.com/","code_link":"","research_link":"","media_link":"https://ff12.fastforwardlabs.com/ff12-deep-learning-for-anomaly-detection.pdf","dataset_link":"","demo_link":"","other_link":"https://anomagram.fastforwardlabs.com/#/"}]},{"id":505,"title":"Anomaly detection with Keras, TensorFlow, and Deep Learning","description":"Perform anomaly detection in your own image datasets using deep learning.","tags":["article","tutorial","keras","tensorflow","autoencoders","deep-learning","anomaly-detection","computer-vision"],"details":"\u2022\u00a0What model architecture should we use?\r\n\u2022\u00a0Are some deep neural network architectures better than others for anomaly/outlier detection?\r\n\u2022\u00a0How do we handle the class imbalance problem?\r\n\u2022\u00a0What if we wanted to train an unsupervised anomaly detector?","links":[{"article_link":"https://www.pyimagesearch.com/2020/03/02/anomaly-detection-with-keras-tensorflow-and-deep-learning/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":504,"title":"Deep Learning for Anomaly Detection: A Survey","description":"We present a structured and comprehensive review of research methods in deep anomaly detection (DAD).","tags":["paper","research","tutorial","anomaly-detection","survey","arxiv:1901.03407"],"details":"We also discuss the adoption of DAD methods across various application domains and assess their effectiveness.","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/1901.03407","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":503,"title":"Anomaly Detection with Autoencoder in TensorFlow 2.0","description":"How to implement a Deep Neural Network Model for Anomaly Detection in TensorFlow 2.0.","tags":["article","tutorial","tensorflow","autoencoders","finance","anomaly-detection","fraud-detection","financial-fraud"],"details":"\u2022\u00a0Introduction\r\n\u2022\u00a0Anomaly Detection\r\n\u2022\u00a0Uses Cases for Anomaly Detection Systems\r\n\u2022\u00a0Anomaly Case Study: Financial Fraud\r\n\u2022\u00a0How does an Autoencoder work?\r\n\u2022\u00a0Anomaly Detection with AutoEncoder\r\n\u2022\u00a0Fraud Detection in TensorFlow 2.0","links":[{"article_link":"https://www.deeplearning-academy.com/p/ai-wiki-anomaly-detection","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":502,"title":"Anomaly Detection for Dummies","description":"Unsupervised anomaly detection for univariate & multivariate data.","tags":["article","code","notebook","tutorial","anomaly-detection","outlier-detection","unsupervised-learning","univariate","multivariate"],"details":"Anomaly detection is the process of identifying unexpected items or events in data sets, which differ from the norm. And anomaly detection is often applied on unlabeled data which is known as unsupervised anomaly detection. ","links":[{"article_link":"https://towardsdatascience.com/anomaly-detection-for-dummies-15f148e559c1","code_link":"https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Anomaly_Detection_for_Dummies.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":501,"title":"Shakespeare Meets Google's Flax","description":"Application of RNNs in Flax: Character-Level Language Model.","tags":["article","code","tutorial","recurrent-neural-networks","natural-language-processing","text-generation","flax","char-rnn"],"details":"","links":[{"article_link":"https://hackernoon.com/shakespeare-meets-googles-flax-8m1r34q9","code_link":"https://github.com/Skyy93/CharacterLevelModelFlax/","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":500,"title":"Homomorphic Encryption in Pysyft With Seal and Pytorch","description":"Evaluate tensor operations on encrypted data by leveraging the CKKS homomorphic encryption scheme implemented on the SEAL Microsoft library.","tags":["article","code","tutorial","pytorch","library","privacy","pysyft","differential-privacy","homomorphic-encryption","seal","tenseal"],"details":"In this post we showcase a new tensor type that leverages the CKKS homomorphic encryption scheme implemented on the SEAL Microsoft library to evaluate tensor operations on encrypted data.","links":[{"article_link":"https://blog.openmined.org/ckks-homomorphic-encryption-pytorch-pysyft-seal/","code_link":"https://github.com/OpenMined/TenSEAL","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":499,"title":"Deep Learning for Videos: A 2018 Guide to Action Recognition","description":"In this post, I summarize the literature on action recognition from videos. ","tags":["article","tutorial","video","convolutional-neural-networks","spatial-temporal-cnn","temporal-cnn","computer-vision","video-classification","action-recognition"],"details":"\u2022\u00a0What is action recognition and why is it tough\r\n\u2022\u00a0Overview of approaches\r\n\u2022\u00a0Summary of papers","links":[{"article_link":"http://blog.qure.ai/notes/deep-learning-for-videos-action-recognition-review","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":498,"title":"DCGAN Tutorial ","description":"This tutorial will give an introduction to DCGANs through an example.","tags":["article","code","tutorial","pytorch","generative-adversarial-networks","dcgan"],"details":"We will train a generative adversarial network (GAN) to generate new celebrities after showing it pictures of many real celebrities. Most of the code here is from the dcgan implementation in pytorch/examples, and this document will give a thorough explanation of the implementation and shed light on how and why this model works. But don\u2019t worry, no prior knowledge of GANs is required, but it may require a first-timer to spend some time reasoning about what is actually happening under the hood. Also, for the sake of time it will help to have a GPU, or two. ","links":[{"article_link":"https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html","code_link":"https://github.com/pytorch/tutorials/blob/master/beginner_source/dcgan_faces_tutorial.py","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":497,"title":"Torchvision Object Detection Finetuning Tutorial","description":"Finetuning a pre-trained Mask R-CNN model in the Penn-Fudan Database for Pedestrian Detection and Segmentation.","tags":["article","code","notebook","tutorial","pytorch","convolutional-neural-networks","computer-vision","fine-tuning","object-detection","segmentation","mask-rcnn","torchvision"],"details":"For this tutorial, we will be finetuning a pre-trained Mask R-CNN model in the Penn-Fudan Database for Pedestrian Detection and Segmentation. It contains 170 images with 345 instances of pedestrians, and we will use it to illustrate how to use the new features in torchvision in order to train an instance segmentation model on a custom dataset.","links":[{"article_link":"https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html","code_link":"https://colab.research.google.com/github/pytorch/vision/blob/temp-tutorial/tutorials/torchvision_finetuning_instance_segmentation.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":496,"title":"Fast- Neural Style","description":"Pytorch implementation of an algorithm for artistic style transfer. ","tags":["code","paper","research","tutorial","pytorch","computer-vision","style-transfer","arxiv:1603.08155"],"details":"The algorithm can be used to mix the content of an image with the style of another image. For example, here is a photograph of a door arch rendered in the style of a stained glass painting.","links":[{"article_link":"","code_link":"https://github.com/pytorch/examples/tree/master/fast_neural_style","research_link":"https://arxiv.org/abs/1603.08155","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":495,"title":"Neural Style Transfer","description":"This tutorial uses deep learning to compose one image in the style of another image (ever wish you could paint like Picasso or Van Gogh?).","tags":["article","code","notebook","paper","research","tutorial","tensorflow","computer-vision","style-transfer","arxiv:1508.06576"],"details":"This is implemented by optimizing the output image to match the content statistics of the content image and the style statistics of the style reference image. These statistics are extracted from the images using a convolutional network.","links":[{"article_link":"https://www.tensorflow.org/tutorials/generative/style_transfer","code_link":"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/style_transfer.ipynb","research_link":"https://arxiv.org/abs/1508.06576","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":494,"title":"Fast Online Object Tracking and Segmentation: A Unifying Approach","description":"We illustrate how to perform both realtime object tracking and semi-supervised video object segmentation using a fully-convolutional Siamese approach.","tags":["article","code","paper","research","tutorial","video","convolutional-neural-networks","siamese-networks","computer-vision","object-tracking","segmentation","arxiv:1812.05050"],"details":"We illustrate how to perform both realtime object tracking and semi-supervised video object segmentation with a single simple approach. Our method, dubbed SiamMask, improves the offline training procedure of popular fully-convolutional Siamese approaches for object tracking by augmenting the loss with a binary segmentation task. Once trained, SiamMask solely relies on a single bounding-box initialisation and operates online, producing class-agnostic object segmentation masks and rotated bounding boxes at 35 frames per second. Despite its simplicity, versatility and fast speed, our strategy allows us to establish a new state-of-the-art among real-time trackers on VOT-2018, while at the same time demonstrating competitive performance and the best speed for the semi-supervised video object segmentation task on DAVIS-2016 and DAVIS-2017.","links":[{"article_link":"http://www.robots.ox.ac.uk/~qwang/SiamMask/","code_link":"https://github.com/foolwood/SiamMask","research_link":"https://arxiv.org/abs/1812.05050","media_link":"https://www.youtube.com/watch?v=I_iOVrcpEBw&feature=youtu.be","dataset_link":"","demo_link":"","other_link":""}]},{"id":493,"title":"DeepSORT: Deep Learning to Track Custom Objects in a Video","description":"A look at deep learning based approached for object tracking.","tags":["article","code","tutorial","computer-vision","object-tracking","yolo","kalman-filters","deepsort"],"details":"\u2022\u00a0Single object tracking\r\n\u2022\u00a0Multiple object tracking\r\n\u2022\u00a0Object detection vs Object Tracking\r\n\u2022\u00a0Challenges\r\n\u2022\u00a0Traditional Methods\r\n\u2022\u00a0Kalman Filters\r\n\u2022\u00a0Deep Learning based Approaches\r\n\u2022\u00a0Deep SORT","links":[{"article_link":"https://nanonets.com/blog/object-tracking-deepsort/","code_link":"https://github.com/abhyantrika/nanonets_object_tracking/","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":492,"title":"Second-order Attention Network for Single Image Super-resolution","description":"We propose a second-order attention network (SAN) for more powerful feature expression and feature correlation learning.","tags":["code","paper","research","tutorial","attention","computer-vision","super-resolution","arxiv:1909.11937"],"details":"We propose a second-order attention network (SAN) for more powerful feature expression and feature correlation learning. Specifically, a novel train- able second-order channel attention (SOCA) module is developed to adaptively rescale the channel-wise features by using second-order feature statistics for more discriminative representations. Furthermore, we present a non-locally enhanced residual group (NLRG) structure, which not only incorporates non-local operations to capture long-distance spatial contextual information, but also contains repeated local-source residual attention groups (LSRAG) to learn increasingly abstract feature representations. Experimental results demonstrate the superiority of our SAN network over state-of-the-art SISR methods in terms of both quantitative metrics and visual quality.","links":[{"article_link":"","code_link":"https://github.com/daitao/SAN","research_link":"https://arxiv.org/abs/1909.11937","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":491,"title":"Deep Learning for Image Super-resolution: A Survey","description":"This article aims to provide a comprehensive survey on recent advances of image super-resolution using deep learning approaches.","tags":["paper","research","computer-vision","super-resolution","survey","arxiv:1902.06068"],"details":"In general, we can roughly group the existing studies of SR techniques into three major categories: supervised SR, unsupervised SR, and domain-specific SR. In addition, we also cover some other important issues, such as publicly available benchmark datasets and performance evaluation metrics. Finally, we conclude this survey by highlighting several future directions and open issues which should be further addressed by the community in the future.","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/1902.06068","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":490,"title":"U-Net Deep Learning Colorization of Greyscale Images","description":"This article describes experiments training a neural network to generate 3 channel colour images from single channel greyscale images using deep learning.","tags":["article","tutorial","colorization","computer-vision","unet"],"details":"","links":[{"article_link":"https://towardsdatascience.com/u-net-deep-learning-colourisation-of-greyscale-images-ee6c1c61aabe","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":489,"title":"Deep Learning Based Super Resolution, Without Using a GAN","description":"Techniques and training a deep learning model for image improvement, image restoration, inpainting and super resolution.","tags":["tutorial","computer-vision","image-restoration","super-resolution","inpainting","image-improvement"],"details":"As far as I\u2019m aware some of the techniques I\u2019ve applied with the training data are unique at this point with these learning methods (as of February 2019) and only a handful of researchers are using all these techniques together, who will mostly are likely to be Fastai researchers/students","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":488,"title":"V2V-PoseNet Pytorch","description":"PyTorch implementation of V2V-PoseNet with IntegralPose/PoseFix loss.","tags":["code","paper","research","tutorial","pytorch","computer-vision","hand-pose-estimation","pose-estimation","human-pose-estimation","arxiv:1711.07399"],"details":"This repository provides:\r\n\u2022\u00a0V2V-PoseNet core modules(model, voxelization, ..)\r\n\u2022\u00a0An experiment demo on MSRA hand pose dataset, result in ~11mm mean error.\r\n\u2022\u00a0Additional Integral Pose Loss (or PoseFix Loss) implementation, result in ~10mm mean error on the same demo.","links":[{"article_link":"","code_link":"https://github.com/dragonbook/V2V-PoseNet-pytorch","research_link":"https://arxiv.org/abs/1711.07399","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":487,"title":"Face Alignment in Full Pose Range: A 3D Total Solution","description":"Face Alignment in Full Pose Range: A 3D Total Solution.","tags":["article","code","paper","research","tutorial","pytorch","3d","computer-vision","pose-estimation","face-alignment","3d-face","arXiv:1804.01005"],"details":"The PyTorch improved version of TPAMI 2017 paper: Face Alignment in Full Pose Range: A 3D Total Solution.","links":[{"article_link":"https://arxiv.org/abs/1804.01005","code_link":"https://github.com/cleardusk/3DDFA","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":486,"title":"A 2019 guide to Human Pose Estimation with Deep Learning","description":"The basics of Human Pose Estimation (2D) and review the literature on this topic.","tags":["article","tutorial","computer-vision","pose-estimation","survey"],"details":"In this post, I write about the basics of Human Pose Estimation (2D) and review the literature on this topic. This post will also serve as a tutorial in Human Pose Estimation and can help you learn the basics.","links":[{"article_link":"https://nanonets.com/blog/human-pose-estimation-2d-guide/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":485,"title":"Health Checks for Machine Learning","description":"A guide to model retraining and evaluation.","tags":["article","tutorial","systems-design","checklist","health-checks"],"details":"\u2022\u00a0Cost of poor Machine Learning models\r\n\u2022\u00a0Why is tracking a model\u2019s performance difficult?\r\n\u2022\u00a0How to track a model's performance?\r\n\u2022\u00a0Case Study\r\n\u2022\u00a0Machine Learning in production is not static - Changes with environment\r\n\u2022\u00a0Model Drift\r\n\u2022\u00a0Solution - Retraining your model\r\n\u2022\u00a0Setting up infrastructure for model retraining\r\n\u2022\u00a0Conclusion","links":[{"article_link":"https://nanonets.com/blog/machine-learning-production-retraining/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":483,"title":"Gate Decorator: Global Filter Pruning","description":"A global filter pruning algorithm called Gate Decorator, which transforms a vanilla CNN module by multiplying its output by the channel-wise scaling factors.","tags":["article","paper","research","tutorial","convolutional-neural-networks","model-compression","pruning","quantization","gate-decorator","arxiv:1909.08174"],"details":"","links":[{"article_link":"https://medium.com/@nainaakash012/gate-decorator-global-filter-pruning-afc12fcc71c6","code_link":"","research_link":"https://arxiv.org/abs/1909.08174","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":482,"title":"A Visual Exploration of DeepCluster","description":"DeepCluster is a self-supervised method to combine clustering and representation learning","tags":["article","tutorial","pytorch","computer-vision","image-clustering","representation-learning","self-supervised-learning"],"details":"- Learn how K-means can be combined with ConvNets to jointly learn labels and representations\r\n- Understand how paper author performed clustering at scale with faiss library","links":[{"article_link":"https://amitness.com/2020/04/deepcluster/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":481,"title":"Training an Image Classifier in PyTorch","description":"Torchvision, that has data loaders for common datasets such as Imagenet, CIFAR10, MNIST, etc. and data transformers for images, vizualization and data loaders.","tags":["article","code","tutorial","pytorch","computer-vision","image-classification","torchvision"],"details":"For this tutorial, we will use the CIFAR10 dataset. It has the classes: \u2018airplane\u2019, \u2018automobile\u2019, \u2018bird\u2019, \u2018cat\u2019, \u2018deer\u2019, \u2018dog\u2019, \u2018frog\u2019, \u2018horse\u2019, \u2018ship\u2019, \u2018truck\u2019. The images in CIFAR-10 are of size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.","links":[{"article_link":"https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html","code_link":"https://github.com/pytorch/tutorials/blob/master/beginner_source/blitz/cifar10_tutorial.py","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":480,"title":"ViLBERT-MT: Multi-Task Vision & Language Representation Learning","description":"A single ViLBERT Multi-Task model can perform 8 different vision and language tasks learnt from 12 datasets!","tags":["article","code","paper","research","tutorial","computer-vision","image-captioning","multi-modal","visual-question-answering","multi-task-learning","arxiv:1912.02315"],"details":"A single model on 12 datasets from four broad categories of task including visual question answering, caption-based image retrieval, grounding referring expressions, and multi-modal verification. \r\n\r\nDatasets: VQA v2, GQA, Visual Genome QA, RefCOCO, RefCOCO+, RefCOCOg, Visual7W, GuessWhat, COCO Retrieval, Flickr30k Retrieval, SNLI-VE, NLVR2.","links":[{"article_link":"https://vilbert.cloudcv.org/","code_link":"https://github.com/facebookresearch/vilbert-multi-task","research_link":"https://arxiv.org/abs/1912.02315","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":479,"title":"Deep Tutorials for PyTorch","description":"This is a series of in-depth tutorials I'm writing for implementing cool deep learning models on your own with the amazing PyTorch library.","tags":["code","tutorial","pytorch","attention","computer-vision","image-captioning","machine-translation","natural-language-processing","object-detection","semantic-segmentation","super-resolution","text-classification","text-summarization","segmentation","sequence-labeling","text-recognition"],"details":"In each tutorial, we will focus on a specific application or area of interest by implementing a model from a research paper.","links":[{"article_link":"","code_link":"https://github.com/sgrvinod/Deep-Tutorials-for-PyTorch","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":478,"title":"Semantic Segmentation on MIT ADE20K dataset in PyTorch","description":"Pytorch implementation for Semantic Segmentation/Scene Parsing on MIT ADE20K dataset.","tags":["code","tutorial","pytorch","computer-vision","semantic-segmentation","segmentation","scene-parsing","ade20k"],"details":"This is a PyTorch implementation of semantic segmentation models on MIT ADE20K scene parsing dataset (http://sceneparsing.csail.mit.edu/\r\n\r\nADE20K is the largest open source dataset for semantic segmentation and scene parsing, released by MIT Computer Vision team. Follow the link below to find the repository for our dataset and implementations on Caffe and Torch7: https://github.com/CSAILVision/sceneparsing\r\n\r\nIf you simply want to play with our demo, please try this link: http://scenesegmentation.csail.mit.edu You can upload your own photo and parse it!\r\n\r\nAll pretrained models can be found at: http://sceneparsing.csail.mit.edu/model/pytorch)\r\n\r\n![](https://github.com/CSAILVision/semantic-segmentation-pytorch/raw/master/teaser/ADE_val_00000278.png)","links":[{"article_link":"","code_link":"https://github.com/CSAILVision/semantic-segmentation-pytorch","research_link":"","media_link":"http://scenesegmentation.csail.mit.edu/","dataset_link":"","demo_link":"","other_link":""}]},{"id":477,"title":"SimpleGAN","description":"A Tensorflow-based framework to ease the training of generative models","tags":["article","code","keras","tensorflow","autoencoders","deep-learning","generative-adversarial-networks","neural-networks","library","computer-vision","cyclegan","pix2pix","wgan","infogan","dcgan","voxelgan","3dgan"],"details":"SimpleGAN is a framework based on TensorFlow to make the training of generative models easier. SimpleGAN provides high-level APIs with customizability options to the user which allows them to train a generative model with minimal lines of code.\r\n\r\nSupported Models:\r\n- Vanilla Autoencoder\r\n- Convolutional Autoencoder\r\n- Variational Autoencoder \r\n- Vector Quantized - Variational Autoencoder\r\n- Vanilla GAN \r\n- DCGAN\r\n- WGAN\r\n- CGAN\r\n- InfoGAN\r\n- Pix2Pix\r\n- CycleGAN\r\n- 3DGAN(VoxelGAN)\r\n","links":[{"article_link":"https://towardsdatascience.com/simplegan-train-gans-with-3-lines-of-code-c221bbf244","code_link":"https://github.com/grohith327/simplegan","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://simplegan.readthedocs.io/en/latest/"}]},{"id":476,"title":"Show and Tell: A Neural Image Caption Generator","description":"A TensorFlow implementation of the image-to-text model.","tags":["article","code","paper","research","tutorial","tensorflow","convolutional-neural-networks","lstm","computer-vision","image-captioning","arxiv:1609.06647"],"details":"The Show and Tell model is an example of an encoder-decoder neural network. It works by first \"encoding\" an image into a fixed-length vector representation, and then \"decoding\" the representation into a natural language description.","links":[{"article_link":"https://www.tensorflow.org/tutorials/text/image_captioning","code_link":"https://github.com/tensorflow/models/tree/master/research/im2txt","research_link":"https://arxiv.org/abs/1609.06647","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":475,"title":"BLOCK: Bilinear Superdiagonal Fusion for VQA and VRD","description":"We introduce a novel module (BLOCK) to fuse two representations together.","tags":["code","paper","research","tutorial","visual-question-answering","block","visual-relationship-detection","arxiv:1902.00038"],"details":"In Machine Learning, an important question is \"How to fuse two modalities in a same space\". For instance, in Visual Question Answering, one must fuse the image and the question embeddings in a same bi-modal space. This multimodal embedding is latter classified to provide the answer.","links":[{"article_link":"","code_link":"https://github.com/Cadene/block.bootstrap.pytorch","research_link":"https://arxiv.org/abs/1902.00038","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":474,"title":"PyTorch Tutorial for Deep Learning Researchers","description":"This repository provides tutorial code for deep learning researchers to learn PyTorch. ","tags":["code","tutorial","pytorch","autoencoders","generative-adversarial-networks","variational-autoencoders","computer-vision","image-captioning","style-transfer"],"details":"This repository provides tutorial code for deep learning researchers to learn PyTorch. In the tutorial, most of the models were implemented with less than 30 lines of code. Before starting this tutorial, it is recommended to finish Official Pytorch Tutorial.","links":[{"article_link":"","code_link":"https://github.com/yunjey/pytorch-tutorial","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":473,"title":"Neural Machine Translation With Attention","description":"This notebook trains a sequence to sequence (seq2seq) model for Spanish to English translation. ","tags":["code","tutorial","sequence-to-sequence","machine-translation","natural-language-processing"],"details":"After training the model in this notebook, you will be able to input a Spanish sentence, such as \"\u00bftodavia estan en casa?\", and return the English translation: \"are you still at home?\"","links":[{"article_link":"","code_link":"https://www.tensorflow.org/tutorials/text/nmt_with_attention","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":471,"title":"Building a COVID-19 Project Recommendation System","description":"How to create a GitHub open source repo recommendation system web app with MLflow, Sagemaker, and Booklet.ai.","tags":["article","code","github","scikit-learn","natural-language-processing","recommendation-systems"],"details":"- We want to help users find relevant open source COVID-19 related projects on Github, given their coding and general skills set.\r\n- To build this, we used GitHub's repo list, parsed the text, and build a CountVectorizer-based recommendation system.\r\n- The model is available for a demo at booklet.ai: https://app.booklet.ai/model/covid19-project-recommender","links":[{"article_link":"https://towardsdatascience.com/building-a-covid-19-project-recommendation-system-4607806923b9","code_link":"https://github.com/BookletAI/covid19-repo-recommender","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://app.booklet.ai/model/covid19-project-recommender"}]},{"id":470,"title":"Transfer Learning with T5: the Text-To-Text Transfer Transformer","description":"In the paper, we demonstrate how to achieve state-of-the-art results on multiple NLP tasks using a text-to-text transformer pre-trained on a large text corpus.","tags":["article","code","paper","research","tutorial","transformers","machine-translation","natural-language-processing","question-answering","reading-comprehension","text-classification","text-summarization","transfer-learning","t5","multi-task-learning","arxiv:1910.10683"],"details":"Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts every language problem into a text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled datasets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new \"Colossal Clean Crawled Corpus\", we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our dataset, pre-trained models, and code.","links":[{"article_link":"https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html","code_link":"https://github.com/google-research/text-to-text-transfer-transformer","research_link":"https://arxiv.org/abs/1910.10683","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":469,"title":"Understanding Text With Bert","description":"Building a machine reading comprehension system using the latest advances in deep learning for NLP.","tags":["article","tutorial","attention","bert","transformers","natural-language-processing","question-answering","reading-comprehension"],"details":"Here we are going to look at a new language representation model called BERT (Bidirectional Encoder Representations from Transformers) applied to reading comprehension, specifically question answering.","links":[{"article_link":"https://blog.scaleway.com/2019/understanding-text-with-bert/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":468,"title":"Text Classification With Torchtext","description":"This example shows how to train a supervised learning algorithm for classification using one of these TextClassification datasets.","tags":["article","code","tutorial","pytorch","natural-language-processing","text-classification","torchtext","ngrams"],"details":"This tutorial shows how to use the text classification datasets in torchtext, including:\r\n- AG_NEWS,\r\n- SogouNews,\r\n- DBpedia,\r\n- YelpReviewPolarity,\r\n- YelpReviewFull,\r\n- YahooAnswers,\r\n- AmazonReviewPolarity,\r\n- AmazonReviewFull","links":[{"article_link":"https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html","code_link":"https://github.com/pytorch/tutorials/blob/master/beginner_source/text_sentiment_ngrams_tutorial.py","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":467,"title":"Practical Text Classification With Python and Keras","description":"You will get a grasp of current advancements of (deep) neural networks and how they can be applied to text.","tags":["article","tutorial","keras","natural-language-processing","sentiment-analysis","text-classification"],"details":"Reading the mood from text with machine learning is called sentiment analysis, and it is one of the prominent use cases in text classification. This falls into the very active research field of natural language processing (NLP). Other common use cases of text classification include detection of spam, auto tagging of customer queries, and categorization of text into defined topics.","links":[{"article_link":"https://realpython.com/python-keras-text-classification/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":466,"title":"Tokenizers: How Machines Read","description":"A survey of different tokenization strategies in NLP.","tags":["tutorial","natural-language-processing","tokenizers","survey"],"details":"\u2022\u00a0Why is reading difficult for machines?\r\n\u2022\u00a0Subword Tokenization\r\n\u2022\u00a0Byte Pair Encoding (BPE)\r\n\u2022\u00a0Unigram Subword Tokenization\r\n\u2022\u00a0WordPiece\r\n\u2022\u00a0SentencePiece","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":465,"title":"3D Photography using Context-aware Layered Depth Inpainting","description":"A multi-layer representation for novel view synthesis that contains hallucinated color and depth structures in regions occluded in the original view. ","tags":["article","code","notebook","paper","research","tutorial","video","design","3d","computer-vision","image-generation","inpainting","arxiv:2004.04727"],"details":"We propose a method for converting a single RGB-D input image into a 3D photo, i.e., a multi-layer representation for novel view synthesis that contains hallucinated color and depth structures in regions occluded in the original view. We use a Layered Depth Image with explicit pixel connectivity as underlying representation, and present a learning-based inpainting model that iteratively synthesizes new local color-and-depth content into the occluded region in a spatial context-aware manner. The resulting 3D photos can be efficiently rendered with motion parallax using standard graphics engines. We validate the effectiveness of our method on a wide range of challenging everyday scenes and show fewer artifacts when compared with the state-of-the-arts.","links":[{"article_link":"https://shihmengli.github.io/3D-Photo-Inpainting/","code_link":"https://github.com/vt-vl-lab/3d-photo-inpainting","research_link":"https://arxiv.org/abs/2004.04727","media_link":"https://www.youtube.com/watch?v=Z_kNHoA2Ysg","dataset_link":"","demo_link":"","other_link":"https://colab.research.google.com/drive/1706ToQrkIZshRSJSHvZ1RuCiM__YX3Bz"}]},{"id":464,"title":"A Survey of Methods for Model Compression in NLP","description":"A look at model compression techniques applied on base model pre-training to reduce the computational cost of prediction.","tags":["article","tutorial","knowledge-distillation","model-compression","pruning","quantization","precision-reduction","model-replacement","operation-fusion","survey"],"details":"* Numeric Precision Reduction: yielding speedups through the use of floating point reduction and quantization\r\n* Operation Fusion: numerical tricks to merge select nodes in computational graphs\r\n* Pruning: identifying and removing non-essential portions of a network\r\n* Knowledge Distillation: efficiently training smaller student models to mimic the behavior of more expressive and expensive teachers\r\n* Module Replacement: reducing model complexity or depth via a replacement curriculum","links":[{"article_link":"https://www.pragmatic.ml/a-survey-of-methods-for-model-compression-in-nlp/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":463,"title":"Gradient Centralization","description":"Optimization technique that operates directly on gradients by centralizing their vectors to zero mean.","tags":["code","paper","research","tutorial","deep-learning","neural-networks","normalization","optimization","gradients","gradient-centralization","arxiv:2004.01461"],"details":"Gradient Centralization (GC) is a simple and effective optimization technique for Deep Neural Networks (DNNs), which operates directly on gradients by centralizing the gradient vectors to have zero mean. It can both speedup training process and improve the final generalization performance of DNNs. GC is very simple to implement and can be easily embedded into existing gradient based DNN optimizers with only few lines of code. It can also be directly used to finetune the pre-trained DNNs.","links":[{"article_link":"","code_link":"https://github.com/Yonghongwei/Gradient-Centralization","research_link":"https://arxiv.org/abs/2004.01461","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":462,"title":"A Visual Guide to Self-Labelling Images","description":"A self-supervised method to generate labels via simultaneous clustering and representation learning","tags":["article","tutorial","computer-vision","image-clustering","representation-learning","self-supervised-learning","illustrated"],"details":"* Give an intuitive understanding of self-labelling method for self-supervised learning\r\n* Understand optimal transport problem and it's application in machine learning\r\n* Know application of self-labelling for practical projects","links":[{"article_link":"https://amitness.com/2020/04/illustrated-self-labelling/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":461,"title":"Human in the Loop: Deep Learning without Wasteful Labelling","description":"A new practical method for choosing batches of informative points in Deep Active Learning which avoids labelling redundancies that plague existing methods. ","tags":["article","code","paper","research","tutorial","bayesian-deep-learning","active-learning","labeling","bayesian-active-learning","arxiv:1906.08158"],"details":"TLDR: In Active Learning we use a \u201chuman in the loop\u201d approach to data labelling, reducing the amount of data that needs to be labelled drastically, and making machine learning applicable when labelling costs would be too high otherwise. In our paper,  we present BatchBALD: a new practical method for choosing batches of informative points in Deep Active Learning which avoids labelling redundancies that plague existing methods. Our approach is based on information theory and expands on useful intuitions. We have also made our implementation available on GitHub at https://github.com/BlackHC/BatchBALD.","links":[{"article_link":"https://oatml.cs.ox.ac.uk/blog/2019/06/24/batchbald.html","code_link":"https://github.com/BlackHC/BatchBALD","research_link":"https://arxiv.org/abs/1906.08158","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":460,"title":"Customer Analytics","description":"Customer Segmentation, RFM analysis on demographic, purchase data respectively and  Price Elasticity simulation for purchase probability","tags":["code","clustering","dimensionality-reduction","principal-component-analysis","rfm","price-elasticty"],"details":"# **Contents**\r\n- **Context**\r\n- **Objective**\r\n- **Customer Segmentation**\r\n- **Methodology**\r\n- **Results**\r\n- **Limitations**\r\n\r\n<hr>\r\n\r\n\r\n# Context and Data\r\nThe dataset consists of information about the purchases of chocolate candy bars(5 different brands) of 500 individuals from a given area when entering a physical \u2018FMCG\u2019 store in a period of 2 years. All data has been collected through the loyalty cards they use at checkout. The data has been preprocessed and there are no missing values. In addition, the volume of the dataset has been restricted and anonymized  to protect the privacy of the customers.\r\n\r\nDescription of each column and what they represent are present in [purchase-data-legend file](https://github.com/sai-krishna-msk/Customer_Anylatics/blob/master/purchase-data-legend.pdf)\r\n\r\n<hr>\r\n\r\n# Objective\r\n**There are two main objectives of the projects**:\r\n\r\n- Customer Segmentation\r\n- Price Elasticity\r\n\r\n<br>\r\n\r\n## Customer Segmentation\r\n\r\nDividing our customers into different      segments(Groups/buckets) such that customers in one segment would be homogeneous in terms of the following\r\n\r\n- These groups will have comparable purchase behaviors \r\n- Members from the same segment respond similarly to different marketing activities \r\n- Members from different segments respond differently to different marketing activities \r\n\r\nAs we have both customer purchase data and customer demographic data, we will be using appropriate frameworks/algorithms best suited for each of those to perform segmentation\r\n\r\nCarrying out Analysis on each of segments for KYC(know your customer)\r\n\r\nThis process would help the marketing team to have a better understanding of our customers, enabling them to design and implement efficient marketing strategies suitable for each of the segments to maximize purchase probability\r\n\r\n<br>\r\n\r\n## Price Elasticity\r\nPrice Elasticity of a product is a key indicator in determining a products purchase probability or how likely is a customer to purchase a given product at that price point\r\n\r\n1) Simulating Price elasticity of Candy's at different price points\r\n\r\n2) How do these Price Elasticity effect in the presence/absence of a promotion\r\n\r\n**Performing the above tasks would help us in the following ways**\r\n\r\n- As Revenue = Sales*Price, it would help us in determining the optimal price at which we would have high purchase probability, thus increasing our revenue\r\n\r\n- Help us decide %discount, for the next sale\r\n\r\n- If we are about to release a new product it could give us insight into what price range would be a safe bet\r\n\r\nAs we have 5 different brands and their respective purchase data, Computing cross price elasticity, of our brand with respect to others, Doing this would give us the following insights\r\n\r\n- Which brand can be considered in our product category as the closest competitor(i.e: Which brand is more likely to be an alternative to our brand for customers currently purchasing our products)\r\n\r\n- Forecast how sales or market share of our brand would impact based on changes in the prices of our competitors\r\n\r\n- In the case of huge discounts from our competitors, how much should we decrease our prices in our order to regain the market share \r\n\r\n<hr>\r\n\r\n# Methodology\r\n<br>\r\n\r\n## Segmentation\r\n\r\n- For Segmentation with demographic data, K-means clustering is used. As the results initially were not satisfying PCA was used as a means to extract latent features and K-Means was applied on these latent features we obtained  4 clusters as optimal(verified by Elbow method)\r\n\r\n- For segmentation based on transaction/purchase data RFM(Recency Frequency Monetary) analysis is used do segment customers\r\n\r\n\r\n<br>\r\n\r\n## Price Elasticity\r\n\r\n- Logistic Regression is used to model the relationship between prices and purchases probabilities\r\n\r\n- Using the model to further simulate purchase probabilities for different price ranges, These predictions along with coefficients of the model are used to compute Price Elasticity\r\n\r\n- Multivariate Logistic Regression is used to compute Cross Price Elasticity\r\n\r\n<hr>\r\n\r\n# Results\r\n\r\n*All of  the results shown can be found in the notebooks present in [github](https://github.com/sai-krishna-msk/Customer_Anylatics)*\r\n\r\n<br>\r\n## Segmentation\r\n\r\n<br>\r\n\r\n### K-Means Clustering\r\n- Based on the demographic data such as their income, where they live, age, etc...Segments are labeled as Working Class, Urbanities, Veterans and wholesome(Names of the segments are subjective)\r\n\r\n- Various characteristics of each segment were found such as the following\r\n    - **which brand does each segment spend more money on** \r\n    - **which segment visits the store more often**\r\n    - **which customer purchase more when in promotion**\r\n \r\n- So when we have a new customer signed-up just based on his/her demographic data we can classify them into one of the segments which would increase the probability of targeted marketing and send personalized promotion\r\n\r\n**A few other results of segmentation are mentioned in the price elasticity section below**\r\n\r\n<img src=\"https://github.com/sai-krishna-msk/Customer_Anylatics/blob/master/images/cluster_pca_wpca.png?raw=true\">\r\n\r\n<br>\r\n\r\n### RFM Analysis\r\n\r\nBased on the purchase data of each customer spanning across two years, they were classified into the following segments\r\n\r\n- Champion Customers\r\n- Loyal Customers\r\n- Potential Loyalist\r\n- Recent Customers\r\n- Promising Customers \r\n- Customers Needing Attention\r\n- About To Sleep\r\n- At-Risk Customers \r\n- Can\u2019t Lose Them(valuable)\r\n- Lost\r\n\r\nUnlike in segments generated using K-Means these are industry-standard labels, How to treat these segment to benefit the most is also well [documented](https://www.putler.com/rfm-analysis/), these segments would also help us in identifying customers most likely to churn\r\n\r\n<br>\r\n\r\n## Price Elasticity\r\n\r\nFollowing are the insights as the results of computing Price elasticity\r\n\r\n- For a given product at a price point, we can predict the purchase probability of  what would happen if the price varies by x%\r\n\r\n- **if we increased our prices by 1% at a price of 1.25$ then purchase probability of our product would go down by 1.04%, this probability would increase to 3.5% if it was to increase of 1% at 2$**\r\n\r\n- Thus concluding that inc of the same 1% at different price points has different impacts on our sales\r\n    \r\n    <img src=\"https://github.com/sai-krishna-msk/Customer_Anylatics/blob/master/images/price-elasticity-curve.png?raw=true\">\r\n    \r\n- We were able to find out which segment of customers are most sensitive to price changes than others\r\n    - **Working Class is the most sensitive to price changes**\r\n    \r\n    <img src=\"https://github.com/sai-krishna-msk/Customer_Anylatics/blob/master/images/segment-price-elasticity.png?raw=true\">\r\n    \r\n- **We found out that people were less elastic to price increases when there was a sale, meaning advertising the price of a product as a discounted price would make customers less sensitive to price increases of the product**\r\n\r\n<img src=\"https://github.com/sai-krishna-msk/Customer_Anylatics/blob/master/images/prom0-prom1.png?raw=true\">\r\n\r\n\r\nThese insights can assist us in making decisions like budget allocation for marketing/advertisement of each segment for a promotion\r\n\r\nFollowing are the insights as the result of computing cross-price elasticity, considering our brand as brand-2\r\n\r\n- We found out based on sales data which brands were our closest competitor(i.e: which brand is more likely to be preferred by our customers as an alternative)\r\n    - **Closest competitor to our brand is brand-1**\r\n  \r\n- We were able to compute by how much would our brand's Sales(purchase probability) effect as the result of a change in our competitor's prices\r\n    - **if brand-1 decreased the price of its product by 1%(at its mean price) then it would decrease sales(purchase probability )of our brand by 0.2%**\r\n\r\n- We computed what if we decreased our product's price by 1% as a counter for brand-1 discount, then we would see a rise of around 1% in our sales\r\n\r\n- We also computed by how much should we decrease our prices in order to maintain the market share if our competitor happens to give discounts\r\n    -** It was computed that if brand-1 increases it's price by 1% then to nullify the decrease in our sales we could simply decrease our price by 0.2%**\r\n    \r\n\r\n<img src=\"https://github.com/sai-krishna-msk/Customer_Anylatics/blob/master/images/cross-elastic.png?raw=true\">\r\n\r\nThese insights would help us in making strategic decisions about adjusting our prices to gain or maintain the market share as the result of our competitors altering their prices\r\n\r\n<hr>\r\n\r\n# Limitation\r\n\r\n- One of the major drawbacks in computing price elasticity is we are trying to model purchase probability of customers using only the price of the product, which means we are summing price of a product is the only factor stopping or encouraging a customer to purchase a product which we know is not the case in real world\r\n\r\n  \r\n\r\n- Price is undoubtedly one of the important features or variables which customer uses to make the decision of whether to purchase or not, but it isn't the only factor he/she would consider\r\n\r\n  \r\n\r\n- Other factors like customers personal taste, which things does customer gravitates towards does that brand or product possess such characteristics, customers needs, etc, also play a major role, having said that for some products which can be called commodities, price would be more or less the only factor which customer would consider\r\n\r\n  \r\n\r\n- So Price Elasticity analysis would be more accurate for products which are commodities and chocolate isn't a commodity, For products other than commodity we would require other features which can takes into consideration elements such as customers psychology,taste's, requirements etc.\r\n","links":[{"article_link":"","code_link":"https://github.com/sai-krishna-msk/Customer_Anylatics","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":459,"title":"Beyond the Pixel Plane: Sensing and Learning in 3d","description":"Recent deep learning techniques that enable 3D object classification and semantic segmentation.","tags":["article","tutorial","3d","autonomous-vehicles","computer-vision","object-classification","semantic-segmentation","segmentation"],"details":"We'll begin by reviewing some background information on common ways to capture and represent 3D data. We'll then describe fundamental deep learning methods for three different representations of 3D data. Finally, we'll describe promising new research directions and conclude with our perspective on where the field is headed.","links":[{"article_link":"https://thegradient.pub/beyond-the-pixel-plane-sensing-and-learning-in-3d/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":458,"title":"Limitations of Deep Learning for Vision, and How We Might Fix The","description":"This is an opinion paper about the strengths and weaknesses of Deep Nets for vision.","tags":["article","paper","research","tutorial","deep-learning","computer-vision","limitations","arxiv:1805.04025"],"details":"* Firstly, deep learning nearly always requires a large amount of annotated data. This biases vision researchers to work on tasks where annotation is easy instead of tasks that are important.\r\n\u2022\u00a0Secondly, Deep Nets perform well on benchmarked datasets, but can fail badly on real world images outside the dataset. \r\n* Thirdly, Deep Nets are overly sensitive to changes in the image which would not fool a human observer. ","links":[{"article_link":"https://thegradient.pub/the-limitations-of-visual-deep-learning-and-how-we-might-fix-them/","code_link":"","research_link":"https://arxiv.org/abs/1805.04025","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":457,"title":"BigGanEx: A Dive into the Latent Space of BigGan","description":"A closer look at the generative abilities of the BigGAN.","tags":["article","tutorial","generative-adversarial-networks","art","generative-models","biggan","latent-space"],"details":"","links":[{"article_link":"https://thegradient.pub/bigganex-a-dive-into-the-latent-space-of-biggan/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":456,"title":"Gaussian Processes, Not Quite for Dummies","description":"More than just scratch the surface of GPs by reading some \"machine learning for dummies\" tutorial, but aren't quite yet ready to take on a textbook.","tags":["article","tutorial","video","gaussian-processes","nonlinear-regression"],"details":"","links":[{"article_link":"https://thegradient.pub/gaussian-process-not-quite-for-dummies/","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=92-98SYOdlY","dataset_link":"","demo_link":"","other_link":""}]},{"id":455,"title":"Illustrated: Self-Attention","description":"Step-by-step guide to self-attention with illustrations and code.","tags":["article","code","notebook","tutorial","pytorch","attention","self-attention","transformers","natural-language-processing","illustrated"],"details":"The main content of this post is to walk you through the mathematical operations involved in a self-attention module. By the end of this article, you should be able to write or code a self-attention module from scratch.","links":[{"article_link":"https://towardsdatascience.com/illustrated-self-attention-2d627e33b20a","code_link":"https://colab.research.google.com/drive/1rPk3ohrmVclqhH7uQ7qys4oznDdAhpzF","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":454,"title":"All The Ways You Can Compress BERT","description":"In this post I\u2019ll list and briefly taxonomize all the papers I\u2019ve seen compressing BERT. ","tags":["article","tutorial","attention","bert","transformers","knowledge-distillation","model-compression","natural-language-processing","pruning","quantization","pretraining","compression","weight-factorization","weight-sharing","downstream-tasks"],"details":"Model compression reduces redundancy in a trained neural network. This is useful, since BERT barely fits on a GPU (BERT-Large does not) and definitely won\u2019t fit on your smart phone. Improved memory and inference speed efficiency can also save costs at scale.","links":[{"article_link":"http://mitchgordon.me/machine/learning/2019/11/18/all-the-ways-to-compress-BERT.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":453,"title":"CS231n: Convolutional Neural Networks for Visual Recognition","description":"Deep dive into details of the deep learning architectures with a focus on learning end-to-end models for these tasks, particularly image classification.","tags":["course","tutorial","video","convolutional-neural-networks","deep-learning","computer-vision","cs231n","stanford"],"details":"During the 10-week course, students will learn to implement, train and debug their own neural networks and gain a detailed understanding of cutting-edge research in computer vision. The final assignment will involve training a multi-million parameter convolutional neural network and applying it on the largest image classification dataset (ImageNet). We will focus on teaching how to set up the problem of image recognition, the learning algorithms (e.g. backpropagation), practical engineering tricks for training and fine-tuning the networks and guide the students through hands-on assignments and a final course project. Much of the background and materials of this course will be drawn from the ImageNet Challenge.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/playlist?list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk","dataset_link":"","demo_link":"","other_link":"http://cs231n.stanford.edu/"}]},{"id":452,"title":"CS224n: Natural Language Processing with Deep Learning","description":"In this course, students will gain a thorough introduction to cutting-edge research in Deep Learning for NLP.","tags":["course","tutorial","video","deep-learning","natural-language-processing","stanford","cs224n"],"details":"This lecture series provides a thorough introduction to the cutting-edge research in deep learning applied to NLP, an approach that has recently obtained very high performance across many different NLP tasks including question answering and machine translation.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/playlist?list=PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6","dataset_link":"","demo_link":"","other_link":"http://web.stanford.edu/class/cs224n/"}]},{"id":451,"title":"Evaluation Metrics for Language Modeling","description":"In this article, we will focus on traditional intrinsic metrics that are extremely useful during the process of training the language model itself. ","tags":["tutorial","bayesian-inference","language-modeling","metrics","natural-language-processing","generative-models","perplexity","gaussian-processes","cross-entropy","bits-per-character","bpc","glue"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":450,"title":"CS330: Deep Multi-Task and Meta Learning","description":"Study how the structure arising from multiple tasks can be leveraged to learn more efficiently or effectively.","tags":["course","tutorial","video","meta-learning","stanford","cs330","multi-task-learning"],"details":"* Multi-task learning basics\r\n* Meta-learning algorithms: black-box approaches, optimization based meta-learning, metric learning\r\n* Hierarchical Bayesian models & meta-learning\r\n* Multi-task RL, goal-conditioned RL, hierarchical RL\r\n*  Meta-reinforcement learning ","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/playlist?list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5","dataset_link":"","demo_link":"","other_link":"https://cs330.stanford.edu/"}]},{"id":449,"title":"Mimicry","description":"A PyTorch library for the reproducibility of GAN research.","tags":["article","code","pytorch","generative-adversarial-networks","library","benchmarks","reproducability","dcgan","wgan-gp","sngan","cgan-pd","ssgan","infomax-gan"],"details":"Comparing GANs is often difficult - mild differences in implementations and evaluation methodologies can result in huge performance differences. Mimicry aims to resolve this by providing: (a) Standardized implementations of popular GANs that closely reproduce reported scores; (b) Baseline scores of GANs trained and evaluated under the same conditions; (c) A framework for researchers to focus on implementation of GANs without rewriting most of GAN training boilerplate code, with support for multiple GAN evaluation metrics.","links":[{"article_link":"https://kwotsin.github.io/post/introducing-mimicry/","code_link":"https://github.com/kwotsin/mimicry","research_link":"","media_link":"https://github.com/kwotsin/mimicry/blob/master/docs/gallery/README.md","dataset_link":"","demo_link":"","other_link":"https://mimicry.readthedocs.io/en/latest/index.html"}]},{"id":448,"title":"\ud83e\udd84 How to build a SOTA Conversational AI with Transfer Learning","description":"Train a dialog agent leveraging transfer Learning from an OpenAI GPT and GPT-2 Transformer language model.","tags":["article","code","tutorial","transformers","chatbot","dialogue","language-modeling","natural-language-processing","transfer-learning","conversational-ai"],"details":"* How you can use Transfer Learning to build a State-of-the-Art dialog agent based on OpenAI GPT and GPT-2 Transformer language models,\r\n* How you can reproduce the model we used in the NeurIPS 2018 dialog competition ConvAI2 which won the automatic metrics track,\r\n* How we distilled 3k+ lines of competition code in less than 250 lines of commented training code (with distributed & FP16 options!), and\r\n* How you can train this model for less than $20 on a cloud instance, or just use our open-sourced pre-trained model.","links":[{"article_link":"https://medium.com/huggingface/how-to-build-a-state-of-the-art-conversational-ai-with-transfer-learning-2d818ac26313","code_link":"https://github.com/huggingface/transfer-learning-conv-ai","research_link":"","media_link":"https://convai.huggingface.co/","dataset_link":"","demo_link":"","other_link":""}]},{"id":447,"title":"TOMA: Torch Memory-adaptive Algorithms","description":"Helps you write algorithms in PyTorch that adapt to the available (CUDA) memory.","tags":["code","pytorch","deep-learning","lstm","machine-learning","library","training","gpu","cuda","toma"],"details":"Has your PyTorch code ever crashed because it ran out-of-memory in CUDA, and you had to fiddle with batch sizes repeatedly? Write code that adapted to the available memory instead of resorting to brittle hand-tuning? ","links":[{"article_link":"","code_link":"https://github.com/BlackHC/toma","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":446,"title":"Tips for Successfully Training Transformers on Small Datasets","description":"It turns out that you can easily train transformers on small datasets when you use tricks (and have the patience to train a very long time).","tags":["article","code","tutorial","transformers","training","data-augmentation","embeddings","natural-language-processing","small-datasets","ptb","wikitext-2","dropout"],"details":"\u2022\u00a0The most dramatic performance gain comes from discrete embedding dropout: You embed as usual, but now with a probability p you zero the entire word vector. This is akin to masked language modeling but the goal is not to predict the mask \u2014 just regular LM with uncertain context. \r\n\u2022\u00a0The second most important factor is regular input dropout: You take the embeddings and dropout elements with probability p. This also has a data augmentation effect very similar to dropping out random pixels for images. What is a good way to think about this?","links":[{"article_link":"https://threadreaderapp.com/thread/1247998807494684672.html","code_link":"https://github.com/TimDettmers/transformer-xl/tree/wikitext2","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":445,"title":"Natural Language Processing With spaCy in Python","description":"A comprehensive guide to NLP with spaCy.","tags":["article","tutorial","python","spacy","natural-language-processing","preprocessing","tokenization"],"details":"In this tutorial, you\u2019ll learn:\r\n\u2022\u00a0What the foundational terms and concepts in NLP are\r\n\u2022\u00a0How to implement those concepts in spaCy\r\n\u2022\u00a0How to customize and extend built-in functionalities in spaCy\r\n\u2022\u00a0How to perform basic statistical analysis on a text\r\n\u2022\u00a0How to create a pipeline to process unstructured text\r\n\u2022\u00a0How to parse a sentence and extract meaningful insights from it","links":[{"article_link":"https://realpython.com/natural-language-processing-spacy-python/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":444,"title":"sotabench","description":"Insight into the performance of open source Machine Learning .","tags":["library","state-of-the-art","sota","benchmarking"],"details":"We provide a free benchmarking service for all open source ML repositories that is integrated with GitHub. It is like Continuous Integration, but instead of running unit tests, it runs benchmarks.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://sotabench.com/"}]},{"id":443,"title":"AllenNLP Interpret","description":"A Framework for Explaining Predictions of NLP Models","tags":["api","article","code","paper","research","tutorial","conditional-random-fields","lstm","front-end-design","library","interpretability","language-modeling","named-entity-recognition","natural-language-processing","sentiment-analysis","squad","explainability","elmo","adversarial-learning","adversarial-attacks","allenai","saliency-maps","allen-nlp","textual-entailment","arxiv:1909.09251"],"details":"We present AllenNLP Interpret, a toolkit built on top of AllenNLP for interactive model interpretations. The toolkit makes it easy to apply gradient-based saliency maps and adversarial attacks to new models, as well as develop new interpretation methods. ","links":[{"article_link":"https://allennlp.org/interpret","code_link":"https://github.com/allenai/allennlp/tree/master/allennlp/interpret","research_link":"https://arxiv.org/abs/1909.09251","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":442,"title":"CausalML","description":"Uplift modeling and causal inference with machine learning algorithms.","tags":["code","paper","research","machine-learning","library","causal-inference","uplift-modeling","incubation","arxiv:2002.11631"],"details":"Causal ML is a Python package that provides a suite of uplift modeling and causal inference methods using machine learning algorithms based on recent research. It provides a standard interface that allows user to estimate the Conditional Average Treatment Effect (CATE) or Individual Treatment Effect (ITE) from experimental or observational data.","links":[{"article_link":"","code_link":"https://github.com/uber/causalml","research_link":"https://arxiv.org/abs/2002.11631","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":441,"title":"Fairness and Machine Learning","description":"This book gives a perspective on machine learning that treats fairness as a central concern rather than an afterthought.","tags":["article","tutorial","machine-learning","interpretability","privacy","explainability","fairness","bias","transparency","accountability"],"details":"Most of the book is about fairness, but we include a chapter that touches upon a few related concepts: privacy, interpretability, explainability, transparency, and accountability.","links":[{"article_link":"https://fairmlbook.org/","code_link":"","research_link":"","media_link":"https://fairmlbook.org/tutorial1.html","dataset_link":"","demo_link":"","other_link":""}]},{"id":440,"title":"lazynlp","description":"Library to scrape and clean web pages to create massive datasets.","tags":["code","dataset","library","language-modeling","natural-language-processing","data-collection","text-mining","lazynlp"],"details":"A straightforward library that allows you to crawl, clean up, and deduplicate webpages to create massive monolingual datasets. Using this library, you should be able to create datasets larger than the one used by OpenAI for GPT-2.","links":[{"article_link":"","code_link":"https://github.com/chiphuyen/lazynlp","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":439,"title":"Universal Adversarial Triggers for Attacking and Analyzing NLP","description":"We create short phrases that cause a specific model prediction when concatenated to \ud835\ude22\ud835\ude2f\ud835\ude3a input from a dataset. ","tags":["article","code","paper","research","tutorial","gpt2","transformers","adversarial-defense","natural-language-processing","squad","adversarial-learning","adversarial-attacks","allenai","arxiv:1908.07125"],"details":"Triggers cause:\r\n\u2022\u00a0GPT-2 to spew racism\r\n\u2022\u00a0SQuAD models to answer \"to kill american people\" for 72% of questions asking \"Why...\"\r\n\u2022\u00a0Classification models to drop from 90% accuracy to 1%","links":[{"article_link":"https://www.ericswallace.com/triggers#","code_link":"https://github.com/Eric-Wallace/universal-triggers","research_link":"https://arxiv.org/abs/1908.07125","media_link":"https://demo.allennlp.org/gpt2?text=TH PEOPLEMan goddreams Blacks","dataset_link":"","demo_link":"","other_link":"https://demo.allennlp.org/reading-comprehension/MTAwODU2MA=="}]},{"id":438,"title":"Compressing Bert for Faster Prediction","description":"In this blog post, we discuss ways to make huge models like BERT smaller and faster. ","tags":["article","tutorial","attention","bert","transformers","knowledge-distillation","model-compression","natural-language-processing","pruning","quantization","distillation","inference","compression","tflite"],"details":"\u2022\u00a0Why compressing today\u2019s best-performing models is very important.\r\n\u2022\u00a0What ways to compress models there are and why accelerating models is more difficult than making them smaller.\r\n\u2022\u00a0What we found out while trying to compress BERT with the quantization method, using TensorFlow Lite.","links":[{"article_link":"https://blog.rasa.com/compressing-bert-for-faster-prediction-2/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":437,"title":"Pruning Bert to Accelerate Inference","description":"After previously discussing various ways of accelerating models like BERT, in this blog post we empirically evaluate the pruning approach.","tags":["article","tutorial","attention","bert","transformers","model-compression","natural-language-processing","pruning","inference"],"details":"* Read about the implementation of weight and neuron pruning with BERT.\r\n* See how much faster and smaller we can make BERT.\r\n\u2022\u00a0Understand what neuron pruning can tell us \u2013 e.g that sometimes BERT doesn\u2019t need attention at all.","links":[{"article_link":"https://blog.rasa.com/pruning-bert-to-accelerate-inference/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":436,"title":"InterpretML ","description":"Fit interpretable machine learning models. Explain blackbox machine learning.","tags":["code","paper","research","library","feature-importance","interpretability","lime","shap","explainability","sensitivity-analysis","partial-dependence","explainable-boosting","arxiv:1909.09223"],"details":"InterpretML is an open-source python package for training interpretable machine learning models and explaining blackbox systems. Interpretability is essential for:\r\n\u2022\u00a0Model debugging - Why did my model make this mistake?\r\n\u2022\u00a0Detecting bias - Does my model discriminate?\r\n\u2022\u00a0Human-AI cooperation - How can I understand and trust the model's decisions?\r\n\u2022\u00a0Regulatory compliance - Does my model satisfy legal requirements?\r\n\u2022\u00a0High-risk applications - Healthcare, finance, judicial, ...","links":[{"article_link":"","code_link":"https://github.com/interpretml/interpret","research_link":"https://arxiv.org/abs/1909.09223","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":435,"title":"Adversarial Attacks and Defenses in Images, Graphs and Text","description":"We review the state of the art algorithms for generating adversarial examples and the countermeasures against adversarial examples for images, graphs and text.","tags":["paper","research","tutorial","adversarial-defense","adversarial-learning","adversarial-attacks","arxiv:1909.08072"],"details":"Deep neural networks (DNN) have achieved unprecedented success in numerous machine learning tasks in various domains. However, the existence of adversarial examples has raised concerns about applying deep learning to safety-critical applications. As a result, we have witnessed increasing interests in studying attack and defense mechanisms for DNN models on different data types, such as images, graphs and text. Thus, it is necessary to provide a systematic and comprehensive overview of the main threats of attacks and the success of corresponding countermeasures. In this survey, we review the state of the art algorithms for generating adversarial examples and the countermeasures against adversarial examples, for the three popular data types, i.e., images, graphs and text.","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/1909.08072","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":434,"title":"scispaCy","description":"A full spaCy pipeline and models for scientific/biomedical documents.","tags":["article","spacy","health","library","entity-linking","named-entity-recognition","natural-language-processing","biomedical","allenai","clinical"],"details":"scispaCy is a Python package containing spaCy models for processing biomedical, scientific or clinical text.","links":[{"article_link":"https://github.com/allenai/scispacy","code_link":"","research_link":"","media_link":"https://scispacy.apps.allenai.org/","dataset_link":"","demo_link":"","other_link":"https://allenai.github.io/scispacy/"}]},{"id":433,"title":"ML for Clinicians: Advances for Multi-Modal Health Data","description":"This tutorial is intended for clinicians and other healthcare professionals who wish to become familiar with recent advances in machine learning in health.","tags":["tutorial","machine-learning","health","multi-modal","multilayer-perceptrons","clinical"],"details":"The tutorial has 3 parts. \r\n\r\n\u2022\u00a0The first part will provide a common foundation of common methods used training basic single-data-source predictors (e.g. predict length of stay from patient vital signs) as well as best practices for evaluating these predictors. \r\n\r\n\u2022\u00a0The second part will cover methods for learning rich representations that can handle structured data such as time series, text, and images. \r\n\r\n\u2022\u00a0The final part will cover recent methods that address 6 key methodological challenges arising from healthcare applications, such as missing data, methods for combining labeled and unlabeled data (semi-supervised learning), methods for learning from multiple data sources (multimodal learning), explainable/interpretable models, models that try to account for causality, and sequential decision-making (reinforcement learning).","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.michaelchughes.com/mlhc2018_tutorial.html"}]},{"id":432,"title":"Self-Supervised Learning and Computer Vision","description":"So, what do you do if there are no pre-trained models in your domain? ","tags":["article","tutorial","computer-vision","self-supervised-learning"],"details":"\u2022\u00a0Introduction to self-supervised learning\r\n\u2022\u00a0Self-supervised learning in computer vision\r\n\u2022\u00a0Fine tuning for your downstream tasks\r\n\u2022\u00a0Consistency loss\r\n\u2022\u00a0Further reading","links":[{"article_link":"https://www.fast.ai/2020/01/13/self_supervised/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":431,"title":"Genomic ULMFiT","description":"ULMFiT for Genomic Sequence Data","tags":["code","tutorial","fastai","pytorch","embeddings","language-modeling","natural-language-processing","ulmfit","genomics"],"details":"This is an implementation of ULMFiT for genomics classification using Pytorch and Fastai. The model architecture used is based on the AWD-LSTM model, consisting of an embedding, three LSTM layers, and a final set of linear layers. The ULMFiT approach uses three training phases to produce a classification model:\r\n\u2022\u00a0Train a language model on a large, unlabeled corpus\r\n\u2022\u00a0Fine tune the language model on the classification corpus\r\n\u2022\u00a0Use the fine tuned language model to initialize a classification model","links":[{"article_link":"","code_link":"https://github.com/kheyer/Genomic-ULMFiT","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":430,"title":"Controlling Text Generation with Plug and Play Language Models","description":"This article discusses an alternative approach to controlled text generation, titled the Plug and Play Language Model (PPLM).","tags":["article","code","paper","research","tutorial","huggingface","transformers","language-modeling","natural-language-processing","text-generation","uber-ai","conditional-generation","pplm","arxiv:1912.02164"],"details":"PPLM allows a user to flexibly plug in one or more simple attribute models representing the desired control objective into a large, unconditional LM. The method has the key property that it uses the LM as is\u2014no training or fine-tuning is required\u2014which enables researchers to leverage best-in-class LMs even if they do not have the extensive hardware required to train them.","links":[{"article_link":"https://eng.uber.com/pplm/","code_link":"https://github.com/uber-research/PPLM","research_link":"https://arxiv.org/abs/1912.02164","media_link":"https://transformer.huggingface.co/model/pplm","dataset_link":"","demo_link":"","other_link":""}]},{"id":429,"title":"6 GAN Architectures You Really Should Know","description":"Some of the most popular GAN architectures, particularly 6 architectures that you should know to have a diverse coverage on GANs.","tags":["article","tutorial","generative-adversarial-networks","survey"],"details":"In this article, we will talk about some of the most popular GAN architectures, particularly 6 architectures that you should know to have a diverse coverage on Generative Adversarial Networks (GANs).\r\n* CycleGAN\r\n* StyleGAN\r\n* pixelRNN\r\n* text-2-image\r\n* DiscoGAN\r\n* lsGAN","links":[{"article_link":"https://neptune.ai/blog/6-gan-architectures","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":428,"title":"AiLight: Automatic  Highlighting Using BERT","description":"Automatically highlight pdfs using BERT embeddings and clustering. \r\nhttps://anishthite.github.io/ailight","tags":["article","attention","bert","transformers","library","embeddings","natural-language-processing"],"details":"Summarization takes away details from the paper that may be important later. Highlighting preserves details and provides landmarks for important points. I always found it hard to skim papers but with the important parts already highlighted its easier to segment the document","links":[{"article_link":"https://anishthite.github.io/ailight/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":427,"title":"An Overview of Early Vision in InceptionV1","description":"A guided tour of the first five layers of InceptionV1,\r\ntaxonomized into \u201cneuron groups.\u201d","tags":["article","tutorial","convolutional-neural-networks","computer-vision","distill-pub","inception"],"details":"By limiting ourselves to early vision, this article \u201conly\u201d considers the first 1,056 neurons of InceptionV1. 2 But our experience is that a thousand neurons is more than enough to be disorienting when one begins studying a model. Our hope is that this article will help readers avoid this disorientation by providing some structure and handholds for thinking about them.","links":[{"article_link":"https://distill.pub/2020/circuits/early-vision/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":426,"title":"The Transformer Family","description":"This post presents how the vanilla Transformer can be improved for longer-term attention span, less memory and computation consumption, RL task solving, etc.","tags":["article","tutorial","attention","transformers","natural-language-processing"],"details":"It has been almost two years since my last post on attention. Recent progress on new and enhanced versions of Transformer motivates me to write another post on this specific topic, focusing on how the vanilla Transformer can be improved for longer-term attention span, less memory and computation consumption, RL task solving and more.","links":[{"article_link":"https://lilianweng.github.io/lil-log/2020/04/07/the-transformer-family.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":425,"title":"Backtester","description":"A backtesting framework for timeseries data.","tags":["code","library","time-series","time-series-forecasting","backtester"],"details":"* Make it possible to test any timeseries not just financial data","links":[{"article_link":"","code_link":"https://github.com/EricSchles/backtester","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":424,"title":"Sparse Sinkhorn Attention","description":"A new efficient and sparse method for learning to attend based on differentiable sorting of internal representations.","tags":["code","paper","research","attention","transformers","natural-language-processing","reformer","sinkhorn","differentiable-sorting","arxiv:2002.11296"],"details":"* It includes a parameterized sorting network, using sinkhorn normalization to sample a permutation matrix that matches the most relevant buckets of keys to the buckets of queries.\r\n\u2022\u00a0This work also brings in reversible networks and feed forward chunking (concepts introduced from Reformer) to bring about further memory savings.","links":[{"article_link":"","code_link":"https://github.com/lucidrains/sinkhorn-transformer","research_link":"https://arxiv.org/abs/2002.11296","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":423,"title":"3D Ken Burns Effect from a Single Image","description":"Implementation of 3D Ken Burns Effect from a Single Image using PyTorch.","tags":["code","paper","research","tutorial","animation","3d","computer-vision","image-processing","ken-burns-effect","cupy","arxiv:1909.05483"],"details":"This is a reference implementation of 3D Ken Burns Effect from a Single Image using PyTorch. Given a single input image, it animates this still image with a virtual camera scan and zoom subject to motion parallax. ","links":[{"article_link":"","code_link":"https://github.com/sniklaus/3d-ken-burns","research_link":"https://arxiv.org/abs/1909.05483","media_link":"http://content.sniklaus.com/kenburns/video.mp4","dataset_link":"","demo_link":"","other_link":""}]},{"id":422,"title":"Training Neural Nets on Larger Batches","description":"\ud83d\udca5 Practical Tips for 1-GPU, Multi-GPU & Distributed setups","tags":["article","tutorial","convolutional-neural-networks","training","distributed-training","gpu","batch-size"],"details":"In this post I will mainly talk about the PyTorch framework. Some of these tools are not in PyTorch yet (as of 1.0) so I include some custom code as well.","links":[{"article_link":"https://medium.com/huggingface/training-larger-batches-practical-tips-on-1-gpu-multi-gpu-distributed-setups-ec88c3e51255","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":421,"title":"Strategies to Expand Data for Specialized Genomics Problems","description":"How can we train a model that captures the specialized aspects of a data-limited problem and benefits from large amounts of related training data? ","tags":["article","tutorial","data-augmentation","genomics"],"details":"* Jointly train with both WGS and WES data, select a model using tune performance on WES.\r\n\u2022\u00a0Warmstart from a pre-trained WGS model and train on WES data to adapt to it.\r\n\u2022\u00a0Add an additional vector within the model architecture to capture sequencing type.","links":[{"article_link":"https://google.github.io/deepvariant/posts/2019-12-06-covering-all-your-bases-strategies-to-expand-training-data-for-specialized-genomics-problems/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":420,"title":"Fairness Indicators: Scalable Infrastructure for Fair ML Systems","description":"Algorithms and the datasets on which ML models are trained on also have the ability to reflect or reinforce unfair biases.","tags":["article","code","tutorial","machine-learning","library","fairness","bias"],"details":"","links":[{"article_link":"https://blog.tensorflow.org/2019/12/fairness-indicators-fair-ML-systems.html","code_link":"https://github.com/tensorflow/fairness-indicators","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":419,"title":"Text Feature Selection for Causal Inference","description":"Identifying the linguistic features that cause people to act a certain way after reading a text, regardless of confounding variables, is something people do.","tags":["article","code","tutorial","causal-inference","feature-selection","natural-language-processing","text","confounding-variables"],"details":"* Making Causal Inferences with Text\r\n* Formalizing Textual Causality\r\n* Social Science Applications","links":[{"article_link":"http://ai.stanford.edu/blog/text-causal-inference/","code_link":"https://github.com/rpryzant/causal_attribution","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":418,"title":"Three Principles for Designing ML-Powered Products","description":"Reflecting on a handful of projects at Spotify, we\u2019ve come up with three principles we believe will help others design ML-powered experiences.","tags":["article","tutorial","design","product-management","systems-design"],"details":"* Identify friction and automate it away.\r\n* Ask the right questions.\r\n* Go manual before you go magical.","links":[{"article_link":"https://spotify.design/article/three-principles-for-designing-ml-powered-products","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":417,"title":"Initializing Neural  Networks","description":"In this post, we'll explain how to initialize neural network parameters effectively.","tags":["neural-networks","library","weights-initialization","interactive","weights","initialization"],"details":"Initialization can have a significant impact on convergence in training deep neural networks. Simple initialization schemes have been found to accelerate training, but they require some care to avoid common pitfalls. ","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.deeplearning.ai/ai-notes/initialization/","dataset_link":"","demo_link":"","other_link":""}]},{"id":416,"title":"Parameter Optimization in Neural Networks","description":"Visualizing parameter optimization","tags":["article","tutorial","tensorflow","convolutional-neural-networks","neural-networks","training","interactive","optimization","parameter-optimization","d3-js"],"details":"Training a machine learning model is a matter of closing the gap between the model's predictions and the observed training data labels. But optimizing the model parameters isn't so straightforward. Through interactive visualizations, we'll help you develop your intuition for setting up and solving this optimization problem.","links":[{"article_link":"https://www.deeplearning.ai/ai-notes/optimization/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":415,"title":"BertViz","description":"Tool for visualizing attention in the Transformer model (BERT, GPT-2, Albert, XLNet, RoBERTa, CTRL, etc.)","tags":["article","code","paper","research","attention","bert","gpt2","transformers","xlnet","library","interpretability","natural-language-processing","visualization","roberta","xlm","ctrl","tensor2tensor","arxiv:1906.05714"],"details":"BertViz is a tool for visualizing attention in the Transformer model, supporting all models from the transformers library (BERT, GPT-2, XLNet, RoBERTa, XLM, CTRL, etc.).","links":[{"article_link":"https://towardsdatascience.com/deconstructing-bert-part-2-visualizing-the-inner-workings-of-attention-60a16d86b5c1","code_link":"https://github.com/jessevig/bertviz","research_link":"https://arxiv.org/abs/1906.05714","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":414,"title":"TensorBoard.dev ","description":"Easily host, track, and share your ML experiments for free.","tags":["tensorflow","experiment-tracking","tensorboard"],"details":"A managed TensorBoard experience that lets you upload and share your ML experiment results with anyone.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://tensorboard.dev/"}]},{"id":413,"title":"Basic Relationship Patterns","description":"A quick walkthrough of the basic relational patterns.","tags":["article","code","tutorial","sql","sqlalchemy","alembic","relational-db"],"details":"Basic relationship patterns:\r\n* One To Many\r\n* Many To One\r\n* One To One\r\n* Many To Many","links":[{"article_link":"https://docs.sqlalchemy.org/en/13/orm/basic_relationships.html","code_link":"https://github.com/sqlalchemy/sqlalchemy","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":412,"title":"RunwayML","description":"Machine learning for creators","tags":["code","design","library","computer-vision","face-detection","motion-capture","natural-language-processing","posenet","runwayml","densepose","mask-rcnn","body-estimation"],"details":"Bring the power of artificial intelligence to your creative projects with an intuitive and simple visual interface. Start exploring new ways of creating today.","links":[{"article_link":"","code_link":"https://github.com/runwayml","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://runwayml.com/"}]},{"id":411,"title":"W&B: Weights and Biases","description":"Track model training at scale.","tags":["code","library","experiment-tracking","wandb","hyperparameter-optimization","weights-and-biases"],"details":"Record and visualize every detail of your research, collaborate easily, advance the state of the art","links":[{"article_link":"","code_link":"https://github.com/wandb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.wandb.com/"}]},{"id":410,"title":"Frameworks for Machine Learning Model Management","description":"This blog post will follow up by comparing three different tools developed to support reproducible machine learning model development.","tags":["article","tutorial","model-management","mlflow","experiment-tracking","systems-design","dvc","versioning","sacred"],"details":"\u2022\u00a0MLFlow developed by DataBricks (the company behind Apache Spark)\r\n\u2022\u00a0DVC, an open-source project that gets its main support by the San Francisco-/ London based startup iterative.ai\r\n\u2022\u00a0Sacred, an academical project developed by different researchers","links":[{"article_link":"https://www.inovex.de/blog/machine-learning-model-management/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":409,"title":"DeepChem","description":"Democratizing Deep-Learning for Drug Discovery, Quantum Chemistry, Materials Science and Biology ","tags":["code","deep-learning","machine-learning","library","drug-discovery","quantum-chemistry","biology","materials-science"],"details":"DeepChem aims to provide a high quality open-source toolchain that democratizes the use of deep-learning in drug discovery, materials science, quantum chemistry, and biology.","links":[{"article_link":"","code_link":"https://github.com/deepchem/deepchem","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://deepchem.io/"}]},{"id":408,"title":"FlashTorch","description":"Visualization toolkit for neural networks in PyTorch","tags":["article","code","video","pytorch","library","computer-vision","interpretability","visualization","explainability","flashtorch"],"details":"You can apply feature visualization techniques (such as saliency maps and activation maximization) on your model, with as little as a few lines of code. It is compatible with pre-trained models that come with torchvision, and seamlessly integrates with other custom models built in PyTorch.","links":[{"article_link":"https://towardsdatascience.com/feature-visualisation-in-pytorch-saliency-maps-a3f99d08f78a","code_link":"https://github.com/MisaOgura/flashtorch","research_link":"","media_link":"https://www.youtube.com/watch?v=18Iw4qYqfPo","dataset_link":"","demo_link":"","other_link":""}]},{"id":407,"title":"AllenNLP","description":"An open-source NLP research library, built on PyTorch.","tags":["code","pytorch","library","natural-language-processing","allennlp","allenai"],"details":"An Apache 2.0 NLP research library, built on PyTorch, for developing state-of-the-art deep learning models on a wide variety of linguistic tasks.","links":[{"article_link":"","code_link":"https://github.com/allenai/allennlp","research_link":"","media_link":"https://demo.allennlp.org/","dataset_link":"","demo_link":"","other_link":"http://www.allennlp.org/"}]},{"id":406,"title":"tf-explain","description":"Interpretability Methods for tf.keras models with Tensorflow 2.0","tags":["article","code","keras","tensorflow","library","interpretability","tensorflow-2-0"],"details":"tf-explain implements interpretability methods as Tensorflow 2.0 callbacks to ease neural network's understanding.","links":[{"article_link":"https://www.sicara.ai/blog/2019-07-31-tf-explain-interpretability-tensorflow","code_link":"https://github.com/sicara/tf-explain","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://tf-explain.readthedocs.io"}]},{"id":405,"title":"Lucid","description":"A collection of infrastructure and tools for research in neural network interpretability.","tags":["code","tutorial","tensorflow","interpretability"],"details":"Lucid is research code, not production code. We provide no guarantee it will work for your use case. Lucid is maintained by volunteers who are unable to provide significant technical support.","links":[{"article_link":"","code_link":"https://github.com/tensorflow/lucid","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":404,"title":"GPyTorch","description":"A highly efficient and modular implementation of Gaussian Processes in PyTorch","tags":["code","pytorch","library","gaussian-processes"],"details":"GPyTorch is a Gaussian process library implemented using PyTorch. GPyTorch is designed for creating scalable, flexible, and modular Gaussian process models with ease.","links":[{"article_link":"","code_link":"https://github.com/cornellius-gp/gpytorch","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://gpytorch.ai/"}]},{"id":403,"title":"A 2019 Guide to Speech Synthesis with Deep Learning","description":"A look at recent deep learning based speech synthesis research and techniques.","tags":["article","tutorial","natural-language-processing","speech","speech-synthesis","wavenet","tacotron","voiceloop","deep-voice","text-to-speech"],"details":"In this article, we\u2019ll look at research and model architectures that have been written and developed to do just that using deep learning.","links":[{"article_link":"https://heartbeat.fritz.ai/a-2019-guide-to-speech-synthesis-with-deep-learning-630afcafb9dd","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":402,"title":"The Infinite Drum Machine","description":"Create beats using sounds from the everyday world.","tags":["code","video","music","audio","embeddings","music-generation","interactive"],"details":"Sounds are complex and vary widely. This experiment uses machine learning to organize thousands of everyday sounds. The computer wasn\u2019t given any descriptions or tags \u2013 only the audio. Using a technique called t-SNE, the computer placed similar sounds closer together. You can use the map to explore neighborhoods of similar sounds and even make beats using the drum sequencer.","links":[{"article_link":"","code_link":"https://github.com/googlecreativelab/aiexperiments-drum-machine","research_link":"","media_link":"https://www.youtube.com/watch?v=9x-_My5yjQY&feature=emb_logo","dataset_link":"","demo_link":"","other_link":"https://experiments.withgoogle.com/ai/drum-machine/view/"}]},{"id":401,"title":"Quick, Draw","description":"Can a neural network learn to recognize doodling?","tags":["code","dataset","paper","research","library","computer-vision","image-recognition","interactive","quick-draw","arxiv:1704.03477"],"details":"We present sketch-rnn, a recurrent neural network (RNN) able to construct stroke-based drawings of common objects. The model is trained on thousands of crude human-drawn images representing hundreds of classes. We outline a framework for conditional and unconditional sketch generation, and describe new robust training methods for generating coherent sketch drawings in a vector format.","links":[{"article_link":"","code_link":"https://github.com/googlecreativelab/quickdraw-dataset","research_link":"https://arxiv.org/abs/1704.03477","media_link":"https://quickdraw.withgoogle.com/data","dataset_link":"","demo_link":"","other_link":"https://quickdraw.withgoogle.com/"}]},{"id":400,"title":"Teachable Machine","description":"Train a computer to recognize your own images, sounds, & poses. Create machine learning models for your sites, apps, and more \u2013 no expertise. ","tags":["node-js","tensorflow","library","p5-js","ml5-js"],"details":"Teachable Machine is a web-based tool that makes creating machine learning models fast, easy, and accessible to everyone\r\n","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://teachablemachine.withgoogle.com/"}]},{"id":399,"title":"Whack a Mole","description":"\ud83d\udd28whack a mole with your nose, built with p5.js & ml5.js and powered by PoseNet.","tags":["code","library","interactive","posenet"],"details":"Whack a Mole (gif above) is the first game in the collection. You can play whack a mole with your nose\ud83d\udc43. It's a physical game on the web developed with PoseNet.","links":[{"article_link":"","code_link":"https://github.com/vibertthio/posenet-whack-a-mole","research_link":"","media_link":"https://vibertthio.com/posenet-whack-a-mole/","dataset_link":"","demo_link":"","other_link":""}]},{"id":398,"title":"Neural Slime Volleyball","description":"Recurrent neural network playing slime volleyball.  Can you beat them?","tags":["article","recurrent-neural-networks","library","video-games","interactive","convnet-js","p5-js"],"details":"The inputs of the network would be the position and velocity of the agent, the position and velocity of the ball, and also of the opponent.  The output would be three signals that would trigger the \u2018forward\u2019, \u2018backward\u2019, and \u2018jump\u2019 controls to be activated. ","links":[{"article_link":"https://blog.otoro.net/2015/03/28/neural-slime-volleyball/","code_link":"","research_link":"","media_link":"https://otoro.net/slimevolley/","dataset_link":"","demo_link":"","other_link":""}]},{"id":397,"title":"Image-to-Image Translation with Conditional Adversarial Networks","description":"Tensorflow port of Image-to-Image Translation with Conditional Adversarial Nets","tags":["article","code","paper","research","tutorial","tensorflow","generative-adversarial-networks","library","computer-vision","image-to-image-translation","pix2pix","interactive","arxiv:1611.07004"],"details":"The pix2pix model works by training on pairs of images such as building facade labels to building facades, and then attempts to generate the corresponding output image from any input image you give it.","links":[{"article_link":"https://phillipi.github.io/pix2pix/","code_link":"https://github.com/affinelayer/pix2pix-tensorflow","research_link":"https://arxiv.org/abs/1611.07004","media_link":"https://affinelayer.com/pixsrv/","dataset_link":"","demo_link":"","other_link":""}]},{"id":396,"title":"D3 Graph Theory","description":"\ud83d\udca5 Interactive and colorful \ud83c\udfa8 graph theory tutorials made using d3.js \u26a1\ufe0f","tags":["code","tutorial","d3","library","interactive","graph-theory"],"details":"D3 Graph Theory is a front-end project aimed at anyone who wants to learn graph theory. It provides a quick and interactive introduction to the subject. The visuals used in the project makes it an effective learning tool.","links":[{"article_link":"","code_link":"https://github.com/mrpandey/d3graphTheory","research_link":"","media_link":"https://d3gt.com","dataset_link":"","demo_link":"","other_link":""}]},{"id":395,"title":"Word2Viz: Explore Word Analogies","description":"Interactive visualization of word analogies in GloVe.","tags":["article","library","embeddings","natural-language-processing","word-embeddings","visualization","interactive","glove"],"details":"Hover to highlight, double-click to remove. Change axes by specifying word differences, on which you want to project. Uses (compressed) pre-trained word vectors from glove.6B.50d. Made by Julia Bazi\u0144ska under the mentorship of Piotr Migda\u0142 (2017).\r\n","links":[{"article_link":"https://p.migdal.pl/2017/01/06/king-man-woman-queen-why.html","code_link":"","research_link":"","media_link":"https://lamyiowce.github.io/word2viz/","dataset_link":"","demo_link":"","other_link":""}]},{"id":394,"title":"ConvnetJS Demo","description":"Toy 2d classification with 2-layer neural network","tags":["article","neural-networks","library","interactive","convnet-js"],"details":"The simulation below shows a toy binary problem with a few data points of class 0 (red) and 1 (green). ","links":[{"article_link":"https://cs.stanford.edu/people/karpathy/convnetjs/demo/classify2d.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":393,"title":"Seeing Theory","description":"A visual introduction to probability and statistics. ","tags":["code","library","statistics","illustrated","interactive","probability"],"details":"Seeing Theory is a project designed and created by Daniel Kunin with support from Brown University's Royce Fellowship Program and National Science Foundation group STATS4STEM. The goal of the project is to make statistics more accessible to a wider range of students through interactive visualizations. ","links":[{"article_link":"","code_link":"https://github.com/seeingtheory/Seeing-Theory","research_link":"","media_link":"https://seeing-theory.brown.edu/","dataset_link":"","demo_link":"","other_link":""}]},{"id":392,"title":"Embedding Projector","description":"Visualization of high dimensional data, namely embeddings.","tags":["library","embeddings","natural-language-processing","word-embeddings","visualization","interactive"],"details":"Visualize embeddings by uploading your data as well.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://projector.tensorflow.org/","dataset_link":"","demo_link":"","other_link":""}]},{"id":390,"title":"Deep Playground","description":"Tinker With a Neural Network Right Here in Your Browser.","tags":["code","tensorflow","neural-networks","library","interactive","playground","demo"],"details":"Deep playground is an interactive visualization of neural networks, written in TypeScript using d3.js. We use GitHub issues for tracking new requests and bugs. Your feedback is highly appreciated!","links":[{"article_link":"","code_link":"https://github.com/tensorflow/playground","research_link":"","media_link":"","dataset_link":"","demo_link":"http://playground.tensorflow.org","other_link":""}]},{"id":389,"title":"Exploring Neural Networks with Activation Atlases","description":"An explorable activation atlas of features the network has learned which can reveal how the network typically represents some concepts.","tags":["article","tutorial","convolutional-neural-networks","library","activations","interactive"],"details":"In this article we introduce activation atlases to this quiver of techniques. (An example is shown at the top of this article.) Broadly speaking, we use a technique similar to the one in CNN codes, but instead of showing input data, we show feature visualizations of averaged activations. By combining these two techniques, we can get the advantages of each in one view\u2009\u2014\u2009a global map seen through the eyes of the network.","links":[{"article_link":"https://distill.pub/2019/activation-atlas/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":388,"title":"ConvNet Playground","description":"An interactive visualization for exploring Convolutional Neural Networks applied to the task of semantic image search.","tags":["article","data-visualization","convolutional-neural-networks","neural-networks","library","computer-vision","image-similarity-search","interactive","playground","semantic-image-search"],"details":"The prototype allows users to select search configurations (datasets, models, layers, distance metrics) and interactively explore how these impact search query performance. It allows users to ask questions such as: How does semantic search (with pretrained models) perform for given datasets? How well does each model/layer configuration capture \u201csemantic meaning\u201d for a given dataset? For a given search query, how does search performance compare for each model/layer configuration? What type of features/patterns are detected by various layers in a pretrained model?","links":[{"article_link":"https://blog.fastforwardlabs.com/2019/07/22/new-research-deep-learning-for-image-analysis.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://convnetplayground.fastforwardlabs.com/"}]},{"id":385,"title":"GAN Lab","description":"An Interactive, Visual Experimentation Tool for Generative Adversarial Networks ","tags":["code","generative-adversarial-networks","neural-networks","library","interactive","demo"],"details":"GAN Lab is a novel interactive visualization tool for anyone to learn and experiment with Generative Adversarial Networks (GANs), a popular class of complex deep learning models. With GAN Lab, you can interactively train GAN models for 2D data distributions and visualize their inner-workings, similar to TensorFlow Playground.","links":[{"article_link":"","code_link":"https://github.com/poloclub/ganlab","research_link":"","media_link":"","dataset_link":"","demo_link":"https://poloclub.github.io/ganlab/","other_link":""}]},{"id":384,"title":"Visualizing Memorization in RNNs","description":"Inspecting gradient magnitudes in context can be a powerful tool to see when recurrent units use short-term or long-term contextual understanding.","tags":["article","code","tutorial","attention","bert","recurrent-neural-networks","transformers","library","interpretability","natural-language-processing","visualization","debugging","distill-pub","memorization","heatmap","text-heatmap","distill-bert"],"details":"This article presents a qualitative visualization method for comparing recurrent units with regards to memorization and contextual understanding. The method is applied to the three recurrent units mentioned above: Nested LSTMs, LSTMs, and GRUs.","links":[{"article_link":"https://distill.pub/2019/memorization-in-rnns/","code_link":"https://github.com/AndreasMadsen/python-textualheatmap","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":383,"title":"The Building Blocks of Interpretability","description":"We explore the powerful interfaces that arise when you combine interpretability techniques\u2009and the rich structure of this combinatorial space.","tags":["article","tutorial","deep-learning","neural-networks","interpretability","distill-pub"],"details":"In this article, we treat existing interpretability methods as fundamental and composable building blocks for rich user interfaces. ","links":[{"article_link":"https://distill.pub/2018/building-blocks/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":382,"title":"Feature Visualization","description":"How neural networks build up their understanding of images","tags":["article","tutorial","interpretability","visualization","distill-pub","features","feature-visualization"],"details":"This article focuses on feature visualization. While feature visualization is a powerful tool, actually getting it to work involves a number of details. In this article, we examine the major issues and explore common approaches to solving them. We find that remarkably simple methods can produce high-quality visualizations. Along the way we introduce a few tricks for exploring variation in what neurons react to, how they interact, and how to improve the optimization process.","links":[{"article_link":"https://distill.pub/2017/feature-visualization/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":380,"title":"Graph Nets","description":"PyTorch Implementation and Explanation of Graph Representation Learning papers involving DeepWalk, GCN, GraphSAGE, ChebNet & GAT.","tags":["code","research","tutorial","pytorch","deep-learning","graph-convolutional-networks","graph-neural-networks","graphs","representation-learning","graph-representation-learning"],"details":"* DeepWalk Blog\r\n* GCN Blog\r\n* GraphSAGE Blog\r\n* ChebNet Blog\r\n* GAT Blog","links":[{"article_link":"","code_link":"https://github.com/dsgiitr/graph_nets","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://dsgiitr.com/work/graph_nets/"}]},{"id":378,"title":"Ray","description":"Ray is a fast and simple framework for building and running distributed applications.","tags":["article","code","pytorch","library","distributed-training","reinforcement-learning","hyperparameter-tuning","hyperparameter-optimization","scalable-reinforcement-learning","raysgd","rllib","tuning"],"details":"Ray is packaged with the following libraries for accelerating machine learning workloads:\r\n\r\n* Tune: Scalable Hyperparameter Tuning\r\n* RLlib: Scalable Reinforcement Learning\r\n* RaySGD: Distributed Training Wrappers","links":[{"article_link":"https://medium.com/distributed-computing-with-ray/faster-and-cheaper-pytorch-with-raysgd-a5a44d4fd220","code_link":"https://github.com/ray-project/ray","research_link":"","media_link":"https://ray.readthedocs.io/en/latest/index.html","dataset_link":"","demo_link":"","other_link":"https://ray.io"}]},{"id":377,"title":"Checklist for debugging neural networks","description":"Tangible steps you can take to identify and fix issues with training, generalization, and optimization for machine learning models.","tags":["article","tutorial","debugging","systems-design","checklist"],"details":"\u2022\u00a0Start simple\r\n\u2022\u00a0Confirm your loss\r\n\u2022\u00a0Check intermediate outputs and connections\r\n\u2022\u00a0Diagnose parameters\r\n\u2022\u00a0Tracking your work","links":[{"article_link":"https://towardsdatascience.com/checklist-for-debugging-neural-networks-d8b2a9434f21","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":376,"title":"A Recipe for Training Neural Networks","description":"The most common neural net mistakes and listing a few common gotchas related to training neural nets.","tags":["article","tutorial","training","debugging","checklist","recipe"],"details":"However, instead of going into an enumeration of more common errors or fleshing them out, I wanted to dig a bit deeper and talk about how one can avoid making these errors altogether (or fix them very fast). The trick to doing so is to follow a certain process, which as far as I can tell is not very often documented. Let\u2019s start with two important observations that motivate it.","links":[{"article_link":"http://karpathy.github.io/2019/04/25/recipe/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":375,"title":"Manifold","description":"A model-agnostic visual debugging tool for machine learning","tags":["code","react","tensorflow-js","machine-learning","library","feature-importance","visualization","debugging","visual-debugging","model-agnostic","feature-attribution","performance-comparison","performance","redux"],"details":"As a visual analytics tool, Manifold allows ML practitioners to look beyond overall summary metrics to detect which subset of data a model is inaccurately predicting. Manifold also explains the potential cause of poor model performance by surfacing the feature distribution difference between better and worse-performing subsets of data.","links":[{"article_link":"","code_link":"https://github.com/uber/manifold","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"http://manifold.mlvis.io/"}]},{"id":374,"title":"Practical Introduction to Web Scraping in Python","description":"Setting up a web scraper using Beautiful Soup 4.","tags":["article","tutorial","library","web-scraping","beautiful-soup","bs4","scraping"],"details":"In this tutorial, you will be writing a Python program that downloads the list of 100 mathematicians and their XTools pages, selects data about their popularity, and finishes by telling us the top 5 most popular mathematicians of all time! ","links":[{"article_link":"https://realpython.com/python-web-scraping-practical-introduction/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.crummy.com/software/BeautifulSoup/bs4/doc/"}]},{"id":373,"title":"An introduction to web scraping with Python ","description":"Let\u2019s scrape a fictional book store\u2019s website with BeautifulSoup!","tags":["article","code","tutorial","web-scraping","beautiful-soup","bs4"],"details":"As a data scientist, I often find myself looking for external data sources that could be relevant for my machine learning projects. The problem is that it is uncommon to find open source data sets that perfectly correspond to what you are looking for, or free APIs that give you access to data. In this case, web scraping can be one solution to get more data.","links":[{"article_link":"https://towardsdatascience.com/an-introduction-to-web-scraping-with-python-a2601e8619e5","code_link":"https://github.com/jonathanoheix/scraping_basics_with_beautifulsoup","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":372,"title":"An introduction to Q-Learning: Reinforcement Learning","description":"Q-Learning algorithm along with an implementation in Python using Numpy.","tags":["article","tutorial","q-learning","reinforcement-learning"],"details":"In the first half of the article, we will be discussing reinforcement learning in general with examples where reinforcement learning is not just desired but also required. We will then study the Q-Learning algorithm along with an implementation in Python using Numpy.","links":[{"article_link":"https://blog.floydhub.com/an-introduction-to-q-learning-reinforcement-learning/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":371,"title":"Introduction to K-Means Clustering in Python With Scikit-Learn","description":"A look at the old faithful K-Means clustering algorithm which has impacted a very huge number of applications in a wide variety of domains.","tags":["article","tutorial","scikit-learn","clustering","unsupervised-learning","k-means-clustering"],"details":"We will start off by building the general notion of clustering and some of the rules that govern it. We will review some of the different types of clustering briefly and then we will dive into the nitty gritty details of  K-Means. We\u2019ll conclude this article by seeing K-Means in action in Python using a toy dataset. By the time you are done, you\u2019ll have working knowledge of the algorithm and can start applying it to your own use cases.","links":[{"article_link":"https://blog.floydhub.com/introduction-to-k-means-clustering-in-python-with-scikit-learn/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":370,"title":"Introduction to Genetic Algorithms","description":"An introduction to the concepts and techniques around genetic algorithms.","tags":["article","tutorial","evolution-strategies","genetic-algorithms","evolutionary-algorithms"],"details":"This article will briefly discuss the terms and concepts required to understand genetic algorithms then provide two examples. The first example will be estimating the optimal inputs and maximum value of a multivariable function. The second example will develop a simple simulation of cooperating and non-cooperating species in a resource-constrained environment to explore how genetic algorithms can model complex behavior. ","links":[{"article_link":"https://blog.floydhub.com/introduction-to-genetic-algorithms/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":369,"title":"The Case for Bayesian Deep Learning","description":"What makes Bayesian inference distinctive, and why Bayesian inference is worthwhile in deep learning.","tags":["article","tutorial","bayesian-deep-learning","bayesian-inference","bayesian-neural-networks"],"details":"Prologue: I posted a response to recent misunderstandings around Bayesian deep learning. I have since been urged to collect and develop my remarks into an accessible and self-contained reference. For this purpose, I have written the note posted here. I hope this exposition will be helpful to those seeking to understand what makes Bayesian inference distinctive, and why Bayesian inference is worthwhile in deep learning. ","links":[{"article_link":"https://cims.nyu.edu/~andrewgw/caseforbdl/","code_link":"","research_link":"","media_link":"https://twitter.com/andrewgwils/status/1210354001041969152?s=20","dataset_link":"","demo_link":"","other_link":""}]},{"id":368,"title":"The Machine Learning Reproducibility Checklist ","description":"How the AI Community Can Get Serious About Reproducibility","tags":["article","machine-learning","library","systems-design","checklist","reproducability"],"details":"","links":[{"article_link":"https://ai.facebook.com/blog/how-the-ai-community-can-get-serious-about-reproducibility/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.cs.mcgill.ca/~jpineau/ReproducibilityChecklist.pdf"}]},{"id":367,"title":"ML Code Completeness Checklist","description":"Tips for releasing research code in Machine Learning (with official NeurIPS 2020 recommendations).","tags":["article","code","library","systems-design","checklist","reproducability","research-code"],"details":"\u2022\u00a0Specification of dependencies\r\n\u2022\u00a0Training code\r\n\u2022\u00a0Evaluation code\r\n\u2022\u00a0Pre-trained models\r\n\u2022\u00a0README file including table of results accompanied by precise commands to run/produce those results","links":[{"article_link":"https://medium.com/paperswithcode/ml-code-completeness-checklist-e9127b168501","code_link":"https://github.com/paperswithcode/releasing-research-code","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":366,"title":"Introduction to Adversarial Machine Learning","description":"In this article we are going to learn about a handful of attacks, namely how they work and how we can defend networks against these attacks.","tags":["article","tutorial","adversarial-defense","adversarial-learning","adversarial-attacks","adversarial"],"details":"Attacks:\r\n\u2022\u00a0Noise\r\n\u2022\u00a0Semantic\r\n\u2022\u00a0Fast Gradient Sign Method\r\n\u2022\u00a0Projected Gradient Descent\r\n\u2022\u00a0DeepFool\r\n\r\nDefences:\r\n\u2022\u00a0Adversarial Training\r\n\u2022\u00a0Random Resizing and Padding","links":[{"article_link":"https://blog.floydhub.com/introduction-to-adversarial-machine-learning/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":365,"title":"ML beyond Curve Fitting: Causal Inference and do-Calculus","description":"An Intro to Causal Inference and do-Calculus","tags":["article","tutorial","causal-inference","do-calculus","judea-pearl"],"details":"In this post I'll try to explain the basics, and convince you why you should think about this, too. If you work on deep learning, that's an even better reason to understand this. Pearl's comments may be unhelpful if interpreted as contrasting deep learning with causal inference. Rather, you should interpret it as highlighting causal inference as a huge, relatively under-explored, application of deep learning. Don't get discouraged by causal diagrams looking a lot like Bayesian networks (not a coincidence seeing they were both pioneered by Pearl) they don't compete with, they complement deep learning.","links":[{"article_link":"https://www.inference.vc/untitled/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":364,"title":"Named Entity Recognition Tagging","description":"In this post, we go through an example from Natural Language Processing, in which we learn how to load text data and perform NER tagging for each token.","tags":["article","tutorial","pytorch","recurrent-neural-networks","named-entity-recognition","natural-language-processing","stanford","cs230"],"details":"\u2022\u00a0Learn how to use PyTorch to load sequential data\r\n\u2022\u00a0Specify a recurrent neural network\r\n\u2022\u00a0Understand the key aspects of the code well-enough to modify it to suit your needs","links":[{"article_link":"https://cs230.stanford.edu/blog/namedentity/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":363,"title":"Keras TCN","description":"Keras Temporal Convolutional Network.","tags":["code","tutorial","keras","convolutional-neural-networks","temporal-cnn","library"],"details":"\u2022\u00a0TCNs exhibit longer memory than recurrent architectures with the same capacity.\r\n\u2022\u00a0Constantly performs better than LSTM/GRU architectures on a vast range of tasks (Seq. MNIST, Adding Problem, Copy Memory, Word-level PTB...).\r\n\u2022\u00a0Parallelism, flexible receptive field size, stable gradients, low memory requirements for training, variable length inputs...","links":[{"article_link":"","code_link":"https://github.com/philipperemy/keras-tcn","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":362,"title":"Flask Mega-Tutorial series","description":"A comprehensive tutorial on Flask to create a complete app.","tags":["article","code","tutorial","databases","flask","html","javascript","sql","full-stack","sqlalchemy","jinja","bootstrap","ajax"],"details":"You are about to start on a journey to learn how to create web applications with Python and the Flask framework. ","links":[{"article_link":"https://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-i-hello-world","code_link":"https://github.com/miguelgrinberg/microblog","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":361,"title":"Logging in Python","description":"Logging is a very useful tool in a programmer\u2019s toolbox. ","tags":["article","tutorial","video","python","logging"],"details":"The logging module is considered to be very flexible. Its design is very practical and should fit your use case out of the box. You can add basic logging to a small project, or you can go as far as creating your own custom log levels, handler classes, and more if you are working on a big project.","links":[{"article_link":"https://realpython.com/python-logging/","code_link":"","research_link":"","media_link":"https://realpython.com/lessons/logging-python-introduction/","dataset_link":"","demo_link":"","other_link":""}]},{"id":360,"title":"PyTorch Metric Learning","description":"The easiest way to use deep metric learning in your application. Modular, flexible, and extensible. Written in PyTorch.","tags":["article","code","paper","research","pytorch","library","metrics","self-supervised-learning","custom-metrics","losses","miners","regularizers","testers","trainers","custom-loss","deep-metric-learning","metric-learning"],"details":"**Ease of use**:\r\n\r\n* Add metric learning to your application with just 2 lines of code in your training loop.\r\n* Mine pairs and triplets with a single function call.\r\n* Flexibility\r\n* Mix and match losses, miners, and trainers in ways that other libraries don't allow.\r\n\r\n**Blog posts**:\r\n\r\n* [The New PyTorch Package that makes Metric Learning Simple](https://medium.com/@tkm45/the-new-pytorch-package-that-makes-metric-learning-simple-5e844d2a1142)\r\n* [PyTorch Metric Learning: What\u2019s New](https://medium.com/@tkm45/pytorch-metric-learning-whats-new-15d6c71a644b)\r\n","links":[{"article_link":"https://medium.com/@tkm45/the-new-pytorch-package-that-makes-metric-learning-simple-5e844d2a1142","code_link":"https://github.com/KevinMusgrave/pytorch-metric-learning","research_link":"https://medium.com/@tkm45/pytorch-metric-learning-whats-new-15d6c71a644b","media_link":"","dataset_link":"","demo_link":"","other_link":"https://kevinmusgrave.github.io/pytorch-metric-learning/"}]},{"id":359,"title":"Annoy: Approximate Nearest Neighbors","description":"Approximate Nearest Neighbors in C++/Python optimized for memory usage and loading/saving to disk","tags":["code","c++","library","embeddings","similarity-search","spotify","vector-similarity","annoy"],"details":"Annoy (Approximate Nearest Neighbors Oh Yeah) is a C++ library with Python bindings to search for points in space that are close to a given query point. It also creates large read-only file-based data structures that are mapped into memory so that many processes may share the same data.","links":[{"article_link":"","code_link":"https://github.com/spotify/annoy","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":358,"title":"Milvus","description":"An open source vector similarity search engine.","tags":["code","library","similarity-search","vector-similarity","milvus"],"details":"As an open source vector similarity search engine, Milvus is easy-to-use, highly reliable, scalable, robust, and blazing fast. Adopted by over 100 organizations and institutions worldwide, Milvus empowers applications in a variety of fields, including image processing, computer vision, natural language processing, voice recognition, recommender systems, drug discovery, etc.","links":[{"article_link":"","code_link":"https://github.com/milvus-io/milvus/","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://milvus.io"}]},{"id":357,"title":"Learn TensorFlow.js - Deep Learning and Neural Networks with JS","description":"This full course introduces the concept of client-side artificial neural networks.","tags":["tutorial","video","tensorflow","tensorflow-js"],"details":"We will learn how to deploy and run models along with full deep learning applications in the browser! To implement this cool capability, we\u2019ll be using TensorFlow.js (TFJS), TensorFlow\u2019s JavaScript library.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=EoYfa6mYOG4","dataset_link":"","demo_link":"","other_link":""}]},{"id":356,"title":"TensorFlow.js Crash Course \u2014 Machine Learning For The Web","description":"Welcome to the first episode of the CodingTheSmartWay.com TensorFlow.js Crash Course for absolute beginners.","tags":["article","code","tutorial","video","tensorflow","tensorflow-js"],"details":"In this first part of the series you\u2019ll learn:\r\n\u2022\u00a0What TensorFlow.js is\r\n\u2022\u00a0How TensorFlow.js is added to your web application\r\n\u2022\u00a0How TensorFlow.js can be used to add machine learning capabilities to your web application","links":[{"article_link":"https://medium.com/codingthesmartway-com-blog/tensorflow-js-crash-course-machine-learning-for-the-web-getting-started-50694a575238","code_link":"https://github.com/seeschweiler/tensorflow_js_1","research_link":"","media_link":"https://www.youtube.com/watch?v=M4YsClyTMzg","dataset_link":"","demo_link":"","other_link":"https://demo-080.codingthesmartway.com/"}]},{"id":355,"title":"TensorFlow JS Examples","description":"Examples built with TensorFlow.js ","tags":["code","tutorial","javascript","tensorflow","tensorflow-js","library"],"details":"This repository contains a set of examples implemented in TensorFlow.js. Each example directory is standalone so the directory can be copied to another project.","links":[{"article_link":"","code_link":"https://github.com/tensorflow/tfjs-examples","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://js.tensorflow.org/"}]},{"id":353,"title":"Keras OCR","description":"A packaged and flexible version of the CRAFT text detector and Keras CRNN recognition model. ","tags":["code","keras","library","computer-vision","optical-character-recognition"],"details":"This is a slightly polished and packaged version of the Keras CRNN implementation and the published CRAFT text detection model. It provides a high level API for training a text detection and OCR pipeline.","links":[{"article_link":"","code_link":"https://github.com/faustomorales/keras-ocr","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://keras-ocr.readthedocs.io/"}]},{"id":352,"title":"Do We Really Need Model Compression?","description":"In this blog post, we\u2019ll explore the obstacles involved in training small models from scratch. ","tags":["article","tutorial","model-compression"],"details":"We\u2019ll discuss why model compression works and two approaches to memory-efficient training: over-parameterization bounds and better optimization methods, which may reduce or eliminate the need for post-hoc model compression. We\u2019ll wrap up with future research directions.","links":[{"article_link":"http://mitchgordon.me/machine/learning/2020/01/13/do-we-really-need-model-compression.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":351,"title":"EvoNorms: Evolving Normalization-Activation Layers","description":"We use evolution to design new layers called EvoNorms, which outperform BatchNorm-ReLU on many tasks. ","tags":["paper","research","automl","batch-normalization","relu","normalization","activations","activation-layers","evonorms","group-normalization","groupnorm","batchnorm","arxiv:2004.02967"],"details":"Key ideas: \r\n\u2022\u00a0(1) to start from low-level primitives, and \r\n\u2022\u00a0(2) to evolve the layers' generalization over multiple architectures. EvoNorms achieved promising results on ResNets, MobileNets, EfficientNets, Mask R-CNN and BigGAN. Pseudocode available in the appendix.","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2004.02967","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":350,"title":"Data Project Checklist","description":"There\u2019s a lot more to creating useful data projects than just training an accurate model!","tags":["article","tutorial","databases","product-management","training","systems-design","checklist"],"details":"* Strategy: What is the organization trying to do (objective) and what can it change to do it better (levers)?\r\n* Data: Is the organization capturing necessary data and making it available?\r\n* Analytics: What kinds of insights would be useful to the organization?\r\n* Implementation: What organizational capabilities does it have?\r\n* Maintenance: What systems are in place to track changes in the operational environment?\r\n* Constraints: What constraints need to be considered in each of the above areas?","links":[{"article_link":"https://www.fast.ai/2020/01/07/data-questionnaire/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.oreilly.com/radar/drivetrain-approach-data-products/"}]},{"id":349,"title":"The Dark Secrets of BERT","description":"How much of the linguistically interpretable self-attention patterns that are presumed to be its strength are actually used to solve downstream tasks?","tags":["article","paper","research","tutorial","attention","bert","self-attention","transformers","fine-tuning","interpretability","natural-language-processing","disadvantages"],"details":"This work focuses on the complementary question: what happens in the fine-tuned BERT? In particular, how much of the linguistically interpretable self-attention patterns that are presumed to be its strength are actually used to solve downstream tasks?","links":[{"article_link":"https://text-machine-lab.github.io/blog/2020/bert-secrets/","code_link":"","research_link":"https://www.aclweb.org/anthology/D19-1445.pdf","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":348,"title":"Captum","description":"Model Interpretability for PyTorch","tags":["article","code","tutorial","pytorch","library","interpretability","multi-modal","captum","multimodal-learning"],"details":"* Multi-modal: Supports interpretability of models across modalities including vision, text, and more.\r\n* Built on PyTorch: Supports most types of PyTorch models and can be used with minimal modification to the original neural network.\r\n* Extensible: Open source, generic library for interpretability research. Easily implement and benchmark new algorithms.","links":[{"article_link":"https://captum.ai/tutorials/IMDB_TorchText_Interpret","code_link":"https://github.com/pytorch/captum","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://captum.ai/"}]},{"id":347,"title":"The State of Transfer Learning in NLP","description":"This post expands on the NAACL 2019 tutorial on Transfer Learning in NLP. It highlights key insights and takeaways and provides updates based on recent work.","tags":["article","code","notebook","tutorial","natural-language-processing","transfer-learning","pretraining"],"details":"We will present an overview of modern transfer learning methods in NLP, how models are pre-trained, what information the representations they learn capture, and review examples and case studies on how these models can be integrated and adapted in downstream NLP tasks.","links":[{"article_link":"https://ruder.io/state-of-transfer-learning-in-nlp/","code_link":"https://github.com/huggingface/naacl_transfer_learning_tutorial","research_link":"","media_link":"https://docs.google.com/presentation/d/1fIhGikFPnb7G5kr58OvYC3GN4io7MznnM0aAgadvJfc/edit","dataset_link":"","demo_link":"","other_link":"https://colab.research.google.com/drive/1iDHCYIrWswIKp-n-pOg69xLoZO09MEgf"}]},{"id":346,"title":"Bayesian Neural Networks Need Not Concentrate","description":"We show that if the prior does not distinguish between functions that generalize and functions that don\u2019t, Bayesian inference cannot provide uncertainties.","tags":["article","code","tutorial","bayesian-deep-learning","bayesian-neural-networks"],"details":"The Bayesian community has produced decades of important insights in machine learning, and is often viewed as one of the most rigorous sub-communities within ML. However, in our opinion, Bayesian neural networks have failed to live up to this ideal. The Bayesian community has not demonstrated that the distributions output by BNNs correspond well to the true posteriors. Without this guarantee, BNNs are no different from any other neural network which maps its inputs to a distribution over outputs; researchers should therefore avoid making the claim that the distribution output by a BNN encodes model uncertainty.","links":[{"article_link":"https://jacobbuckman.com/2020-01-22-bayesian-neural-networks-need-not-concentrate/","code_link":"https://github.com/jbuckman/bnn-blog-experiments","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":345,"title":"HMTL: Hierarchical Multi-Task Learning","description":"\ud83c\udf0a A State-of-the-Art neural network model for several NLP tasks based on PyTorch and AllenNLP","tags":["code","paper","research","tutorial","huggingface","pytorch","natural-language-processing","allennlp","allenai","multi-task-learning","arxiv:1811.06031"],"details":"HMTL is a Hierarchical Multi-Task Learning model which combines a set of four carefully selected semantic tasks (namely Named Entity Recoginition, Entity Mention Detection, Relation Extraction and Coreference Resolution). The model achieves state-of-the-art results on Named Entity Recognition, Entity Mention Detection and Relation Extraction. Using SentEval, we show that as we move from the bottom to the top layers of the model, the model tend to learn more complex semantic representation.","links":[{"article_link":"","code_link":"https://github.com/huggingface/hmtl","research_link":"https://arxiv.org/abs/1811.06031","media_link":"https://huggingface.co/hmtl/","dataset_link":"","demo_link":"","other_link":""}]},{"id":344,"title":"Tokenizers","description":"\ud83d\udca5Fast State-of-the-Art Tokenizers optimized for Research and Production.","tags":["code","huggingface","library","natural-language-processing","preprocessing","tokenization","tokenizers"],"details":"Main features:\r\n\u2022\u00a0Train new vocabularies and tokenize, using today's most used tokenizers.\r\n\u2022\u00a0Extremely fast (both training and tokenization), thanks to the Rust implementation. Takes less than 20 seconds to tokenize a GB of text on a server's CPU.\r\n\u2022\u00a0Easy to use, but also extremely versatile.\r\n\u2022\u00a0Designed for research and production.\r\n\u2022\u00a0Normalization comes with alignments tracking. It's always possible to get the part of the original sentence that corresponds to a given token.\r\n\u2022\u00a0Does all the pre-processing: Truncate, Pad, add the special tokens your model needs.","links":[{"article_link":"","code_link":"https://github.com/huggingface/tokenizers","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":343,"title":"Machine Learning Systems Design","description":"Designing a machine learning system.","tags":["article","tutorial","machine-learning","full-stack","product-management","systems-design","machine-learning-systems-design","checklist","mlops"],"details":"**Table on contents**:\r\n\r\n* Introduction\r\n\t* Research vs production\r\n\t\t* Performance requirements\r\n\t\t* Compute requirements\r\n* Design a machine learning system\r\n\t* Project setup \r\n\t* Data pipeline \r\n\t* Modeling \r\n\t\t* Model selection \r\n\t\t* Training \r\n\t\t* Debugging \r\n\t\t* Hyperparameter tuning \r\n\t\t* Scaling \r\n\t* Serving\r\n* Case studies \r\n* Exercises","links":[{"article_link":"https://github.com/chiphuyen/machine-learning-systems-design/blob/master/build/build1/consolidated.pdf","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":342,"title":"Multiprocessing vs. Threading in Python for Data Scientists","description":"We'll explore how data scientists can go about choosing between the two and which factors should be kept in mind while doing so.","tags":["article","tutorial","full-stack","multiprocessing","threading"],"details":"Sooner or later, every data science project faces an inevitable challenge: speed. Working with larger data sets leads to slower processing thereof, so you'll eventually have to think about optimizing your algorithm's run time. As most of you already know, parallelization is a necessary step of this optimization. Python offers two built-in libraries for parallelization: multiprocessing and threading. In this article, we'll explore how data scientists can go about choosing between the two and which factors should be kept in mind while doing so.","links":[{"article_link":"https://blog.floydhub.com/multiprocessing-vs-threading-in-python-what-every-data-scientist-needs-to-know/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":341,"title":"How to Unit Test Machine Learning Code","description":"Wouldn\u2019t suck to have to throw away perfectly good ideas because our implementations were buggy?","tags":["article","tutorial","unit-tests","testing"],"details":"These bugs are really hard to catch for a few reasons.\r\n\u2022\u00a0This code never crashes, raises an error, or even slows down.\r\n\u2022\u00a0This network still trains and the loss will still go down.\r\n\u2022\u00a0The values converge after a few hours, but to really poor results, leaving you scratching your head as to what you need to fix.","links":[{"article_link":"https://medium.com/@keeper6928/how-to-unit-test-machine-learning-code-57cf6fd81765","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":340,"title":"Building Machine Learning Products: A Problem Well-Defined","description":" In this post, we'll dig deeper into how to develop the requirements for a machine learning project when you're given a vague problem to solve.","tags":["article","tutorial","machine-learning","product-management","systems-design","products","guides","checklist"],"details":"Some questions that we'll address include:\r\n\r\n* What specific task should our model be automating?\r\n* How does the user interact with the model?\r\n* What information should we expose to the user?\r\n\r\nPrevious post on [Organizing machine learning projects: project management guidelines.](https://www.jeremyjordan.me/ml-projects-guide/)","links":[{"article_link":"http://jeremyjordan.me/ml-requirements/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":339,"title":"An Introduction to Kubernetes","description":"This blog post will provide an introduction to Kubernetes so that you can understand the motivation behind the tool, what it is, and how you can use it.","tags":["code","tutorial","docker","kubernetes","devops"],"details":"","links":[{"article_link":"","code_link":"https://www.jeremyjordan.me/kubernetes/","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":338,"title":"BayesNet","description":"TikZ ibrary for drawing Bayesian networks, graphical models and (directed) factor graphs in LaTeX.","tags":["code","bayesian-deep-learning","library","graphs","visualization","bayesian-networks","directed-factor-graphs","latex","tikz"],"details":"This library is derived from a technical report \"Directed Factor Graph Notation for Generative Models\" and the accompanying TikZ macros by Laura Dietz 2010 (http://people.cs.umass.edu/~dietz/). The technical report is available in this repository as dietz-techreport.pdf.","links":[{"article_link":"","code_link":"https://github.com/jluttine/tikz-bayesnet","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":337,"title":"Discovering Millions of Datasets on the Web","description":"Dataset Search has indexed almost 25 million of these datasets, giving you a single place to search for datasets and find links to where the data is.","tags":["article","machine-learning","library","search","datasets","dataset-search"],"details":"Based on what we\u2019ve learned from the early adopters of Dataset Search, we\u2019ve added new features. You can now filter the results based on the types of dataset that you want (e.g., tables, images, text), or whether the dataset is available for free from the provider. If a dataset is about a geographic area, you can see the map. Plus, the product is now available on mobile and we\u2019ve significantly improved the quality of dataset descriptions. One thing hasn't changed however: anybody who publishes data can make their datasets discoverable in Dataset Search by using an open standard (schema.org) to describe the properties of their dataset on their own web page.","links":[{"article_link":"https://blog.google/products/search/discovering-millions-datasets-web/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://datasetsearch.research.google.com/"}]},{"id":336,"title":"Organizing Machine Learning Projects Project Management Guideline","description":"The goal of this document is to provide a common framework for approaching machine learning projects that can be referenced by practitioners. ","tags":["article","tutorial","machine-learning","design","project-management","systems-design","projects-guide","machine-learning-systems"],"details":"If you build ML models, this post is for you. If you collaborate with people who build ML models, I hope that this guide provides you with a good perspective on the common project workflow. Knowledge of machine learning is assumed.","links":[{"article_link":"https://www.jeremyjordan.me/ml-projects-guide/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":335,"title":"BioBERT: a pre-trained biomedical language representation model ","description":"Code for fine-tuning BioBERT for biomedical text mining tasks such as biomedical NER, relation extraction, QA, etc.","tags":["code","paper","research","attention","bert","transformers","health","library","named-entity-recognition","natural-language-processing","question-answering","relation-extraction","biomedical","biobert","text-mining"],"details":"This repository provides the code for fine-tuning BioBERT, a biomedical language representation model designed for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, question answering, etc. Please refer to our paper BioBERT: a pre-trained biomedical language representation model for biomedical text mining for more details. This project is done by DMIS-Lab.","links":[{"article_link":"","code_link":"https://github.com/dmis-lab/biobert","research_link":"https://academic.oup.com/bioinformatics/article/36/4/1234/5566506","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":334,"title":"BioWordVec & BioSentVec","description":"Pre-trained embeddings for biomedical words and sentences","tags":["code","notebook","tutorial","fasttext","health","library","embeddings","natural-language-processing","sentence-embeddings","word-embeddings","bionlp","pubmed","sentence-similarity","mimic-iii"],"details":"We created biomedical word and sentence embeddings using PubMed and the clinical notes from MIMIC-III Clinical Database. Both PubMed and MIMIC-III texts were split and tokenized using NLTK. We also lowercased all the words. The statistics of the two corpora are shown below.","links":[{"article_link":"","code_link":"https://github.com/ncbi-nlp/BioSentVec","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://github.com/ncbi-nlp/BioSentVec/blob/master/BioSentVec_tutorial.ipynb"}]},{"id":333,"title":"ONNX","description":"Open standard for machine learning interoperability.","tags":["code","onnx","machine-learning","library","interoperability"],"details":"Open Neural Network Exchange (ONNX) is an open ecosystem that empowers AI developers to choose the right tools as their project evolves. ONNX provides an open source format for AI models, both deep learning and traditional ML. It defines an extensible computation graph model, as well as definitions of built-in operators and standard data types. Currently we focus on the capabilities needed for inferencing (scoring).","links":[{"article_link":"","code_link":"https://github.com/onnx/onnx","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://onnx.ai/"}]},{"id":332,"title":"Numba","description":"NumPy aware dynamic Python compiler using LLVM. A Just-In-Time Compiler for Numerical Functions in Python.","tags":["code","library","numpy","numba"],"details":"Numba is an open source, NumPy-aware optimizing compiler for Python sponsored by Anaconda, Inc. It uses the LLVM compiler project to generate machine code from Python syntax.","links":[{"article_link":"","code_link":"https://github.com/numba/numba","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"http://numba.pydata.org/"}]},{"id":331,"title":"Modin: Speed up your Pandas workflows ","description":"Scale your pandas workflows by changing one line of code.","tags":["code","library","pandas","modin","efficient"],"details":"In pandas, you are only able to use one core at a time when you are doing computation of any kind. With Modin, you are able to use all of the CPU cores on your machine.","links":[{"article_link":"","code_link":"https://github.com/modin-project/modin","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"http://modin.readthedocs.io"}]},{"id":330,"title":"Breaking Linear Classifiers on ImageNet","description":"We say that we break, or fool ConvNets.","tags":["article","paper","research","tutorial","convolutional-neural-networks","adversarial-learning","adversarial-attacks","adversarial-examples","arxiv:1412.6572"],"details":"","links":[{"article_link":"http://karpathy.github.io/2015/03/30/breaking-convnets/","code_link":"","research_link":"https://arxiv.org/abs/1412.6572","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":329,"title":"How to Know When Machine Learning Does Not Now","description":"It is becoming increasingly important to understand how a prediction made by a Machine Learning model is informed by its training data. ","tags":["article","paper","research","tutorial","active-learning","anomaly-detection","interpretability","outlier-detection","semi-supervised-learning","adversarial-learning","uncertainty","adversarial-examples","arxiv:1803.04765"],"details":"This post will outline an approach we call Deep k-Nearest Neighbors [Papernot and McDaniel] that attempts to address this issue. We will also explore a loss function we recently introduced to shine some light on how models structure their internal representations [Frosst et al.]. We\u2019ll illustrate how the Deep k-Nearest Neighbors (DkNN) helps recognize data that is not from the training distribution by observing anomalies in the internal representation of such data.","links":[{"article_link":"http://www.cleverhans.io/security/2019/05/20/dknn.html","code_link":"","research_link":"https://arxiv.org/abs/1803.04765","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":328,"title":"ProteinGCN: Protein model quality assessment using GCNs","description":"Source code for the paper: ProteinGCN: Protein model quality assessment using Graph Convolutional Networks.","tags":["code","paper","research","tutorial","pytorch","deep-learning","graph-convolutional-networks","health","graph-neural-networks","graphs","protein-model-quality-estimation","protein"],"details":"Overview of ProteinGCN: Given a protein structure, it first generates a protein graph and uses GCN to learn the atom embeddings. Then, it pools the atom embeddings to generate residue-level embeddings. The residue embeddings are passed through a non-linear fully connected layer to predict the local scores. Further, the residue embeddings are pooled to generate a global protein embedding. Similar to residue embeddings, this is used to predict the global score.","links":[{"article_link":"","code_link":"https://github.com/malllabiisc/ProteinGCN","research_link":"https://www.biorxiv.org/content/10.1101/2020.04.06.028266v1.full.pdf","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":327,"title":"How to Steal Modern NLP Systems with Gibberish?","description":"It\u2019s possible to steal BERT-based models without any real training data, even using gibberish word sequences.","tags":["article","paper","research","tutorial","attention","bert","transformers","computer-security","natural-language-processing","adversarial-learning","adversarial-attacks","arxiv:1910.12366"],"details":"Fine-tuning models has emerged as one of the popular approaches to natural language processing (NLP). Rather than train models from random initialization, that is from scratch, models are repurposed: previous model parameters are loaded as initializations and training continues on data from a new distribution. The success of BERT is indicative of this trend. In this blog, we ask \u201cwhat are the security implications for NLP models trained in this way?\u201d In particular, we take a look at model extraction attacks where the adversary queries a model with the hope of stealing it.","links":[{"article_link":"http://www.cleverhans.io/2020/04/06/stealing-bert.html","code_link":"","research_link":"https://arxiv.org/abs/1910.12366","media_link":"https://twitter.com/kalpeshk2011/status/1247550470454984705","dataset_link":"","demo_link":"","other_link":""}]},{"id":326,"title":"CleverHans","description":"An adversarial example library for constructing attacks, building defenses, and benchmarking both.","tags":["article","code","library","adversarial-learning","adversarial-attacks","cleverhans"],"details":"This repository contains the source code for CleverHans, a Python library to benchmark machine learning systems' vulnerability to adversarial examples. You can learn more about such vulnerabilities on the accompanying blog.","links":[{"article_link":"http://www.cleverhans.io/","code_link":"https://github.com/tensorflow/cleverhans","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":325,"title":"Advbox Family","description":"Advbox Family is a series of AI model security tools set of Baidu Open Source,including the generation, detection and protection of adversarial examples.","tags":["code","onnx","paddlepaddle","pytorch","library","security","adversarial-learning","advbox","deepfool","fgsm","graphpipe"],"details":"Advbox is a toolbox to generate adversarial examples that fool neural networks in PaddlePaddle\u3001PyTorch\u3001Caffe2\u3001MxNet\u3001Keras\u3001TensorFlow and Advbox can benchmark the robustness of machine learning models. Advbox give a command line tool to generate adversarial examples with Zero-Coding.","links":[{"article_link":"","code_link":"https://github.com/advboxes/AdvBox","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":324,"title":"AdverTorch","description":"A Toolbox for Adversarial Robustness Research","tags":["code","library","security","adversarial-learning","adversarial-attacks","adversarial-perturbations"],"details":"advertorch text is a Python toolbox for adversarial robustness research. The primary functionalities are implemented in PyTorch. Specifically, AdverTorch contains modules for generating adversarial perturbations and defending against adversarial examples, also scripts for adversarial training.","links":[{"article_link":"","code_link":"https://github.com/BorealisAI/advertorch","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":323,"title":"Applied Deep Learning Bootcamp","description":"This Bootcamp contains materials for an end-to-end deep learning project based on image classification.","tags":["code","tutorial","gcp","data-pipelines","better-training","deplyoment","ai-platform"],"details":"* Show the practitioners how to go about research: Finding out the elements where it might be worth putting some research investments.\r\n* Improved data input pipelines\r\n* Better model training with learning rate annealing, mixed-precision policy, and so on. \r\n* Deployment on serverless AI-Platform and scaling it.","links":[{"article_link":"","code_link":"https://github.com/sayakpaul/ML-Bootcamp-Launchpad/","research_link":"","media_link":"http://bit.ly/mlb-sayak","dataset_link":"","demo_link":"","other_link":""}]},{"id":322,"title":"Harnessing Organizational Knowledge for Machine Learning","description":"A new weak supervision management system for this setting.","tags":["article","paper","research","library","labeling","rules","snorkel","snorkel-drybell","weka-supervision","arxiv:1812.00417"],"details":"Labeling training data is one of the most costly bottlenecks in developing machine learning-based applications. We present a first-of-its-kind study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude, and introduce Snorkel DryBell.","links":[{"article_link":"https://ai.googleblog.com/2019/03/harnessing-organizational-knowledge-for.html","code_link":"","research_link":"https://arxiv.org/abs/1812.00417","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":321,"title":"Snorkel","description":"A system for quickly generating training data with weak supervision.","tags":["article","code","library","data-augmentation","weak-supervision","rules","snorkel","snorkel-drybell"],"details":"* Labeling data, e.g., using heuristic rules or distant supervision techniques\r\n* Transforming data, e.g., rotating or stretching images to perform data augmentation\r\n* Slicing data into different critical subsets for monitoring or targeted improvement","links":[{"article_link":"https://www.snorkel.org/use-cases/","code_link":"https://github.com/snorkel-team/snorkel","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://snorkel.org"}]},{"id":320,"title":"Bokeh","description":"Bokeh is an interactive visualization library for modern web browsers.","tags":["code","library","visualization","bokeh"],"details":"Provides elegant, concise construction of versatile graphics, and affords high-performance interactivity over large or streaming datasets. Bokeh can help anyone who would like to quickly and easily make interactive plots, dashboards, and data applications.","links":[{"article_link":"","code_link":"https://github.com/bokeh/bokeh","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://bokeh.org"}]},{"id":319,"title":"LabelImg","description":"\ud83d\udd8d\ufe0f A graphical image annotation tool and label object bounding boxes in images.","tags":["code","video","library","annotation","computer-vision","image-classification","labeling","yolo"],"details":"A cross-platform GUI tool to annotate images and saved the file into PASCAL VOC and ImageNet format. ","links":[{"article_link":"","code_link":"https://github.com/tzutalin/labelImg","research_link":"","media_link":"https://www.youtube.com/watch?v=p0nR2YsCY_U","dataset_link":"","demo_link":"","other_link":""}]},{"id":318,"title":"Computer Vision Annotation Tool (CVAT)","description":"Free, online, interactive video and image annotation tool for computer vision.","tags":["code","library","annotation","computer-vision","labeling","segmentation","instance-segmentation","image-labeling","image-annotation","video-annotation"],"details":"CVAT is free, online, interactive video and image annotation tool for computer vision. It is being used by our team to annotate million of objects with different properties. Many UI and UX decisions are based on feedbacks from professional data annotation team.","links":[{"article_link":"","code_link":"https://github.com/opencv/cvat","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":317,"title":"COCO Annotator","description":"\u270f\ufe0f Web-based image segmentation tool for object detection, localization and key points.","tags":["code","library","action-localization","annotation","computer-vision","labeling","object-detection","segmentation","image-labeling","coco","annotated-images"],"details":"COCO Annotator is a web-based image annotation tool designed for versatility and efficiently label images to create training data for image localization and object detection. It provides many distinct features including the ability to label an image segment (or part of a segment), track object instances, labeling objects with disconnected visible parts, efficiently storing and export annotations in the well-known COCO format. The annotation process is delivered through an intuitive and customizable interface and provides many tools for creating accurate datasets.","links":[{"article_link":"","code_link":"https://github.com/jsbroks/coco-annotator","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":316,"title":"Clinical BERT","description":"Repository for Publicly Available Clinical BERT Embeddings","tags":["code","paper","research","attention","bert","transformers","health","library","medicine","embeddings","natural-language-processing","clinical-bert","arxiv:1904.05342"],"details":"You can now use ClinicalBERT directly through the transformers library. Check out the Bio+Clinical BERT and Bio+Discharge Summary BERT model pages for instructions on how to use the models within the Transformers library.","links":[{"article_link":"","code_link":"https://github.com/EmilyAlsentzer/clinicalBERT","research_link":"https://arxiv.org/abs/1904.05342","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":315,"title":"VoTT: Visual Object Tagging Tool","description":"An electron app for building end to end Object Detection Models from Images and Videos.","tags":["code","library","annotation","computer-vision","labeling","object-detection","cntk","video-tagging","image-annotation","tagging","image-tagging"],"details":"Features include:\r\n\u2022\u00a0The ability to label images or video frames\r\n\u2022\u00a0Extensible model for importing data from local or cloud storage providers\r\n\u2022\u00a0Extensible model for exporting labeled data to local or cloud storage providers","links":[{"article_link":"","code_link":"https://github.com/Microsoft/VoTT","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":314,"title":"The Autonomous Learning Library","description":"A PyTorch library for building deep reinforcement learning agents.","tags":["code","pytorch","deep-q-networks","library","reinforcement-learning","deep-reinforcement-learning","soft-actor-critic","proximal-policy-optimization","deep-q-learning","actor-critic","policy-gradients"],"details":"The autonomous-learning-library is an object-oriented deep reinforcement learning (DRL) library for PyTorch. The goal of the library is to provide the necessary components for quickly building and evaluating novel reinforcement learning agents, as well as providing high-quality reference implementations of modern DRL algorithms. The full documentation can be found at the following URL: https://autonomous-learning-library.readthedocs.io.","links":[{"article_link":"","code_link":"https://github.com/cpnota/autonomous-learning-library","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":313,"title":"NVIDIA Neural Modules: NeMo","description":"A toolkit for conversational AI.","tags":["article","code","deep-learning","library","natural-language-processing","speech","speech-recognition","conversational-ai"],"details":"NeMo toolkit makes it possible for researchers to easily compose complex neural network architectures for conversational AI using reusable components - Neural Modules. Neural Modules are conceptual blocks of neural networks that take typed inputs and produce typed outputs. Such modules typically represent data layers, encoders, decoders, language models, loss functions, or methods of combining activations.","links":[{"article_link":"https://medium.com/pytorch/nvidia-nemo-neural-modules-and-models-for-conversational-ai-d660480d9696","code_link":"https://github.com/NVIDIA/NeMo","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://nvidia.github.io/NeMo/"}]},{"id":311,"title":"Privacy Preserving Deep Learning with PyTorch & PySyft","description":"In this step-by-step tutorial series, you'll learn about all the ways PySyft can be used to bring Privacy and Decentralization to the Deep Learning ecosystem.","tags":["code","library","privacy","pysyft","openmined"],"details":"This tutorial series is continually updated with new features as they are implemented, and is designed for complete beginners.","links":[{"article_link":"","code_link":"https://github.com/OpenMined/PySyft/tree/master/examples/tutorials","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":310,"title":"PySyft","description":"A library for encrypted, privacy preserving machine learning.","tags":["code","paper","research","library","security","privacy","pysyft","openmined","differential-privacy","encryption","federated-deep-learning","decentralized-ai","arxiv:1811.04017"],"details":"PySyft is a Python library for secure and private Deep Learning. PySyft decouples private data from model training, using Federated Learning, Differential Privacy, and Encrypted Computation (like Multi-Party Computation (MPC) and Homomorphic Encryption (HE)) within the main Deep Learning frameworks like PyTorch and TensorFlow. ","links":[{"article_link":"","code_link":"https://github.com/OpenMined/PySyft","research_link":"https://arxiv.org/abs/1811.04017","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.openmined.org/"}]},{"id":309,"title":"Web Scraping For Machine Learning - With SQL Database","description":"Machine Learning requires data. But what about when the data you need is not available as a dataset? What then? Do you pay someone, or do it yourself?","tags":["article","code","tutorial","sql","full-stack","web-scraping"],"details":"In this article, we are going to web scrape Reddit \u2013 specifically, the /r/DataScience (and a little of /r/MachineLearning) subreddit. There will be no usage of the Reddit API, since we usually web scrape when an API is not available. Furthermore, you are going to learn to combine the knowledge of HTML, Python, Databases, SQL and datasets for Machine Learning. We are doing a small NLP sample project at last, but this is only to showcase that you can pickup the dataset and create a model providing predictions.","links":[{"article_link":"https://mlfromscratch.com/web-scraping-machine-learning/#/","code_link":"https://github.com/casperbh96/Web-Scraping-Reddit","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":308,"title":"TinyBERT","description":"TinyBERT is 7.5x smaller and 9.4x faster on inference than BERT-base and achieves competitive performances in the tasks of natural language understanding.","tags":["code","paper","research","tutorial","attention","bert","transformers","natural-language-processing","tinybert","distillation","arxiv:1909.10351"],"details":"In general distillation, we use the original BERT-base without fine-tuning as the teacher and a large-scale text corpus as the learning data. By performing the Transformer distillation on the text from general domain, we obtain a general TinyBERT which provides a good initialization for the task-specific distillation.","links":[{"article_link":"","code_link":"https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/TinyBERT","research_link":"https://arxiv.org/abs/1909.10351","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":307,"title":"GLUE Explained: Understanding BERT Through Benchmarks","description":"In this post we take a look at an important NLP benchmark used to evaluate BERT and other transfer learning models!","tags":["article","tutorial","attention","bert","transformers","natural-language-processing","transfer-learning","blue","benchmarks"],"details":"","links":[{"article_link":"http://mccormickml.com/2019/11/05/GLUE/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":306,"title":"BERT Research - Key Concepts & Sources","description":"Video series on BERT's key concepts and sources.","tags":["article","tutorial","video","attention","bert","transformers","natural-language-processing"],"details":"I think that the NLP community is currently missing an in-depth tutorial on the BERT model which does not require extensive background knowledge in LSTMs and Attention. More on this in the \u201cObjectives\u201d section.","links":[{"article_link":"http://mccormickml.com/2019/11/11/bert-research-ep-1-key-concepts-and-sources/","code_link":"","research_link":"","media_link":"https://www.youtube.com/playlist?list=PLam9sigHPGwOBuH4_4fr-XvDbe5uneaf6","dataset_link":"","demo_link":"","other_link":""}]},{"id":305,"title":"Question Answering with a Fine-Tuned BERT","description":"What does it mean for BERT to achieve \u201chuman-level performance on Question Answering\u201d?","tags":["article","code","notebook","tutorial","video","attention","bert","transformers","fine-tuning","natural-language-processing","question-answering","squad"],"details":"* In Part 1 of this post / notebook, I\u2019ll explain what it really means to apply BERT to QA, and illustrate the details.\r\n* Part 2 contains example code\u2013we\u2019ll be downloading a model that\u2019s already been fine-tuned for question answering, and try it out on our own text!","links":[{"article_link":"http://mccormickml.com/2020/03/10/question-answering-with-a-fine-tuned-BERT/","code_link":"https://colab.research.google.com/drive/1uSlWtJdZmLrI3FCNIlUHFxwAJiSu2J0-","research_link":"","media_link":"https://www.youtube.com/watch?v=l8ZYCvgGu0o","dataset_link":"","demo_link":"","other_link":""}]},{"id":304,"title":"An intuitive guide to Gaussian processes","description":"A maths-free explanation of an under appreciated algorithm.","tags":["article","tutorial","gaussian-processes"],"details":"\u2022\u00a0Recap on machine learning\r\n\u2022\u00a0How to deal with uncertainty\r\n\u2022\u00a0Bayesian inference in a nutshell\r\n\u2022\u00a0Gaussian processes","links":[{"article_link":"https://towardsdatascience.com/an-intuitive-guide-to-gaussian-processes-ec2f0b45c71d","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":303,"title":"Gaussian Processes for Dummies","description":"Gaussian Processes (GPs) are the natural next step in that journey as they provide an alternative approach to regression problems. ","tags":["article","tutorial","gaussian-processes"],"details":"This has been a very basic intro to Gaussian Processes \u2014 it aimed to keep things as simple as possible to illustrate the main idea and hopefully whet the appetite for a more extensive treatment of the topic such as can be found in the Rasmussen and Williams book.","links":[{"article_link":"https://katbailey.github.io/post/gaussian-processes-for-dummies/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":302,"title":"From both sides now: the math of linear regression","description":"Linear regression from both frequentist and Bayesian perspectives.","tags":["article","tutorial","linear-regression","regression","bayesian-inference","maximum-likelihood-estimation","gaussian-processes","bayesian-linear-regression","gaussian"],"details":"","links":[{"article_link":"https://katbailey.github.io/post/from-both-sides-now-the-math-of-linear-regression/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":301,"title":"A Visual Exploration of Gaussian Processes","description":"How to turn a collection of small building blocks into a versatile tool for solving regression problems.","tags":["article","tutorial","illustrated","kernels","gaussian-processes","distill-pub","posterior-distribution","prior-distribution","multivariate-gaussian-distributions"],"details":"We will first explore the mathematical foundation that Gaussian processes are built on\u2009\u2014\u2009we invite you to follow along using the interactive figures and hands-on examples. They help to explain the impact of individual components, and show the flexibility of Gaussian processes. After following this article we hope that you will have a visual intuition on how Gaussian processes work and how you can configure them for different types of data.","links":[{"article_link":"https://distill.pub/2019/visual-exploration-gaussian-processes/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":300,"title":"LightFM","description":"A Python implementation of LightFM, a hybrid recommendation algorithm.","tags":["code","library","recommendation-systems","matrix-factorization"],"details":"LightFM is a Python implementation of a number of popular recommendation algorithms for both implicit and explicit feedback, including efficient implementation of BPR and WARP ranking losses. It's easy to use, fast (via multithreaded model estimation), and produces high quality results.","links":[{"article_link":"","code_link":"https://github.com/lyst/lightfm","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":299,"title":"Build a Recommendation Engine With Collaborative Filtering","description":"Building a recommendation system in Python.","tags":["article","tutorial","python","scikit-learn","recommendation-systems"],"details":"\u2022\u00a0Collaborative filtering and it types\r\n\u2022\u00a0Data needed to build a recommender\r\n\u2022\u00a0Libraries available in Python to build recommenders\r\n\u2022\u00a0Use cases and challenges of collaborative filtering","links":[{"article_link":"https://realpython.com/build-recommendation-engine-collaborative-filtering/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":298,"title":"Introduction to Recommender Systems in 2019","description":"An introduction to building a recommendation system.","tags":["article","tutorial","collaborative-filtering","recommendation-systems","content-based","hybrid-approach"],"details":"In this blog post, you\u2019ll learn the broad types of popular recommender systems, how they work, and how they are used by companies in the industry.","links":[{"article_link":"https://tryolabs.com/blog/introduction-to-recommender-systems/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":297,"title":"Introduction to recommender systems","description":"Overview of some major recommendation algorithms.","tags":["article","tutorial","collaborative-filtering","recommendation-systems","matrix-factorization","content-based","user-user","item-item","bayesian-classifier"],"details":"In this article, we will go through different paradigms of recommender systems. For each of them, we will present how they work, describe their theoretical basis and discuss their strengths and weaknesses.","links":[{"article_link":"https://towardsdatascience.com/introduction-to-recommender-systems-6c66cf15ada","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":295,"title":"DGL: Deep Graph Library","description":"Python package built to ease deep learning on graph, on top of existing DL frameworks. ","tags":["code","paper","research","graph-convolutional-networks","library","graph-neural-networks","graphs","deep-graph-library","dgl","arxiv:2003.00982"],"details":"DGL is an easy-to-use, high performance and scalable Python package for deep learning on graphs. DGL is framework agnostic, meaning if a deep graph model is a component of an end-to-end application, the rest of the logics can be implemented in any major frameworks, such as PyTorch, Apache MXNet or TensorFlow.","links":[{"article_link":"","code_link":"https://github.com/dmlc/dgl","research_link":"https://arxiv.org/abs/2003.00982","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.dgl.ai/"}]},{"id":294,"title":"PyTorch Geometric ","description":"Geometric deep learning extension library for PyTorch.","tags":["code","paper","research","pytorch","graph-convolutional-networks","library","graph-neural-networks","graphs","geometric","pytorch-geometric","arxiv:1903.02428"],"details":"PyTorch Geometric makes implementing Graph Neural Networks a breeze . It consists of various methods for deep learning on graphs and other irregular structures, also known as geometric deep learning, from a variety of published papers. In addition, it consists of an easy-to-use mini-batch loader for many small and single giant graphs, multi gpu-support, a large number of common benchmark datasets (based on simple interfaces to create your own), and helpful transforms, both for learning on arbitrary graphs as well as on 3D meshes or point clouds.\r\n\r\n","links":[{"article_link":"","code_link":"https://github.com/rusty1s/pytorch_geometric","research_link":"https://arxiv.org/abs/1903.02428","media_link":"","dataset_link":"","demo_link":"","other_link":"https://pytorch-geometric.readthedocs.io/en/latest/"}]},{"id":293,"title":"PyTorch - GAN","description":"PyTorch implementations of Generative Adversarial Networks.","tags":["code","tutorial","pytorch","generative-adversarial-networks","library","cyclegan","pix2pix","wasserstein-gan","began","infogan","dragan","stargan","dualgan","adversarial-autoencoders"],"details":"Collection of PyTorch implementations of Generative Adversarial Network varieties presented in research papers. Model architectures will not always mirror the ones proposed in the papers, but I have chosen to focus on getting the core ideas covered instead of getting every layer configuration right. Contributions and suggestions of GANs to implement are very welcomed.","links":[{"article_link":"","code_link":"https://github.com/eriklindernoren/PyTorch-GAN","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://github.com/eriklindernoren/Keras-GAN"}]},{"id":292,"title":"BLiTZ \u2014 A Bayesian Neural Network library for PyTorch","description":"Bayesian Layers in Torch Zoo is a simple and extensible library to create Bayesian Neural Network layers on the top of PyTorch.","tags":["article","code","paper","research","tutorial","pytorch","bayesian-deep-learning","library","blitz","bayesian-neural-networks","bayesian-regression","arxiv:1505.05424"],"details":"Documentation for our layers, weight (and prior distribution) sampler and utils:\r\n\u2022\u00a0Bayesian Layers\r\n\u2022\u00a0Weight and prior distribution samplers\r\n\u2022\u00a0Utils (for easy integration with PyTorch)\r\n\u2022\u00a0Losses","links":[{"article_link":"https://towardsdatascience.com/blitz-a-bayesian-neural-network-library-for-pytorch-82f9998916c7","code_link":"https://github.com/piEsposito/blitz-bayesian-deep-learning","research_link":"https://arxiv.org/abs/1505.05424","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":291,"title":"Kornia: Differentiable Computer Vision Library for PyTorch","description":"Set of routines and differentiable modules to solve generic computer vision problems. ","tags":["code","pytorch","library","computer-vision","data-augmentation","edge-detection","image-filtering","color-space-conversions","kornia"],"details":"Inspired by OpenCV, this library is composed by a subset of packages containing operators that can be inserted within neural networks to train models to perform image transformations, epipolar geometry, depth estimation, and low-level image processing such as filtering and edge detection that operate directly on tensors.","links":[{"article_link":"","code_link":"https://github.com/kornia/kornia","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://kornia.github.io/"}]},{"id":290,"title":"GANSpace: Discovering Interpretable GAN Controls","description":"This paper describes a simple technique to analyze Generative Adversarial Networks (GANs) and create interpretable controls for image synthesis.","tags":["code","paper","research","tutorial","video","generative-adversarial-networks","computer-vision","dimensionality-reduction","image-generation","interpretability","image-synthesis","interpretable-gans","ganspace","biggan","stylegan","latent-space","activation-space","principal-component-analysis","arxiv:2004.02546"],"details":"We identify important latent directions based on Principal Components Analysis (PCA) applied in activation space. Then, we show that interpretable edits can be defined based on layer-wise application of these edit directions. Moreover, we show that BigGAN can be controlled with layer-wise inputs in a StyleGAN-like manner. A user may identify a large number of interpretable controls with these mechanisms. We demonstrate results on GANs from various datasets.","links":[{"article_link":"","code_link":"https://github.com/harskish/ganspace","research_link":"https://arxiv.org/abs/2004.02546","media_link":"https://www.youtube.com/watch?v=jdTICDa_eAI","dataset_link":"","demo_link":"","other_link":""}]},{"id":289,"title":"How to Explain the Prediction of a Machine Learning Model?","description":"Model interpretability, covering two aspects: (i) interpretable models w/ model-specific interpretation methods & (ii) approaches of explaining black-box models","tags":["article","tutorial","interpretability","lime","beta"],"details":"* Interpretable Models\r\n* Interpreting Black-Box Models\r\n* Explainable Artificial Intelligence","links":[{"article_link":"https://lilianweng.github.io/lil-log/2017/08/01/how-to-explain-the-prediction-of-a-machine-learning-model.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":288,"title":"From GAN to WGAN","description":"This post explains the maths behind a GAN model and why it is hard to be trained. ","tags":["article","code","tutorial","generative-adversarial-networks","wasserstein-gan","wgan","kl-divergence"],"details":"Wasserstein GAN is intended to improve GANs\u2019 training by adopting a smooth metric for measuring the distance between two probability distributions.","links":[{"article_link":"https://lilianweng.github.io/lil-log/2017/08/20/from-GAN-to-WGAN.html","code_link":"https://github.com/lilianweng/unified-gan-tensorflow","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":287,"title":"Learning Word Embedding","description":"This post introduces several models for learning word embedding and how their loss functions are designed for the purpose.","tags":["article","tutorial","embeddings","natural-language-processing","word-embeddings"],"details":"Word embedding is a dense representation of words in the form of numeric vectors. It can be learned using a variety of language models. The word embedding representation is able to reveal many hidden relationships between words. For example, vector(\u201ccat\u201d) - vector(\u201ckitten\u201d) is similar to vector(\u201cdog\u201d) - vector(\u201cpuppy\u201d). ","links":[{"article_link":"https://lilianweng.github.io/lil-log/2017/10/15/learning-word-embedding.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":286,"title":"Object Detection for Dummies","description":"We will go through several basic concepts, algorithms, and popular deep learning models for image processing and object detection.","tags":["article","tutorial","convolutional-neural-networks","computer-vision","object-detection","yolo","image-processing","alexnet","vgg","resnet","r-cnn","mask-r-cnn"],"details":"* Gradient Vector, HOG, and SS: https://lilianweng.github.io/lil-log/2017/10/29/object-recognition-for-dummies-part-1.html\r\n* CNN, DPM and Overfeat: https://lilianweng.github.io/lil-log/2017/12/15/object-recognition-for-dummies-part-2.html\r\n* R-CNN Family: https://lilianweng.github.io/lil-log/2017/12/31/object-recognition-for-dummies-part-3.html\r\n* Fast Detection Models: https://lilianweng.github.io/lil-log/2018/12/27/object-detection-part-4.html","links":[{"article_link":"https://lilianweng.github.io/lil-log/2017/10/29/object-recognition-for-dummies-part-1.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":285,"title":"A (Long) Peek into Reinforcement Learning","description":"In this post, we are gonna briefly go over the field of Reinforcement Learning (RL), from fundamental concepts to classic algorithms.","tags":["article","tutorial","policy-gradient-methods","q-learning","reinforcement-learning","evolution-strategies","monte-carlo","dynamic-programming","alphago-zero"],"details":"It is pretty hard not to be curious about the magic behind these algorithms \u2014 Reinforcement Learning (RL). I\u2019m writing this post to briefly go over the field. We will first introduce several fundamental concepts and then dive into classic approaches to solving RL problems. Hopefully, this post could be a good starting point for newbies, bridging the future study on the cutting-edge research.","links":[{"article_link":"https://lilianweng.github.io/lil-log/2018/02/19/a-long-peek-into-reinforcement-learning.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":284,"title":"Policy Gradient Algorithms","description":"In this post, we are going to look deep into policy gradient, why it works, and many new policy gradient algorithms proposed in recent years.","tags":["article","tutorial","policy-gradient-methods","reinforcement-learning"],"details":"In this post, we are going to look deep into policy gradient, why it works, and many new policy gradient algorithms proposed in recent years: vanilla policy gradient, actor-critic, off-policy actor-critic, A3C, A2C, DPG, DDPG, D4PG, MADDPG, TRPO, PPO, ACER, ACTKR, SAC, TD3 & SVPG.","links":[{"article_link":"https://lilianweng.github.io/lil-log/2018/04/08/policy-gradient-algorithms.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":283,"title":"From Autoencoder to Beta-VAE","description":"This post reviews several variations, including denoising, sparse, and contractive autoencoders, and VAE and its modification beta-VAE.","tags":["article","tutorial","autoencoders","variational-autoencoders","beta-vae"],"details":"Autocoders are a family of neural network models aiming to learn compressed latent variables of high-dimensional data. Starting from the basic autocoder model, this post reviews several variations, including denoising, sparse, and contractive autoencoders, and then Variational Autoencoder (VAE) and its modification beta-VAE.","links":[{"article_link":"https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":282,"title":"Meta-Learning: Learning to Learn Fast","description":"An overview of meta learning.","tags":["article","tutorial","meta-learning"],"details":"Meta-learning, also known as \u201clearning to learn\u201d, intends to design models that can learn new skills or adapt to new environments rapidly with a few training examples. There are three common approaches: 1) learn an efficient distance metric (metric-based); 2) use (recurrent) network with external or internal memory (model-based); 3) optimize the model parameters explicitly for fast learning (optimization-based).","links":[{"article_link":"https://lilianweng.github.io/lil-log/2018/11/30/meta-learning.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":281,"title":"Generalized Language Models","description":"Trend in large unsupervised pre-trained language models which have achieved amazing SOTA results on a variety of language tasks.","tags":["article","tutorial","attention","bert","gpt2","transformers","language-modeling","natural-language-processing","ulmfit","albert","elmo","perplexity","conversational-ai"],"details":"As a follow up of word embedding post, we will discuss the models on learning contextualized word vectors, as well as the new trend in large unsupervised pre-trained language models which have achieved amazing SOTA results on a variety of language tasks.","links":[{"article_link":"https://lilianweng.github.io/lil-log/2019/01/31/generalized-language-models.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":280,"title":"Meta Reinforcement Learning","description":"Explore cases when we try to \u201cmeta-learn\u201d Reinforcement Learning (RL) tasks by developing an agent that can solve unseen tasks fast and efficiently.","tags":["article","tutorial","meta-learning","reinforcement-learning"],"details":"Meta-RL is meta-learning on reinforcement learning tasks. After trained over a distribution of tasks, the agent is able to solve a new task by developing a new RL algorithm with its internal activity dynamics. This post starts with the origin of meta-RL and then dives into three key components of meta-RL.","links":[{"article_link":"https://lilianweng.github.io/lil-log/2019/06/23/meta-reinforcement-learning.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":279,"title":"Evolution Strategies","description":"Evolutionary algorithms refer to a division of population-based optimization algorithms inspired by natural selection. ","tags":["article","tutorial","reinforcement-learning","evolution","evolution-strategies"],"details":"Gradient descent is not the only option when learning optimal model parameters. Evolution Strategies (ES) works out well in the cases where we don\u2019t know the precise analytic form of an objective function or cannot compute the gradients directly. This post dives into several classic ES methods, as well as how ES can be used in deep reinforcement learning.","links":[{"article_link":"https://lilianweng.github.io/lil-log/2019/09/05/evolution-strategies.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":278,"title":"Self-Supervised Representation Learning","description":"What if we can get labels for free for unlabelled data and train unsupervised dataset in a supervised manner? ","tags":["article","tutorial","generative-adversarial-networks","computer-vision","object-recognition","representation-learning","self-supervised-learning","generative-modeling"],"details":"Self-supervised learning opens up a huge opportunity for better utilizing unlabelled data, while learning in a supervised learning manner. This post covers many interesting ideas of self-supervised learning tasks on images, videos, and control problems.\r\n\r\nWhat if we can get labels for free for unlabelled data and train unsupervised dataset in a supervised manner? We can achieve this by framing a supervised learning task in a special form to predict only a subset of information using the rest. In this way, all the information needed, both inputs and labels, has been provided. This is known as self-supervised learning.","links":[{"article_link":"https://lilianweng.github.io/lil-log/2019/11/10/self-supervised-learning.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":277,"title":"Curriculum for Reinforcement Learning","description":"Curriculum learning applied to reinforcement learning, with a few exceptions of supervised learning.","tags":["article","tutorial","meta-learning","reinforcement-learning","generative-models"],"details":"A curriculum is an efficient tool for humans to progressively learn from simple concepts to hard problems. It breaks down complex knowledge by providing a sequence of learning steps of increasing difficulty. In this post, we will examine how the idea of curriculum can help reinforcement learning models learn to solve complicated tasks.","links":[{"article_link":"https://lilianweng.github.io/lil-log/2020/01/29/curriculum-for-reinforcement-learning.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":276,"title":"CycleGAN","description":"Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks.","tags":["article","code","paper","research","tutorial","video","generative-adversarial-networks","cyclegan","pix2pix","arxiv:1703.10593"],"details":"Image-to-image translation is a class of vision and graphics problems where the goal is to learn the mapping between an input image and an output image using a training set of aligned image pairs. However, for many tasks, paired training data will not be available. We present an approach for learning to translate an image from a source domain X to a target domain Y in the absence of paired examples. Our goal is to learn a mapping G:X\u2192Y such that the distribution of images from G(X) is indistinguishable from the distribution Y using an adversarial loss. ","links":[{"article_link":"https://junyanz.github.io/CycleGAN/","code_link":"https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix","research_link":"https://arxiv.org/abs/1703.10593","media_link":"https://www.youtube.com/watch?v=AxrKVfjSBiA","dataset_link":"","demo_link":"","other_link":""}]},{"id":275,"title":"Understanding Variational Autoencoders (VAEs)","description":"Building, step by step, the reasoning that leads to VAEs.","tags":["article","tutorial","autoencoders","variational-autoencoders"],"details":"In the first section, we will review some important notions about dimensionality reduction and autoencoder that will be useful for the understanding of VAEs. Then, in the second section, we will show why autoencoders cannot be used to generate new data and will introduce Variational Autoencoders that are regularised versions of autoencoders making the generative process possible. Finally in the last section we will give a more mathematical presentation of VAEs, based on variational inference.","links":[{"article_link":"https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":274,"title":"Understanding Generative Adversarial Networks (GANs)","description":"Building, step by step, the reasoning that leads to GANs.","tags":["article","tutorial","video","generative-adversarial-networks"],"details":"In the first following section we will discuss the process of generating random variables from a given distribution. Then, in section 2 we will show, through an example, that the problems GANs try to tackle can be expressed as random variable generation problems. In section 3 we will discuss matching based generative networks and show how they answer problems described in section 2. Finally in section 4 we will introduce GANs. More especially, we will present the general architecture with its loss function and we will make the link with all the previous parts.","links":[{"article_link":"https://towardsdatascience.com/understanding-generative-adversarial-networks-gans-cd6e4651a29","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=6v7lJHFaZZ4","dataset_link":"","demo_link":"","other_link":""}]},{"id":273,"title":"Transformers - Hugging Face","description":"\ud83e\udd17 Transformers: State-of-the-art Natural Language Processing for TensorFlow 2.0 and PyTorch. ","tags":["code","huggingface","pytorch","tensorflow","attention","bert","gpt","gpt2","transformers","xlnet","library","information-retrieval","language-modeling","named-entity-recognition","natural-language-processing","question-answering","reading-comprehension","text-classification","text-summarization","albert","roberta","t5","electra","distilbert","bart","conversational-ai"],"details":"\ud83e\udd17 Transformers (formerly known as pytorch-transformers and pytorch-pretrained-bert) provides state-of-the-art general-purpose architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNet, CTRL...) for Natural Language Understanding (NLU) and Natural Language Generation (NLG) with over 32+ pretrained models in 100+ languages and deep interoperability between TensorFlow 2.0 and PyTorch.","links":[{"article_link":"","code_link":"https://github.com/huggingface/transformers","research_link":"","media_link":"https://huggingface.co/transformers/examples.html","dataset_link":"","demo_link":"","other_link":"https://huggingface.co/transformers"}]},{"id":272,"title":"The Annotated GPT-2","description":"GPT-2 explained with visualization and PyTorch code.","tags":["article","tutorial","huggingface","pytorch","attention","gpt2","transformers","natural-language-processing","annotated"],"details":"The GPT-2 might seem like magic at first with all it\u2019s glitter and beauty too, but hopefully I would have uncovered that magic for you and revealed all the tricks by the time you finish reading this post. That is my goal. To make it as simple as possible for the keen to understand how the GPT-2 model works underneath.","links":[{"article_link":"https://amaarora.github.io/2020/02/18/annotatedGPT2.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":271,"title":"The Annotated Transformer","description":"In this post I present an \u201cannotated\u201d version of the paper in the form of a line-by-line implementation. ","tags":["article","code","tutorial","attention","transformers","natural-language-processing","annotated"],"details":" This document itself is a working notebook, and should be a completely usable implementation. In total there are 400 lines of library code which can process 27,000 tokens per second on 4 GPUs.","links":[{"article_link":"https://nlp.seas.harvard.edu/2018/04/03/attention.html","code_link":"https://github.com/harvardnlp/annotated-transformer","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":270,"title":"Attention? Attention!","description":"In this post, we are gonna look into how attention was invented, and various attention mechanisms and models, such as transformer and SNAIL.","tags":["article","tutorial","tensorflow","attention","recurrent-neural-networks","self-attention","transformers","natural-language-processing","pointer-network"],"details":"Attention has been a fairly popular concept and a useful tool in the deep learning community in recent years. In this post, we are gonna look into how attention was invented, and various attention mechanisms and models, such as transformer and SNAIL.","links":[{"article_link":"https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":269,"title":"Attention Mechanism","description":"Main concepts behind Attention, including an implementation of a sequence-to-sequence Attention model, followed by the application of Attention in Transformers.","tags":["article","tutorial","attention","self-attention","transformers","natural-language-processing"],"details":"In broad terms, Attention is one component of a network\u2019s architecture, and is in charge of managing and quantifying the interdependence:\r\n* Between the input and output elements (General Attention)\r\n\u2022\u00a0Within the input elements (Self-Attention)","links":[{"article_link":"https://blog.floydhub.com/attention-mechanism/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":268,"title":"A Gentle Introduction to Text Summarization in Machine Learning","description":"Text summarization is the technique for generating a concise and precise summary of voluminous texts while focusing on the sections that convey useful info.","tags":["article","tutorial","natural-language-processing","text-summarization"],"details":"","links":[{"article_link":"https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":267,"title":"Attention and Augmented Recurrent Neural Networks","description":"Visualized attention and other augmentations with RNNs.","tags":["article","tutorial","attention","neural-turing-machines","adaptive-computation-time","neural-programmers"],"details":"\u2022\u00a0Attention\r\n\u2022\u00a0Neural turing machines\r\n\u2022\u00a0Adaptive computation time\r\n\u2022\u00a0Neural programmers\r\n","links":[{"article_link":"https://distill.pub/2016/augmented-rnns/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":266,"title":"Understanding LSTM Networks","description":"A closer look at the inner workings of LSTM networks.","tags":["article","tutorial","lstm","recurrent-neural-networks"],"details":"","links":[{"article_link":"https://colah.github.io/posts/2015-08-Understanding-LSTMs/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":265,"title":"Lecture 10 | Recurrent Neural Networks","description":"Discuss the use of recurrent neural networks for modeling sequence data.","tags":["tutorial","video","attention","gated-recurrent-units","lstm","recurrent-neural-networks","computer-vision","image-captioning","language-modeling","natural-language-processing","cs231n","stanford"],"details":"In Lecture 10 we discuss the use of recurrent neural networks for modeling sequence data. We show how recurrent neural networks can be used for language modeling and image captioning, and how soft spatial attention can be incorporated into image captioning models. We discuss different architectures for recurrent neural networks, including Long Short Term Memory (LSTM) and Gated Recurrent Units (GRU).","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=6niqTuYFZLQ","dataset_link":"","demo_link":"","other_link":"http://cs231n.stanford.edu/"}]},{"id":264,"title":"The Unreasonable Effectiveness of Recurrent Neural Networks","description":"A close look at how RNNs are able to perform so well.","tags":["article","code","tutorial","recurrent-neural-networks","character-embeddings","embeddings","natural-language-processing","char-rnn"],"details":"I\u2019m training RNNs all the time and I\u2019ve witnessed their power and robustness many times, and yet their magical outputs still find ways of amusing me. This post is about sharing some of that magic with you.","links":[{"article_link":"http://karpathy.github.io/2015/05/21/rnn-effectiveness/","code_link":"https://github.com/karpathy/char-rnn","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":263,"title":"A Visual and Interactive Guide to the Basics of Neural Networks","description":"A visual look at the basics on NNs.","tags":["article","tutorial","neural-networks","illustrated","multilayer-perceptrons"],"details":"Part 1: http://jalammar.github.io/visual-interactive-guide-basics-neural-networks/\r\nPart 2: https://jalammar.github.io/feedforward-neural-networks-visual-interactive/","links":[{"article_link":"http://jalammar.github.io/visual-interactive-guide-basics-neural-networks/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"A Visual And Interactive Look at Basic Neural Network Math"}]},{"id":262,"title":"Visualizing A Neural Machine Translation Model","description":"Mechanics of seq2seq models with attention.","tags":["article","tutorial","attention","sequence-to-sequence","machine-translation","natural-language-processing","illustrated"],"details":"","links":[{"article_link":"http://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":261,"title":"The Illustrated Transformer","description":"In this post, we will look at The Transformer \u2013 a model that uses attention to boost the speed with which these models can be trained.","tags":["article","tutorial","attention","self-attention","transformers","natural-language-processing","decoder","illustrated","masking","positional-encoding","encoder"],"details":"In this post, we will look at The Transformer \u2013 a model that uses attention to boost the speed with which these models can be trained.","links":[{"article_link":"http://jalammar.github.io/illustrated-transformer/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":260,"title":"The Illustrated BERT, ELMo, and co.","description":"How NLP cracked transfer learning.","tags":["article","tutorial","attention","bert","transformers","embeddings","fine-tuning","language-modeling","natural-language-processing","text-classification","transfer-learning","decoder","elmo","masking"],"details":"Visually explaining BERT, ELMo, and the OpenAI transformer. These have been some of the leading NLP models to come out in 2018. They push the envelope of how transfer learning is applied in NLP.","links":[{"article_link":"http://jalammar.github.io/illustrated-bert/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":259,"title":"The Illustrated Word2vec","description":"In this post, we\u2019ll go over the concept of embedding, and the mechanics of generating embeddings with word2vec. ","tags":["article","tutorial","video","embeddings","natural-language-processing","word-embeddings","illustrated","word2vec"],"details":"In this post, we\u2019ll go over the concept of embedding, and the mechanics of generating embeddings with word2vec. But let\u2019s start with an example to get familiar with using vectors to represent things. Did you know that a list of five numbers (a vector) can represent so much about your personality?","links":[{"article_link":"http://jalammar.github.io/illustrated-word2vec/","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=4-QoMdSqG_I","dataset_link":"","demo_link":"","other_link":""}]},{"id":258,"title":"A Visual Intro to NumPy and Data Representation","description":"Ways to use NumPy and how it can represent different types of data (tables, images, text\u2026etc).","tags":["article","tutorial","numpy","illustrated"],"details":"In this post, we\u2019ll look at some of the main ways to use NumPy and how it can represent different types of data (tables, images, text\u2026etc) before we can serve them to machine learning models.","links":[{"article_link":"http://jalammar.github.io/visual-numpy/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":257,"title":"The Illustrated GPT-2 (Visualizing Transformer Language Models)","description":"Visuals explaining the inner-workings of transformers.","tags":["article","tutorial","gpt2","transformers","language-modeling","natural-language-processing","illustrated"],"details":"My goal here is to also supplement my earlier post, The Illustrated Transformer, with more visuals explaining the inner-workings of transformers, and how they\u2019ve evolved since the original paper. My hope is that this visual language will hopefully make it easier to explain later Transformer-based models as their inner-workings continue to evolve.","links":[{"article_link":"https://jalammar.github.io/illustrated-gpt2/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":256,"title":"A Visual Guide to Using BERT for the First Time","description":"Tutorial for how to use a variant of BERT to classify sentences.","tags":["article","code","notebook","tutorial","attention","bert","transformers","natural-language-processing","sentiment-analysis","text-classification","illustrated"],"details":"This post is a simple tutorial for how to use a variant of BERT to classify sentences. This is an example that is basic enough as a first intro, yet advanced enough to showcase some of the key concepts involved.","links":[{"article_link":"http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/","code_link":"https://github.com/jalammar/jalammar.github.io/blob/master/notebooks/bert/A_Visual_Notebook_to_Using_BERT_for_the_First_Time.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":255,"title":"NLP for Developers: Transformers | Rasa","description":"In this video, Rasa Developer Advocate Rachael will talk about what transformers are, how they work, when they're used and some  common errors. ","tags":["tutorial","video","attention","transformers","natural-language-processing","rasa"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=KN3ZL65Dze0","dataset_link":"","demo_link":"","other_link":""}]},{"id":254,"title":"NLP for Developers: Word Embeddings | Rasa","description":"In this video, Rasa Developer Advocate Rachael will talk about what word embeddings are, how they work, when they're used and some  common errors. ","tags":["tutorial","video","character-embeddings","embeddings","natural-language-processing","word-embeddings","rasa"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=oUpuABKoElw","dataset_link":"","demo_link":"","other_link":""}]},{"id":253,"title":"On Word Embeddings","description":"This post presents the most well-known models for learning word embeddings based on language modeling.","tags":["article","tutorial","embeddings","language-modeling","natural-language-processing","word-embeddings"],"details":"On word embeddings - Part 1: https://ruder.io/word-embeddings-1/\r\nOn word embeddings - Approximating the Softmax:  https://ruder.io/word-embeddings-softmax/index.html","links":[{"article_link":"https://ruder.io/word-embeddings-1/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://ruder.io/word-embeddings-softmax/index.html"}]},{"id":252,"title":"Word Embeddings","description":"This tutorial introduces word embeddings. It contains complete code to train word embeddings from scratch on a small dataset.","tags":["article","tutorial","tensorflow","embeddings","natural-language-processing","word-embeddings"],"details":"","links":[{"article_link":"https://www.tensorflow.org/tutorials/text/word_embeddings","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":251,"title":"BRAT: Rapid Annotation Tool","description":"BRAT (brat rapid annotation tool) is based on the stav visualiser which was originally made in order to visualise BioNLP'11 Shared Task data.","tags":["code","health","library","annotation","labeling","named-entity-recognition","natural-language-processing","dependency-graphing"],"details":"\u2022\u00a0De-centralisation of configurations and data, causing synchronisation issues\r\n\u2022\u00a0Annotations and related text not being visually adjacent\r\n\u2022\u00a0Complexity of set-up for annotators","links":[{"article_link":"","code_link":"https://github.com/nlplab/brat","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"http://brat.nlplab.org/"}]},{"id":250,"title":"Doccano","description":"Open source text annotation tool for machine learning practitioner. ","tags":["code","library","annotation","labeling","natural-language-processing","open-source","free","text-annotation","doccano"],"details":"doccano is an open source text annotation tool for humans. It provides annotation features for text classification, sequence labeling and sequence to sequence tasks. So, you can create labeled data for sentiment analysis, named entity recognition, text summarization and so on. Just create a project, upload data and start annotating. You can build a dataset in hours.\r\n\r\nFeatures\r\n\u2022\u00a0Collaborative annotation\r\n\u2022\u00a0Multi-language support\r\n\u2022\u00a0Mobile support\r\n\u2022\u00a0Emoji \ud83d\ude04 support\r\n\u2022\u00a0Dark theme\r\n\u2022\u00a0RESTful API","links":[{"article_link":"","code_link":"https://github.com/doccano/doccano","research_link":"","media_link":"http://doccano.herokuapp.com/demo/named-entity-recognition/","dataset_link":"","demo_link":"","other_link":"https://doccano.herokuapp.com/"}]},{"id":249,"title":"makesense.ai","description":"Free to use online tool for labelling photos.","tags":["code","library","annotation","computer-vision","labeling","make-sense","image-labeling","bounding-boxes","open-source","free"],"details":"makesense.ai is a free to use online tool for labelling photos. Thanks to the use of a browser it does not require any complicated installation - just visit the website and you are ready to go. It also doesn't matter which operating system you're running on - we do our best to be truly cross-platform. It is perfect for small computer vision deeplearning projects, making the process of preparing a dataset much easier and faster. Prepared labels can be downloaded in one of multiple supported formats. The application was written in TypeScript and is based on React/Redux duo.","links":[{"article_link":"","code_link":"https://github.com/SkalskiP/make-sense","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.makesense.ai/"}]},{"id":248,"title":"Optuna: A hyperparameter optimization framework","description":"A lightweight, parallel distributed hyperparameter optimization framework.","tags":["article","code","chainer","keras","mxnet","pytorch","scikit-learn","tensorflow","library","xgboost","hyperparameter-optimization","hyperparamtere-tuning"],"details":"Optuna is an automatic hyperparameter optimization software framework, particularly designed for machine learning. It features an imperative, define-by-run style user API. Thanks to our define-by-run API, the code written with Optuna enjoys high modularity, and the user of Optuna can dynamically construct the search spaces for the hyperparameters.","links":[{"article_link":"https://optuna.readthedocs.io/en/stable/tutorial/index.html","code_link":"https://github.com/optuna/optuna","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://optuna.org/"}]},{"id":247,"title":"Hyperopt: Distributed Hyperparameter Optimization","description":"Distributed Asynchronous Hyperparameter Optimization in Python.","tags":["code","library","hyperparameter-tuning","hyperparameter-optimization"],"details":"Hyperopt is a Python library for serial and parallel optimization over awkward search spaces, which may include real-valued, discrete, and conditional dimensions.","links":[{"article_link":"","code_link":"https://github.com/hyperopt/hyperopt","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"http://hyperopt.github.io/hyperopt/"}]},{"id":246,"title":"Keras Tuner","description":"A hyperparameter tuner for Keras, specifically for tf.keras with TensorFlow 2.0.","tags":["article","code","keras","tensorflow","library","keras-tuner","hyperparameter-optimization","hyperparameter-tuner"],"details":"Keras Tuner is an easy-to-use, distributable hyperparameter optimization framework that solves the pain points of performing a hyperparameter search. Keras Tuner makes it easy to define a search space and leverage included algorithms to find the best hyperparameter values. Keras Tuner comes with Bayesian Optimization, Hyperband, and Random Search algorithms built-in, and is also designed to be easy for researchers to extend in order to experiment with new search algorithms.","links":[{"article_link":"https://blog.tensorflow.org/2020/01/hyperparameter-tuning-with-keras-tuner.html","code_link":"https://github.com/keras-team/keras-tuner","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://keras-team.github.io/keras-tuner/"}]},{"id":245,"title":"Interpretable Machine Learning","description":"A guide for making black box models explainable.","tags":["article","tutorial","interpretability","lime","shap","explainability","shapely","black-box"],"details":"After exploring the concepts of interpretability, you will learn about simple, interpretable models such as decision trees, decision rules and linear regression. Later chapters focus on general model-agnostic methods for interpreting black box models like feature importance and accumulated local effects and explaining individual predictions with Shapley values and LIME.","links":[{"article_link":"https://christophm.github.io/interpretable-ml-book/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":244,"title":"SHAP: SHapley Additive exPlanations","description":"A game theoretic approach to explain the output of any machine learning model.","tags":["code","library","interpretability","gradient-boosting","shap","explainability","shapely"],"details":"SHAP (SHapley Additive exPlanations) is a game theoretic approach to explain the output of any machine learning model. It connects optimal credit allocation with local explanations using the classic Shapley values from game theory and their related extensions (see papers for details and citations).","links":[{"article_link":"","code_link":"https://github.com/slundberg/shap","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":243,"title":"Lime: Local Interpretable Model-Agnostic Explanations","description":"Explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction.","tags":["code","paper","research","video","library","interpretability","lime","arxiv:1602.04938"],"details":"This project is about explaining what machine learning classifiers (or models) are doing. At the moment, we support explaining individual predictions for text classifiers or classifiers that act on tables (numpy arrays of numerical or categorical data) or images, with a package called lime (short for local interpretable model-agnostic explanations). ","links":[{"article_link":"","code_link":"https://github.com/marcotcr/lime","research_link":"https://arxiv.org/abs/1602.04938","media_link":"https://www.youtube.com/watch?v=hUnRCxnydCc","dataset_link":"","demo_link":"","other_link":""}]},{"id":242,"title":"ELI5","description":"A library for debugging/inspecting machine learning classifiers and explaining their predictions.","tags":["code","library","interpretability","debugging","eli5","inspection","explain"],"details":"It provides support for the following machine learning frameworks and packages:\r\n\u2022\u00a0scikit-learn. Currently ELI5 allows to explain weights and predictions of scikit-learn linear classifiers and regressors, print decision trees as text or as SVG, show feature importances and explain predictions of decision trees and tree-based ensembles. ELI5 understands text processing utilities from scikit-learn and can highlight text data accordingly. Pipeline and FeatureUnion are supported. It also allows to debug scikit-learn pipelines which contain HashingVectorizer, by undoing hashing.\r\n\u2022\u00a0Keras - explain predictions of image classifiers via Grad-CAM visualizations.\r\n\u2022\u00a0xgboost - show feature importances and explain predictions of \u2022\u00a0XGBClassifier, XGBRegressor and xgboost.Booster.\r\n\u2022\u00a0LightGBM - show feature importances and explain predictions of \u2022\u00a0LGBMClassifier and LGBMRegressor.\r\n\u2022\u00a0CatBoost - show feature importances of CatBoostClassifier, CatBoostRegressor and catboost.CatBoost.\r\n\u2022\u00a0lightning - explain weights and predictions of lightning classifiers and regressors.\r\n\u2022\u00a0sklearn-crfsuite. ELI5 allows to check weights of sklearn_crfsuite.CRF models.\r\n\r\nELI5 also implements several algorithms for inspecting black-box models (see Inspecting Black-Box Estimators):\r\n\u2022\u00a0TextExplainer allows to explain predictions of any text classifier using LIME algorithm (Ribeiro et al., 2016). There are utilities for using LIME with non-text data and arbitrary black-box classifiers as well, but this feature is currently experimental.\r\n\u2022\u00a0Permutation importance method can be used to compute feature importances for black box estimators.","links":[{"article_link":"","code_link":"https://github.com/TeamHG-Memex/eli5","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"http://eli5.readthedocs.io"}]},{"id":241,"title":"TFA: TensorFlow Addons","description":"Useful extra functionality for TensorFlow 2.x maintained by SIG-addons","tags":["code","tensorflow","library","utilities","addons"],"details":"TensorFlow Addons is a repository of contributions that conform to well-established API patterns, but implement new functionality not available in core TensorFlow. TensorFlow natively supports a large number of operators, layers, metrics, losses, and optimizers. However, in a fast moving field like ML, there are many interesting new developments that cannot be integrated into core TensorFlow (because their broad applicability is not yet clear, or it is mostly used by a smaller subset of the community).","links":[{"article_link":"","code_link":"https://github.com/tensorflow/addons","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":240,"title":"Skorch","description":"A scikit-learn compatible neural network library that wraps pytorch","tags":["code","pytorch","scikit-learn","library","skorch"],"details":"The goal of skorch is to make it possible to use PyTorch with sklearn. This is achieved by providing a wrapper around PyTorch that has an sklearn interface. In that sense, skorch is the spiritual successor to nolearn, but instead of using Lasagne and Theano, it uses PyTorch.\r\n\r\nskorch also provides many convenient features, among others:\r\n\u2022\u00a0Learning rate schedulers (Warm restarts, cyclic LR and many more)\r\n\u2022\u00a0Scoring using sklearn (and custom) scoring functions\r\n\u2022\u00a0Early stopping\r\n\u2022\u00a0Checkpointing\r\n\u2022\u00a0Parameter freezing/unfreezing\r\n\u2022\u00a0Progress bar (for CLI as well as jupyter)\r\n\u2022\u00a0Automatic inference of CLI parameters","links":[{"article_link":"","code_link":"https://github.com/skorch-dev/skorch","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://skorch.readthedocs.io/en/latest/?badge=latest"}]},{"id":239,"title":"Prophet: Forecasting At Scale","description":"Tool for producing high quality forecasts for time series data that has multiple seasonality with linear or non-linear growth.","tags":["article","code","paper","research","library","forecasting","time-series","time-series-forecasting","prophet","facebook"],"details":"Prophet is a procedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects. It works best with time series that have strong seasonal effects and several seasons of historical data. Prophet is robust to missing data and shifts in the trend, and typically handles outliers well.\r\n\r\n","links":[{"article_link":"https://facebook.github.io/prophet/docs/quick_start.html#python-api","code_link":"https://github.com/facebook/prophet","research_link":"https://peerj.com/preprints/3190/","media_link":"","dataset_link":"","demo_link":"","other_link":"https://facebook.github.io/prophet/"}]},{"id":238,"title":"Googletrans","description":"Googletrans: Free and Unlimited Google translate API for Python. Translates totally free of charge.","tags":["code","library","translation","machine-translation","natural-language-processing"],"details":"Googletrans is a free and unlimited python library that implemented Google Translate API. This uses the Google Translate Ajax API to make calls to such methods as detect and translate.","links":[{"article_link":"","code_link":"https://github.com/ssut/py-googletrans","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://py-googletrans.readthedocs.io/en/latest/"}]},{"id":237,"title":"Common Architectures in Convolutional Neural Networks","description":"In this post, I'll discuss commonly used architectures for convolutional networks. ","tags":["article","tutorial","convolutional-neural-networks","computer-vision","architectures","survey"],"details":"Almost all CNN architectures follow the same general design principles of successively applying convolutional layers to the input, periodically downsampling the spatial dimensions while increasing the number of feature maps.\r\n\r\nClassic network architectures (included for historical purposes)\r\n* LeNet-5\r\n* AlexNet\r\n* VGG 16\r\n\r\nModern network architectures\r\n* Inception\r\n* ResNet\r\n* ResNeXt\r\n* DenseNet","links":[{"article_link":"https://www.jeremyjordan.me/convnet-architectures/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":236,"title":"Convolutional Neural Networks","description":"A in-depth look at convolutional neural networks.","tags":["article","tutorial","convolutional-neural-networks"],"details":"Today, I'll be talking about convolutional neural networks which are used heavily in image recognition applications of machine learning. Convolutional neural networks provide an advantage over feed-forward networks because they are capable of considering locality of features.","links":[{"article_link":"https://www.jeremyjordan.me/convolutional-neural-networks/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":235,"title":"Evaluating Image Segmentation Models","description":"A look at evaluation techniques for semantic and instance segmentation.","tags":["article","tutorial","computer-vision","natural-language-processing","semantic-composition","segmentation","instance-segmentation","evaluation"],"details":"When evaluating a standard machine learning model, we usually classify our predictions into four categories: true positives, false positives, true negatives, and false negatives. However, for the dense prediction task of image segmentation, it's not immediately clear what counts as a \"true positive\" and, more generally, how we can evaluate our predictions. In this post, I'll discuss common methods for evaluating both semantic and instance segmentation techniques.","links":[{"article_link":"https://www.jeremyjordan.me/evaluating-image-segmentation-models/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":234,"title":"An Overview of Semantic Image Segmentation","description":"Image segmentation is a computer vision task in which we label specific regions of an image according to what's being shown.","tags":["article","tutorial","computer-vision","semantic-segmentation","segmentation"],"details":"More specifically, the goal of semantic image segmentation is to label each pixel of an image with a corresponding class of what is being represented. Because we're predicting for every pixel in the image, this task is commonly referred to as dense prediction.","links":[{"article_link":"https://www.jeremyjordan.me/semantic-segmentation/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":233,"title":"Lecture 13 | Generative Models - CS231n","description":"A look at the motivation and concepts behind variational autoencoders. ","tags":["tutorial","video","autoencoders","variational-autoencoders","cs231n","stanford","generative-models"],"details":"In Lecture 13 we move beyond supervised learning, and discuss generative modeling as a form of unsupervised learning. We cover the autoregressive PixelRNN and PixelCNN models, traditional and variational autoencoders (VAEs), and generative adversarial networks (GANs).","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=5WoItGTWV54&feature=youtu.be&t=19m38s","dataset_link":"","demo_link":"","other_link":"http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture13.pdf"}]},{"id":232,"title":"PYRO: Deep Universal Probabilistic Programming","description":"Pyro is a flexible, scalable deep probabilistic programming library built on PyTorch.","tags":["article","code","pytorch","autoencoders","hidden-markov-models","latent-dirichlet-allocation","variational-autoencoders","library","forecasting","pyro","probabilistic-programming","uber","uber-ai","monte-carlo-filtering","kernels","multivariate-forecasting","markov-chain-monte-carlo","gaussian-mixture-models","bayesian-optimization","kalman-filters"],"details":"Notably, it was designed with these principles in mind.\r\n\u2022\u00a0Universal: Pyro is a universal PPL - it can represent any computable probability distribution.\r\n\u2022\u00a0Scalable: Pyro scales to large data sets with little overhead compared to hand-written code.\r\n\u2022\u00a0Minimal: Pyro is agile and maintainable. It is implemented with a small core of powerful, composable abstractions.\r\n\u2022\u00a0Flexible: Pyro aims for automation when you want it, control when you need it. This is accomplished through high-level abstractions to express generative and inference models, while allowing experts easy-access to customize inference.","links":[{"article_link":"http://pyro.ai/examples/index.html#","code_link":"https://github.com/pyro-ppl/pyro","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"http://pyro.ai/"}]},{"id":230,"title":"Variational Autoencoders","description":"An introduction to VAEs with Pyro.","tags":["article","code","tutorial","autoencoders","variational-autoencoders","pyro"],"details":"The variational autoencoder (VAE) is arguably the simplest setup that realizes deep probabilistic modeling. Note that we\u2019re being careful in our choice of language here. The VAE isn\u2019t a model as such\u2014rather the VAE is a particular setup for doing variational inference for a certain class of models. The class of models is quite broad: basically any (unsupervised) density estimator with latent random variables.","links":[{"article_link":"http://pyro.ai/examples/vae.html","code_link":"https://github.com/pyro-ppl/pyro/blob/dev/examples/vae/vae.py","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":229,"title":"Variational Autoencoders","description":"Statistical motivation and implementation of variational autoencoders.","tags":["article","tutorial","autoencoders","variational-autoencoders","representation-learning"],"details":"A variational autoencoder (VAE) provides a probabilistic manner for describing an observation in latent space. Thus, rather than building an encoder which outputs a single value to describe each latent state attribute, we'll formulate our encoder to describe a probability distribution for each latent attribute.","links":[{"article_link":"https://www.jeremyjordan.me/variational-autoencoders/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":228,"title":"Introduction to Autoencoders","description":"A look at autoencoders for representation learning.","tags":["article","tutorial","autoencoders","representation-learning"],"details":"Autoencoders are an unsupervised learning technique in which we leverage neural networks for the task of representation learning. Specifically, we'll design a neural network architecture such that we impose a bottleneck in the network which forces a compressed knowledge representation of the original input.","links":[{"article_link":"https://www.jeremyjordan.me/autoencoders/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":227,"title":"SQL for Data Analysis","description":"A look at using SQL for properly dealing with mid-large sized datasets for data analysis.","tags":["article","tutorial","databases","sql"],"details":"As a data scientist, you deal with a lot of data. For small datasets, maybe you just store this information in a CSV file and load it into Pandas. However, this isn't really a scalable solution and won't do too well if you're constantly updating and inserting new data. You need a database; somewhere to hold your information that allows for easy inserting, updating, and reading.","links":[{"article_link":"https://www.jeremyjordan.me/sql/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":225,"title":"Visualization with Matplotlib","description":"We'll now take an in-depth look at the Matplotlib package for visualization in Python.","tags":["article","tutorial","matplotlib","visualization"],"details":"* Simple Line Plots\r\n* Simple Scatter Plots\r\n* Visualizing Errors\r\n* Density and Contour Plots\r\n* Histograms, Binnings, and Density\r\n* Customizing Plot Legends\r\n* Customizing Colorbars\r\n* Multiple Subplots\r\n* Text and Annotation\r\n* Customizing Ticks\r\n* Customizing Matplotlib: Configurations and Stylesheets\r\n* Three-Dimensional Plotting in Matplotlib\r\n* Geographic Data with Basemap\r\n* Visualization with Seaborn\r\n* Further Resources","links":[{"article_link":"https://jakevdp.github.io/PythonDataScienceHandbook/04.00-introduction-to-matplotlib.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":224,"title":"Understanding Convolutional Neural Networks for NLP","description":"More recently we\u2019ve also started to apply CNNs to problems in Natural Language Processing and gotten some interesting results.","tags":["article","tutorial","convolutional-neural-networks","natural-language-processing","text-classification"],"details":"In this post I\u2019ll try to summarize what CNNs are, and how they\u2019re used in NLP. The intuitions behind CNNs are somewhat easier to understand for the Computer Vision use case, so I\u2019ll start there, and then slowly move towards NLP.","links":[{"article_link":"http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":223,"title":"An Intuitive Explanation of Convolutional Neural Networks","description":"Convolutional Neural Networks are a category of Neural Networks that have proven very effective in areas such as image recognition and classification.","tags":["article","tutorial","convolutional-neural-networks"],"details":"In this post, I have tried to explain the main concepts behind Convolutional Neural Networks in simple terms. There are several details I have oversimplified / skipped, but hopefully this post gave you some intuition around how they work.","links":[{"article_link":"https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":222,"title":"A Beginner's Guide To Understanding Convolutional Neural Networks","description":"A in-depth guide to understanding CNNs.","tags":["article","tutorial","convolutional-neural-networks"],"details":"* Part 1: https://adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/\r\n* Part 2: https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks-Part-2/\r\n* Part 3: https://adeshpande3.github.io/adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html","links":[{"article_link":"https://adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":221,"title":"Machine Learning is Fun! Part 3: CNNs","description":"This time, we are going to learn how to write programs that recognize objects in images using deep learning.","tags":["article","tutorial","convolutional-neural-networks"],"details":"","links":[{"article_link":"https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":220,"title":"Module 2: Convolutional Neural Networks - CS231n ","description":"In Lecture 5 we move from fully-connected neural networks to convolutional neural networks.","tags":["article","tutorial","video","convolutional-neural-networks","video-games","computer-vision","image-classification","cs231n","stanford"],"details":"\u2022\u00a0Convolutional Neural Networks: Architectures, Convolution / Pooling Layers\r\n\u2022\u00a0Understanding and Visualizing Convolutional Neural Networks\r\n\u2022\u00a0Transfer Learning and Fine-tuning Convolutional Neural Networks\r\n","links":[{"article_link":"https://cs231n.github.io/","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=bNb2fEVKeEo&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=5","dataset_link":"","demo_link":"","other_link":""}]},{"id":219,"title":"Natural Language Processing: Pretraining - d2l","description":"An interactive deep learning book with code, math, and discussions, based on the NumPy interface.","tags":["article","code","tutorial","mxnet","attention","bert","transformers","natural-language-processing","pretraining","book"],"details":"We have re-organized Chapter: NLP pretraining and Chapter: NLP applications, and added sections of BERT (model, data, pretraining, fine-tuning, application) and natural language inference (data, model).","links":[{"article_link":"https://d2l.ai/chapter_natural-language-processing-pretraining/index.html","code_link":"https://github.com/d2l-ai/d2l-en","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":218,"title":"Distributional RL using TensorFlow2","description":"\ud83d\udc33 Implementation of various Distributional Reinforcement Learning Algorithms using TensorFlow2.","tags":["code","tutorial","tensorflow","machine-learning","reinforcement-learning"],"details":"https://github.com/marload/dist-rl-tf2\r\n* C51\r\n\u2022\u00a0QR-DQN\r\n* IQN","links":[{"article_link":"","code_link":"https://github.com/marload/dist-rl-tf2","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":217,"title":"Neural Networks - Machine Learning Glossary","description":"Neural network concepts explained with pure python.","tags":["article","tutorial","neural-networks","multilayer-perceptrons"],"details":"* Neural Network\r\n* Neuron\r\n* Synapse\r\n* Weights\r\n* Bias\r\n* Layers\r\n* Weighted Input\r\n* Activation Functions\r\n* Loss Functions\r\n* Optimization Algorithms\r\n* Gradient Accumulation","links":[{"article_link":"https://ml-cheatsheet.readthedocs.io/en/latest/nn_concepts.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":216,"title":"Module 1: Neural Networks - CS231n","description":"These notes accompany the Stanford CS class CS231n: Convolutional Neural Networks for Visual Recognition.","tags":["article","code","tutorial","video","cs231n","stanford","multilayer-perceptrons"],"details":"\u2022\u00a0Neural Networks Part 1: Setting up the Architecture\r\n\u2022\u00a0Neural Networks Part 2: Setting up the Data and the Loss\r\n\u2022\u00a0Neural Networks Part 3: Learning and Evaluation","links":[{"article_link":"https://cs231n.github.io/","code_link":"https://github.com/cs231n/cs231n.github.io","research_link":"","media_link":"https://www.youtube.com/watch?v=d14TUNcbn1k&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=4","dataset_link":"","demo_link":"","other_link":""}]},{"id":215,"title":"XGBoost: eXtreme Gradient Boosting","description":"Scalable, Portable and Distributed Gradient Boosting (GBDT, GBRT or GBM) Library, for Python, R, Java, Scala, C++ and more. Runs on single machine, Hadoop, Spar","tags":["code","library","gradient-boosting","xgboost"],"details":"XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. It implements machine learning algorithms under the Gradient Boosting framework. XGBoost provides a parallel tree boosting (also known as GBDT, GBM) that solve many data science problems in a fast and accurate way. The same code runs on major distributed environment (Kubernetes, Hadoop, SGE, MPI, Dask) and can solve problems beyond billions of examples.","links":[{"article_link":"","code_link":"https://github.com/dmlc/xgboost","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://xgboost.ai/"}]},{"id":214,"title":"XGBoost Algorithm: Long May She Reign","description":"A closer look at XGBoost and why it performs so well on structured data.","tags":["article","tutorial","gradient-boosting","xgboost"],"details":"XGBoost is a decision-tree-based ensemble Machine Learning algorithm that uses a gradient boosting framework. In prediction problems involving unstructured data (images, text, etc.) artificial neural networks tend to outperform all other algorithms or frameworks. However, when it comes to small-to-medium structured/tabular data, decision tree based algorithms are considered best-in-class right now. ","links":[{"article_link":"https://towardsdatascience.com/https-medium-com-vishalmorde-xgboost-algorithm-long-she-may-rein-edd9f99be63d","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":213,"title":"In-Depth: Support Vector Machines","description":"An in-depth look at SVMs with scikit-learn.","tags":["article","tutorial","scikit-learn","support-vector-machines"],"details":"Support vector machines (SVMs) are a particularly powerful and flexible class of supervised algorithms for both classification and regression. In this section, we will develop the intuition behind support vector machines and their use in classification problems.","links":[{"article_link":"https://jakevdp.github.io/PythonDataScienceHandbook/05.07-support-vector-machines.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":212,"title":"In-Depth: Decision Trees and Random Forests","description":"An in-depth look at decision trees and random forests with scikit-learn.","tags":["article","code","notebook","tutorial","scikit-learn","decision-trees","random-forests","decision-tree"],"details":"Random forests are an example of an ensemble method, meaning that it relies on aggregating the results of an ensemble of simpler estimators. The somewhat surprising result with such ensemble methods is that the sum can be greater than the parts: that is, a majority vote among a number of estimators can end up being better than any of the individual estimators doing the voting!","links":[{"article_link":"https://jakevdp.github.io/PythonDataScienceHandbook/05.08-random-forests.html","code_link":"https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.08-Random-Forests.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":211,"title":"Support Vector Machines","description":"SVMs work well in complicated feature domains, albeit requiring clear separation between classes. ","tags":["article","tutorial","support-vector-machines"],"details":"","links":[{"article_link":"https://www.jeremyjordan.me/support-vector-machines/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":210,"title":"Linear classification: Support Vector Machine, Softmax","description":"The SVM loss is set up so that the SVM \u201cwants\u201d the correct class for each image to a have a score higher than the incorrect classes by some fixed margin \u0394.","tags":["article","tutorial","support-vector-machines","cs231n","stanford"],"details":"\u2022\u00a0Parametric approach\r\n\u2022\u00a0Bias trick\r\n\u2022\u00a0Hinge loss\r\n\u2022\u00a0Cross-entropy loss\r\n\u2022\u00a0L2 regularization\r\n\u2022\u00a0web demo","links":[{"article_link":"https://cs231n.github.io/linear-classify/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":209,"title":"Decision Trees","description":"An overview of decision trees with an implementation in scikit-learn.","tags":["article","tutorial","scikit-learn","decision-trees","random-forests","decision-tree"],"details":"Decision trees are one of the oldest and most widely-used machine learning models, due to the fact that they work well with noisy or missing data, can easily be ensembled to form more robust predictors, and are incredibly fast at runtime. Moreover, you can directly visual your model's learned logic, which means that it's an incredibly popular model for domains where model interpretability is important.","links":[{"article_link":"https://www.jeremyjordan.me/decision-trees/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":208,"title":"A Visual Introduction to Machine Learning","description":"In machine learning, computers apply statistical learning techniques to automatically identify patterns in data. ","tags":["tutorial","decision-trees","random-forests","illustrated","decision-tree","r2d3"],"details":"* Machine learning identifies patterns using statistical learning and computers by unearthing boundaries in data sets. You can use it to make predictions.\r\n* One method for making predictions is called a decision trees, which uses a series of if-then statements to identify boundaries and define patterns in the data.\r\n* Overfitting happens when some boundaries are based on on distinctions that don't make a difference. You can see if a model overfits by having test data flow through the model.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"http://www.r2d3.us/visual-intro-to-machine-learning-part-1/","dataset_link":"","demo_link":"","other_link":""}]},{"id":207,"title":"Regularization in Machine Learning","description":"This article will focus on a technique that helps in avoiding overfitting and also increasing model interpretability.","tags":["article","tutorial","linear-regression","regression","interpretability","regularization"],"details":"One of the major aspects of training your machine learning model is avoiding overfitting. The model will have a low accuracy if it is overfitting. This happens because your model is trying too hard to capture the noise in your training dataset. By noise we mean the data points that don\u2019t really represent the true properties of your data, but random chance. Learning such data points, makes your model more flexible, at the risk of overfitting.","links":[{"article_link":"https://towardsdatascience.com/regularization-in-machine-learning-76441ddcf99a","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":206,"title":"Decision Trees in Machine Learning","description":"A tree has many analogies in real life, and turns out that it has influenced a wide area of machine learning, covering both classification and regression.","tags":["article","tutorial","decision-trees","random-forests","decision-tree"],"details":"","links":[{"article_link":"https://towardsdatascience.com/decision-trees-in-machine-learning-641b9c4e8052","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":205,"title":"Logistic Regression","description":"An overview of the concept and math behind logistic regression.","tags":["article","tutorial","logistic-regression","regression"],"details":"The goal of logistic regression, as with any classifier, is to figure out some way to split the data to allow for an accurate prediction of a given observation's class using the information present in the features. ","links":[{"article_link":"https://www.jeremyjordan.me/logistic-regression/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":204,"title":"Building A Logistic Regression in Python, Step by Step","description":"A step-by-step guide for logistic regression in Python.","tags":["article","code","notebook","tutorial","logistic-regression","regression"],"details":"Logistic Regression is a Machine Learning classification algorithm that is used to predict the probability of a categorical dependent variable. In logistic regression, the dependent variable is a binary variable that contains data coded as 1 (yes, success, etc.) or 0 (no, failure, etc.). In other words, the logistic regression model predicts P(Y=1) as a function of X.","links":[{"article_link":"https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8","code_link":"https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Logistic Regression balanced.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":203,"title":"K-nearest Neighbors","description":"A quick look at KNN with code.","tags":["article","tutorial","k-nearest-neighbors"],"details":"Many machine learning techniques involve building a model that is capable of representing the data and then finding the optimal parameters for the model to minimize error. K-nearest neighbors, however, is an example of instance-based learning where we instead simply store the training data and use it to make new predictions.\r\n\r\n","links":[{"article_link":"https://www.jeremyjordan.me/k-nearest-neighbors/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":202,"title":"An Intuitive (and Short) Explanation of Bayes\u2019 Theorem","description":"A condensed version for Bayesian newcomers like myself.","tags":["article","tutorial","naive-bayes"],"details":"","links":[{"article_link":"https://betterexplained.com/articles/an-intuitive-and-short-explanation-of-bayes-theorem/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":201,"title":"Naive Bayes Classification","description":"Naive Bayes classification methods are quite simple (in terms of model complexity) and commonly used for tasks such as document classification & spam filtering.","tags":["article","tutorial","naive-bayes"],"details":"Bayes' theorem provides a statistical framework for incorporating test evidence into our probabilistic viewpoint of events. We can apply Bayes' theorem to classification tasks within machine learning to calculate the probability of an observation belonging to each of the possible classes, given a feature vector that describes the observation.","links":[{"article_link":"https://www.jeremyjordan.me/naive-bayes-classification/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":200,"title":"k-Nearest Neighbor - CS231n","description":"Nearest Neighbor Classifier in Python.","tags":["article","tutorial","k-nearest-neighbors"],"details":"Tips for applying KNN in practice (hopefully not on images, or perhaps as only a baseline) are located at the bottom of the post.","links":[{"article_link":"https://cs231n.github.io/classification/#k---nearest-neighbor-classifier","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":199,"title":"Logistic Regression - Machine Learning Glossary","description":"Brief visual explanations of logistic regression with diagrams, code examples and links to resources for learning more.","tags":["article","tutorial","logistic-regression","regression"],"details":"* Binary logistic regression\r\n* Multiclass logistic regression","links":[{"article_link":"https://ml-cheatsheet.readthedocs.io/en/latest/logistic_regression.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":198,"title":"Linear Regression - Machine Learning Glossary","description":"Brief visual explanations of linear regression with diagrams, code examples and links to resources for learning more.","tags":["article","tutorial","linear-regression","regression"],"details":"* Simple regression\r\n* Multivariate regression","links":[{"article_link":"https://ml-cheatsheet.readthedocs.io/en/latest/linear_regression.html","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":197,"title":"Linear Algebra - Machine Learning Glossary","description":"Brief visual explanations of linear algebra with diagrams, code examples and links to resources for learning more.","tags":["code","tutorial","linear-algebra"],"details":"Linear algebra is a mathematical toolbox that offers helpful techniques for manipulating groups of numbers simultaneously. It provides structures like vectors and matrices (spreadsheets) to hold these numbers and new rules for how to add, subtract, multiply, and divide them. Here is a brief overview of basic linear algebra concepts taken from my linear algebra post on Medium.","links":[{"article_link":"","code_link":"https://github.com/bfortuner/ml-glossary","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://ml-cheatsheet.readthedocs.io/en/latest/linear_algebra.html"}]},{"id":196,"title":"Linear Regression from Scratch in Python","description":"We will explore linear regression and we will implement it using Python from scratch.","tags":["article","tutorial","linear-regression","regression"],"details":"","links":[{"article_link":"https://mubaris.com/posts/linear-regression/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":195,"title":"Essence of linear algebra","description":"A geometric understanding of matrices, determinants, eigen-stuffs and more.","tags":["tutorial","video","linear-algebra"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab","dataset_link":"","demo_link":"","other_link":""}]},{"id":194,"title":"How kNN algorithm works","description":"I describe how the k Nearest Neighbors algorithm works, and provide a simple example using 2-dimensional data and k = 3.","tags":["tutorial","video","k-nearest-neighbors"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=UqYde-LULfs","dataset_link":"","demo_link":"","other_link":""}]},{"id":193,"title":"Machine Learning Basics with the K-Nearest Neighbors Algorithm","description":"The k-nearest neighbors (KNN) algorithm is a simple, easy-to-implement supervised machine learning algorithm for both classification and regression.","tags":["article","tutorial","k-nearest-neighbors"],"details":"","links":[{"article_link":"https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":192,"title":"Develop k-Nearest Neighbors in Python From Scratch","description":"In this tutorial you are going to learn about the k-Nearest Neighbors algorithm including how it works and how to implement it from scratch in Python.","tags":["article","tutorial","python","k-nearest-neighbors"],"details":"\u2022\u00a0How to code the k-Nearest Neighbors algorithm step-by-step.\r\n\u2022\u00a0How to evaluate k-Nearest Neighbors on a real dataset.\r\n\u2022\u00a0How to use k-Nearest Neighbors to make a prediction for new data.","links":[{"article_link":"https://machinelearningmastery.com/tutorial-to-implement-k-nearest-neighbors-in-python-from-scratch/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":191,"title":"Unfolding Na\u00efve Bayes from Scratch","description":"Na\u00efve Bayes explained via math, pure Python and then Scikit-learn.","tags":["article","code","tutorial","python","scikit-learn","naive-bayes"],"details":"The sole purpose is to deeply and clearly understand the working of a well know Text Classification ML Algorithm (Na\u00efve Bayes) without being trapped in the gibberish mathematical jargon that is often used in the explanation of ML Algorithms!","links":[{"article_link":"https://towardsdatascience.com/unfolding-na%C3%AFve-bayes-from-scratch-2e86dcae4b01","code_link":"https://towardsdatascience.com/na%C3%AFve-bayes-from-scratch-using-python-only-no-fancy-frameworks-a1904b37222d","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":189,"title":"How MLE (Maximum Likelihood Estimation) algorithm works","description":"Simplified and visualized explanation of Maximum Likelihood Estimation","tags":["tutorial","video","maximum-likelihood-estimation"],"details":"In this video I show how the MLE algorithm works. We provide an animation where several points are classified considering three classes with mean and standard deviation values previously computed. We compute the class conditional density for the three classes and conclude the classification of a sample point with unknown class.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=RPtYRm2tboA","dataset_link":"","demo_link":"","other_link":""}]},{"id":188,"title":"Linear Algebra - Khan Academy","description":"Learn the basics, starting with Vectors","tags":["tutorial","linear-algebra"],"details":"Course summary:\r\n\u2022\u00a0Vectors and spaces\r\n\u2022\u00a0Matrix transformations\r\n\u2022\u00a0Alternate coordinate systems (bases)\r\n","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.khanacademy.org/math/linear-algebra"}]},{"id":187,"title":"Computational Linear Algebra for Coders","description":"Free online textbook of Jupyter notebooks for fast.ai Computational Linear Algebra course.","tags":["code","course","tutorial","machine-learning","linear-algebra","top-down"],"details":"This course is structured with a top-down teaching method, which is different from how most math courses operate. Typically, in a bottom-up approach, you first learn all the separate components you will be using, and then you gradually build them up into more complex structures. The problems with this are that students often lose motivation, don't have a sense of the \"big picture\", and don't know what they'll need.","links":[{"article_link":"","code_link":"https://github.com/fastai/numerical-linear-algebra","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.fast.ai/2017/07/17/num-lin-alg/"}]},{"id":186,"title":"Understanding PyTorch with an example: a step-by-step tutorial","description":"Structured, incremental and from first principles approach to PyTorch.","tags":["article","tutorial","pytorch"],"details":"In this post, I will guide you through the main reasons why PyTorch makes it much easier and more intuitive to build a Deep Learning model in Python \u2014 autograd, dynamic computation graph, model classes and more \u2014 and I will also show you how to avoid some common pitfalls and errors along the way.","links":[{"article_link":"https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":184,"title":"Learning PyTorch with Examples","description":"This tutorial introduces the fundamental concepts of PyTorch through self-contained examples.","tags":["tutorial","pytorch"],"details":"At its core, PyTorch provides two main features:\r\n* An n-dimensional Tensor, similar to numpy but can run on GPUs\r\n* Automatic differentiation for building and training neural networks\r\n\r\nWe will use a fully-connected ReLU network as our running example. The network will have a single hidden layer, and will be trained with gradient descent to fit random data by minimizing the Euclidean distance between the network output and the true output.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://pytorch.org/tutorials/beginner/pytorch_with_examples.html"}]},{"id":183,"title":"What does a CNN see?","description":"First super clean notebook showcasing @TensorFlow 2.0. An example of end-to-end DL with interpretability.","tags":["code","notebook","tutorial","tensorflow","convolutional-neural-networks","computer-vision","interpretability"],"details":"This notebook aims at Model Interpretability using TF2.0. Machine learning models, especially Deep Learning models are often considered as a black box and hard to interpret. Well, this statement is neither completely true nor it is completely false. It is a fact that debugging a deep learning model is way harder than other machine learning models but there are ways by which you can get insights about your model and to an extent, you can see what is happening.","links":[{"article_link":"","code_link":"https://colab.research.google.com/drive/1xM6UZ9OdpGDnHBljZ0RglHV_kBrZ4e-9","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":182,"title":"Tutorials | TensorFlow Core","description":"The TensorFlow tutorials are written as Jupyter notebooks and run directly in Google Colab\u2014a hosted notebook environment that requires no setup. ","tags":["tutorial","tensorflow"],"details":"\u2022\u00a0For beginners\r\nThe best place to start is with the user-friendly Keras sequential API. Build models by plugging together building blocks. After these tutorials, read the Keras guide.\r\n\r\n* For experts\r\nThe Keras functional and subclassing APIs provide a define-by-run interface for customization and advanced research. Build your model, then write the forward and backward pass. Create custom layers, activations, and training loops.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.tensorflow.org/tutorials"}]},{"id":181,"title":"Talking-Heads Attention","description":"A variation on multi-head attention which includes linear projections across the attention-heads dimension, immediately before and after the softmax operation.","tags":["article","paper","research","tutorial","attention","transformers","natural-language-processing","multi-head-attention","talking-heads-attention","linear-projections","arxiv:2003.02436"],"details":"","links":[{"article_link":"https://www.pragmatic.ml/talking-heads-attention/","code_link":"","research_link":"https://arxiv.org/abs/2003.02436","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":180,"title":"Hands On Machine Learning","description":"A series of Jupyter notebooks that walk you through the fundamentals of Machine Learning and Deep Learning in Python using Scikit-Learn, Keras and TensorFlow 2.","tags":["code","tutorial","keras","scikit-learn","tensorflow"],"details":"This project aims at teaching you the fundamentals of Machine Learning in python. It contains the example code and solutions to the exercises in the second edition of my O'Reilly book Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow.","links":[{"article_link":"","code_link":"https://github.com/ageron/handson-ml2","research_link":"","media_link":"https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/","dataset_link":"","demo_link":"","other_link":""}]},{"id":179,"title":"scikit-learn","description":"Examples for all the different utilities within scikit-learn.","tags":["scikit-learn","decision-trees","linear-regression","logistic-regression","naive-bayes","random-forests","regression","support-vector-machines","library","gradient-boosting","k-nearest-neighbors","decision-tree","gaussian-processes"],"details":"1. Supervised learning\r\n2. Unsupervised learning\r\n3. Model selection and evaluation\r\n4. Inspection\r\n5. Visualizations\r\n6. Dataset transformations\r\n7. Dataset loading utilities\r\n8. Computing with scikit-learn","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://scikit-learn.org/stable/user_guide.html"}]},{"id":178,"title":"Scikit-learn Tutorial","description":"This repository contains notebooks and other files associated with my Scikit-learn tutorial.","tags":["code","tutorial","scikit-learn"],"details":"Note also that some of the code in these notebooks will not work outside the directory structure of this tutorial, so it is important to clone the full repository if possible.","links":[{"article_link":"","code_link":"https://github.com/jakevdp/sklearn_tutorial","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":177,"title":"cuDF - GPU DataFrames","description":"cuDF is a GPU DataFrame library for loading, joining, aggregating, filtering, and otherwise manipulating data.","tags":["code","library","pandas","cudf","rapidsai"],"details":"cuDF provides a pandas-like API that will be familiar to data engineers & data scientists, so they can use it to easily accelerate their workflows without going into the details of CUDA programming.","links":[{"article_link":"","code_link":"https://github.com/rapidsai/cudf","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://rapids.ai/"}]},{"id":176,"title":"Complete Python Pandas Data Science Tutorial","description":"In this video we walk through many of the fundamental concepts to use the Python Pandas Data Science Library.","tags":["code","tutorial","video","python","pandas"],"details":"We start off by installing pandas and loading in an example csv. We then look at different ways to read the data. Read a column, rows, specific cell, etc. Also ways to read data based on conditioning. We then move into some more advanced ways to sort & filter data. We look at making conditional changes to our data. We also start doing aggregate stats using the groupby function. We finished the video talking about how you would work with a very large dataset (many gigabytes)","links":[{"article_link":"","code_link":"https://github.com/KeithGalli/pandas","research_link":"","media_link":"https://www.youtube.com/watch?v=vmEHCJofslg","dataset_link":"","demo_link":"","other_link":""}]},{"id":175,"title":"Python NumPy Tutorial for Beginners","description":"Learn the basics of the NumPy library in this tutorial for beginners.","tags":["code","tutorial","video","numpy"],"details":"It provides background information on how NumPy works and how it compares to Python's Built-in lists. This video goes through how to write code with NumPy. It starts with the basics of creating arrays and then gets into more advanced stuff. The video covers creating arrays, indexing, math, statistics, reshaping, and more.","links":[{"article_link":"","code_link":"https://github.com/KeithGalli/NumPy","research_link":"","media_link":"https://www.youtube.com/watch?v=QUT1VHiLmmI","dataset_link":"","demo_link":"","other_link":""}]},{"id":174,"title":"Python Numpy Tutorial (with Jupyter and Colab)","description":"A quick crash course on both the Python programming language and its use for scientific computing.","tags":["article","tutorial","python","numpy"],"details":"We will use the Python programming language for all assignments in this course. Python is a great general-purpose programming language on its own, but with the help of a few popular libraries (numpy, scipy, matplotlib) it becomes a powerful environment for scientific computing.","links":[{"article_link":"http://cs231n.github.io/python-numpy-tutorial/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":173,"title":"Design Patterns for Production NLP Systems","description":"Designs and tips for designing NLP production systems.","tags":["article","tutorial","natural-language-processing","systems-design"],"details":"Production NLP systems can be complex. When building an NLP system, it is important to remember that the system you are building is solving a task and is simply a means to that end. During system building, the engineers, researchers, designers, and product managers have several choices to make.","links":[{"article_link":"https://deliprao.com/archives/294","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":171,"title":"Python is Cool","description":"A gentle guide to the Python features that I didn't know existed or was too afraid to use. This will be updated as I learn more and become less lazy.","tags":["code","tutorial","python"],"details":"Tips and tricks for lesser known Python features that can be very useful.","links":[{"article_link":"","code_link":"https://github.com/chiphuyen/python-is-cool","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":170,"title":"Python Tutorial","description":"Python is a programming language. Python can be used on a server to create web applications.","tags":["tutorial","python"],"details":"Learning by Examples: With our \"Try it Yourself\" editor, you can edit the code and view the result.","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.w3schools.com/python/default.asp"}]},{"id":169,"title":"Python Practice Book","description":"A comprehensive, online book to learn the basics of Python development with code examples.","tags":["code","tutorial","python"],"details":"1. Getting Started\r\n2. Working with Data\r\n3. Modules\r\n4. Object Oriented Programming\r\n5. Iterators & Generators\r\n6. Functional Programming","links":[{"article_link":"","code_link":"https://github.com/anandology/python-practice-book","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://anandology.com/python-practice-book/index.html"}]},{"id":168,"title":"Self-Supervised Scene De-occlusion","description":"We investigate the problem of scene de-occlusion, which aims to recover the underlying occlusion ordering and complete the invisible parts of occluded objects.","tags":["article","code","paper","research","video","computer-vision","image-generation","self-supervised-learning","de-occlusion","arxiv:2004.02788"],"details":"We make the first attempt to address the problem through a novel and unified framework that recovers hidden scene structures without ordering and amodal annotations as supervisions. This is achieved via Partial Completion Network (PCNet)-mask (M) and -content (C), that learn to recover fractions of object masks and contents, respectively, in a self-supervised manner. Based on PCNet-M and PCNet-C, we devise a novel inference scheme to accomplish scene de-occlusion, via progressive ordering recovery, amodal completion and content completion.","links":[{"article_link":"https://xiaohangzhan.github.io/projects/deocclusion/","code_link":"https://github.com/XiaohangZhan/deocclusion/","research_link":"https://arxiv.org/abs/2004.02788","media_link":"https://www.youtube.com/watch?v=xIHCyyaB5gU","dataset_link":"","demo_link":"","other_link":""}]},{"id":167,"title":"Meta Pseudo Labels","description":"We all know about meta-learning and pseudo labeling but what if we combine the two techniques for semi-supervised learning? Can it be any beneficial? ","tags":["article","paper","research","deep-learning","machine-learning","neural-networks","meta-learning","semi-supervised-learning","arxiv:2003.10580"],"details":"","links":[{"article_link":"https://medium.com/@nainaakash012/meta-pseudo-labels-6480acb1b68","code_link":"","research_link":"https://arxiv.org/abs/2003.10580","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":166,"title":"Made With ML Topics","description":"A tagged and curated collection of trending tutorials, toolkits and research.","tags":["tutorial","deep-learning","machine-learning","computer-vision","natural-language-processing","newsletter"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://madewithml.com"}]},{"id":164,"title":"The Batch","description":"The Batch highlights a mix of the most practical research papers, industry-shaping applications, and high-impact business news.","tags":["tutorial","deep-learning","newsletter"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.deeplearning.ai/thebatch/"}]},{"id":163,"title":"NLP Newsletter","description":"Democratizing Artificial Intelligence Research, Education, and Technologies.","tags":["tutorial","education","natural-language-processing","newsletter"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://dair.ai/"}]},{"id":162,"title":"Natural Language Processing News","description":"Get the highlights from Natural Language Processing & Machine Learning research & industry straight to your inbox every month.","tags":["tutorial","natural-language-processing","newsletter"],"details":"","links":[{"article_link":"","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"http://newsletter.ruder.io/"}]},{"id":161,"title":"Towards an ImageNet Moment for Speech-to-Text","description":"An overview of the conditions met by the Speech-to-Text ML subfield to reach the ImageNet moment.","tags":["article","code","tutorial","speech","speech-recognition","speech-to-text","asr","russian","automated-speech-recognition"],"details":"\u2022\u00a0Introducing the diverse 20,000 hour Open STT dataset published under CC-NC-BY license;\r\n\u2022\u00a0Demonstrating that it is possible to achieve competitive results using only two consumer-grade and widely available GPUs;\r\n\u2022\u00a0Offering a plethora of design patterns that democratize entry to the speech domain for a wide range of researchers and practitioners.","links":[{"article_link":"https://thegradient.pub/towards-an-imagenet-moment-for-speech-to-text/","code_link":"https://github.com/snakers4/open_stt","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":160,"title":"Programming Probabilistically","description":"A book on data science and machine learning with a foundation in applied statistics leading into deep learning.","tags":["code","tutorial","linear-discriminant-analysis","linear-regression","machine-learning","neural-networks","regression","linear-algebra"],"details":"* Create a book to help improve understanding of statistics and machine learning\r\n* Helping junior machine learning engineers and data scientists can get up to speed on how to develop machine learning systems start to finish\r\n","links":[{"article_link":"","code_link":"https://github.com/EricSchles/datascience_book","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":159,"title":"Drifter-ML","description":"A machine learning testing framework for sklearn and pandas.  The goal is to help folks assess whether things have changed over time.","tags":["code","video","scikit-learn","machine-learning","library","unit-tests","pandas","testing"],"details":"* Build a robust testing framework for machine learning models\r\n* Revolutionize the productionization of machine learning systems\r\n* Integrate machine learning and engineering teams","links":[{"article_link":"","code_link":"https://github.com/EricSchles/drifter_ml","research_link":"","media_link":"https://www.youtube.com/watch?v=bZtdnFVAfbs","dataset_link":"","demo_link":"","other_link":""}]},{"id":158,"title":"Tracking Objects as Points","description":"Simultaneous object detection and tracking using center points.","tags":["code","paper","research","tutorial","computer-vision","object-detection","object-tracking","arxiv:2004.01177"],"details":"Tracking has traditionally been the art of following interest points through space and time. This changed with the rise of powerful deep networks. Nowadays, tracking is dominated by pipelines that perform object detection followed by temporal association, also known as tracking-by-detection. In this paper, we present a simultaneous detection and tracking algorithm that is simpler, faster, and more accurate than the state of the art. Our tracker, CenterTrack, applies a detection model to a pair of images and detections from the prior frame. Given this minimal input, CenterTrack localizes objects and predicts their associations with the previous frame. ","links":[{"article_link":"","code_link":"https://github.com/xingyizhou/CenterTrack","research_link":"https://arxiv.org/abs/2004.01177","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":157,"title":"TransMoMo: Invariance-Driven Unsupervised Motion Retargeting","description":"A lightweight video motion retargeting approach that is capable of transferring motion of a person in a source video realistically to another video of a target ","tags":["article","code","paper","research","tutorial","video","pytorch","computer-vision","motion-generation","retargeting","transmomo","arxiv:2003.14401"],"details":"We present a lightweight video motion retargeting approach that is capable of transferring motion of a person in a source video realistically to another video of a target person. Without using any paired data for supervision, the proposed method can be trained in an unsupervised manner by exploiting invariance properties of three orthogonal factors of variation including motion, structure, and view angle. ","links":[{"article_link":"https://yzhq97.github.io/transmomo/","code_link":"https://github.com/yzhq97/transmomo.pytorch","research_link":"https://arxiv.org/abs/2003.14401","media_link":"https://www.youtube.com/watch?v=akbRtnRMkMk&feature=youtu.be","dataset_link":"","demo_link":"","other_link":""}]},{"id":156,"title":"How to setup a local AWS SageMaker environment for PyTorch","description":"Learn how to develop an ML app for a PyTorch Model faster by using AWS SageMaker local mode vs. deploying directly to AWS.","tags":["article","code","tutorial","aws","pytorch","web-services","sagemaker","web-app"],"details":"* The AWS SageMaker docs emphasize deploying direct to AWS versus developing locally and deploying larger chunks of work. This makes the dev process very slow (~10 minutes to deploy a SageMaker endpoint).\r\n* I'll show you how to use SageMaker local mode to deploy an endpoint locally on your computer (<30 seconds to deploy) and how to easily toggle btw local and production environments. We'll finish with a working web demo hosted by Booklet.ai (see the other link).\r\n* This builds on an existing  MadeWithML Lesson that creates an API for a PyTorch Text Classifier.","links":[{"article_link":"https://booklet.ai/blog/aws-sagemaker-pytorch-local-dev-flow/","code_link":"https://github.com/itsderek23/lessons/tree/master/notebooks/03_APIs/pt-text-classification/deploy/sagemaker","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://app.booklet.ai/model/pytorch-text-classification"}]},{"id":155,"title":"What You Need to Know About Product Management for AI","description":"A product manager for AI does everything a traditional PM does, and much more.","tags":["article","tutorial","video","machine-learning","business","product-management"],"details":"The increasing push to adopt AI into product, across many industries, puts the intersection of AI and product management into sharp focus. Challenges abound: non-deterministic outcomes, uncertainty (schedule, accuracy, relevance), opacity (models can be difficult to understand and explain), fairness issues, and other factors make AI a difficult sell to decision-makers and upper management. ","links":[{"article_link":"https://www.oreilly.com/radar/what-you-need-to-know-about-product-management-for-ai/","code_link":"","research_link":"","media_link":"https://www.youtube.com/watch?v=iMaqGHkUKgI","dataset_link":"","demo_link":"","other_link":""}]},{"id":154,"title":"Separating Sources of Randomness in NN at Initialization Time","description":"Neurons can have very different distributions when they are computed over weight randomness compared to when they are computed over sample randomness. In a rand","tags":["article","paper","research","tutorial","neural-networks","weights-initialization","randomness","kaiming-initialization","relu","variance","arxiv:1902.04942"],"details":"In this post, we\u2019ll identify two fundamental sources of randomness at initialization time: network randomness (randomness in weight configurations), and sample randomness (randomness in the input distribution). We\u2019ll show that neuron distributions arising from the two sources can be very different from each other.","links":[{"article_link":"https://kyleluther.github.io/2020/03/31/sample-vs-weight-randomness.html","code_link":"","research_link":"https://arxiv.org/abs/1902.04942","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":153,"title":"Why Batch Norm Causes Exploding Gradients","description":"Our beloved Batch Norm can actually cause exploding gradients, at least at initialization time.","tags":["article","paper","research","tutorial","deep-learning","batch-normalization","exploding-gradients","weights-initialization","normalization"],"details":"Inserting Batch Norm into a network means that in the forward pass each neuron is divided by its standard deviation, \u03c3, computed over a minibatch of samples. In the backward pass, gradients are divided by the same \u03c3. In ReLU nets, we\u2019ll show that this standard deviation is less than 1, in fact we can approximate \u03c3 \u2248 \u221a((\u03c0\u22121)/\u03c0)) \u2248 0.82. Since this occurs at every layer, gradient norms in early layers are amplified by roughly 1.21 \u2248 (1/0.82) in every layer.","links":[{"article_link":"https://kyleluther.github.io/2020/02/18/batchnorm-exploding-gradients.html","code_link":"","research_link":"https://openreview.net/pdf?id=SyMDXnCcF7","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":152,"title":"A Two-Step Graph Convolutional Decoder for Molecule Generation","description":"A simple auto-encoder framework for molecule generation.","tags":["article","paper","research","video","graph-convolutional-networks","graph-neural-networks","graphs","chemistry","molecule-generation","arxiv:1906.03412"],"details":"This two-step process, in which a bag of atoms is first generated, and then assembled, provides a simple framework that allows us to develop an efficient molecule auto-encoder. ","links":[{"article_link":"https://graphdeeplearning.github.io/publication/bresson-2019-two/","code_link":"","research_link":"https://arxiv.org/abs/1906.03412","media_link":"https://www.youtube.com/watch?v=VXNjCAmb6Zw","dataset_link":"","demo_link":"","other_link":"http://helper.ipam.ucla.edu/publications/glws4/glws4_16076.pdf"}]},{"id":151,"title":"SimCLR","description":"What's new in semi-supervised learning? This paper, SimCLR, presents a new framework for contrastive learning of visual representations.","tags":["article","paper","research","tutorial","deep-learning","machine-learning","semi-supervised-learning","simclr","arxiv:2002.05709"],"details":"Semi-supervised learning is finally getting all the attention it deserves. From vision-based tasks to Language Modeling, self-supervised learning has paved a new way of learning (much) better representations. This paper, SimCLR, presents a new framework for contrastive learning of visual representations.","links":[{"article_link":"https://medium.com/@nainaakash012/simclr-contrastive-learning-of-visual-representations-52ecf1ac11fa","code_link":"","research_link":"https://arxiv.org/abs/2002.05709","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":150,"title":"The Illustrated FixMatch for Semi-Supervised Learning","description":"Learn how to leverage unlabeled data using FixMatch for semi-supervised learning","tags":["article","tutorial","pytorch","computer-vision","semi-supervised-learning","illustrated"],"details":"* Understand rationale  behind semi-supervised learning\r\n* Know working mechanism of FixMatch and how it achieved 78% accuracy on CIFAR-10 with just 10 labeled images\r\n* Learn about RandAugment, CTAugment, Consistency Regularization and Pseudo-Labeling","links":[{"article_link":"https://amitness.com/2020/03/fixmatch-semi-supervised/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":148,"title":"An Illustrated Guide to Graph Neural Networks","description":"A breakdown of the inner workings of GNNs.","tags":["article","tutorial","graph-neural-networks","graphs","illustrated","graph-deep-learning"],"details":"Here, I cover the basic intuitions and mechanisms of Graph Neural Networks. Using colorful diagrams, I try to condense the essential steps needed to learn over structured graph data.","links":[{"article_link":"https://medium.com/dair-ai/an-illustrated-guide-to-graph-neural-networks-d5564a551783","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":147,"title":"Back Translation for Text Augmentation with Google Sheets","description":"Learn how to augment existing labeled text data for free using Google Sheets.","tags":["article","tutorial","data-augmentation","natural-language-processing"],"details":"* Explanation of backtranslation for augmentation in NLP\r\n* Using Google Translate in Sheets for Free","links":[{"article_link":"https://amitness.com/2020/02/back-translation-in-google-sheets/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":146,"title":"Cycle Text-To-Image GAN with BERT","description":"Image generation from their respective captions, building on state-of-the-art GAN architectures.","tags":["code","paper","research","attention","bert","generative-adversarial-networks","transformers","computer-vision","image-generation","natural-language-processing","image-to-text","cycle-gan","attn-gan","arxiv:2003.12137"],"details":"* We baseline our models with the Attention-based GANs that learn attention mappings from words to image features. To better capture the features of the descriptions, we then built a novel cyclic design that learns an inverse function to maps the image back to original caption. \r\n* Additionally, we incorporated recently developed BERT pre-trained word embeddings as our initial text featurizer and observe a noticeable improvement in qualitative and quantitative performance compared to the Attention GAN baseline.","links":[{"article_link":"","code_link":"https://github.com/suetAndTie/cycle-image-gan","research_link":"https://arxiv.org/abs/2003.12137","media_link":"http://www.vision.caltech.edu/visipedia/CUB-200-2011.html","dataset_link":"","demo_link":"","other_link":""}]},{"id":145,"title":"Controllable Person Image Synthesis with Attribute-Decomposed GAN","description":"A novel generative model for controllable person image synthesis, which can produce realistic person images with desired human attributes.","tags":["article","code","paper","research","generative-adversarial-networks","computer-vision","image-synthesis","pose","person-image-synthesis"],"details":"* The core idea of the proposed model is to embed human attributes into the latent space as independent codes and thus achieve flexible and continuous control of attributes via mixing and interpolation operations in explicit style representations. \r\n* Specifically, a new architecture consisting of two encoding pathways with style block connections is proposed to decompose the original hard mapping into multiple more accessible subtasks. ","links":[{"article_link":"https://menyifang.github.io/projects/ADGAN/ADGAN.html","code_link":"https://github.com/menyifang/ADGAN","research_link":"https://menyifang.github.io/projects/ADGAN/ADGAN_files/Paper_ADGAN_CVPR2020.pdf","media_link":"https://menyifang.github.io/projects/ADGAN/ADGAN_files/Video_ADGAN_CVPR2020.mp4","dataset_link":"","demo_link":"","other_link":"https://menyifang.github.io/projects/ADGAN/ADGAN_files/Supp_ADGAN_CVPR2020.pdf"}]},{"id":144,"title":"Finetuning Transformers with JAX + Haiku","description":"Walking through a port of the RoBERTa pre-trained model to JAX + Haiku, then fine-tuning the model to solve a downstream task.","tags":["article","code","notebook","tutorial","jax","attention","bert","transformers","fine-tuning","natural-language-processing","haiku","pretraining","roberta"],"details":"* This post will be code-oriented and will usually show code examples first before providing commentary.\r\n* We're going to be working in a top-down fashion, so we'll lay out our Transformer model in broad strokes and then fill in the detail.\r\n* I'll introducing Haiku's features as they're needed for our Transformer finetuning project.","links":[{"article_link":"https://www.pragmatic.ml/finetuning-transformers-with-jax-and-haiku/","code_link":"https://colab.research.google.com/drive/1kqLY-oofgLS-8_xWq-r_T7sNnjsgIMwe","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":143,"title":"torchlayers","description":"Shape inference for PyTorch (like Keras)  & new layers","tags":["article","code","keras","pytorch","library","inference","sota","shape","layers"],"details":"### Some functionalities:\r\n\r\n* __Shape inference__ for most of `torch.nn` module (__convolutional, recurrent, transformer, attention and linear layers__)\r\n* __Dimensionality inference__ (e.g. `torchlayers.Conv` working as `torch.nn.Conv1d/2d/3d` based on `input shape`)\r\n* __Shape inference of custom modules__ (see examples section)\r\n* __Additional [Keras-like](https://www.tensorflow.org/guide/keras) layers__ (e.g. `torchlayers.Reshape` or `torchlayers.StandardNormalNoise`)\r\n* __Additional SOTA layers__ mostly from ImageNet competitions\r\n(e.g. [PolyNet](https://arxiv.org/abs/1608.06993),\r\n[Squeeze-And-Excitation](https://arxiv.org/abs/1709.01507),\r\n[StochasticDepth](www.arxiv.org/abs/1512.03385>))\r\n* __Useful defaults__ (`\"same\"` padding and default `kernel_size=3` for `Conv`, dropout rates etc.)\r\n* __Zero overhead and [torchscript](https://pytorch.org/docs/stable/jit.html) support__\r\n\r\nSee project's full description, examples etc. under this link:\r\n[https://github.com/szymonmaszke/torchlayers](https://github.com/szymonmaszke/torchlayers)","links":[{"article_link":"https://www.kdnuggets.com/2020/04/pytorch-models-torchlayers.html","code_link":"https://github.com/szymonmaszke/torchlayers","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://szymonmaszke.github.io/torchlayers/"}]},{"id":142,"title":"TorchIO:  Medical Image Processing in Deep Learning and PyTorch","description":"Tools for medical image processing in deep learning and PyTorch","tags":["code","paper","research","pytorch","library","computer-vision","medical-imaging","radiology","arxiv:2003.04696"],"details":"\u2022\u00a0TorchIO is a Python library for efficient loading, preprocessing, augmentation and patch-based sampling of 3D medical images in deep learning, following the design of PyTorch.\r\n\r\n* It includes multiple intensity and spatial transforms for data augmentation and preprocessing. These transforms include typical computer vision operations such as random affine transformations and also domain-specific ones such as simulation of intensity artifacts due to MRI magnetic field inhomogeneity or k-space motion artifacts.","links":[{"article_link":"","code_link":"https://github.com/fepegar/torchio","research_link":"https://arxiv.org/abs/2003.04696","media_link":"","dataset_link":"","demo_link":"","other_link":"https://torchio.readthedocs.io/"}]},{"id":141,"title":"First Order Motion Model for Image Animation","description":"Generating a video sequence so that an object in a source image is animated according to the motion of a driving video.","tags":["article","code","paper","research","video","pytorch","animation","computer-vision","motion","image-animation"],"details":"We decouple appearance and motion information using a self-supervised formulation. To support complex motions, we use a representation consisting of a set of learned keypoints along with their local affine transformations. A generator network models occlusions arising during target motions and combines the appearance extracted from the source image and the motion derived from the driving video. Our framework scores best on diverse benchmarks and on a variety of object categories.","links":[{"article_link":"https://aliaksandrsiarohin.github.io/first-order-model-website/","code_link":"https://github.com/AliaksandrSiarohin/first-order-model","research_link":"http://papers.nips.cc/paper/8935-first-order-motion-model-for-image-animation","media_link":"https://www.youtube.com/watch?v=mUfJOQKdtAk","dataset_link":"","demo_link":"","other_link":""}]},{"id":140,"title":"Visual Paper Summary: ALBERT(A Lite BERT)","description":"An illustrated summary of ALBERT paper and how it improves BERT and makes it resource efficient","tags":["article","tutorial","attention","bert","transformers","natural-language-processing","albert","illustrated","summary"],"details":"* Explain rationale behind language models\r\n* Explains BERT and the various issues with it\r\n* Understand how ALBERT improves the problems with BERT","links":[{"article_link":"https://amitness.com/2020/02/albert-visual-summary/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":139,"title":"Flax: Google\u2019s Open Source Approach To Flexibility In ML","description":"A gentle introduction to Flax: a neural network library for JAX that is designed for flexibility.","tags":["article","code","tutorial","jax","deep-learning","library","flax"],"details":"Flax offers:\r\n\u2022\u00a0Easy to read code\r\n* Prefers duplication, instead of bad abstraction or inflated functions\r\n* Helpful error messages, seems they learned from the TensorFlow error messages\r\n\u2022\u00a0Easy expandability of basic implementations","links":[{"article_link":"https://hackernoon.com/flax-googles-open-source-approach-to-flexibility-in-machine-learning-iw9y324j","code_link":"https://github.com/Skyy93/SimpsonsFaceRecognitionFlax","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":138,"title":"BachGAN: High-Res Image Synthesis from Salient Object Layout","description":"We propose a new task towards more practical application for image generation - high-quality image synthesis from salient object layout. ","tags":["code","paper","research","pytorch","generative-adversarial-networks","computer-vision","image-generation","salient-object-layout","image-synthesis","arxiv:2003.11690"],"details":"Two main challenges spring from this new task: \r\n* (i) how to generate fine-grained details and realistic textures without segmentation map input; and \r\n* (ii) how to create a background and weave it seamlessly into standalone objects. \r\n\r\nTo tackle this, we propose Background Hallucination Generative Adversarial Network (BachGAN), which first selects a set of segmentation maps from a large candidate pool via a background retrieval module, then encodes these candidate layouts via a background fusion module to hallucinate a suitable background for the given objects.","links":[{"article_link":"","code_link":"https://github.com/Cold-Winter/BachGAN","research_link":"https://arxiv.org/abs/2003.11690","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":137,"title":"Debugging Neural Networks with PyTorch and W&B","description":"A closer look at debugging common issues when training neural networks.","tags":["article","code","tutorial","pytorch","debugging","experiment-tracking","wandb"],"details":"\u2022\u00a0In this post, we\u2019ll see what makes a neural network underperform and ways we can debug this by visualizing the gradients and other parameters associated with model training. We\u2019ll also discuss the problem of vanishing and exploding gradients and methods to overcome them.\r\n* Finally, we\u2019ll see why proper weight initialization is useful, how to do it correctly, and dive into how regularization methods like dropout and batch normalization affect model performance.","links":[{"article_link":"https://app.wandb.ai/ayush-thakur/debug-neural-nets/reports/Debugging-Neural-Networks-with-PyTorch-and-W&B--Vmlldzo2OTUzNA","code_link":"https://github.com/ayulockin/debugNNwithWandB","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":136,"title":"Finetune: Scikit-learn Style Model Finetuning for NLP","description":"Finetune is a library that allows users to leverage state-of-the-art pretrained NLP models for a wide variety of downstream tasks.","tags":["code","scikit-learn","transformers","library","language-modeling","natural-language-processing","finetuning","pretraining"],"details":"Finetune currently supports TensorFlow implementations of the following models:\r\n\r\n* BERT, from \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\"\r\n* RoBERTa, from \"RoBERTa: A Robustly Optimized BERT Pretraining Approach\"\r\n* GPT, from \"Improving Language Understanding by Generative Pre-Training\"\r\n* GPT2, from \"Language Models are Unsupervised Multitask Learners\"\r\n* TextCNN, from \"Convolutional Neural Networks for Sentence Classification\"\r\n* Temporal Convolution Network, from \"An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling\"\r\n* DistilBERT from \"Smaller, faster, cheaper, lighter: Introducing DistilBERT, a distilled version of BERT\"","links":[{"article_link":"","code_link":"https://github.com/IndicoDataSolutions/finetune","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://finetune.indico.io/"}]},{"id":135,"title":"The Illustrated SimCLR Framework","description":"A visual introduction to SimCLR: A Simple Framework for Contrastive Learning of Visual Representations.","tags":["article","paper","research","tutorial","self-supervised-learning","simclr","illustrated","contrastive-learning","arxiv:2002.05709"],"details":"* Explain key ideas of the SimCLR framework proposed in the research paper using diagrams.\r\n* Walkthrough a step-by-step example, downstream tasks and compare objective results.","links":[{"article_link":"https://amitness.com/2020/03/illustrated-simclr/","code_link":"","research_link":"https://arxiv.org/abs/2002.05709","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":134,"title":"Advanced Native Python Features Behind PyTorch","description":"Learn about the advanced python native features powering the PyTorch API","tags":["article","tutorial","python","pytorch"],"details":"* Explain how PyTorch borrows native Python features in its API design\r\n* Understand behind the scenes working of magic methods\r\n* Understand why we write code specific way in PyTorch Models, DataLoader and Dataset","links":[{"article_link":"https://amitness.com/2020/03/python-magic-behind-pytorch/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":133,"title":"A Survey of Long-Term Context in Transformers","description":"Over the past two years the NLP community has developed a veritable zoo of methods to combat expensive multi-head self-attention.","tags":["article","tutorial","attention","transformers","natural-language-processing","multi-head-attention"],"details":"In this post we'll focus on six promising approaches:\r\n\u2022\u00a0Sparse Transformers\r\n\u2022\u00a0Adaptive Span Transformers\r\n\u2022\u00a0Transformer-XL\r\n\u2022\u00a0Compressive Transformers\r\n\u2022\u00a0Reformer\r\n\u2022\u00a0Routing Transformer","links":[{"article_link":"https://www.pragmatic.ml/a-survey-of-methods-for-incorporating-long-term-context/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":132,"title":"Driver and Car Monitoring.","description":"Understand driver's behavior and car control inside a vehicle.\r\nThis will help us to know how good does it drive, are the roads faulty, accident prone spots, etc","tags":["code","tutorial","tensorflow","deep-learning","tensorflow-lite","gis"],"details":"Activity recognition for driver inside the car.\r\n\r\nOptimized and quantized using tensorflow lite.\r\nDeployed on Raspberry Pi 4B +. Worked around 3fps.\r\n\r\nUse sensor data from driver's mobile to detect his current driving statistics.\r\nWe have collected and cleaned the data.\r\nWe are building a model to accurately forecast driver's control on car.\r\nThis can help us detect the state of the road as well as driver's grip and control depends on road.\r\nThis too will run on edge IoT device.\r\n\r\nGis Mapping\r\nImplementing Gis mapping to mark on world map where we have vulnerable spots for driving.\r\nUsing the above two data we can mark using folium api where such dangerous spots for driving occur.\r\nWe have used the folium api and are able to map to world map.\r\nWe would obtain the location from edge IoT device.\r\n","links":[{"article_link":"","code_link":"https://github.com/oke-aditya/Deep_Drive","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":131,"title":"EfficientDet: Scalable and Efficient Object Detection","description":"Implementation EfficientDet: Scalable and Efficient Object Detection in PyTorch.","tags":["code","paper","research","tutorial","pytorch","computer-vision","object-detection","efficientdet","arxiv:1911.09070"],"details":"EfficientDets are a family of object detection models, which achieve state-of-the-art accuracy, yet being an order-of-magnitude smaller and more efficient than previous models. EfficientDets are developed based on the advanced backbone, a new BiFPN, and a new scaling technique:\r\n* Backbone: we employ the more advanced EfficientNets as our backbone networks.\r\n* BiFPN: we propose a new bi-directional feature network, named \u2022\u00a0BiFPN, to enable easy and fast feature fusion. In addition to the bi-directional topology, we also propose a new fast normalized fusion that enables better fusion with negligible latency cost.\r\n* Scaling: we propose to use a single compound scaling factor to govern the network depth, width, and resolution for all backbone, feature network, and prediction networks.","links":[{"article_link":"","code_link":"https://github.com/toandaominh1997/EfficientDet.Pytorch","research_link":"https://arxiv.org/abs/1911.09070","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":130,"title":"Gymnast Pose Analysis","description":"Pose modelling for gymnasts using open-pose and open-cv.\r\n","tags":["code","tutorial","computer-vision","pose-estimation","pose-tracking","open-cv"],"details":"* Used openpose to generate graph for poses. I then converted this to a stick figure in red with black background (looks really good).\r\n* Used the shi-thomasi-corner detector to again detect the movement in joints of gymnasts. \r\n* Exported this graphs as networkx graph. This would reduce pose-modelling to graph problems such as min-cut.","links":[{"article_link":"","code_link":"https://github.com/oke-aditya/Gymnast_Analysis","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":129,"title":"Neural Encryption Networks","description":"I used a multiple autoencoders to effectively encode and encrypt text data.\r\nThese provide encryption for user defined bits.\r\nAs proof of concept 8 and 9 bit done","tags":["code","tutorial","deep-learning","machine-learning","cyber-security","neural-cryptography"],"details":"* Implemented a random hashing mechanism which hashes every utf encoding character to a random n bit character.\r\n* Weights and architecture of neural network are private keys.\r\n* Neural network ordering is public key.\r\n* Train multiple auto-enocoders that can encrypt this data.\r\n* Run them parallely to provide n bit fast encryption.\r\n* Hard to break encryption, as a word encrypted with letters of 8 bit 9 bit and 17 bit, which leads to exponential combinatorics problems.","links":[{"article_link":"","code_link":"https://github.com/oke-aditya/Neurex","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":128,"title":"Multimodal Brain Tumor Segmentation","description":"Segmentation of gliomas in pre-operative MRI scans. Use the provided clinically-acquired training data to produce segmentation labels.","tags":["code","tutorial","computer-vision","medical-imaging","semantic-segmentation","u-net","tumor-segmentation","segmentation"],"details":"Segmentation of gliomas in pre-operative MRI scans. Use the provided clinically-acquired training data to produce segmentation labels.\r\n","links":[{"article_link":"","code_link":"https://github.com/as791/Multimodal-Brain-Tumor-Segmentation","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":127,"title":"OSMI Mental Health Analysis","description":"Analyzing how healthy people are Mentally in Tech Sector.","tags":["code","tutorial","mental-health-care","mental-health"],"details":"","links":[{"article_link":"","code_link":"https://github.com/oke-aditya/Mental_Health_Analysis","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":126,"title":"Unet Implementation is Keras with GPU","description":"Vector Map generation from aerial imagery using deep learning GeoSpatial UNET","tags":["code","paper","research","tutorial","computer-vision","geospatial","satellite","uav"],"details":"We propose a simple yet efficient technique to leverage semantic segmentation model to extract and separate individual buildings in densely compacted areas using medium resolution satellite/UAV orthoimages. We adopted standard UNET architecture, additionally added batch normalization layer after every convolution, to label every pixel in the image. The result obtained is fed into proposed post-processing pipeline for separating connected binary blobs of buildings and converting it into GIS layer for further analysis as well as for generating 3D buildings. The proposed algorithm extracts building footlogging.infos from aerial images, transform semantic to instance map and convert it into GIS layers to generate 3D buildings. We integrated this method in Indshine\u2019s cloud platform to speed up the process of digitization, generate automatic 3D models, and perform the geospatial analysis. Our network achieved ~70% Dice coefficient for the segmentation process.","links":[{"article_link":"","code_link":"https://github.com/ManishSahu53/Vector-Map-Generation-from-Aerial-Imagery-using-Deep-Learning-GeoSpatial-UNET","research_link":"https://www.isprs-ann-photogramm-remote-sens-spatial-inf-sci.net/IV-2-W5/157/2019/","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":125,"title":"TensorWatch","description":"TensorWatch is a debugging and visualization tool designed for data science, deep learning and reinforcement learning from Microsoft Research. It works in Jupyt","tags":["article","code","paper","research","library","visualization","debugging","monitoring","arxiv:2001.01215"],"details":"* Build Jupyter Notebook based tool for monitoring ML training\r\n* Enable interactive debugging\r\n* Allow log-less on-demand monitoring","links":[{"article_link":"https://www.microsoft.com/en-us/research/blog/microsoft-makes-ai-debugging-and-visualization-tool-tensorwatch-open-source/","code_link":"https://github.com/microsoft/tensorwatch","research_link":"https://arxiv.org/abs/2001.01215","media_link":"","dataset_link":"","demo_link":"","other_link":"http://tensorwatch.com"}]},{"id":124,"title":"Unsupervised Toolbox","description":"Unsupervised learning Tool box : A micro framework for State of the Art Methods and models for unsupervised learning for NLU / NLG\r\n","tags":["code","autoencoders","library","clustering","embeddings","natural-language-processing","question-answering","question-generation","question-similarity","unsupervised-learning","text-similarity"],"details":"Features:\r\n\r\n* Semantic similarity with context-aware attention\r\n* State of the art embeddings for text dataset\r\n* From NLU to NLG : Question Generation\r\n* Question Answering\r\n* Deep Learning Clustering\r\n* Autoencoders, Latent representation","links":[{"article_link":"","code_link":"https://github.com/monk1337/Unbox","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":123,"title":"Using Different Decoding Methods for LM with Transformers","description":"A look at different decoding methods for generate subsequent tokens in language modeling.","tags":["article","code","notebook","tutorial","huggingface","transformers","language-modeling","natural-language-processing","decoder","greedy-search","beam-search","sampling","survey"],"details":"This blog post gives a brief overview of different decoding strategies and more importantly shows how you can implement them with very little effort using the popular transformers library!","links":[{"article_link":"https://huggingface.co/blog/how-to-generate","code_link":"https://colab.research.google.com/github/huggingface/blog/blob/master/notebooks/02_how_to_generate.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":122,"title":"Custom Classifier on Top of Bert-like Language Model","description":"Take pre-trained language model and build custom classifier on top of it.","tags":["article","code","tutorial","pytorch","attention","bert","transformers","language-modeling","natural-language-processing","sentiment-analysis","pytorch-lightning","polberta"],"details":"* Taking existing pre-trained language model and understanding it\u2019s output - here I use PolBERTa trained for Polish language.\r\n* Building custom classification head on top of the LM.\r\n* Using fast tokenizers to efficiently tokenize and pad input text as well as prepare attention masks.\r\n* Preparing reproducible training code with PyTorch Lightning.\r\n* Finding good starting learning rate for the model.\r\n* Validating the trained model on PolEmo 2.0 dataset (benchmark for Polish language sentiment analysis with 4 classes).","links":[{"article_link":"https://zablo.net/blog/post/custom-classifier-on-bert-model-guide-polemo2-sentiment-analysis/","code_link":"https://github.com/marrrcin/transformers-sentiment-analysis","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://pytorch-lightning.readthedocs.io/en/0.7.1/"}]},{"id":121,"title":"Deep Reinforcement Learning in TensorFlow2","description":"deep-rl-tf2 is a repository that implements a variety of polular Deep-RL algorithms using TF2. The key to this repo is an easy to understand code. ","tags":["code","tutorial","tensorflow","reinforcement-learning"],"details":"deep-rl-tf2 is a repository that implements a variety of popular Deep Reinforcement Learning algorithms using TensorFlow2. The key to this repository is an easy-to-understand code. Therefore, if you are a student or a researcher studying Deep Reinforcement Learning, I think it would be the **best choice to study** with this repository. One algorithm relies only on one python script file. So you don't have to go in and out of different files to study specific algorithms. This repository is constantly being updated and will continue to add a new Deep Reinforcement Learning algorithm.","links":[{"article_link":"","code_link":"https://github.com/marload/deep-rl-tf2","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":120,"title":"Gliding Vertex on Horizontal Bounding Box for Object Detection","description":"Gliding vertex on the horizontal bounding box for multi-oriented object detection.","tags":["code","paper","research","pytorch","computer-vision","object-detection","rcnn","multi-oriented-object","aerial-image","scene-text","pedestrian-detection","maskrcnn","arxiv:1911.09358"],"details":"Widely adopted horizontal bounding box representation is not appropriate for ubiquitous oriented objects such as objects in aerial images and scene texts. In this paper, we propose a simple yet effective framework to detect multi-oriented objects. Instead of directly regressing the four vertices, we glide the vertex of the horizontal bounding box on each corresponding side to accurately describe a multi-oriented object. ","links":[{"article_link":"","code_link":"https://github.com/MingtaoFu/gliding_vertex","research_link":"https://arxiv.org/abs/1911.09358","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":119,"title":"Self-Supervision with FastAI","description":"A tutorial of rotation-based self-supervision using FastAI2 & PyTorch!","tags":["article","code","notebook","tutorial","fastai","pytorch","self-supervised-learning"],"details":"Using self-supervision can help learn features that can transfer to a down-stream task, such as classification! In this example, we used rotation predication as our pretext task for feature representation learning. Pretraining our model on rotation prediction prior to training for classification allowed us to achieve 61.7% accuracy, on just 0.3% of the labeled data (180 samples)! Training from scratch with the same amount of data yields an accuracy of 13%. The motivation for using self-supervised learning is the ability to train models with decent accuracy without the need of much labeled data!","links":[{"article_link":"https://amarsaini.github.io/Epoching-Blog/jupyter/2020/03/23/Self-Supervision-with-FastAI.html","code_link":"https://github.com/AmarSaini/Epoching-Blog/blob/master/_notebooks/2020-03-23-Self-Supervision-with-FastAI.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":118,"title":"Sinext","description":"Sign language to text with OpenCV and MNIST sign-language dataset","tags":["code","tutorial","computer-vision","opencv","sign-language"],"details":"The original MNIST image dataset of handwritten digits is a popular benchmark for image-based machine learning methods but researchers have renewed efforts to update it and develop drop-in replacements that are more challenging for computer vision and original for real-world applications.","links":[{"article_link":"","code_link":"https://github.com/Geektrovert/sinext","research_link":"","media_link":"https://www.kaggle.com/datamunge/sign-language-mnist","dataset_link":"","demo_link":"","other_link":""}]},{"id":117,"title":"SiamFC++: Towards Robust and Accurate Visual Tracking","description":"Implementation of a series of basic algorithms which is useful for video understanding, including Single Object Tracking (SOT), Video Object Segmentation (VOS).","tags":["code","paper","research","video","pytorch","computer-vision","segmentation","arxiv:1911.06188"],"details":"In this work, we address the task of semi-supervised video object segmentation(VOS) and explore how to make efficient use of video property to tackle the challenge of semi-supervision. We propose a novel pipeline called State-Aware Tracker(SAT), which can produce accurate segmentation results with real-time speed. For higher efficiency, SAT takes advantage of the inter-frame consistency and deals with each target object as a tracklet. For more stable and robust performance over video sequences, SAT gets awareness for each state and makes self-adaptation via two feedback loops. One loop assists SAT in generating more stable tracklets.","links":[{"article_link":"","code_link":"https://github.com/MegviiDetection/video_analyst","research_link":"https://arxiv.org/abs/1911.06188","media_link":"https://www.youtube.com/watch?v=TCziWahnXT8","dataset_link":"","demo_link":"","other_link":""}]},{"id":116,"title":"PCDet: 3D Point Cloud Detection","description":"PCDet Toolbox in PyTorch for 3D Object Detection from Point Cloud","tags":["code","paper","research","tutorial","pytorch","convolutional-neural-networks","autonomous-vehicles","computer-vision","object-detection","point-cloud-generation","3d-object-detection","arxiv:1907.03670"],"details":"PCDet is a general PyTorch-based codebase for 3D object detection from point cloud. It currently supports several state-of-the-art 3D object detection methods (PointPillar, SECOND, Part-A^2 Net) with highly refactored codes for both one-stage and two-stage frameworks.","links":[{"article_link":"","code_link":"https://github.com/sshaoshuai/PCDet","research_link":"https://arxiv.org/abs/1907.03670","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":115,"title":"SOLT: Data Augmentation for Deep Learning","description":"Data augmentation library for Deep Learning, which supports images, segmentation masks, labels and key points.","tags":["code","pytorch","deep-learning","library","computer-vision","data-augmentation","segmentation"],"details":"* Support of Images, masks and keypoints for all the transforms (including multiple items at the time)\r\n* Fast and PyTorch-integrated\r\n* Convenient and flexible serialization API\r\n* Excellent documentation\r\n* Easy to extend\r\n* 100% Code coverage","links":[{"article_link":"","code_link":"https://github.com/MIPT-Oulu/solt","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://mipt-oulu.github.io/solt/"}]},{"id":114,"title":"Transformer OCR","description":"Rectification-free OCR using spatial attention from Transformers.","tags":["code","paper","research","tutorial","attention","transformers","computer-vision","natural-language-processing","optical-character-recognition","arxiv:2003.08077"],"details":"Scene text recognition with arbitrary shape is very challenging due to large variations in text shapes, fonts, colors, backgrounds, etc. Most state-of-the-art algorithms rectify the input image into the normalized image, then treat the recognition as a sequence prediction task. The bottleneck of such methods is the rectification, which will cause errors due to distortion perspective. In this paper, we find that the rectification is completely unnecessary. What all we need is the spatial attention.","links":[{"article_link":"","code_link":"https://github.com/fengxinjie/Transformer-OCR","research_link":"https://arxiv.org/abs/2003.08077","media_link":"","dataset_link":"","demo_link":"","other_link":"http://nlp.seas.harvard.edu/2018/04/03/attention.html"}]},{"id":113,"title":"AI for 3D Generative Design","description":"Making the design process faster and more efficient by generating 3D objects from natural language descriptions.","tags":["article","code","research","tutorial","autoencoders","variational-autoencoders","3d","computer-vision","natural-language-processing"],"details":"Using semi-supervised learning to encode the prior knowledge in a way that can be interacted with intuitively would allow designers to iterate faster, make fewer mistakes, and more deeply explore the design space.","links":[{"article_link":"https://blog.insightdatascience.com/ai-for-3d-generative-design-17503d0b3943","code_link":"https://github.com/starstorms9/shape","research_link":"","media_link":"https://insight2020a.streamlit.io/starstorms9/shape/","dataset_link":"","demo_link":"","other_link":"https://docs.google.com/presentation/d/1u9Iq2nyES0Rx55F-Nn02x4phViBae2Ps4181UONW_DI/edit#slide=id.g6f46c32e9d_0_608"}]},{"id":112,"title":"Learning to See before Learning to Act: Visual Pre-training","description":"We find that pre-training on vision tasks significantly improves generalization and sample efficiency for learning to manipulate objects.","tags":["article","code","paper","research","video","pytorch","tensorflow","computer-vision","robotics","transfer-learning","affordance","nerf"],"details":"Does having visual priors (e.g. the ability to detect objects) facilitate learning to perform vision-based manipulation (e.g. picking up objects)? We study this problem under the framework of transfer learning, where the model is first trained on a passive vision task, and adapted to perform an active manipulation task. We find that pre-training on vision tasks significantly improves generalization and sample efficiency for learning to manipulate objects. However, realizing these gains requires careful selection of which parts of the model to transfer. Our key insight is that outputs of standard vision models highly correlate with affordance maps commonly used in manipulation. Therefore, we explore directly transferring model parameters from vision networks to affordance prediction networks, and show that this can result in successful zero-shot adaptation, where a robot can pick up certain objects with zero robotic experience.","links":[{"article_link":"https://ai.googleblog.com/2020/03/visual-transfer-learning-for-robotic.html","code_link":"https://github.com/yenchenlin/vision2action","research_link":"https://drive.google.com/file/d/1D0d2plVlvdk0ltGSTK7940TCs3CGTgKy/view","media_link":"https://www.youtube.com/embed/7tFO2V0sYJg","dataset_link":"","demo_link":"","other_link":"https://yenchenlin.me/vision2action/"}]},{"id":111,"title":"Docker Job Queue","description":"A RabbitMq based job queuing system to run docker as jobs.","tags":["code","docker","library","queue","rabbitmq"],"details":"\u2022\u00a0Make the docker command take basic arguments and run\r\n\u2022\u00a0Make the MEMORY requirement check\r\n\u2022\u00a0Make the CPU requirement check\r\n\u2022\u00a0Make the messages durable and stay across restarts.","links":[{"article_link":"","code_link":"https://github.com/sagarkar10/JobQueue","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":110,"title":"Gitjk: Undo What You Just Did in Git","description":"If you just ran a git command that you didn't mean to, this program will either undo it, tell you how to undo it, or tell you it's impossible to undo. ","tags":["code","git","library"],"details":"Included:\r\nadd, archive, branch, cat-file, checkout, clone, commit, diff, fetch, grep, init, log, ls-tree, merge, mv, pull, push, remote, revert, rm, show, stash, status\r\n\r\nNot included:\r\nbisect, fsck, gc, prune, rebase, reset, tag","links":[{"article_link":"","code_link":"https://github.com/mapmeld/gitjk","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.npmjs.com/package/gitjk"}]},{"id":109,"title":"iyasai: Book Recommendation System","description":"Recommender system for books and stories that could help you and your loved ones lift up your mood whenever you are facing stress or unpleasant situations.","tags":["code","tutorial","flask","natural-language-processing","recommendation-systems"],"details":"iyas.ai (from the Japanese word 'iyasu', which means healing) is a recommender system for books and stories that could help you and your loved ones lift up your mood whenever you are facing stress or unpleasant situations. Just type in how you are feeling and we will suggest a (few) books or stories that might just brighten up your day.\r\n\r\n\u2022\u00a0Goodreads: I scraped 50000 books from Goodreads' 'Best Books Ever' list with their titles, authors, and descriptions.\r\n* The Novel Cure by Ella Berthoud and Susan Elderkin: this is where the inspiration for this project came from. Ella and Susan have created a marvelous list of books for you to read through your difficult times. However, there are only 751 books mentioned in The Novel Cure. I believe no literary experts could have read through the entirety of human literature, and so some machine learning 'magic' could step in and help guide you through your search for the perfect books.","links":[{"article_link":"","code_link":"https://github.com/nolanvo5894/iyasai","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"http://iyasai.me"}]},{"id":108,"title":"Tuned ALBERT (ensemble model)","description":"Top 6 in Squad 2.0","tags":["code","research","tutorial","natural-language-processing","question-answering","albert","squad"],"details":"**Tuned Albert**:\r\n\r\n* Base Network(Transformer)\r\n* Albert Architecture (Multi Headed Self Attention)\r\n* QA Layer Architecture\r\n* Parameter Tuning\r\n\r\n**Ensembling Strategy**:\r\n\r\n* Model 1 - with full dataset\r\n* Model 2 \u2013 Model 1 + Additional Dataset of specific Class\r\n* Bagging Technique","links":[{"article_link":"","code_link":"https://github.com/Ankur3107/squad-submission","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://rajpurkar.github.io/SQuAD-explorer/"}]},{"id":107,"title":"Plant Fruit Classifier","description":"Building a world-class image classifier model with a custom dataset.","tags":["article","code","tutorial","fastai","computer-vision","image-collection"],"details":"So, I just watched the Lesson 1 video in the course. Jeremy claims anyone can create a world-class image classification model in just 4 lines of code. So I decided to give a try to see if it\u2019s true. Although I know Deep Learning, I\u2019m just pretending as if I don\u2019t know anything about deep learning and following the steps taught in the course.","links":[{"article_link":"https://medium.com/@leslyarun/create-a-plants-fruits-image-classifier-using-fastai-v1-in-colab-3df42bb4a775","code_link":"https://github.com/leslyarun/plant-fruit-classifier","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":105,"title":"Grape","description":"GRAPE is a regression API in Python environment","tags":["api","code","python","regression","library"],"details":"GRAPE makes it easy to fit a regression model with hyperparameter optimization. It strings together the workflow of model fitting, hyperparameter tuning, and model diagnostics. \r\n\r\nAvailable Regression Methods\r\n* Elastic Net (from sklearn)\r\n\u2022\u00a0Random Forest (from sklearn)\r\n\u2022\u00a0xgboost\r\n\u2022\u00a0lightgbm\r\n\u2022\u00a0Hyperparameter Optimization","links":[{"article_link":"","code_link":"https://github.com/joshuacortez/grape","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":104,"title":"Spotify Recommendation Engine","description":"Web app that implements a basic version of Spotify's Discover Weekly.","tags":["article","code","tutorial","video","scikit-learn","music","recommendation-systems","spotify","firebase","flutter"],"details":"A common task of recommender systems is to improve customer experience through personalized recommendations based on prior implicit feedback. These systems passively track different sorts of user behavior, such as purchase history, watching habits and browsing activity, in order to model user preferences. Unlike the much more extensively researched explicit feedback, we do not have any direct input from the users regarding their preferences. In particular, we lack substantial evidence on which products consumer dislike. In this work we identify unique properties of implicit feedback datasets. We propose treating the data as indication of positive and negative preference associated with vastly varying confidence levels. This leads to a factor model which is especially tailored for implicit feedback recommenders. We also suggest a scalable optimization procedure, which scales linearly with the data size. The algorithm is used successfully within a recommender system for television shows. It compares favorably with well tuned implementations of other known methods. In addition, we offer a novel way to give explanations to recommendations given by this factor model.","links":[{"article_link":"https://github.com/ucalyptus/Spotify-Recommendation-Engine/blob/master/Implicit-Matrix-Factorization.md","code_link":"https://github.com/ucalyptus/Spotify-Recommendation-Engine","research_link":"","media_link":"https://www.youtube.com/watch?v=otrW8brCAiU","dataset_link":"","demo_link":"","other_link":"https://ucalyptus.github.io/Spotify-Recommendation-Engine/"}]},{"id":103,"title":"Dupre","description":"Dupre provides an easy-to-use UI that simplifies the task of finding exact and near- duplicates in an image.","tags":["code","research","tutorial","tensorflow","convolutional-neural-networks","deep-learning","duplicate-detection"],"details":"* Find similar and exact duplicate images in a folder\r\n* One-click delete duplicate photos\r\n* Reduce storage space of photos","links":[{"article_link":"","code_link":"https://github.com/amolnaik/dupre","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://idealo.github.io/imagededup/"}]},{"id":102,"title":"Deep Learning with Fashion MNIST dataset using Keras","description":"The project is a basic project where a sequential artificial neural network has been created to solve the famous Fashion MNIST dataset. ","tags":["code","tutorial","keras","tensorflow","deep-learning","feed-forward-neural-networks"],"details":"* Get started with deep learning\r\n* Create a Keras model using its Sequential API\r\n","links":[{"article_link":"","code_link":"https://github.com/adamdavis99/Fashion_MNIST_with_Keras","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":101,"title":"ELECTRA: Pre-training Text Encoders as Discriminators","description":"PyTorch implementation of the electra model from the paper: ELECTRA - Pre-training Text Encoders as Discriminators Rather Than Generators","tags":["code","paper","research","pytorch","transformers","language-modeling","natural-language-processing","discriminators","generators"],"details":"PyTorch implementation of the electra model from the paper: ELECTRA - Pre-training Text Encoders as Discriminators Rather Than Generators. This pre-training method proves to be significantly more efficient and than masked language modeling.","links":[{"article_link":"","code_link":"https://github.com/lonePatient/electra_pytorch","research_link":"https://openreview.net/pdf?id=r1xMH1BtvB","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":99,"title":"Gender Change of People's Face using CycleGAN","description":"CycleGAN architecture in Keras and train the model with CelebA faces dataset to perform gender change on people's faces.","tags":["article","code","research","tutorial","keras","generative-adversarial-networks","computer-vision","cyclegan","celeba"],"details":"The goal of this project is to change the gender of a person's face using a CycleGAN architecture.","links":[{"article_link":"https://github.com/rangasaishreyas/facegenderswap/blob/master/EE599___Project_Report.pdf","code_link":"https://github.com/rangasaishreyas/facegenderswap","research_link":"","media_link":"http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html","dataset_link":"","demo_link":"","other_link":""}]},{"id":98,"title":"Bachelorette Predictor","description":"Predict the Bachelorette winners from profile images.","tags":["code","tutorial","fastai","computer-vision","facial-recognition"],"details":"This code seeks to predict the winner of the Bachelorette from the contestant's headshots.","links":[{"article_link":"","code_link":"https://github.com/dan-jacobson/bachelorette_predictor","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":97,"title":"Graph Convolution on Structured Documents","description":"Convert structured documents to graphs for document entity classification.","tags":["code","tutorial","graph-convolutional-networks","computer-vision","graph-neural-networks","graphs","optical-character-recognition","document-processing"],"details":"This repo contains code to convert Structured Documents to Graphs and implement a Graph Convolution Neural Network (incomplete) for Node Classification, each node being an entity in the document.","links":[{"article_link":"","code_link":"https://github.com/thisisbhavin/graphicalForest","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":96,"title":"Markov Tweet Bot","description":"Auto tweeting bot that amplifies tweets and writes tweets using a Markov chain.","tags":["code","tutorial","hidden-markov-models","bots"],"details":"Using Markov Chain in text generator has following advantages:\r\n\u2022\u00a0It has simple structure so you can easily understand the principle.\r\n* It works well enough if the corpus has the similar context of data as the sentence you want to generate.\r\n* You don't need any complex Neural networks to set this up.","links":[{"article_link":"","code_link":"https://github.com/Aabhash/markov-tweet-bot","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":94,"title":"Visualizing Towed vehicles in Montreal","description":"The data show vehicles towed by the City of Montreal since 2016. Towing is performed for example during snow removal, construction work or during special events","tags":["code","paper","research","tutorial","streamlit"],"details":"Web app tutorial project made with streamlit. You can use Streamlit to create interactive Data Science pages, deployable to the web through all major deployment surfaces.\r\n","links":[{"article_link":"","code_link":"https://github.com/louiswillems/Towed-vehicles-in-Montreal","research_link":"http://donnees.ville.montreal.qc.ca/dataset/remorquages-de-vehicules-genants/resource/e62322fb-3e14-4ee0-b724-a77190dac8e7","media_link":"https://towed-vehicles-montreal.herokuapp.com/","dataset_link":"","demo_link":"","other_link":""}]},{"id":93,"title":"Music Genre Classification with Deep Learning","description":"Custom music genre classification system with our own genres and data.","tags":["code","tutorial","tensorflow","deep-learning","music-classification","conv-lstm"],"details":"In this project we adapt the model from Choi et al. to train a custom music genre classification system with our own genres and data. The model takes as an input the spectogram of music frames and analyzes the image using a Convolutional Neural Network (CNN) plus a Recurrent Neural Network (RNN). The output of the system is a vector of predicted genres for the song.\r\n\r\nWe fine-tuned their model with a small dataset (30 songs per genre) and test it on the GTZAN dataset providing a final accuracy of 80%.","links":[{"article_link":"","code_link":"https://github.com/vs74/Music-Genre-Classificattion-Using-Deep-Learning-","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":92,"title":"Image Spam Buster - Kreate Hackathon","description":"\"Spam Buster\" for user generated IMAGE content.","tags":["code","tutorial","web-services","computer-vision","image-processing","spam-filtering","application"],"details":"Build a \"Spam Buster\" for user generated IMAGE content which includes promotional texts containing images, vulgar images, etc.\r\n\r\nThe \"Spam Buster\" would need to analyze at image level, identify text components inside image and build appropriate logic to give a score to the image.\r\n\r\nA similar use case is employed by Facebook Ads technology to identify if the image ad contains too much text or contains any objectionable text.\"","links":[{"article_link":"","code_link":"https://github.com/shwetkm/image-spam-buster-kreate-hackathon","research_link":"","media_link":"https://raw.githubusercontent.com/shwetkm/image-spam-buster-kreate-hackathon/master/app_demo.gif","dataset_link":"","demo_link":"","other_link":""}]},{"id":91,"title":"Pytest Board","description":"Continuous pytest runner with awesome visualization.","tags":["code","library","unit-tests","pytest","testing"],"details":"pytest-board is a testing visualization tool for pytest runner. Works with ptb. Use it instead of py.test.","links":[{"article_link":"","code_link":"https://github.com/kuss/pytest-convey","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":90,"title":"Sum of 3 Palindromes using ML","description":"Representing any number as the sum of three palindromes using ML.","tags":["code","paper","research","tutorial","machine-learning","puzzles","palindromes","arxiv:1602.06208"],"details":"I have always thought about using an overfitted model for something , There should be something it should be good for right so my approach is to scrape data from that site above to make a huge dataset of number and its respective palindromes and train some multi-output regression models specifically where I would want to overfit on the training set, as it has a mathematical formula behind it to solve as represented in the research paper, that's why I think a deep neural network can reproduce this same thing if we overfit it.","links":[{"article_link":"","code_link":"https://github.com/biswaroop1547/Any_num_as_sum_of_three_palindromes_using_ML","research_link":"https://arxiv.org/abs/1602.06208","media_link":"","dataset_link":"","demo_link":"","other_link":"http://www.rnta.eu/cgi-bin/three_palindromes/pal3.py"}]},{"id":89,"title":"Rethinking Batch Normalization in Transformers","description":"We found that NLP batch statistics exhibit large variance throughout training, which leads to poor BN performance.","tags":["paper","research","tutorial","transformers","natural-language-processing","power-normalization","batch-normalization","normalization","arxiv:2003.07845"],"details":"Ever wondered why BN is not used in NLP? We found that NLP batch statistics exhibit large variance throughout training, which leads to poor BN performance. To address this, we propose Power Norm that achieves SOTA vs. LN/BN. ","links":[{"article_link":"","code_link":"","research_link":"https://arxiv.org/abs/2003.07845","media_link":"https://twitter.com/shengs1123/status/1240730615344844801","dataset_link":"","demo_link":"","other_link":""}]},{"id":88,"title":"Recurrent Independent Mechanisms","description":"An implementation of Recurrent Independent Mechanisms (Goyal et al. 2019) in PyTorch.","tags":["code","paper","research","tutorial","pytorch","recurrent-independent-mechanisms","arxiv:1909.10893"],"details":"This paper aims to build models that can generalize to different environments with specific factors of variation from the environment that it was trained on. To achieve this the authors build recurrent networks that are modular in nature and each module is independent of the other modules and only interact sparsely through attention. In this way each module can learn different aspects of the environment and is only responsible for ensuring similar performance on the same aspect of a different environment.","links":[{"article_link":"","code_link":"https://github.com/dido1998/Recurrent-Independent-Mechanisms","research_link":"https://arxiv.org/abs/1909.10893","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":86,"title":"Anchor Boxes with KMeans","description":"Initial anchor boxes estimation using kmeans clustering for Faster-RCNN.","tags":["article","code","paper","research","tutorial","tensorflow","convolutional-neural-networks","clustering","rcnn","kmeans","faster-rcnn","arxiv:1506.01497"],"details":"When we train Faster RCNN for custom datasets, we often get confused over how to choose hyperparameters for the Network. Anchor boxes (one of the hyperparameters) are very important to detect objects with different scales and aspect ratios. We will get improved detection results if we get the anchors right.","links":[{"article_link":"https://tryolabs.com/blog/2018/01/18/faster-r-cnn-down-the-rabbit-hole-of-modern-object-detection/","code_link":"https://github.com/joydeepmedhi/Anchor-Boxes-with-KMeans","research_link":"https://arxiv.org/abs/1506.01497","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":85,"title":"Message Passing GNNs C++","description":"C++ implementation using Eigen for the forward pass of Graph Convolutional Neural Networks.","tags":["code","tutorial","c++","graph-neural-networks","graphs","message-passing"],"details":"The model doesn't involve any training loops and backpropagation. Pytorch is used to train the GCN model in Python and save the weights learnt after convergence. These saved weights are then imported and used in the C++ implementation of the model for the forward pass on the same dataset.","links":[{"article_link":"","code_link":"https://github.com/AnirudhDagar/MessagePassing_for_GNNs","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":84,"title":"Mention Classifier","description":"Category prediction model\r\nThis repo contains AllenNLP model for prediction of Named Entity categories by its mentions.","tags":["code","tutorial","named-entity-recognition","natural-language-processing","mention-classification"],"details":"Mention classification lays between Named Entity Recognition and Entity Linking.\r\n- It provides much more detailed information about an object than NER does.\r\n- At the same time, it does not require storing and maintaining any knowledge base with known objects.\r\n- The Classifier able to work with absolutely new objects never appeared in the train set.\r\n- The neural net is able to look at up to five mentions simultaneously. It combines evidence more efficient than it could be achieved by averaging individual predictions.","links":[{"article_link":"","code_link":"https://github.com/generall/EntityCategoryPrediction","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://mention-classifier.ml/#/"}]},{"id":83,"title":"Positive and Unlabeled Materials Machine Learning","description":"PUMML is a code that uses semi-supervised machine learning to classify materials from only positive and unlabeled examples.","tags":["code","paper","research","machine-learning","library","semi-supervised-learning","materials","informatics","physics","chemistry","materials-science"],"details":"* Construct a dataset of materials with quantum mechanical simulations using high-performance computing resources.\r\n* Develop a semi-supervised ML model to predict a \"synthesizability\" score for materials.\r\n*  Identify most interesting materials with high synthesizability for laboratory experiments.","links":[{"article_link":"","code_link":"https://github.com/ncfrey/pumml","research_link":"https://pubs.acs.org/doi/abs/10.1021/acsnano.8b08014","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":82,"title":"An Essentials Guide to PyTorch Dataset and DataLoader Usage","description":"A brief guide for basic usage of PyTorch's Dataset and DataLoader classes.","tags":["article","code","dataset","notebook","tutorial","pytorch"],"details":"* Provide a working example with basic code for understanding how PyTorch uses its Dataset and DataLoader classes.","links":[{"article_link":"https://dthiagarajan.github.io/technical_blog/pytorch/2020/03/09/PyTorch-Dataset-and-DataLoaders.html","code_link":"https://github.com/dthiagarajan/technical_blog/blob/master/_notebooks/2020-03-09-PyTorch-Dataset-and-DataLoaders.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":81,"title":"GradCAM for the BreaKHis Dataset","description":"An NBDev package for fine-tuning ResNets to visualize gradient-weighted class activation for the BreaKHis dataset.","tags":["article","code","tutorial","computer-vision","medical-imaging","transfer-learning"],"details":"* Use transfer learning and cyclic learning rate schedules to quickly obtain an accurate classifier for the task\r\n* Use gradient-weighted class activation maps to understand how the classifier is performing\r\n* Use NBDev to wrap the code from notebooks into a package with documentation","links":[{"article_link":"https://dthiagarajan.github.io/breakhis_gradcam/","code_link":"https://github.com/dthiagarajan/breakhis_gradcam","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":80,"title":"NeRF: Neural Radiance Fields","description":"Representing scenes as neural radiance fields for view synthesis.","tags":["article","code","paper","research","video","computer-vision","view-synthesis","5d","arxiv:2003.08934"],"details":"\u2022\u00a0We present a method that achieves state-of-the-art results for synthesizing novel views of complex scenes by optimizing an underlying continuous volumetric scene function using a sparse set of input views.\r\n* Our algorithm represents a scene using a fully-connected (non-convolutional) deep network, whose input is a single continuous 5D coordinate (spatial location (x, y, z) and viewing direction (\u03b8, \u03c6)) and whose output is the volume density and view-dependent emitted radiance at that spatial location.\r\n\r\nTensorFlow: https://github.com/bmild/nerf\r\nPyTorch: https://github.com/yenchenlin/nerf-pytorch","links":[{"article_link":"http://www.matthewtancik.com/nerf","code_link":"https://github.com/bmild/nerf","research_link":"https://arxiv.org/abs/2003.08934","media_link":"https://www.youtube.com/watch?v=JuH79E8rdKc&feature=youtu.be","dataset_link":"","demo_link":"","other_link":"https://drive.google.com/drive/folders/128yBriW1IG_3NJ5Rp7APSTZsJqdJdfc1"}]},{"id":79,"title":"Planar Data Classification","description":"Planar Data Classification with one Hidden Layer , performed using traditional Mathematical approach. ","tags":["code","tutorial","classification","planar-data"],"details":"Planar Data Classification with one Hidden Layer , performed using traditional Mathematical approach. The model achieved an accuracy of 91% with Hidden Layer of size 4.","links":[{"article_link":"","code_link":"https://github.com/infiniteoverflow/Planar-Data-Classification","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":78,"title":"The Illustrated Self-Supervised Learning","description":"A visual introduction to self-supervised learning methods in Computer Vision","tags":["article","tutorial","computer-vision","self-supervised-learning","illustrated"],"details":"* Explain motivation behind self-supervised learning\r\n* Explain the creative ways people have applied self-supervised learning to images in layman terms\r\n* Link relevant papers for each method for further exploration","links":[{"article_link":"https://amitness.com/2020/02/illustrated-self-supervised-learning/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":77,"title":"Sign Language Interpreter using Deep Learning","description":"A sign language interpreter using live video feed from the camera. The project was completed in 24 hours as part of HackUNT-19, the University of North Texas's ","tags":["code","tutorial","video","computer-vision","sign-language"],"details":"The theme at HACK UNT 19 was to use technology to improve accessibility by finding a creative solution to benefit the lives of those with a disability. We wanted to make it easy for 70 million deaf people across the world to be independent of translators for their daily communication needs, so we designed the app to work as a personal translator 24*7 for the deaf people.","links":[{"article_link":"","code_link":"https://github.com/harshbg/Sign-Language-Interpreter-using-Deep-Learning","research_link":"","media_link":"https://www.youtube.com/watch?v=cg_wbt4KTiE#042","dataset_link":"","demo_link":"","other_link":""}]},{"id":75,"title":"Psychopathology FER Assistant","description":"An intelligent assistant platform to track psychopathology patients responses during face-to-face and remote sessions.","tags":["code","tutorial","video","flask","mental-health-care","facial-recognition"],"details":"With a lot of love \ud83d\udc96, motivation to help others \ud83d\udcaa\ud83c\udffc and Python \ud83d\udc0d, using:\r\n\u2022\u00a0Tensorflow 2.0 \r\n\u2022\u00a0Google Colab  (with its wonderful GPUs)\r\n* Model quantization with tf.lite for serving \u2699\ufe0f\r\n\u2022\u00a0A Raspberry Pi Model 3B+ \r\n* A real-time Flask and Dash integration (along with Dash Bootstrap Components)  + \r\n\u2022\u00a0A real-time database, of course, from Firebase \r\n\u2022\u00a0The Kaggle API to get the dataset ","links":[{"article_link":"","code_link":"https://github.com/RodolfoFerro/psychopathology-fer-assistant","research_link":"","media_link":"https://www.youtube.com/watch?v=Y1DfFQbkmYM","dataset_link":"","demo_link":"","other_link":""}]},{"id":74,"title":"K Means using PyTorch","description":"PyTorch implementation of kmeans for utilizing GPU","tags":["article","code","tutorial","pytorch","library","package","kmeans"],"details":"* Useful when clustering large number of samples\r\n* Utilizes GPU for faster matrix computations\r\n* Support euclidean and cosine distances (for now)","links":[{"article_link":"https://subhadarship.github.io/kmeans_pytorch/","code_link":"https://github.com/subhadarship/kmeans_pytorch","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":73,"title":"Face Verification","description":"Implementation of Siamese Neural network model used for face verification. The dataset used for this task is IMDB-WIKI-face images Dataset.","tags":["code","tutorial","siamese-networks","computer-vision","face-detection"],"details":"These two kinds of networks used when labels are very few and for comparing positive labels and negative labels(ranking). only one image is available for 38,614 celebrities out of 50546 celebrities\r\n\r\nThe idea behind a siamese network is that it takes two inputs which need to be compared each other, so we reduce each input into a latent vector representation and compare it using some standard arithmetic. In the case of the Triple Nets, we take three inputs one is the ground truth and compare it with one positive and one negative sample using some standard arithmetic.","links":[{"article_link":"","code_link":"https://github.com/sriharsha0806/Face-Verification","research_link":"","media_link":"https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/","dataset_link":"","demo_link":"","other_link":""}]},{"id":72,"title":"Embedding Java Classes with Code2Vec","description":"Code for the paper \"Obfuscated code2vec: Improving Class-Level Embeddings by Hiding Information\".","tags":["code","tutorial","embeddings","code-analysis"],"details":"This repository contains links to all data and models used in the paper, code for the dataset pipeline, as well as the obfuscation tool used for obfuscating the datasets.","links":[{"article_link":"","code_link":"https://github.com/basedrhys/obfuscated-code2vec","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":71,"title":"Introduction to Python","description":"Quickstart your journey into Python.","tags":["code","paper","research","tutorial","python"],"details":"Hey! The aim of this PDF is to quickstart your journey into Python. It's not an introductin to programming in general, so you should have some basic understanding of common principles.","links":[{"article_link":"","code_link":"https://github.com/koenigscode/python-introduction","research_link":"https://github.com/koenigscode/python-introduction/releases/latest","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":70,"title":"AI for Web Accessibility","description":"Applying AI technologies to make the web more accessible to people who are differently abled.","tags":["article","code","tutorial","machine-learning","accessibility"],"details":"Artificial Intelligence for Web Accessibility which I completed as a part of my MSc in Data Science course in the University of Southampton, UK under the supervision of Prof. Mike Wald","links":[{"article_link":"https://shaunaksen.github.io/AI-for-Web-Accessibility/","code_link":"https://github.com/ShaunakSen/AI-for-Web-Accessibility","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":68,"title":"End-to-end ML Lead Scoring Example using SKlearn","description":"A full machine learning tutorial, from idea to implemented python solution with Jupyter, MLflow, AWS Sagemaker, and Booklet.ai","tags":["article","code","tutorial","scikit-learn","library","lead-scoring","sagemaker","mlflow","booklet-ai"],"details":"* We want to understand features about potential sales leads and understand which of these leads are most likely to turn into paying customers.\r\n* To do this, we use a variety of tools: Jupyer, MLflow, Sagemaker, Booklet.ai","links":[{"article_link":"https://towardsdatascience.com/a-true-end-to-end-ml-example-lead-scoring-f5b52e9a3c80","code_link":"https://github.com/BookletAI/lead-scoring-demo","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":67,"title":"Fruit Detection using Convolution Neural Networks in TensorFlow","description":"Trained a Convolutional Neural Network Model to predict fruits of over 100+ Classes (types) with a training accuracy of over 95%, and testing accuracy of over 9","tags":["code","paper","research","tutorial","keras","tensorflow","convolutional-neural-networks","deep-learning","computer-vision"],"details":"* The Dataset Can be found over : https://www.kaggle.com/moltean/fruits and https://github.com/Horea94/Fruit-Images-Dataset\r\n\u2022\u00a0This is the work of Horea Muresan, Mihai Oltean, Fruit recognition from images using deep learning, Acta Univ. Sapientiae, Informatica Vol. 10, Issue 1, pp. 26-42, 2018.\r\n* The paper introduces the dataset and an implementation of a Neural Network trained to recognized the fruits in the dataset.","links":[{"article_link":"","code_link":"https://github.com/srbhr/Fruits_360","research_link":"https://www.researchgate.net/publication/321475443_Fruit_recognition_from_images_using_deep_learning","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":66,"title":"Securely Storing Configuration Credentials in a Jupyter Notebook","description":"A look at different methods to store configuration credentials in your applications.","tags":["article","tutorial","security","password-management","jupyter","credentials"],"details":"Another issue is that you should never store your passwords in the same place as your code. This comes from one of the core tenets of the 12-factor app, which was written a while back by a group of developers at Heroku and walks through best practices for working with code in the modern age.","links":[{"article_link":"http://veekaybee.github.io/2020/02/25/secrets/","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":65,"title":"Coloring Greyscale Images","description":"Coloring black and white images with neural networks.","tags":["article","code","tutorial","video","generative-adversarial-networks","colorization","computer-vision","image-processing"],"details":"* The network is built in four parts and gradually becomes more complex. The first part is the bare minimum to understand the core parts of the network. It's built to color one image. Once I have something to experiment with, I find it easier to add the remaining 80% of the network.\r\n* For the second stage, the Beta version, I start automating the training flow. In the full version, I add features from a pre-trained classifier. The GAN version is not covered in the tutorial. It's an experimental version using some of the emerging best practices in image colorization.","links":[{"article_link":"https://www.blog.google/technology/ai/creative-coder-adding-color-machine-learning/","code_link":"https://github.com/emilwallner/Coloring-greyscale-images","research_link":"","media_link":"https://www.youtube.com/watch?v=xKPk7tG2upc","dataset_link":"","demo_link":"","other_link":""}]},{"id":64,"title":"Screenshot to Code","description":"Turning design mockups into code with deep learning.","tags":["article","code","tutorial","convolutional-neural-networks","recurrent-neural-networks","web-design"],"details":"In this post, we\u2019ll teach a neural network how to code a basic a HTML and CSS website based on a picture of a design mockup. Here's a quick overview of the process:\r\n1. Give a design image to the trained neural network\r\n2. The neural network converts the image into HTML markup","links":[{"article_link":"https://blog.floydhub.com/turning-design-mockups-into-code-with-deep-learning/","code_link":"https://github.com/emilwallner/Screenshot-to-code","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":63,"title":"Predicting mortgage approvals: EDA and Azure ML Studio","description":"Introductory EDA (Exploratory Data Analysis) on mortgage approvals. Our goal is to explore and analyze the data then we design a predictor on Azure ML Studio","tags":["article","tutorial","azure","machine-learning","classification","exploratory-data-analysis"],"details":"* Data exploratory analysis\r\n* Data Visualization on python\r\n* Model an ML classification problem","links":[{"article_link":"https://medium.com/@edumunozsala/predicting-mortgage-approvals-data-analysis-and-prediction-with-azure-ml-studio-part-1-8629d2f938a8","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":61,"title":"Using JAX to Improve Separable Image Filters","description":"Optimizing the filters to improve the filtered images for computer vision tasks.","tags":["article","code","notebook","tutorial","jax","computer-vision","numpy","separable-filters"],"details":"* How to use JAX (\u201chyped\u201d new Python ML / autodifferentiation library).\r\n* Basic application that is follow-up to my previous blog post on using SVD for low-rank approximations and separable image filters \u2013 we will look at \u201coptimizing\u201d the filters to improve the filtered images.","links":[{"article_link":"https://bartwronski.com/2020/03/15/using-jax-numpy-and-optimization-techniques-to-improve-separable-image-filters/","code_link":"https://colab.research.google.com/github/bartwronski/BlogPostsExtraMaterial/blob/master/optimization_for_separable_filters.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":60,"title":"From PyTorch to JAX","description":"Towards neural net frameworks that purify stateful code.","tags":["article","code","notebook","tutorial","jax","haiku"],"details":"* Quickly recap a stateful LSTM-LM implementation in a tape-based gradient framework, specifically PyTorch.\r\n* See how PyTorch-style coding relies on mutating state, learn about mutation-free pure functions and build (pure) zappy one-liners in JAX.\r\n* Step-by-step go from individual parameters to medium-size modules by registering them as pytree nodes.\r\n* Combat growing pains by building fancy scaffolding, and controlling context to extract initialized parameters purify functions and realize that we could get that easily in a framework like DeepMind's haiku using its transform mechanism.","links":[{"article_link":"https://sjmielke.com/jax-purify.htm","code_link":"https://colab.research.google.com/drive/1ZL1XHobaaEgTidTxFBLpMgIkQ796CHH9","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":59,"title":"Getting started with JAX (MLPs, CNNs & RNNs)","description":"Learn the building blocks of JAX and use them to build some standard Deep Learning architectures (MLP, CNN, RNN, etc.).","tags":["article","code","notebook","tutorial","jax","xla","autograd","tpu"],"details":"* I will walk you through some exciting CS concepts which were new to me (I am not a computer engineer, so this will be an educational experience for you and me). \r\n* Along the process, we will go through the individual building blocks of JAX and use them to build some standard Deep Learning architectures (Multilayer Perceptron, Convolutional Neural Nets and a Gated Recurrent Unit RNN) from scratch. \r\n* In the process we will encounter the basic operators of JAX (jit, vmap, grad), dive deeper into stax - the sequential layer API of JAX - and use lax.scan to quickly compile the for-loop of an RNN. ","links":[{"article_link":"https://roberttlange.github.io/posts/2020/03/blog-post-10/","code_link":"https://github.com/RobertTLange/code-and-blog/blob/master/04_jax_intro/jax_workspace.ipynb","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":58,"title":"Coronavirus Tracker API","description":"\ud83e\udda0 A simple and fast (< 200ms) API for tracking the global coronavirus (COVID-19, SARS-CoV-2) outbreak. It's written in python using the \ud83c\udf7c Flask framework. ","tags":["api","code","dataset","flask","library","covid-19"],"details":"All requests must be made to the base url: https://coronavirus-tracker-api.herokuapp.com (e.g: https://coronavirus-tracker-api.herokuapp.com/all). You can try them out in your browser to further inspect responses.","links":[{"article_link":"","code_link":"https://github.com/ExpDev07/coronavirus-tracker-api","research_link":"","media_link":"https://coronavirus-tracker-api.herokuapp.com/all","dataset_link":"","demo_link":"","other_link":""}]},{"id":57,"title":"2019-nCov Novel Coronavirus Data analysis in Python","description":"A demo on Google Colab, showing how to extract / aggregate / slice data, and basic time series / cross-sectional plotting.","tags":["article","code","covid-19"],"details":"* coronavirus_demo_colab.ipynb: A demo on Google Colab, showing how to extract / aggregate / slice data, and basic time series / cross-sectional plotting\r\n* demo.ipynb: Similar demo in a traditional Python Notebook, Chinese version\r\n* demo.en.ipynb: Similar demo in a traditional Python Notebook, English version\r\n* demo.html, demo.pdf: For those who doon't have Python Notebook, these two files serve as demo.ipynb for demonstration purpose (both are in Chinese)\r\n* death_rate.ipynb: An example analysis of the heterogeneity of death rate across different regions\r\n* utils.py: Utility functions","links":[{"article_link":"https://towardsdatascience.com/understanding-the-coronavirus-epidemic-data-44d2fb356ecb","code_link":"https://github.com/jianxu305/nCov2019_analysis","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":56,"title":"COVID-19 Comprehensive Medical Dataset & Visualizer","description":"COVID-19 Korea Dataset with patient routes and visualizer.","tags":["code","dataset","library","covid-19"],"details":"* Displays infected patient route and regional patient count\r\n* Visualizes changes in the number of patients and route with time\r\n* Displays non-COVID-19 data as heatmap","links":[{"article_link":"","code_link":"https://github.com/ThisIsIsaac/COVID-19_Korea_Dataset","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":55,"title":"Valproic Acid for COVID-2019","description":"Identified Valproic Acid as potential treatments for COVID-2019","tags":["code","r","medicine","covid-19","pyrx","pharmacogx"],"details":"Connectivity map or Cmap is resource that uses gene expression data to connect disease transcriptomic signature with those of different types of cells after drug treatment. If the transcriptomic signature of a drug on cell line is opposite from disease signature, it can be expected that this drug could have a positive effect on amelioration of disease.","links":[{"article_link":"","code_link":"https://github.com/tinkavidovic/competition","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://www.sage-health.org/coronavirus/"}]},{"id":54,"title":"Remdesivir as a Coronavirus Cure using Generative RNNs","description":"Identified Remdesivir as a potential COVID-2019 treatment, as well as a few other novel molecules that still need to be tested for synthetic feasibility.","tags":["code","tutorial","recurrent-neural-networks","covid-19","moses","chembl","pyrx"],"details":"* This is an original submission to the Coronavirus Deep Learning Competition hosted by Sage Health. The goal is to create a novel small molecule which can bind with the coronavirus, using deep learning techniques for molecule generation and PyRx to evaluate binding affinities.\r\n* Binding scores of leading existing drugs (HIV inhibitors) are around -10 to -11 (the more negative the score the better), and around -13 for the drug Remdesivir which recently entered clinical testing.\r\n* By combining a generative RNN model with techniques and principles from transfer learning and genetic algorithms, I was able to create several small molecule candidates which achieved binding scores approaching -18.","links":[{"article_link":"","code_link":"https://github.com/mattroconnor/deep_learning_coronavirus_cure","research_link":"","media_link":"https://vimeo.com/396023525","dataset_link":"","demo_link":"","other_link":"https://www.sage-health.org/coronavirus/"}]},{"id":53,"title":"Potential molecular solutions for COVID-19 using Graph VAEs","description":"Efforts towards proposing a potentially highly active molecule against a target protein of the 2019 Novel Coronavirus.","tags":["code","tutorial","video","autoencoders","variational-autoencoders","medicine","covid-19","graph-vae"],"details":"* A generative deep learning model was trained on a self-generated set of protease inhibitors, and 50 new compounds were sampled from the latent space of the model. The 10 most promising compounds were docked to the ligand. The highest scoring compound is shown above and has a score of -9.8kcal/mol\r\n* The best compounds from each method show significant gains over the baseline score of -7.9kcal/mol for the n3 ligand.","links":[{"article_link":"","code_link":"https://github.com/tmacdou4/2019-nCov","research_link":"","media_link":"https://www.youtube.com/watch?v=hNdh8EzalCU","dataset_link":"","demo_link":"","other_link":"https://www.youtube.com/watch?v=AbizsxxWcDk"}]},{"id":49,"title":"MixHop and NGCN","description":"A PyTorch implementation of \"MixHop: Higher-Order Graph Convolutional Architectures via Sparsified Neighborhood Mixing\" (ICML 2019) and \"A Higher-Order Graph Co","tags":["code","paper","research","tutorial","pytorch","deep-learning","embeddings","graph-classification","graph-clustering","graph-embedding","graphs","node-classification","representation-learning","node-embedding","network-embedding","graph-convolution","network-representation","arxiv:1905.00067"],"details":"- Multi-scale graph convolutions\r\n- Node classification","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/MixHop-and-N-GCN","research_link":"https://arxiv.org/abs/1905.00067","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":48,"title":"Ego-splitting Framework","description":"A NetworkX implementation of \"Ego-splitting Framework: from Non-Overlapping to Overlapping Clusters\" (KDD 2017)","tags":["code","paper","research","tutorial","deep-learning","embeddings","graph-classification","graph-clustering","graph-embedding","graphs","node-classification","representation-learning","node-embedding","network-embedding","graph-convolution","network-representation"],"details":"Overlapping clustering without latent space creation","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/EgoSplitting","research_link":"https://www.eecs.yorku.ca/course_archive/2017-18/F/6412/reading/kdd17p145.pdf","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":47,"title":"SEAL-CI","description":"A PyTorch implementation of  \"Semi-Supervised Graph Classification: A Hierarchical Graph Perspective\" (WWW 2019)","tags":["code","paper","research","tutorial","pytorch","deep-learning","embeddings","graph-classification","graph-clustering","graph-embedding","graphs","node-classification","representation-learning","node-embedding","network-embedding","graph-convolution","network-representation","arxiv:1904.05003"],"details":"- Graph classification with macro structure","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/SEAL-CI","research_link":"https://arxiv.org/abs/1904.05003","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":46,"title":"Graph Attention Mechansim","description":"A PyTorch implementation of \"Graph Classification Using Structural Attention\" (KDD 2018).","tags":["code","paper","research","tutorial","pytorch","attention","deep-learning","embeddings","graph-classification","graph-clustering","graph-embedding","graphs","node-classification","representation-learning","node-embedding","network-embedding","graph-convolution","network-representation"],"details":"- Attention based exploration graph for classification.","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/GAM","research_link":"http://ryanrossi.com/pubs/KDD18-graph-attention-model.pdf","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":45,"title":"SimGNN","description":"A PyTorch implementation of \"SimGNN: A Neural Network Approach to Fast Graph Similarity Computation\" (WSDM 2019). ","tags":["code","paper","research","tutorial","pytorch","deep-learning","embeddings","graph-classification","graph-clustering","graph-embedding","graph-neural-networks","graphs","node-classification","representation-learning","node-embedding","network-embedding","graph-convolution","network-representation"],"details":"- Graph similarity measurement with neural networks","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/SimGNN","research_link":"http://web.cs.ucla.edu/~yzsun/papers/2019_WSDM_SimGNN.pdf","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":44,"title":"Capsule Graph Neural Network","description":"A PyTorch implementation of \"Capsule Graph Neural Network\" (ICLR 2019).","tags":["code","paper","research","tutorial","pytorch","deep-learning","embeddings","graph-classification","graph-clustering","graph-embedding","graph-neural-networks","graphs","node-classification","representation-learning","node-embedding","network-embedding","graph-convolution","network-representation"],"details":"- Integrating Capsule Theory with Graph Convolutions","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/CapsGNN","research_link":"https://openreview.net/forum?id=Byl8BnRcYm","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":43,"title":"Enhanced Network Embedding with Text Information","description":"A sparsity aware implementation of \"Enhanced Network Embedding with Text Information\" (ICPR 2018). ","tags":["code","paper","research","tutorial","deep-learning","embeddings","graph-classification","graph-clustering","graph-embedding","graphs","node-classification","representation-learning","node-embedding","network-embedding","graph-convolution","network-representation"],"details":"- Attributed Node Embedding","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/TENE","research_link":"https://ieeexplore.ieee.org/abstract/document/8545577","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":42,"title":"Text Associated Deep Walk","description":"An implementation of \"Network Representation Learning with Rich Text Information\" (IJCAI '15).","tags":["code","paper","research","tutorial","deep-learning","embeddings","graph-classification","graph-clustering","graph-embedding","graphs","node-classification","representation-learning","node-embedding","network-embedding","graph-convolution","network-representation"],"details":"- Attributed Node Embedding","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/TADW","research_link":"https://www.ijcai.org/Proceedings/15/Papers/299.pdf","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":41,"title":"DANMF","description":"A sparsity aware implementation of \"Deep Autoencoder-like Nonnegative Matrix Factorization for Community Detection\" (CIKM 2018).","tags":["code","paper","research","tutorial","autoencoders","deep-learning","embeddings","graph-classification","graph-clustering","graph-embedding","graphs","node-classification","representation-learning","node-embedding","network-embedding","graph-convolution","network-representation"],"details":"- Clustered node embedding","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/DANMF","research_link":"https://smartyfh.com/Documents/18DANMF.pdf","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":40,"title":"Binarized Attributed Network Embedding","description":"A sparsity aware implementation of \"Binarized Attributed Network Embedding\" (ICDM 2018).","tags":["code","paper","research","tutorial","deep-learning","embeddings","graph-classification","graph-clustering","graph-embedding","graphs","node-classification","representation-learning","node-embedding","network-embedding","graph-convolution","network-representation"],"details":"- Sparse Feature Extraction\r\n- Node Embedding","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/BANE","research_link":"https://www.researchgate.net/publication/328688614_Binarized_Attributed_Network_Embedding","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":39,"title":"GraRep","description":"A SciPy implementation of \"GraRep: Learning Graph Representations with Global Structural Information\" (WWW 2015). ","tags":["code","paper","research","tutorial","deep-learning","embeddings","graph-classification","graph-clustering","graph-embedding","graphs","node-classification","representation-learning","node-embedding","network-embedding","graph-convolution","network-representation"],"details":"- Multi-scale Node Embedding","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/GraRep","research_link":"https://www.researchgate.net/publication/301417811_GraRep","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":38,"title":"Orbital Feature Engineering","description":"A sparsity aware implementation of \"Biological Network Comparison Using Graphlet Degree Distribution\" (Bioinformatics 2007)","tags":["code","paper","research","tutorial","deep-learning","embeddings","graph-classification","graph-clustering","graph-embedding","graphs","node-classification","representation-learning","node-embedding","network-embedding","graph-convolution","network-representation"],"details":"- Cyclic feature extraction","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/OrbitalFeatures","research_link":"https://www.ncbi.nlm.nih.gov/pubmed/17237089","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":37,"title":"Clustered Graph Convolutional Networks","description":"A PyTorch implementation of \"Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks\" (KDD 2019). ","tags":["code","paper","research","tutorial","pytorch","deep-learning","embeddings","graph-classification","graph-clustering","graph-embedding","graphs","node-classification","representation-learning","node-embedding","network-embedding","graph-convolution","network-representation","arxiv:1905.07953"],"details":"Graph convolutions on pre-clustered graphs","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/ClusterGCN","research_link":"https://arxiv.org/abs/1905.07953","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":36,"title":" FSCNMF","description":"An implementation of \"Fusing Structure and Content via Non-negative Matrix Factorization for Embedding Information Networks\". ","tags":["code","paper","research","tutorial","deep-learning","embeddings","graph-classification","graph-clustering","graph-embedding","graphs","node-classification","representation-learning","node-embedding","network-embedding","graph-convolution","network-representation","arxiv:1804.05313"],"details":"- Attributed Node Embedding with Sparsity","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/FSCNMF","research_link":"https://arxiv.org/abs/1804.05313","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":35,"title":"Boosted Factorization","description":"An implementation of \"Multi-Level Network Embedding with Boosted Low-Rank Matrix Approximation\" (ASONAM 2019). ","tags":["code","paper","research","tutorial","deep-learning","embeddings","graph-classification","graph-clustering","graph-embedding","graphs","node-classification","representation-learning","node-embedding","network-embedding","graph-convolution","network-representation","arxiv:1808.08627"],"details":"- Boosted Matrix Factorization\r\n- Boosted Network Embedding","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/BoostedFactorization","research_link":"https://arxiv.org/abs/1808.08627","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":34,"title":"Graph2Vec","description":"A parallel implementation of \"graph2vec: Learning Distributed Representations of Graphs\" (MLGWorkshop 2017). ","tags":["code","paper","research","tutorial","deep-learning","embeddings","graph-classification","graph-clustering","graph-embedding","graphs","node-classification","representation-learning","node-embedding","network-embedding","graph-convolution","network-representation","arxiv:1707.05005"],"details":"- Parallel massively scalable graph embedding","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/graph2vec","research_link":"https://arxiv.org/abs/1707.05005","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":33,"title":"M-NMF","description":"A TensorFlow implementation of \"Community Preserving Network Embedding\" (AAAI 2017) ","tags":["code","research","tutorial","tensorflow","deep-learning","embeddings","graph-classification","graph-clustering","graph-embedding","graphs","node-classification","representation-learning","node-embedding","network-embedding","graph-convolution","network-representation"],"details":"- Clustered node embedding creation","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/M-NMF","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":32,"title":"Walklets","description":"A lightweight implementation of Walklets from \"Don't Walk Skip! Online Learning of Multi-scale Network Embeddings\" (ASONAM 2017). ","tags":["code","paper","research","tutorial","deep-learning","embeddings","graph-classification","graph-clustering","graph-embedding","graphs","node-classification","representation-learning","node-embedding","network-embedding","graph-convolution","network-representation","arxiv:1605.02115"],"details":"- Scalable Node Embedding","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/walklets","research_link":"https://arxiv.org/abs/1605.02115","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":31,"title":"GraphWave","description":"A scalable implementation of \"Learning Structural Node Embeddings Via Diffusion Wavelets (KDD 2018)\". ","tags":["code","paper","research","tutorial","deep-learning","embeddings","graph-classification","graph-clustering","graph-embedding","graphs","node-classification","representation-learning","node-embedding","structural-embedding","graph-convolution","network-representation","arxiv:1710.10321"],"details":"- Featureless structural node embedding","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/GraphWaveMachine","research_link":"https://arxiv.org/abs/1710.10321","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":30,"title":"Label Propagation","description":"A NetworkX implementation of Label Propagation from a \"Near Linear Time Algorithm to Detect Community Structures in Large-Scale Networks\" (Physical Review E 200","tags":["code","paper","research","tutorial","graph-classification","graph-clustering","graphs","node-classification","community-detection","node-embedding","network-embedding","arxiv:0709.2938"],"details":"- Fast graph clustering\r\n- Stochastic clustering","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/LabelPropagation","research_link":"https://arxiv.org/abs/0709.2938","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":29,"title":"Signed Graph Convolutional Network","description":"A PyTorch implementation of \"Signed Graph Convolutional Network\" (ICDM 2018). ","tags":["code","paper","research","tutorial","pytorch","deep-learning","graph-convolutional-networks","embeddings","graph-embedding","graph-neural-networks","graphs","node-classification","representation-learning","network-embedding","network-visualization","signed-graphs","link-prediction","arxiv:1808.06354"],"details":"- Generalized graph convolution to signed graphs","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/SGCN","research_link":"https://arxiv.org/abs/1808.06354","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":28,"title":"Attributed Social Network Embedding","description":"A sparsity aware and memory efficient implementation of \"Attributed Social Network Embedding\" (TKDE 2018). ","tags":["code","paper","research","tutorial","deep-learning","graph-convolutional-networks","embeddings","feature-engineering","graph-clustering","graph-embedding","graph-neural-networks","graphs","representation-learning","attributed-embedding","arxiv:1705.04969"],"details":"- Scalable attributed node embedding\r\n- Feature learning","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/ASNE","research_link":"https://arxiv.org/abs/1705.04969","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":27,"title":"APPNP and PPNP","description":"A PyTorch implementation of \"Predict then Propagate: Graph Neural Networks meet Personalized PageRank\" (ICLR 2019). ","tags":["code","paper","research","tutorial","pytorch","deep-learning","graph-convolutional-networks","embeddings","graph-classification","graph-embedding","graph-neural-networks","graphs","node-classification","representation-learning","node-embedding","network-embedding","pagerank","arxiv:1810.05997"],"details":"- Node classification\r\n- Better graph convolutions\r\n","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/APPNP","research_link":"https://arxiv.org/abs/1810.05997","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":26,"title":"Graph Wavelet Neural Network","description":"A PyTorch implementation of \"Graph Wavelet Neural Network\" (ICLR 2019) ","tags":["code","paper","research","tutorial","pytorch","deep-learning","graph-convolutional-networks","graph-classification","graph-neural-networks","graphs","node-classification","representation-learning","wavelet","spectral-graph-theory"],"details":"- Node classification\r\n- Graph convolution\r\n- Wavelet sparsification","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/GraphWaveletNeuralNetwork","research_link":"https://openreview.net/forum?id=H1ewdiR5tQ","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":25,"title":"AttentionWalk","description":"A PyTorch Implementation of \"Watch Your Step: Learning Node Embeddings via Graph Attention\" (NeurIPS 2018). ","tags":["code","paper","research","tutorial","pytorch","attention","convolutional-neural-networks","deep-learning","graph-convolutional-networks","embeddings","graph-classification","graph-neural-networks","graphs","node-classification","representation-learning"],"details":"- Pooled Factorization\r\n- Meta-Learning\r\n- Node Embedding","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/AttentionWalk","research_link":"http://papers.nips.cc/paper/8131-watch-your-step-learning-node-embeddings-via-graph-attention","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":24,"title":"Splitter","description":"A Pytorch implementation of \"Splitter: Learning Node Representations that Capture Multiple Social Contexts\" (WWW 2019). ","tags":["code","paper","research","tutorial","pytorch","deep-learning","clustering","feature-engineering","graph-clustering","graphs","node-classification","community-detection","node-embedding","network-embedding","network-visualization","arxiv:1905.02138"],"details":"- Node Embedding\r\n- Link Prediction","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/Splitter","research_link":"https://arxiv.org/abs/1905.02138","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":23,"title":"Scalable Incomplete Network Embedding","description":"A PyTorch implementation of \"Scalable Incomplete Network Embedding\" (ICDM 2018).","tags":["code","paper","research","tutorial","pytorch","deep-learning","embeddings","feature-engineering","graphs","node-classification","representation-learning","node-embedding","network-embedding","arxiv:1810.06768"],"details":"- Attributed Node Embedding\r\n- Robust Node Embedding\r\n","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/SINE","research_link":"https://arxiv.org/abs/1810.06768","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":22,"title":"An Edge Enhancement Approach for Motif-aware Community Detection","description":"An implementation of \"EdMot: An Edge Enhancement Approach for Motif-aware Community Detection\" (KDD 2019) ","tags":["code","paper","research","tutorial","graph-clustering","graphs","node-classification","community-detection","node-embedding","network-visualization","arxiv:1906.04560"],"details":"- Higher order community detection\r\n- Graph clustering","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/EdMot","research_link":"https://arxiv.org/abs/1906.04560","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":21,"title":"Learning Role-based Graph Embeddings","description":"A scalable Gensim implementation of \"Learning Role-based Graph Embeddings\" (IJCAI 2018).","tags":["code","paper","research","tutorial","embeddings","graph-embedding","graphs","node-classification","node-embedding","network-embedding","structural-embedding","gensim","arxiv:1802.02896"],"details":"- Automated feature engineering\r\n- Structural node embedding\r\n- Node classification","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/role2vec","research_link":"https://arxiv.org/abs/1802.02896","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":20,"title":"ADMM for Non-Negative Matrix Factorization","description":"A sparsity aware implementation of \"Alternating Direction Method of Multipliers for Non-Negative Matrix Factorization with the Beta-Divergence\" (ICASSP 2014).","tags":["code","paper","research","tutorial","dimensionality-reduction","principal-components","non-negative-matrix-factorization","sparse-nmf","tsne","admm"],"details":"- Non-negative matrix factorization\r\n- Dimensionality reduction\r\n- Recommender systems","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/NMFADMM","research_link":"http://statweb.stanford.edu/~dlsun/papers/nmf_admm.pdf","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":19,"title":"Diffusion to Vector","description":"Reference implementation of Diffusion2Vec (Complenet 2018) built on Gensim and NetworkX. ","tags":["code","paper","research","tutorial","deep-learning","embeddings","graph-embedding","graph-neural-networks","graphs","node-classification","node-embedding","network-embedding","network-visualization","arxiv:2001.07463"],"details":"- Node classification\r\n- Node embedding\r\n- Network embedding\r\n- Network visualization","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/diff2vec","research_link":"https://arxiv.org/abs/2001.07463","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":18,"title":"Multi-scale Attributed Node Embedding","description":"The reference implementation of \"Multi-scale Attributed Node Embedding\".","tags":["code","paper","research","tutorial","deep-learning","embeddings","graphs","node-classification","transfer-learning","node-embedding","network-embedding","attributed-embedding","skip-gram","matrix-factorization","implicit-factorization","arxiv:1909.13021"],"details":"- Node classification\r\n- Attributed node embedding\r\n- Network embedding\r\n- Transfer learning","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/MUSAE/","research_link":"https://arxiv.org/abs/1909.13021","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":17,"title":"GEMSEC: Graph Embedding with Self-Clustering","description":"GEMSEC - a graph embedding algorithm that learns a clustering of the nodes simultaneously with computing their embedding. ","tags":["code","paper","research","tutorial","tensorflow","deep-learning","embeddings","graph-clustering","graphs","node-classification","community-detection","node-embedding","network-embedding","arxiv:1802.03997"],"details":"- Node Embedding\r\n- Clustering and Embedding Jointly\r\n- New Node Classification Datasets","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/GEMSEC","research_link":"https://arxiv.org/abs/1802.03997","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":16,"title":"Karate Club","description":"A general purpose community detection and network embedding library for research built on NetworkX. ","tags":["code","library","embeddings","graph-classification","graph-clustering","graph-embedding","graphs","node-classification","community-detection","node-embedding","network-embedding"],"details":"- Node embedding techniques\r\n- Graph embedding techniques\r\n- Community detection techniques","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/karateclub","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://karateclub.readthedocs.io/en/latest/"}]},{"id":15,"title":"Awesome Monte Carlo Tree Search","description":"A curated list of Monte Carlo tree search papers with implementations. ","tags":["code","tutorial","bayesian-deep-learning","deep-learning","deep-q-networks","hierarchical-reinforcement-learning","multi-agent-reinforcement-learning","reinforcement-learning","monte-carlo-tree-search"],"details":"- Papers from top conferences.\r\n- Implementations.","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/awesome-monte-carlo-tree-search-papers","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":14,"title":"Awesome Fraud Detection","description":"A curated list of data mining papers about fraud detection.","tags":["code","tutorial","deep-learning","anomaly-detection","classification","fraud-detection","community-detection"],"details":"- Papers from top conferences.\r\n- Implementations.","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/awesome-fraud-detection-papers","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":13,"title":"Awesome Decision Trees","description":"A collection of research papers on decision, classification and regression trees with implementations. ","tags":["code","tutorial","decision-trees","classification","gradient-boosting","classification-trees","regression-trees"],"details":"- Papers from top conferences\r\n- Implementations","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/awesome-decision-tree-papers","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":12,"title":"Awesome Gradient Boosting","description":"A curated list of gradient boosting research papers with implementations. ","tags":["code","tutorial","decision-trees","data-mining","boosting","gradient-boosting","nips","neurips"],"details":"- Papers from top conferences\r\n- Implementations included","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/awesome-gradient-boosting-papers","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":11,"title":"Awesome Community Detection","description":"A collection of important community detection and graph clustering papers with implementations.","tags":["code","tutorial","deep-learning","clustering","data-mining","dimensionality-reduction","graph-clustering","graphs"],"details":"- Factorization\r\n- Deep Learning\r\n- Label Propagation, Percolation and Random Walks\r\n- Tensor Decomposition\r\n- Spectral Methods\r\n- Temporal Methods\r\n- Cyclic Pattern Clustering\r\n- Centrality and Cut Based Procedures\r\n- Physics Inspired Techniques","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/awesome-community-detection","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":10,"title":"Machine Learning Tutorials","description":"Creating organized  tutorials for some of the machine learning concepts.","tags":["article","code","tutorial","convolutional-neural-networks","linear-regression","logistic-regression","neural-networks","regression","parameter-estimation","maximum-likelihood-estimation"],"details":"This project aims to create intuitive tutorials for some of machine learning concepts.","links":[{"article_link":"https://sci2lab.github.io/ml_tutorial/","code_link":"https://github.com/sci2lab/ml_tutorial","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":9,"title":"Awesome Graph Classification","description":"A collection of important graph embedding, classification and representation learning papers with implementations.","tags":["code","tutorial","deep-learning","graph-convolutional-networks","embeddings","graph-classification","graph-neural-networks","graphs","knowledge-graphs","representation-learning"],"details":"* Graph kernel papers\r\n* Statistical fingerprints\r\n* Deep learning\r\n* Embeddings","links":[{"article_link":"","code_link":"https://github.com/benedekrozemberczki/awesome-graph-classification","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":8,"title":"ML Experiments using Walmart Recruiting Store Sales Forecasting","description":"It's so cool that we can sit at home and get real-world datasets to solve close to real-world problems. ","tags":["code","tutorial","machine-learning","sales","pandas","structured-data","data-analysis","python-stack","forcasting","sales-forcasting"],"details":"* Apply ML and reinforce my skills\r\n* Data analysis \r\n* Getting hands on with Pandas, sci-kit-learn and as a whole, python stack  ","links":[{"article_link":"","code_link":"https://github.com/ankit1khare/Walmart_Store_Kaggle","research_link":"","media_link":"walmart-recruiting-store-sales-forecasting/overview","dataset_link":"","demo_link":"","other_link":""}]},{"id":7,"title":"Show, Infer & Tell: Contextual Inference for Creative Captioning","description":"The beauty of the work lies in the way it architects the fundamental idea that humans look at the overall image and then individual pieces of it.\r\n","tags":["article","code","paper","research","tutorial","attention","deep-learning","recurrent-neural-networks","computer-vision","image-captioning"],"details":"* Advance the field of image captioning.\r\n* Help make internet more accessible for visually challenged.\r\n* Best Student Paper Award Honorable Mention in BMVC 2019.\r\n* Selected for Oral presentation (4.6% acceptance rate).\r\n","links":[{"article_link":"https://aekhz.com/research/","code_link":"https://github.com/ankit1khare/Show_Infer_and_Tell-CIC","research_link":"https://bmvc2019.org/wp-content/uploads/papers/0655-paper.pdf","media_link":"https://youtu.be/WHadUSUhL-o?t=3646","dataset_link":"","demo_link":"","other_link":"https://bmvc2019.org/wp-content/uploads/papers/0655-supplementary.pdf"}]},{"id":6,"title":"Comparison between YOLO and RCNN on real world videos","description":"Bringing theory to experiment is cool. We can easily train models in colab and find the results in minutes.","tags":["code","tutorial","computer-vision","yolo","rcnn"],"details":"* Analyse trade-offs between Yolo and RCNN\r\n","links":[{"article_link":"","code_link":"https://github.com/ankit1khare/Smart-Park-with-YOLO-V3","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":5,"title":"Deep Learning based parking management system using Fastai","description":"Fastai provides easy to use wrappers to quickly build powerful systems. One could transfer learn a CNN in minutes and tie it to existing system. ","tags":["code","tutorial","fastai","deep-learning","parking-management"],"details":"* Quantitatively analyse the trade-off between HAAR based vehicle classifier and RestNet-101 transfer learned for detecting vehicles. \r\n* Explore cool features of Fastai library.\r\n* Improve accuracy of existing system.","links":[{"article_link":"","code_link":"https://github.com/ankit1khare/Deep-Neural-Network-based-parking-system","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":4,"title":"Easy street parking using region proposal networks","description":"Get a text on your phone whenever a nearby parking spot you need is free. ","tags":["code","tutorial","python","pytorch","machine-learning","computer-vision","opencv","twilio"],"details":"A prototype application that can be transformed into a full-fledged real-time parking management app to help people find parking spots near malls, shopping areas, cinema house etc. A text message is sent to let you know whenever there's a vacancy in the nearby street parking or community parking. Park_clever notebook contains the latest code.","links":[{"article_link":"","code_link":"https://github.com/ankit1khare/Easy_street_parking_with_MASK-RCNN","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://aekhz.com"}]},{"id":3,"title":"Automatic Parking Management using computer vision","description":"Detecting empty and parked spaces in car parking using a camera at lamp-post angle. ","tags":["code","tutorial","video","python","machine-learning","computer-vision","parking-management","haar"],"details":"* Utilize things I learned in my computer vision class and do something cool with it.\r\n* The class was 6000 level PhD grade course so I had to make something really worth my professor's expectation.\r\n* Lay out a baseline system (brute force solution) for managing parking and then think about ways to improve its  performance and increase its capabilities.","links":[{"article_link":"","code_link":"https://github.com/ankit1khare/Automatic-Parking-Management","research_link":"","media_link":"https://www.youtube.com/watch?v=y1M5dNkvCJc","dataset_link":"","demo_link":"","other_link":"https://aekhz.com"}]},{"id":2,"title":"Deep Learning with Electronic Health Record (EHR) Systems","description":"A comprehensive look at recent machine learning advancements in health.","tags":["article","tutorial","deep-learning","health","ehr"],"details":"* Explore novel deep learning techniques applied to health focus on interpretability.\r\n* Bring awareness to the dangers of blindly applying state-of-the-art (SOTA) deep-learning methods on sensitive and unwieldy health data.\r\n* Working with many physicians and clinical researchers (Columbia, NYU and Johns Hopkins) who are developing ML models of their own to draw insights out of their own EHR systems. Mostly focused on niche named entity recognition to extract patient data from large amounts of pdf documents.","links":[{"article_link":"https://goku.me/blog/deep-learning-with-ehr-systems","code_link":"","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":""}]},{"id":1,"title":"Machine Learning Basics","description":"A practical set of notebooks on machine learning basics, implemented in both TF2.0 + Keras and PyTorch.","tags":["code","tutorial","keras","pytorch","tensorflow","deep-learning","natural-language-processing","madewithml","basics","foundation"],"details":"#### Basics\r\n<table class=\"table table-striped table-bordered table-vcenter\">\r\n    <tbody class=ai-notebooks-table-content>\r\n    <tr>\r\n        <td colspan=\"1\" rowspan=\"5\" class=\"ai-notebooks-table-points ai-orange-link\">\r\n        <br>\r\n        <div align=\"center\">\r\n            <a class=\"ai-header-badge\" target=\"_blank\" href=\"https://github.com/madewithml/basics\">\r\n            <img class=\"ai-header-badge-img\" src=\"https://img.shields.io/github/stars/madewithml/basics.svg?style=social&label=Star\">\r\n            </a>&nbsp;\r\n            <a class=\"ai-header-badge\" target=\"_blank\" href=\"https://www.linkedin.com/company/madewithml\">\r\n            <img src=\"https://img.shields.io/badge/style--5eba00.svg?label=LinkedIn&logo=linkedin&style=social\">\r\n            </a>&nbsp;\r\n            <a class=\"ai-header-badge\" target=\"_blank\" href=\"https://twitter.com/madewithml\">\r\n            <img class=\"ai-header-badge-img\" src=\"https://img.shields.io/twitter/follow/madewithml.svg?label=Follow&style=social\">\r\n            </a>\r\n\t\t\t\t\t\t<p>\ud83d\udd25 Among the <a href=\"https://github.com/topics/deep-learning\" target=\"_blank\">top 10</a> ML repos on GitHub</p>\r\n        </div>\r\n        <ul>\r\n            <li>Learn Python basics with notebooks.</li>\r\n            <li>Use data science libraries like <a href=\"https://www.numpy.org/\" target=\"_blank\">NumPy</a> and <a href=\"https://pandas.pydata.org/\" target=\"_blank\">Pandas</a>.</li>\r\n            <li>Implement basic ML models in <a href=\"https://www.tensorflow.org/\" target=\"_blank\">TensorFlow 2.0 + Keras</a> or <a href=\"https://www.pytorch.org/\" target=\"_blank\">PyTorch</a>.</li>\r\n            <li>Learn best practices with clean code, simple math and visualizations.</li>\r\n        </ul>\r\n        </td>\r\n        </td>\r\n        <td><a  target=\"_blank\" href=\"https://colab.research.google.com/github/madewithml/basics/blob/master/notebooks/01_Notebooks.ipynb\">\ud83d\udcd3 Notebooks</a></td>\r\n        <td><a  target=\"_blank\" href=\"https://colab.research.google.com/github/madewithml/basics/blob/master/notebooks/02_Python.ipynb\">\ud83d\udc0d Python</a></td>\r\n        <td><a  target=\"_blank\" href=\"https://colab.research.google.com/github/madewithml/basics/blob/master/notebooks/03_NumPy.ipynb\">\ud83d\udd22 NumPy</a></td>\r\n    </tr>\r\n    <tr>\r\n        <td><a  target=\"_blank\" href=\"https://colab.research.google.com/github/madewithml/basics/blob/master/notebooks/04_Pandas.ipynb\">\ud83d\udc3c Pandas</a></td>\r\n        <td><a  target=\"_blank\" href=\"https://colab.research.google.com/github/madewithml/basics/blob/master/notebooks/05_TensorFlow.ipynb\"><img src=\"https://raw.githubusercontent.com/madewithml/images/master/images/tensorflow.png\" width=\"20rem\"> TensorFlow</a></td>\r\n        <td><a  target=\"_blank\" href=\"https://colab.research.google.com/github/madewithml/basics/blob/master/notebooks/06_PyTorch.ipynb\"><img src=\"https://raw.githubusercontent.com/madewithml/images/master/images/pytorch.png\" width=\"20rem\"> PyTorch</a></td>\r\n    </tr>\r\n    <tr>\r\n        <td><a target=\"_blank\" href=\"https://github.com/madewithml/basics/tree/master/notebooks/07_Linear_Regression\">\ud83d\udcc8 Linear Regression</a>\r\n            <div><a target=\"_blank\" href=\"https://colab.research.google.com/github/madewithml/basics/blob/master/notebooks/07_Linear_Regression/07_TF_Linear_Regression.ipynb\"><img src=\"https://raw.githubusercontent.com/madewithml/images/master/images/tensorflow.png\" width=\"20rem\"></a> | <a target=\"_blank\" href=\"https://colab.research.google.com/github/madewithml/basics/blob/master/notebooks/07_Linear_Regression/07_PT_Linear_Regression.ipynb\"><img src=\"https://raw.githubusercontent.com/madewithml/images/master/images/pytorch.png\" width=\"20rem\"></a></div>\r\n        </td>\r\n        <td>\r\n            <a target=\"_blank\" href=\"https://github.com/madewithml/basics/blob/master/notebooks/08_Logistic_Regression\">\ud83d\udcca Logistic Regression</a>\r\n            <div><a target=\"_blank\" href=\"https://colab.research.google.com/github/madewithml/basics/blob/master/notebooks/08_Logistic_Regression/08_TF_Logistic_Regression.ipynb\"><img src=\"https://raw.githubusercontent.com/madewithml/images/master/images/tensorflow.png\" width=\"20rem\"></a> | <a target=\"_blank\" href=\"https://colab.research.google.com/github/madewithml/basics/blob/master/notebooks/08_Logistic_Regression/08_PT_Logistic_Regression.ipynb\"><img src=\"https://raw.githubusercontent.com/madewithml/images/master/images/pytorch.png\" width=\"20rem\"></a></div>\r\n        </td>\r\n        <td>\r\n            <a target=\"_blank\" href=\"https://github.com/madewithml/basics/blob/master/notebooks/09_Multilayer_Perceptrons\">\ufe0f\ud83c\udf9b Multilayer Perceptrons</a>\r\n            <div><a target=\"_blank\" href=\"https://colab.research.google.com/github/madewithml/basics/blob/master/notebooks/09_Multilayer_Perceptrons/09_TF_Multilayer_Perceptrons.ipynb\"><img src=\"https://raw.githubusercontent.com/madewithml/images/master/images/tensorflow.png\" width=\"20rem\"></a> | <a target=\"_blank\" href=\"https://colab.research.google.com/github/madewithml/basics/blob/master/notebooks/09_Multilayer_Perceptrons/09_PT_Multilayer_Perceptrons.ipynb\"><img src=\"https://raw.githubusercontent.com/madewithml/images/master/images/pytorch.png\" width=\"20rem\"></a></div>\r\n        </td>\r\n    </tr>\r\n    <tr>\r\n    <td>\r\n        <a target=\"_blank\" href=\"https://github.com/madewithml/basics/blob/master/notebooks/10_Data_and_Models\">\ud83d\udd0e Data & Models</a>\r\n        <div><a target=\"_blank\" href=\"https://colab.research.google.com/github/madewithml/basics/blob/master/notebooks/10_Data_and_Models/10_TF_Data_and_Models.ipynb\"><img src=\"https://raw.githubusercontent.com/madewithml/images/master/images/tensorflow.png\" width=\"20rem\"></a> | <a target=\"_blank\" href=\"https://colab.research.google.com/github/madewithml/basics/blob/master/notebooks/10_Data_and_Models/10_PT_Data_and_Models.ipynb\"><img src=\"https://raw.githubusercontent.com/madewithml/images/master/images/pytorch.png\" width=\"20rem\"></a></div>\r\n    </td>\r\n    <td>\r\n        <a target=\"_blank\" href=\"https://github.com/madewithml/basics/blob/master/notebooks/11_Utilities\">\ud83d\udee0 Utilities</a>\r\n        <div><a target=\"_blank\" href=\"https://colab.research.google.com/github/madewithml/basics/blob/master/notebooks/11_Utilities/11_TF_Utilities.ipynb\"><img src=\"https://raw.githubusercontent.com/madewithml/images/master/images/tensorflow.png\" width=\"20rem\"></a> | <a target=\"_blank\" href=\"https://colab.research.google.com/github/madewithml/basics/blob/master/notebooks/11_Utilities/11_PT_Utilities.ipynb\"><img src=\"https://raw.githubusercontent.com/madewithml/images/master/images/pytorch.png\" width=\"20rem\"></a></div>\r\n    </td>\r\n    <td>\r\n        <a target=\"_blank\" href=\"https://github.com/madewithml/basics/blob/master/notebooks/12_Preprocessing\">\ufe0f\u2702\ufe0f Preprocessing</a>\r\n        <div><a target=\"_blank\" href=\"https://colab.research.google.com/github/madewithml/basics/blob/master/notebooks/12_Preprocessing/12_TF_Preprocessing.ipynb\"><img src=\"https://raw.githubusercontent.com/madewithml/images/master/images/tensorflow.png\" width=\"20rem\"></a> | <a target=\"_blank\" href=\"https://colab.research.google.com/github/madewithml/basics/blob/master/notebooks/12_Preprocessing/12_PT_Preprocessing.ipynb\"><img src=\"https://raw.githubusercontent.com/madewithml/images/master/images/pytorch.png\" width=\"20rem\"></a></div>\r\n    </td>\r\n    </tr>\r\n    <tr>\r\n        <td>\r\n            <a target=\"_blank\" href=\"https://github.com/madewithml/basics/blob/master/notebooks/13_Convolutional_Neural_Networks\">\ufe0f\ud83d\uddbc Convolutional Neural Networks</a>\r\n            <div><a target=\"_blank\" href=\"https://colab.research.google.com/github/madewithml/basics/blob/master/notebooks/13_Convolutional_Neural_Networks/13_TF_Convolutional_Neural_Networks.ipynb\"><img src=\"https://raw.githubusercontent.com/madewithml/images/master/images/tensorflow.png\" width=\"20rem\"></a> | <a target=\"_blank\" href=\"https://colab.research.google.com/github/GokuMohandas/madewithml/blob/main/notebooks/11_Convolutional_Neural_Networks.ipynb\"><img src=\"https://raw.githubusercontent.com/madewithml/images/master/images/pytorch.png\" width=\"20rem\"></a></div>\r\n        </td>\r\n        <td>\r\n            <a target=\"_blank\" href=\"https://github.com/madewithml/basics/blob/master/notebooks/14_Embeddings\">\ud83d\udc51 Embeddings</a>\r\n            <div><a target=\"_blank\" href=\"https://colab.research.google.com/github/madewithml/basics/blob/master/notebooks/14_Embeddings/14_TF_Embeddings.ipynb\"><img src=\"https://raw.githubusercontent.com/madewithml/images/master/images/tensorflow.png\" width=\"20rem\"></a> | <a target=\"_blank\" href=\"https://colab.research.google.com/github/GokuMohandas/madewithml/blob/main/notebooks/12_Embeddings.ipynb\"><img src=\"https://raw.githubusercontent.com/madewithml/images/master/images/pytorch.png\" width=\"20rem\"></a></div>\r\n        </td>\r\n        <td>\r\n            <a target=\"_blank\" href=\"https://github.com/madewithml/basics/tree/master/notebooks/15_Recurrent_Neural_Networks\">\ud83d\udcd7 Recurrent Neural Networks</a>\r\n            <div><a target=\"_blank\" href=\"https://colab.research.google.com/github/madewithml/basics/blob/master/notebooks/15_Recurrent_Neural_Networks/15_TF_Recurrent_Neural_Networks.ipynb\"><img src=\"https://raw.githubusercontent.com/madewithml/images/master/images/tensorflow.png\" width=\"20rem\"></a> | <a target=\"_blank\" href=\"https://colab.research.google.com/github/madewithml/basics/blob/master/notebooks/15_Recurrent_Neural_Networks/15_PT_Recurrent_Neural_Networks.ipynb\"><img src=\"https://raw.githubusercontent.com/madewithml/images/master/images/pytorch.png\" width=\"20rem\"></a></div>\r\n        </td>\r\n    </tr>\r\n    </tbody>\r\n</table>\r\n\r\n#### Notebooks\r\n<ul>\r\n    <li>\r\n        \ud83d\udcda Illustrative ML notebooks available in both <a target=\"_blank\" href=\"https://tensorflow.org\">TensorFlow 2.0 + Keras</a> and <a  target=\"_blank\" href=\"https://www.pytorch.org/\" target=\"_blank\">PyTorch</a>.\r\n        <ul>\r\n            <li><b>Should I pick TensorFlow or PyTorch?</b> Choice of framework doesn\u2019t matter! We see a lot of great projects that use either TensorFlow + Keras or PyTorch and there\u2019s tremendous value is knowing how to at least read both. If you have to work with a specific framework because of work/team constraints, you absolutely need to be literate in both so you can reimplement what you need. Don\u2019t dismiss a project because it's not in your framework, especially now when they all share so many similarities. Check out the basic lessons and choose what you find more intuitive/suitable but the most important thing is to work on projects and share them with the community.</li>\r\n            <li><b>Do I need to know both TensorFlow or PyTorch?</b> It is <b>very important</b> to at least know how to read both\r\n            frameworks because cutting edge research continues to use both frameworks. Luckily, they're both very easy to learn and very easy to rewrite in the other framework.</li>\r\n        </ul>\r\n    </li>\r\n    <li>\ud83d\udcbb These are <b>not</b> just a set of tutorials where we just load a bunch of packages and apply it on preloaded datasets. We explain every concept in the notebooks with clean code, simple math and visualizations to make them as intuitive as possible.\r\n    </li>\r\n    <li>\r\n        \ud83d\udcd3 If you prefer Jupyter Notebooks or want to add/fix content, check out the <a href=\"https://github.com/madewithml/basics/tree/master/notebooks\" target=\"_blank\">notebooks</a> directory.\r\n    </li>\r\n</ul>\r\n\r\n#### Next Steps\r\nAs you learn ML, it's important to work on projects, so check out <a href=\"https://madewithml.com\">Made With ML</a> for inspiration and to create a profile to showcase your own projects! **Showcase your projects** because everyone has Coursera, Kaggle, and fastai on their resumes so you need to differentiate yourself by showing what you can do using those fantastic resources.\r\n\r\n[Sign up for your free account \u2192](https://madewithml.com)","links":[{"article_link":"","code_link":"https://github.com/madewithml/basics","research_link":"","media_link":"","dataset_link":"","demo_link":"","other_link":"https://github.com/madewithml/basics"}]}]
